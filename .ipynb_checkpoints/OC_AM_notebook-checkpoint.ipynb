{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCitations Notebook\n",
    "### Arianna Moretti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "#### 2022\n",
    "\n",
    "1. [22/02 - 02/03 (Log Data Study)](#entry_1)\n",
    "2. [02/03 - 09/03 (OC Index Software Code Refactoring - NOCI + Mapping Merge)](#entry_2)\n",
    "3. [09/03 - 15/03 (_____________)](#entry_3)\n",
    "4. [15/03 - 22/03 (Prometheus file format study and data extraction)](#entry_4)\n",
    "5. [22/03 - 29/03 (Prometheus file format visualization - Python)](#entry_5)\n",
    "6. [29/03 - 08/04 (Prometheus file format visualization - JS)](#entry_6)\n",
    "7. [08/04 -12/04 (Prometheus data extraction JS)](#entry_7)\n",
    "8. [12/04 - 20/04 (Prometheus file format extraction, Visualization Refinement )](#entry_8)\n",
    "9. [20/04 - 26/04 (Visualization - Code Finalization + DOCI - Preliminary work)](#entry_9)\n",
    "10. [26/04 - 06/05 (Visualization Final Fix - DOCI + NOCI (citation source parser e glob))](#entry_10)\n",
    "11. [06/05 - 13/05 (Visualization: Final Version + DOCI and NOCI parser and glob for farm_revision)](#entry_11)\n",
    "12. [13/05 - 17/05 (NOCI parser and glob for farm_revision bug fix)](#entry_12)\n",
    "13. [17/05 - 26/05 (Doci, Noci, PMID, Visualizzazioni)](#entry_13)\n",
    "14. [26/05 - 07/06 (NIH preprocessing, NIH parser update, id_type in farm_revision, studio preliminare META, glob)](#entry_14)\n",
    "15. [07/06 - 21/06 (iCiteMetadata preprocessing, NIH finder, NIH glob, test glob, tabelle csv per META NOCI + DOCI, DOCI + NOCI validate](#entry_15)\n",
    "16. [21/06 - 28/06 (International Data Week 2022, glob update)](#entry_16)\n",
    "17. [28/06 - 19/07 (glob update, log data analysis)](#entry_17)\n",
    "18. [19/07 - 26/07 (Log Data Analysis, Glob con CSV_Datasource, Test Validate, Meta)](#entry_18)\n",
    "19. [26/07 - 30/08 (Index final commit (CSVDatasource, ORCIDResourceFinderPMID, CSVDataSource GLOB, Validate NOCI and DOCI + tests), Log data visualizations)](#entry_19)\n",
    "20. [30/08 - 06/09 (User Agent and Referer code refinement + first part of Javascript visualization)](#entry_20)\n",
    "21. [06/09 - 13/09 (NOCI glob update, User agent code fix, ID Manager repo, Tables for meta )](#entry_21)\n",
    "22. [13/09 - 20/09 (ID Manager update - User Agent and Referer Results - Meta Tables)](#entry_22)\n",
    "23. [20/09 - 28/09 (OC_IDManager updates, OC_Meta Tables Update: preprocessing NIH + DC, processing DC, documentation study DC)](#entry_23)\n",
    "24. [28/09 - 06/10 (OC_Meta Tables Update: ------)](#entry_24)\n",
    "\n",
    "\n",
    "\n",
    "#### 2023\n",
    "\n",
    "5. [??/?? - ??/?? (????)](#entry_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 22/02 - 02/03 (Log Data Study) <a class=\"anchor\" id=\"entry_1\"></a>\n",
    "\n",
    "### Studio Files di Log Raw\n",
    "\n",
    "<ul>\n",
    "    <li>Download cartella Dropbox con file di log raw per 2021</li>\n",
    "    <li>Studio dei dati statistici: <a href=\"https://github.com/opencitations/statistics/tree/master/script\">opencitations statistics repo </a> </li>\n",
    "    <li>Studio del file format Prometheus: <a href=\"https://sysdig.com/blog/prometheus-metrics/\"> https://sysdig.com/blog/prometheus-metrics/</a>, <a href=\"https://prometheus.io/docs/instrumenting/clientlibs/\"> https://prometheus.io/docs/instrumenting/clientlibs/</a>\n",
    "    <li>Esempio di <a href=\"http://opencitations.net/statistics/2022-01\">call API per i dati di Log di Gennaio 2021</a> </li>\n",
    "</ul>\n",
    "\n",
    "#### Prometheus File Format\n",
    "Prometheus is an open source time series database including a collection of client libraries which allow metrics to be published, so to be collected by the metrics server. The Prometheus metrics format is largely adopted and became also an independent project: OpenMetrics, aimed at making this metric format specification a standard. Sysdig Monitor dynamically detects and scrape Prometheus metrics.\n",
    "##### Custom Metrics\n",
    "Source: <a href=\"https://sysdig.com/blog/how-to-instrument-code-custom-metrics-vs-apm-vs-opentracing/\">href=\"https://sysdig.com/blog/how-to-instrument-code-custom-metrics-vs-apm-vs-opentracing/</a>\n",
    "Custom Metrics (JMX, Golang expvar, Prometheus, statsd...) is an approach on how to instrument code to easily monitor the performance and troubleshooting of an application. Typical aspects to be monitored are: the most visited components a web page, the slowest components to load, the difference of speed in loading the frontend and the backend, which factors affect the speed of the process (location, browser, device). The options to monitor those aspects are: using an APM instrument, using OpenTracing libraries, or generating metrics ad-hoc for specific components.\n",
    "\n",
    "##### Comparison between CM, APM and Opentracing\n",
    "\n",
    "|Issue | Custom Metrics | APM | Opentracing |\n",
    "| --- | --- | --- | --- |\n",
    "| Code-related problems | Devs need to provide metrics with performance in code but are not as easy to identify | Yes | Yes |\n",
    "| Infrastructure-related problems | Yes | No | No |\n",
    "| Node and service level aggregation | Yes | No | No |\n",
    "| Standard implementaton | Some languages include a standard way to implement them: (Prometheus, Java JMX, Go expvar, …) | No | Yes |\n",
    "| Allows capacity planning | Yes | No | No |\n",
    "| Allows complete statistical measurements | Yes | No | No |\n",
    "| Cloud Native Computing Foundation standard | Prometheus metrics only | No | Yes |\n",
    "| Distributed application analysis | Yes, without per trace analysis | Yes | Yes |\n",
    "| Useful for developers for pre-production environments | Yes | Yes | Yes |\n",
    "| Useful for complete DevOps strategy | Yes | No | No |\n",
    "\n",
    "##### Metrics notations: dot notation vs multi-dimensional tagged metrics\n",
    "Source: <a href=\"https://sysdig.com/blog/prometheus-metrics/\">https://sysdig.com/blog/prometheus-metrics/</a>\n",
    "For Python we need the third-party library Prometheu to feed the monitoring system.\n",
    "There are two main paradigms to represent a metric: <b>dot notation</b> and <b>multi-dimensional tagged metrics</b>.\n",
    "In a dot-notated metric, data are provided in dot-separated format in the name of the metric, which determine the detail and the hierarchy needed. The arrangement of the metric depends on the piece of information needed. \n",
    "In Prometheus metric format a flat approach is adopted to metrics naming. Instead of a hierarchical, dot separated name, there are names combined with a series of labels or tags. \"Highly dimensional data\" imply the possibility to associate any number of context-specific labels to every submitted metric.\n",
    "\n",
    "##### Prometheus metrics (OpenMetrics)\n",
    "Prometheus metrics format is line oriented: lines are separated by a line feed character (n), and the last line must end with a line feed character, while empty lines are somply ignored.\n",
    "\n",
    "A metric is composed by the (optional) components below:\n",
    "\n",
    "<ul>\n",
    "    <li>Metric name</li>\n",
    "    <li>Any number of labels (can be 0), represented as a key-value array</li>\n",
    "    <li>Current metric value</li>\n",
    "    <li>Optional metric timestamp</li>\n",
    "</ul>\n",
    "\n",
    "Metric output is typically preceded with **# HELP** and **# TYPE** metadata lines.\n",
    "The HELP string identifies the metric name and a brief description of it. The TYPE string identifies the type of metric. If there’s no TYPE before a metric, the metric is set to untyped. Everything else that starts with a # is parsed as a comment.\n",
    "\n",
    "(**continua*)\n",
    "\n",
    "##### Implement Prometheus custom metric instrumentation in Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02/03 - 09/03 (OC Index Software Code Refactoring - NOCI + Mapping Merge) <a class=\"anchor\" id=\"entry_2\"></a>\n",
    "\n",
    "### NOCI material\n",
    "\n",
    "1. **OpenCitations Index espansion**\n",
    "\n",
    "   1.1 *ADDITIONS*\n",
    "    \n",
    "      1.1.1 [NIH citation source](#en_1.1.1)\n",
    "\n",
    "      1.1.2 [NOCI glob](#en_1.1.2)\n",
    "\n",
    "      1.1.3 [PMID manager](#en_1.1.3)\n",
    "\n",
    "      1.1.4 [NIH resource finder](#en_1.1.4)\n",
    "        \n",
    "   1.2 *ADJUSTMENTS / EXPANSIONS*\n",
    "    \n",
    "      1.2.1 [citation/oci.py](#en_1.2.1)\n",
    "        \n",
    "      1.2.2 [finder/resourcefinder.py](#en_1.2.2)\n",
    "        \n",
    "      1.2.3 [finder/dataciteresourcefinder.py](#en_1.2.3)\n",
    "      \n",
    "      1.2.4 [finder/crossrefresourcefinder.py](#en_1.2.4)\n",
    "      \n",
    "      1.2.5 [finder/orcidresourcefinder.py](#en_1.2.5)\n",
    "      \n",
    "      1.2.6 [storer/csvmanager.py](#en_1.2.6)\n",
    "      \n",
    "      1.2.7 [storer/datahandler.py](#en_1.2.7)\n",
    "      \n",
    "      1.2.8 [storer/update.py](#en_1.2.8)\n",
    "      \n",
    "      1.2.9 [cnc.py](#en_1.2.9)\n",
    "      \n",
    "      \n",
    "        \n",
    "2. **Ramose**\n",
    "\n",
    "    2.1 [NOCI configuration file](#en_2.1)\n",
    "    \n",
    "    2.2 [indexapi.py extension](#en_2.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 NIH citation source <a class=\"anchor\" id=\"en_1.1.1\"></a>\n",
    "\n",
    "Codice della citation source per il National Institute of Health. Il dataset citazionale (NIH-OCC) fornisce solo le informazioni minime richieste dall'OpenCitations data model, ovvero **citante** e **citato**, espressi rispettivamente nei campi \"citing\" e \"referenced\" del file CSV del NIH-OCC.\n",
    "Il codice è stato testato con successo. \n",
    "Di seguito, il codice del NIH citation source e del rispettivo test case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk, sep, remove\n",
    "from os.path import isdir\n",
    "from json import load\n",
    "from csv import DictWriter\n",
    "from index.citation.citationsource import CSVFileCitationSource\n",
    "from index.identifier.pmidmanager import PMIDManager\n",
    "from index.citation.oci import Citation, OCIManager\n",
    "\n",
    "\n",
    "class NIHCitationSource( CSVFileCitationSource ):\n",
    "    def __init__(self, src, local_name=\"\"):\n",
    "        self.pmid = PMIDManager()\n",
    "        super( NIHCitationSource, self ).__init__( src, local_name )\n",
    "\n",
    "    def get_next_citation_data(self):\n",
    "        row = self._get_next_in_file()\n",
    "        #id_type = OCIManager.pmid_type\n",
    "\n",
    "        while row is not None:\n",
    "            citing = self.pmid.normalise(row.get(\"citing\"))\n",
    "            cited = self.pmid.normalise(row.get(\"referenced\"))\n",
    "\n",
    "            self.update_status_file()\n",
    "            return citing, cited, None, None, None, None #, id_type\n",
    "            self.update_status_file()\n",
    "            row = self._get_next_in_file()\n",
    "\n",
    "        remove(self.status_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test/10_noci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from index.coci.glob import process\n",
    "from os import sep, makedirs\n",
    "from os.path import exists\n",
    "from shutil import rmtree\n",
    "from index.storer.csvmanager import CSVManager\n",
    "from index.noci.nationalinstituteofhealthsource import NIHCitationSource\n",
    "from csv import DictReader\n",
    "\n",
    "\n",
    "class NOCITest(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.input_file = \"index%stest_data%snih_dump%ssource.csv\" % (sep, sep, sep)\n",
    "        self.citations = \"index%stest_data%snih_dump%scitations.csv\" % (sep, sep, sep)\n",
    "\n",
    "    def test_citation_source(self):\n",
    "        ns = NIHCitationSource( self.input_file )\n",
    "        new = []\n",
    "        cit = ns.get_next_citation_data()\n",
    "        while cit is not None:\n",
    "            citing, cited, creation, timespan, journal_sc, author_sc = cit\n",
    "            new.append({\n",
    "                \"citing\": citing,\n",
    "                \"cited\": cited,\n",
    "                \"creation\": \"\" if creation is None else creation,\n",
    "                \"timespan\": \"\" if timespan is None else timespan,\n",
    "                \"journal_sc\": \"no\" if journal_sc is None else journal_sc,\n",
    "                \"author_sc\": \"no\" if author_sc is None else author_sc\n",
    "            })\n",
    "            cit = ns.get_next_citation_data()\n",
    "\n",
    "        with open(self.citations, encoding=\"utf8\") as f:\n",
    "            old = list(DictReader(f))\n",
    "\n",
    "        self.assertEqual(new, old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 NOCI glob <a class=\"anchor\" id=\"en_1.1.2\"></a>\n",
    "L' iCite Database contenente il NIH-OCC, ovvero la data source di NOCI, e un altro dataset: **iCite Metadata**. Se il NIH-OCC contiene solamente dati citazionali rappresentati dai PMID del citante e del citato, iCite Metadata contiene metadati relativi alle entità bibliografiche (identificate da PMID) coinvolte nelle citazioni contenute nel NIH-OCC. iCite Metadata contiene dunque delle informazioni che possono essere rielaborate al fine di ricavarne (direttamente o indirettamente) i metadati utili a completare i quattro campi della tupla a sei elementi non coperti dal NIH-OCC.\n",
    "Tra i campi del dataset iCite Metadata, **\"doi\"** fornisce l'informazione di **mapping** PMID-DOI. Questo dato è particolarmente utile perché permette di sfruttare i servizi API dei DOI per ricavare le informazioni che non vengono fornite né in iCite Metadata né nei servizi API dei PMIDs. \n",
    "I dati ricavati sono salvati in files CSV che vengono utilizzati come materiale di supporto nel processo di popolazione dell'Indice citazionale. \n",
    "Di seguito, il codice del glob di NOCI e il relativo test, passato con successo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from argparse import ArgumentParser\n",
    "from index.storer.csvmanager import CSVManager\n",
    "from index.finder.crossrefresourcefinder import CrossrefResourceFinder\n",
    "from index.finder.orcidresourcefinder import ORCIDResourceFinder\n",
    "from index.identifier.pmidmanager import PMIDManager\n",
    "from index.identifier.doimanager import DOIManager\n",
    "from index.identifier.issnmanager import ISSNManager\n",
    "from index.identifier.orcidmanager import ORCIDManager\n",
    "from os import sep, makedirs, walk\n",
    "import os\n",
    "from os.path import exists\n",
    "import json\n",
    "from re import sub\n",
    "from index.citation.oci import Citation\n",
    "from zipfile import ZipFile\n",
    "from tarfile import TarFile\n",
    "import re\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def issn_data_recover(directory):\n",
    "    journal_issn_dict = dict()\n",
    "    filename = directory + sep + 'journal_issn.json'\n",
    "    if not os.path.exists(filename):\n",
    "        return journal_issn_dict\n",
    "    else:\n",
    "        with open(filename, 'r', encoding='utf8') as fd:\n",
    "            journal_issn_dict = json.load(fd)\n",
    "            types = type(journal_issn_dict)\n",
    "            return journal_issn_dict\n",
    "\n",
    "def issn_data_to_cache(name_issn_dict, directory):\n",
    "    filename = directory + sep + 'journal_issn.json'\n",
    "    with open(filename, 'w', encoding='utf-8' ) as fd:\n",
    "            json.dump(name_issn_dict, fd, ensure_ascii=False, indent=4)\n",
    "\n",
    "#PUB DATE EXTRACTION : takes in input a data structure representing a bibliographic entity\n",
    "def build_pubdate(row):\n",
    "    year = str(row[\"year\"])\n",
    "    str_year = sub( \"[^\\d]\", \"\", year)[:4]\n",
    "    if str_year:\n",
    "        return str_year\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# get_all_files extracts all the needed files from the input directory\n",
    "def get_all_files(i_dir):\n",
    "    result = []\n",
    "    opener = None\n",
    "\n",
    "    if i_dir.endswith( \".zip\" ):\n",
    "        zf = ZipFile( i_dir )\n",
    "        for name in zf.namelist():\n",
    "            if name.lower().endswith(\".csv\") and \"citations\" not in name.lower() and \"source\" not in name.lower():\n",
    "                result.append( name )\n",
    "        opener = zf.open\n",
    "    elif i_dir.endswith( \".tar.gz\" ):\n",
    "        tf = TarFile.open( i_dir )\n",
    "        for name in tf.getnames():\n",
    "            if name.lower().endswith(\".csv\") and \"citations\" not in name.lower() and \"source\" not in name.lower():\n",
    "                result.append(name)\n",
    "        opener = tf.extractfile\n",
    "\n",
    "    else:\n",
    "        for cur_dir, cur_subdir, cur_files in walk(i_dir):\n",
    "            for file in cur_files:\n",
    "                if file.lower().endswith( \".csv\" ) and \"citations\" not in file.lower() and \"source\" not in file.lower():\n",
    "                    result.append(cur_dir + sep + file)\n",
    "        opener = open\n",
    "    return result, opener\n",
    "\n",
    "\n",
    "def process(input_dir, output_dir, n):\n",
    "    if not exists(output_dir):\n",
    "        makedirs(output_dir)\n",
    "\n",
    "    citing_pmid_with_no_date = set()\n",
    "    valid_pmid = CSVManager( output_dir + sep + \"valid_pmid.csv\" )\n",
    "    valid_doi = CSVManager(\"index/test_data/crossref_glob\" + sep + \"valid_doi.csv\")\n",
    "    id_date = CSVManager( output_dir + sep + \"id_date_pmid.csv\" )\n",
    "    id_issn = CSVManager( output_dir + sep + \"id_issn_pmid.csv\" )\n",
    "    id_orcid = CSVManager( output_dir + sep + \"id_orcid_pmid.csv\" )\n",
    "    journal_issn_dict = issn_data_recover(output_dir) #just an empty dict, in case of a code break\n",
    "    pmid_manager = PMIDManager(valid_pmid)\n",
    "    crossref_resource_finder = CrossrefResourceFinder(valid_doi)\n",
    "    orcid_resource_finder = ORCIDResourceFinder(valid_doi)\n",
    "\n",
    "    doi_manager = DOIManager(valid_doi)\n",
    "    issn_manager = ISSNManager()\n",
    "    orcid_manager = ORCIDManager()\n",
    "\n",
    "    all_files, opener = get_all_files(input_dir)\n",
    "    len_all_files = len(all_files)\n",
    "\n",
    "    # Read all the CSV file in the NIH dump to create the main information of all the indexes\n",
    "    print( \"\\n\\n# Add valid PMIDs from NIH metadata\" )\n",
    "    for file_idx, file in enumerate( all_files, 1 ):\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        for chunk in pd.read_csv(file, chunksize=1000 ):\n",
    "            f = pd.concat( [df, chunk], ignore_index=True )\n",
    "            f.fillna(\"\", inplace=True)\n",
    "\n",
    "            print( \"Open file %s of %s\" % (file_idx, len_all_files) )\n",
    "            for index, row in f.iterrows():\n",
    "                if int(index) !=0 and int(index) % int(n) == 0:\n",
    "                    print( \"Group nr.\", int(index)//int(n), \"processed. Data from\", int(index), \"rows saved to journal_issn.json mapping file\")\n",
    "                    issn_data_to_cache(journal_issn_dict, output_dir)\n",
    "\n",
    "                citing_pmid = pmid_manager.normalise(row['pmid'], True)\n",
    "                pmid_manager.set_valid(citing_pmid)\n",
    "                citing_doi = doi_manager.normalise(row['doi'], True)\n",
    "\n",
    "                if id_date.get_value(citing_pmid) is None:\n",
    "                    citing_date = Citation.check_date(build_pubdate(row))\n",
    "                    if citing_date is not None:\n",
    "                        id_date.add_value(citing_pmid, citing_date)\n",
    "                        if citing_pmid in citing_pmid_with_no_date:\n",
    "                            citing_pmid_with_no_date.remove(citing_pmid)\n",
    "                    else:\n",
    "                        citing_pmid_with_no_date.add( citing_pmid )\n",
    "\n",
    "                if id_issn.get_value( citing_pmid ) is None:\n",
    "                    journal_name = row[\"journal\"]\n",
    "                    if journal_name: #check that the string is not empty\n",
    "                        if journal_name in journal_issn_dict.keys():\n",
    "                            for issn in journal_issn_dict[journal_name]:\n",
    "                                id_issn.add_value(citing_pmid, issn)\n",
    "                        else:\n",
    "                            if citing_doi is not None:\n",
    "                                json_res = crossref_resource_finder._call_api(citing_doi)\n",
    "                                if json_res is not None:\n",
    "                                    issn_set = crossref_resource_finder._get_issn(json_res)\n",
    "                                    if len(issn_set)>0:\n",
    "                                        journal_issn_dict[journal_name] = []\n",
    "                                    for issn in issn_set:\n",
    "                                        issn_norm = issn_manager.normalise(str(issn))\n",
    "                                        id_issn.add_value( citing_pmid, issn_norm )\n",
    "                                        journal_issn_dict[journal_name].append(issn_norm)\n",
    "\n",
    "\n",
    "                if id_orcid.get_value(citing_pmid) is None:\n",
    "                    if citing_doi is not None:\n",
    "                        json_res = orcid_resource_finder._call_api(citing_doi)\n",
    "                        if json_res is not None:\n",
    "                            orcid_set = orcid_resource_finder._get_orcid(json_res)\n",
    "                            for orcid in orcid_set:\n",
    "                                orcid_norm = orcid_manager.normalise( orcid )\n",
    "                                id_orcid.add_value(citing_pmid, orcid_norm)\n",
    "\n",
    "            issn_data_to_cache( journal_issn_dict, output_dir )\n",
    "\n",
    "\n",
    "    # Iterate once again for all the rows of all the csv files, so to check the validity of the referenced pmids.\n",
    "    print( \"\\n\\n# Checking the referenced pmids validity\" )\n",
    "    for file_idx, file in enumerate( all_files, 1 ):\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        for chunk in pd.read_csv( file, chunksize=1000 ):\n",
    "            f = pd.concat( [df, chunk], ignore_index=True )\n",
    "            f.fillna(\"\", inplace=True)\n",
    "            print( \"Open file %s of %s\" % (file_idx, len_all_files) )\n",
    "            for index, row in f.iterrows():\n",
    "                if row[\"references\"] != \"\":\n",
    "                    ref_string = row[\"references\"].strip()\n",
    "                    ref_string_norm = re.sub(\"\\s+\", \" \", ref_string)\n",
    "                else:\n",
    "                    print(\"the type of row reference is\", (row[\"references\"]), type(row[\"references\"]))\n",
    "                    print(index, row )\n",
    "\n",
    "                cited_pmids = set(ref_string_norm.split(\" \"))\n",
    "                for cited_pmid in cited_pmids:\n",
    "                    if pmid_manager.is_valid(cited_pmid):\n",
    "                        print(\"valid cited pmid added:\", cited_pmid)\n",
    "                    else:\n",
    "                        print(\"invalid cited pmid discarded:\", cited_pmid)\n",
    "\n",
    "    for pmid in citing_pmid_with_no_date:\n",
    "        id_date.add_value( pmid, \"\" )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    arg_parser = ArgumentParser( \"Global files creator for NOCI\",\n",
    "                                 description=\"Process NIH CSV files and create global indexes to enable \"\n",
    "                                             \"the creation of NOCI.\" )\n",
    "    arg_parser.add_argument( \"-i\", \"--input_dir\", dest=\"input_dir\", required=True,\n",
    "                             help=\"Either the directory or the zip file that contains the NIH data dump \"\n",
    "                                  \"of CSV files.\" )\n",
    "    arg_parser.add_argument( \"-o\", \"--output_dir\", dest=\"output_dir\", required=True,\n",
    "                             help=\"The directory where the indexes are stored.\" )\n",
    "\n",
    "\n",
    "    arg_parser.add_argument( \"-n\", \"--num_lines\", dest=\"n\", required=True,\n",
    "                             help=\"Number of lines after which the data stored in the dictionary for the mapping \"\n",
    "                                  \"between a Journal name and the related issns are passed into a JSON cache file\" )\n",
    "\n",
    "\n",
    "    args = arg_parser.parse_args()\n",
    "\n",
    "    start = timer()\n",
    "    process(args.input_dir, args.output_dir, args.n)\n",
    "    end = timer()\n",
    "    #calculate elapsed time\n",
    "    print(\"elapsed time, in seconds:\", (end-start))\n",
    "\n",
    "\n",
    "#python -m index.noci.glob1 -i \"index/test_data/nih_dump\" -o \"index/test_data/nih_glob1\" -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test/13_glob1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from os import sep, remove\n",
    "import os\n",
    "from os.path import exists\n",
    "from index.noci.glob1 import issn_data_recover, issn_data_to_cache, build_pubdate, get_all_files, process\n",
    "from index.storer.csvmanager import CSVManager\n",
    "from index.identifier.issnmanager import ISSNManager\n",
    "from index.identifier.orcidmanager import ORCIDManager\n",
    "from index.identifier.pmidmanager import PMIDManager\n",
    "from index.identifier.doimanager import DOIManager\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "class MyTestCase( unittest.TestCase ):\n",
    "    def setUp(self):\n",
    "        self.dir_with_issn_map = \"index%stest_data%sglob_noci%sissn_data_recover%swith_issn_mapping\" % (sep, sep, sep, sep)\n",
    "        self.dir_without_issn_map = \"index%stest_data%sglob_noci%sissn_data_recover%swithout_issn_mapping\" % (sep, sep, sep, sep)\n",
    "        self.issn_journal_sample_dict = {\"N Biotechnol\": [\"1871-6784\"], \"Biochem Med\": [\"0006-2944\"], \"Magn Reson Chem\": [\"0749-1581\"]}\n",
    "        self.data_to_cache_dir = \"index%stest_data%sglob_noci%sissn_data_to_cache\" % (sep, sep, sep)\n",
    "        self.get_all_files_dir = \"index%stest_data%sglob_noci%sget_all_files\" % (sep, sep, sep)\n",
    "        self.csv_sample = \"index%stest_data%sglob_noci%sget_all_files%s1.csv\" % (sep, sep, sep, sep)\n",
    "        self.output_dir = \"index%stest_data%sglob_noci%sprocess%soutput\" % (sep, sep, sep, sep)\n",
    "        self.valid_pmid = CSVManager( self.output_dir + sep + \"valid_pmid.csv\" )\n",
    "        self.valid_doi = CSVManager( \"index/test_data/crossref_glob\" + sep + \"valid_doi.csv\" )\n",
    "        self.id_date = CSVManager( self.output_dir + sep + \"id_date_pmid.csv\" )\n",
    "        self.id_issn = CSVManager( self.output_dir + sep + \"id_issn_pmid.csv\" )\n",
    "        self.id_orcid = CSVManager( self.output_dir + sep + \"id_orcid_pmid.csv\" )\n",
    "        self.doi_manager = DOIManager(self.valid_doi)\n",
    "        self.pmid_manager = PMIDManager(self.valid_pmid)\n",
    "        self.issn_manager = ISSNManager()\n",
    "        self.orcid_manager = ORCIDManager()\n",
    "        self.sample_reference = \"pmid:7829625\"\n",
    "\n",
    "    def test_issn_data_recover(self):\n",
    "        #Test the case in which there is no mapping file for journals - issn\n",
    "        self.assertEqual(issn_data_recover(self.dir_without_issn_map), {})\n",
    "        #Test the case in which there is a mapping file for journals - issn\n",
    "        issn_map_dict_len = len(issn_data_recover(self.dir_with_issn_map))\n",
    "        self.assertTrue(issn_map_dict_len>0)\n",
    "\n",
    "    def test_issn_data_to_cache(self):\n",
    "        filename = self.data_to_cache_dir + sep + 'journal_issn.json'\n",
    "        if exists(filename):\n",
    "            remove(filename)\n",
    "        self.assertFalse(exists(filename))\n",
    "        issn_data_to_cache(self.issn_journal_sample_dict, self.data_to_cache_dir)\n",
    "        self.assertTrue(exists(filename))\n",
    "\n",
    "    def test_get_all_files(self):\n",
    "        all_files, opener = get_all_files( self.get_all_files_dir)\n",
    "        len_all_files = len(all_files)\n",
    "        #The folder contains 4 csv files, but two of those contains the words \"citations\" or \"source\" in their filenames\n",
    "        self.assertEqual( len_all_files, 2)\n",
    "\n",
    "    def test_build_pubdate(self):\n",
    "        df = pd.DataFrame()\n",
    "        for chunk in pd.read_csv(self.csv_sample, chunksize=1000):\n",
    "            f = pd.concat( [df, chunk], ignore_index=True )\n",
    "            f.fillna( \"\", inplace=True )\n",
    "            for index, row in f.iterrows():\n",
    "                pub_date = build_pubdate(row)\n",
    "                self.assertTrue(isinstance(pub_date, str))\n",
    "                self.assertTrue(isinstance(int(pub_date), int))\n",
    "                self.assertEqual(len(pub_date), 4)\n",
    "\n",
    "    def test_process(self):\n",
    "        for files in os.listdir( self.output_dir):\n",
    "            path = os.path.join( self.output_dir, files )\n",
    "            try:\n",
    "                shutil.rmtree(path)\n",
    "            except OSError:\n",
    "                os.remove(path)\n",
    "        self.assertEqual(len(os.listdir(self.output_dir)),0)\n",
    "        process(self.get_all_files_dir, self.output_dir, 20)\n",
    "        self.assertTrue(len(os.listdir(self.output_dir))>0)\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        for chunk in pd.read_csv( self.csv_sample, chunksize=1000 ):\n",
    "            f = pd.concat( [df, chunk], ignore_index=True )\n",
    "            f.fillna( \"\", inplace=True )\n",
    "            for index, row in f.iterrows():\n",
    "                if index == 1:\n",
    "                    pmid = row[\"pmid\"]\n",
    "\n",
    "        citing_pmid = self.pmid_manager.normalise(pmid, include_prefix=True)\n",
    "\n",
    "        self.assertEqual(self.valid_pmid.get_value(citing_pmid), {'v'})\n",
    "        self.assertEqual(self.valid_pmid.get_value(self.sample_reference), {'v'})\n",
    "        self.assertEqual(self.id_date.get_value(citing_pmid), {'1998'})\n",
    "        self.assertEqual(self.id_issn.get_value(citing_pmid), {'0918-8959', '1348-4540'})\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        for chunk in pd.read_csv( self.csv_sample, chunksize=1000 ):\n",
    "            f = pd.concat( [df, chunk], ignore_index=True )\n",
    "            f.fillna( \"\", inplace=True )\n",
    "            for index, row in f.iterrows():\n",
    "                if index == 0:\n",
    "                    pmid = row[\"pmid\"]\n",
    "\n",
    "        citing_pmid = self.pmid_manager.normalise(pmid, include_prefix=True)\n",
    "\n",
    "        self.assertEqual(self.id_orcid.get_value(citing_pmid), {'0000-0002-0524-4077'})\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n",
    "\n",
    "#python -m unittest index.test.13_glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 PMID manager <a class=\"anchor\" id=\"en_1.1.3\"></a>\n",
    "La classe PMIDManager è sviluppata come **istanza della superclasse IdentifierManager**. Lo sviluppo del PMIDManager è modellato sull'esempio della classe DOIManager, con cui condivide scopo e funzioni.\n",
    "In particolare, gli identifier manager si occupano di normalizzare il formato degli identificativi, per poi verificarne l'esistenza e la validità ricorrendo a servizi di API specifici per ogni tipo di identificativo.\n",
    "L'**API service** utilizzato per i PMID è **https://pubmed.ncbi.nlm.nih.gov/**, che fornisce in risposta una **pagina HTML**. Per questo motivo, l'informazione relativa all'avvenuta o mancata validazione del PMID in questione viene estratta con gli strumenti forniti dalla libreria **BeautifulSoup**. \n",
    "Di seguito, il codice del PMID manager e l'estensione del test case per gli identifier managers. Il test è stato passato con successo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index.identifier.identifiermanager import IdentifierManager\n",
    "from re import sub, match\n",
    "from urllib.parse import unquote, quote\n",
    "from requests import get\n",
    "from index.storer.csvmanager import CSVManager\n",
    "from requests import ReadTimeout\n",
    "from requests.exceptions import ConnectionError\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "class PMIDManager( IdentifierManager ):\n",
    "    def __init__(self, valid_pmid=None, use_api_service=True):\n",
    "        if valid_pmid is None:\n",
    "            valid_pmid = CSVManager( store_new=False )\n",
    "\n",
    "        self.api = \"https://pubmed.ncbi.nlm.nih.gov/\"\n",
    "        self.valid_pmid = valid_pmid\n",
    "        self.use_api_service = use_api_service\n",
    "        self.p = \"pmid:\"\n",
    "        super( PMIDManager, self ).__init__()\n",
    "\n",
    "    def set_valid(self, id_string):\n",
    "        pmid = self.normalise(id_string, include_prefix=True )\n",
    "        if self.valid_pmid.get_value( pmid ) is None:\n",
    "            self.valid_pmid.add_value( pmid, \"v\" )\n",
    "\n",
    "    def is_valid(self, id_string):\n",
    "        pmid = self.normalise( id_string, include_prefix=True )\n",
    "        if pmid is None or match( \"^pmid:[1-9]\\d*$\", pmid ) is None:\n",
    "            return False\n",
    "        else:\n",
    "            if self.valid_pmid.get_value( pmid ) is None:\n",
    "                if self.__pmid_exists( pmid ):\n",
    "                    self.valid_pmid.add_value( pmid, \"v\" )\n",
    "                else:\n",
    "                    self.valid_pmid.add_value( pmid, \"i\" )\n",
    "            return \"v\" in self.valid_pmid.get_value( pmid )\n",
    "\n",
    "    def normalise(self, id_string, include_prefix=False):\n",
    "        id_string = str(id_string)\n",
    "        try:\n",
    "            pmid_string = sub( \"^0+\", \"\", sub( \"\\0+\", \"\", (sub( \"[^\\d+]\", \"\", id_string )) ) )\n",
    "            return \"%s%s\" % (self.p if include_prefix else \"\", pmid_string)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def __pmid_exists(self, pmid_full):\n",
    "        pmid = self.normalise( pmid_full )\n",
    "        if self.use_api_service:\n",
    "            tentative = 3\n",
    "            while tentative:\n",
    "                tentative -= 1\n",
    "                try:\n",
    "                    r = get( self.api + quote( pmid ) + \"/?format=pmid\", headers=self.headers, timeout=30 )\n",
    "                    if r.status_code == 200:\n",
    "                        r.encoding = \"utf-8\"\n",
    "\n",
    "                        soup = BeautifulSoup( r.content, features=\"lxml\" )\n",
    "                        for i in soup.find_all( \"meta\", {\"name\": \"uid\"} ):\n",
    "                            id = i[\"content\"]\n",
    "                            if id == pmid:\n",
    "                                return True\n",
    "\n",
    "                except ReadTimeout:\n",
    "                    pass\n",
    "                except ConnectionError:\n",
    "                    sleep(5)\n",
    "\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test/02_identifiermanager.py (PMID extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from os import sep\n",
    "from index.identifier.doimanager import DOIManager\n",
    "from index.identifier.issnmanager import ISSNManager\n",
    "from index.identifier.orcidmanager import ORCIDManager\n",
    "from index.identifier.pmidmanager import PMIDManager\n",
    "from index.storer.csvmanager import CSVManager\n",
    "\n",
    "\n",
    "class IdentifierManagerTest(unittest.TestCase):\n",
    "    \"\"\"This class aim at testing the methods of the class CSVManager.\"\"\"\n",
    "\n",
    "    def setUp(self):\n",
    "#[...]\n",
    "\n",
    "#class extension for pubmedid\n",
    "        self.valid_pmid_1 = \"2942070\"\n",
    "        self.valid_pmid_2 = \"1509982\"\n",
    "        self.valid_pmid_3 = \"7189714\"\n",
    "        self.invalid_pmid_1 = \"0067308798798\"\n",
    "        self.invalid_pmid_2 = \"pmid:174777777777\"\n",
    "        self.invalid_pmid_3 = \"000009265465465465\"\n",
    "        self.valid_pmid_path = \"index%stest_data%svalid_pmid.csv\" % (sep, sep)\n",
    "\n",
    "#[...]\n",
    "\n",
    "#class extension for pubmedid\n",
    "    def test_pmid_normalise(self):\n",
    "        pm = PMIDManager()\n",
    "        self.assertEqual(self.valid_pmid_1, pm.normalise(self.valid_pmid_1.replace(\"\", \"pmid:\")))\n",
    "        self.assertEqual(self.valid_pmid_1, pm.normalise(self.valid_pmid_1.replace(\"\", \" \")))\n",
    "        self.assertEqual(self.valid_pmid_1, pm.normalise(\"https://pubmed.ncbi.nlm.nih.gov/\"+self.valid_pmid_1))\n",
    "        self.assertEqual(self.valid_pmid_2, pm.normalise(\"000\"+self.valid_pmid_2))\n",
    "\n",
    "    def test_pmid_is_valid(self):\n",
    "        pm_nofile = PMIDManager()\n",
    "        print(pm_nofile.normalise(self.valid_pmid_1, include_prefix=True ))\n",
    "        print(pm_nofile.is_valid(self.valid_pmid_1))\n",
    "        self.assertTrue(pm_nofile.is_valid(self.valid_pmid_1))\n",
    "        self.assertTrue(pm_nofile.is_valid(self.valid_pmid_2))\n",
    "        self.assertTrue(pm_nofile.is_valid(self.valid_pmid_3))\n",
    "        self.assertFalse(pm_nofile.is_valid(self.invalid_pmid_1))\n",
    "        self.assertFalse(pm_nofile.is_valid(self.invalid_pmid_2))\n",
    "        self.assertFalse(pm_nofile.is_valid(self.invalid_pmid_3))\n",
    "\n",
    "        valid_pmid = CSVManager(self.valid_pmid_path)\n",
    "        pm_file = PMIDManager(valid_pmid=valid_pmid, use_api_service=False)\n",
    "        self.assertTrue(pm_file.is_valid(self.valid_pmid_1))\n",
    "        self.assertFalse(pm_file.is_valid(self.invalid_pmid_1))\n",
    "\n",
    "        pm_nofile_noapi = PMIDManager(use_api_service=False)\n",
    "        self.assertFalse(pm_nofile_noapi.is_valid(self.valid_pmid_1))\n",
    "        self.assertFalse(pm_nofile_noapi.is_valid(self.invalid_pmid_1))\n",
    "        self.assertFalse(pm_nofile_noapi.is_valid(self.valid_pmid_2))\n",
    "        self.assertFalse(pm_nofile_noapi.is_valid(self.invalid_pmid_2))\n",
    "        self.assertFalse(pm_nofile_noapi.is_valid(self.valid_pmid_3))\n",
    "        self.assertFalse(pm_nofile_noapi.is_valid(self.invalid_pmid_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 NIH resource finder <a class=\"anchor\" id=\"en_1.1.4\"></a>\n",
    "La classe NIHResourceFinder è sviluppata come **istanza della superclasse ApiIDResourceFinder** e il suo scopo è quello di **recuperare metadati dall'API per i PMID**, nel caso in cui nel processo non vengano forniti files di supporto generati nel preprocessing dal glob di NOCI. \n",
    "Il servizio utilizzato è https://pubmed.ncbi.nlm.nih.gov/ (con display option \"pubmed\") che restituisce risposte in formato HTML. Per questo motivo, i dati sono estratti utilizzando la libreria **Beautiful Soup** per accedere alla sezione che contiene la stringa testuale con i metadati. A questo punto, i dati sono estratti dalla stringa testuale sfruttando le **regex**. \n",
    "A differenza dei servizi API per i DOI, questa REST API non fornisce dati particolarmente dettagliati e non copre alcune delle informazioni richieste dall'OCDM, come ad esempio gli ORCID degli autori. Tra i metadati a disposizione, gli unici utili sono la **data di pubblicazione** e l'**ISSN** della rivista di pubblicazione. \n",
    "Di seguito, lo script del NIHResourceFinder e la relativa espansionsione del testcase 03_resourcefinder.py. Il test è stato superato con successo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index.finder.resourcefinder import ApiIDResourceFinder\n",
    "from index.citation.oci import OCIManager\n",
    "from requests import get\n",
    "from urllib.parse import quote\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "class NIHResourceFinder(ApiIDResourceFinder):\n",
    "    def __init__(self, date=None, orcid=None, issn=None, pmid=None, use_api_service=True):\n",
    "        self.use_api_service = use_api_service\n",
    "        self.api = \"https://pubmed.ncbi.nlm.nih.gov/\"\n",
    "        self.baseurl = \"https://pubmed.ncbi.nlm.nih.gov/\"\n",
    "        super(NIHResourceFinder, self).__init__(date=date, orcid=orcid, issn=issn, id=pmid, id_type=OCIManager.pmid_type,\n",
    "                                                     use_api_service=use_api_service)\n",
    "\n",
    "    def _get_issn(self, txt_obj):\n",
    "        result = set()\n",
    "        issns = re.findall(\"IS\\s+-\\s+\\d{4}-\\d{4}\", txt_obj)\n",
    "        for i in issns:\n",
    "            issn = re.search(\"\\d{4}-\\d{4}\", i).group(0)\n",
    "            result.add(issn)\n",
    "        return result\n",
    "\n",
    "    def _get_date(self, txt_obj):\n",
    "        date = re.search(\"DP\\s+-\\s+(\\d{4}(\\s?(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec))?(\\s?((3[0-1])|([1-2][0-9])|([0]?[1-9])))?)\", txt_obj).group(1)\n",
    "        re_search = re.search(\"(\\d{4})\\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s+((3[0-1])|([1-2][0-9])|([0]?[1-9]))\", date)\n",
    "        if re_search is not None:\n",
    "            result = re_search.group(0)\n",
    "            datetime_object = datetime.strptime(result, '%Y %b %d')\n",
    "            return datetime.strftime(datetime_object, '%Y-%m-%d')\n",
    "        else:\n",
    "            re_search = re.search(\"(\\d{4})\\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\", date)\n",
    "            if re_search is not None:\n",
    "                result = re_search.group(0)\n",
    "                datetime_object = datetime.strptime(result, '%Y %b')\n",
    "                return datetime.strftime(datetime_object, '%Y-%m')\n",
    "            else:\n",
    "                re_search = re.search(\"(\\d{4})\", date)\n",
    "                if re_search is not None:\n",
    "                    result = re.search(\"(\\d{4})\", date).group(0)\n",
    "                    datetime_object = datetime.strptime(result, '%Y')\n",
    "                    return datetime.strftime(datetime_object, '%Y')\n",
    "                else:\n",
    "                    return None\n",
    "\n",
    "\n",
    "    def _call_api(self, pmid_full):\n",
    "        if self.use_api_service:\n",
    "            pmid = self.pm.normalise(pmid_full)\n",
    "            r = get(self.api + quote(pmid) + \"/?format=pubmed\", headers=self.headers, timeout=30)\n",
    "            if r.status_code == 200:\n",
    "                r.encoding = \"utf-8\"\n",
    "                soup = BeautifulSoup(r.text, features=\"lxml\")\n",
    "                mdata = str(soup.find(id=\"article-details\"))\n",
    "                return mdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test/03_resourcefinder.py (PMID extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from os import sep\n",
    "from index.storer.csvmanager import CSVManager\n",
    "from index.finder.crossrefresourcefinder import CrossrefResourceFinder\n",
    "from index.finder.dataciteresourcefinder import DataCiteResourceFinder\n",
    "from index.finder.nihresourcefinder import NIHResourceFinder\n",
    "from index.finder.orcidresourcefinder import ORCIDResourceFinder\n",
    "from index.finder.resourcefinder import ResourceFinderHandler\n",
    "\n",
    "\n",
    "class ResourceFinderTest(unittest.TestCase):\n",
    "    \"\"\"This class aim at testing the methods of the class CSVManager.\"\"\"\n",
    "\n",
    "    def setUp(self):\n",
    "        self.date_path = \"index%stest_data%sid_date.csv\" % (sep, sep)\n",
    "        self.date_path_pmid = \"index%stest_data%sid_date_pmid.csv\" % (sep, sep)\n",
    "        self.orcid_path = \"index%stest_data%sid_orcid.csv\" % (sep, sep)\n",
    "        self.orcid_path_pmid = \"index%stest_data%sid_orcid_pmid.csv\" % (sep, sep)\n",
    "        self.issn_path = \"index%stest_data%sid_issn.csv\" % (sep, sep)\n",
    "        self.issn_path_pmid = \"index%stest_data%sid_issn_pmid.csv\" % (sep, sep)\n",
    "        self.doi_path = \"index%stest_data%svalid_doi.csv\" % (sep, sep)\n",
    "        self.pmid_path = \"index%stest_data%svalid_pmid.csv\" % (sep, sep)\n",
    "#[...]\n",
    "    \n",
    "    def test_nationalinstititeofhealth_get_orcid(self):\n",
    "        #Do not use support files, only APIs\n",
    "        nf_1 = NIHResourceFinder()\n",
    "        self.assertIsNone(nf_1.get_orcid(\"7189714\"))\n",
    "        self.assertIsNone(nf_1.get_orcid(\"1509982\"))\n",
    "\n",
    "        # Do use support files, but avoid using APIs\n",
    "        nf_2 = NIHResourceFinder(orcid=CSVManager(self.orcid_path_pmid),\n",
    "                                      pmid=CSVManager(self.pmid_path), use_api_service=False)\n",
    "        self.assertIn(\"0000-0002-1825-0097\", nf_2.get_orcid(\"7189714\"))\n",
    "        self.assertNotIn(\"0000-0002-1825-0098\", nf_2.get_orcid(\"1509982\"))\n",
    "\n",
    "        # Do not use support files neither APIs\n",
    "        nf_3 = NIHResourceFinder(use_api_service=False)\n",
    "        self.assertIsNone(nf_3.get_orcid(\"7189714\"))\n",
    "\n",
    "    def test_nationalinstititeofhealth_get_issn(self):\n",
    "        # Do not use support files, only APIs\n",
    "        nf_1 = NIHResourceFinder()\n",
    "        self.assertIn(\"0003-4819\", nf_1.get_container_issn(\"2942070\"))\n",
    "        self.assertNotIn(\"0003-0000\", nf_1.get_container_issn(\"2942070\"))\n",
    "\n",
    "        # # Do use support files, but avoid using APIs\n",
    "        nf_2 = NIHResourceFinder(issn=CSVManager(self.issn_path_pmid),\n",
    "                                      pmid=CSVManager(self.pmid_path), use_api_service=False)\n",
    "        container = nf_2.get_container_issn(\"1509982\")\n",
    "        self.assertIn(\"0065-4299\", container)\n",
    "        self.assertNotIn(\"0065-4444\", nf_2.get_container_issn(\"1509982\"))\n",
    "\n",
    "        # Do not use support files neither APIs\n",
    "        nf_3 = NIHResourceFinder(use_api_service=False)\n",
    "        self.assertIsNone(nf_3.get_container_issn(\"7189714\"))\n",
    "\n",
    "    def test_nationalinstititeofhealth_get_pub_date(self):\n",
    "        # Do not use support files, only APIs\n",
    "        nf_1 = NIHResourceFinder()\n",
    "        self.assertIn(\"1998-05-25\", nf_1.get_pub_date(\"9689714\"))\n",
    "        self.assertNotEqual(\"1998\", nf_1.get_pub_date(\"9689714\"))\n",
    "\n",
    "        # Do not use support files, only APIs\n",
    "        nf_2 = NIHResourceFinder(date=CSVManager(self.date_path_pmid),\n",
    "                                      pmid=CSVManager(self.pmid_path), use_api_service=False)\n",
    "        self.assertIn(\"1980-06\", nf_2.get_pub_date(\"7189714\"))\n",
    "        self.assertNotEqual(\"1980-06-22\", nf_2.get_pub_date(\"7189714\"))\n",
    "\n",
    "        # Do not use support files neither APIs\n",
    "        nf_3 = NIHResourceFinder(use_api_service=False)\n",
    "        self.assertIsNone(nf_3.get_pub_date(\"2942070\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 citation/oci.py <a class=\"anchor\" id=\"en_1.2.1\"></a>\n",
    "Dovendo differenziare il processo a seconda del tipo di identificativo, sono stati introdotti due variabili di classe a OCIManager: **doi_type** and **pmid_type**, i cui valori sono le stringhe “doi” e “pmid”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCIManager(object):\n",
    "    doi_type = \"doi\"\n",
    "    pmid_type = \"pmid\"\n",
    "    def __init__(self, oci_string=None, lookup_file=None, conf_file=None, doi_1=None, doi_2=None, prefix=\"\"):\n",
    "        #[...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 finder/resourcefinder.py <a class=\"anchor\" id=\"en_1.2.2\"></a>\n",
    "1) Aggiunta di **id_type tra i parametri del costruttore di ResourceFinder**, così da **differenziare l'identifier manager** coerentemente col tipo di identificativo.\n",
    "2) Differenziazione dei metodi di **normalizzazione e validazione** nella classe **APIIDResourceFinder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResourceFinder(object):\n",
    "    \"\"\"This is the abstract class that must be implemented by any resource finder\n",
    "    for a particular service (Crossref, DataCite, ORCiD, etc.). It provides\n",
    "    the signatures of the methods that should be implemented, and a basic\n",
    "    constructor.\"\"\"\n",
    "\n",
    "    def __init__(self, date=None, orcid=None, issn=None, id=None, id_type=None, **params):\n",
    "        if date is None:\n",
    "            date = CSVManager(store_new=False)\n",
    "        if orcid is None:\n",
    "            orcid = CSVManager(store_new=False)\n",
    "        if issn is None:\n",
    "            issn = CSVManager(store_new=False)\n",
    "        if id is None:\n",
    "            id = CSVManager(store_new=False)\n",
    "\n",
    "        for key in params:\n",
    "            setattr(self, key, params[key])\n",
    "\n",
    "        self.issn = issn\n",
    "        self.date = date\n",
    "        self.orcid = orcid\n",
    "        self.id_type = id_type\n",
    "        if hasattr(self, 'use_api_service'):\n",
    "            if id_type is OCIManager.doi_type:\n",
    "                print(id.csv_path)  # None\n",
    "                self.dm = DOIManager(id, self.use_api_service)\n",
    "            elif id_type is OCIManager.pmid_type:\n",
    "                self.pm = PMIDManager(id, self.use_api_service)\n",
    "            else:\n",
    "                print(\"The id_type specified is not compliant\")\n",
    "        else:\n",
    "            if id_type is OCIManager.doi_type:\n",
    "                self.dm = DOIManager(id)\n",
    "            elif id_type is OCIManager.pmid_type:\n",
    "                self.pm = PMIDManager(id)\n",
    "            else:\n",
    "                print(\"The id_type specified is not compliant\")\n",
    "\n",
    "        self.im = ISSNManager()\n",
    "        self.om = ORCIDManager()\n",
    "\n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"ResourceFinder / OpenCitations Indexes \"\n",
    "                          \"(http://opencitations.net; mailto:contact@opencitations.net)\"\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApiIDResourceFinder(ResourceFinder): #The name of the class was changed\n",
    "    \"\"\"This is the abstract class that must be implemented by any resource finder\n",
    "        for a particular service which is based on DOI retrieving via HTTP REST APIs\n",
    "        (Crossref, DataCite). It provides basic methods that are be used for\n",
    "        implementing the main methods of the ResourceFinder abstract class.\"\"\"\n",
    "\n",
    "    # The following four methods are those ones that should be implemented in\n",
    "    # the concrete subclasses of this abstract class.\n",
    "    def _get_date(self, json_obj):\n",
    "        pass\n",
    "\n",
    "    def _get_issn(self, json_obj):\n",
    "        return set()\n",
    "\n",
    "    def _get_orcid(self, json_obj):\n",
    "        return set()\n",
    "\n",
    "    def _call_api(self, id_full):\n",
    "        pass\n",
    "\n",
    "    def get_orcid(self, id_string):\n",
    "        return self._get_item(id_string, self.orcid)\n",
    "\n",
    "    def get_pub_date(self, id_string):\n",
    "        return self._get_item(id_string, self.date)\n",
    "\n",
    "    def get_container_issn(self, id_string):\n",
    "        return self._get_item(id_string, self.issn)\n",
    "\n",
    "    def is_valid(self, id_string):\n",
    "        if self.id_type == OCIManager.doi_type:\n",
    "            return self.dm.is_valid(id_string)\n",
    "        elif self.id_type == OCIManager.pmid_type:\n",
    "            return self.pm.is_valid(id_string)\n",
    "        else:\n",
    "            print(\"The id_type specified is not compliant\")\n",
    "\n",
    "    def normalise(self, id_string):\n",
    "        if self.id_type is OCIManager.doi_type:\n",
    "            return self.dm.normalise(id_string, include_prefix=True)\n",
    "        elif self.id_type is OCIManager.pmid_type:\n",
    "            return self.pm.normalise(id_string, include_prefix=True)\n",
    "        else:\n",
    "            print(\"The id_type specified is not compliant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 finder/dataciteresourcefinder.py <a class=\"anchor\" id=\"en_1.2.3\"></a>\n",
    "Conseguentemente alle modifiche in ApiIDResource finder, i **parametri dei costruttori di classe delle istanze di ApiIDresourceeFinder sono stati modificati**. \n",
    "Nello specifico, doi=doi è stato modificato in id=doi, ed è stato aggiunto id_type=OCIManager.doi_type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCiteResourceFinder(ApiIDResourceFinder):\n",
    "    def __init__(self, date=None, orcid=None, issn=None, doi=None, use_api_service=True):\n",
    "        self.api = \"https://api.datacite.org/dois/\"\n",
    "        self.use_api_service = use_api_service\n",
    "        super(DataCiteResourceFinder, self).__init__(date=date, orcid=orcid, issn=issn, id=doi, id_type=OCIManager.doi_type,\n",
    "                                                     use_api_service=use_api_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 finder/crossrefresourcefinder.pyr <a class=\"anchor\" id=\"en_1.2.4\"></a>\n",
    "Conseguentemente alle modifiche in ApiIDResource finder, i **parametri dei costruttori di classe delle istanze di ApiIDresourceeFinder sono stati modificati**. \n",
    "Nello specifico, doi=doi è stato modificato in id=doi, ed è stato aggiunto id_type=OCIManager.doi_type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossrefResourceFinder(ApiIDResourceFinder):\n",
    "    def __init__(self, date=None, orcid=None, issn=None, doi=None, use_api_service=True):\n",
    "        self.use_api_service = use_api_service\n",
    "        self.api = \"https://api.crossref.org/works/\"\n",
    "        super(CrossrefResourceFinder, self).__init__(date=date, orcid=orcid, issn=issn, id=doi, id_type=OCIManager.doi_type,\n",
    "                                                     use_api_service=use_api_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 finder/orcidresourcefinder.py <a class=\"anchor\" id=\"en_1.2.5\"></a>\n",
    "Conseguentemente alle modifiche in ApiIDResource finder, i **parametri dei costruttori di classe delle istanze di ApiIDresourceeFinder sono stati modificati**. \n",
    "Nello specifico, doi=doi è stato modificato in id=doi, ed è stato aggiunto id_type=OCIManager.doi_type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ORCIDResourceFinder(ApiIDResourceFinder):\n",
    "    def __init__(self, date=None, orcid=None, issn=None, doi=None, use_api_service=True, key=None):\n",
    "        self.key = key\n",
    "        self.use_api_service = use_api_service\n",
    "        self.api = \"https://pub.orcid.org/v2.1/search?q=\"\n",
    "        super(ORCIDResourceFinder, self).__init__(date=date, orcid=orcid, issn=issn, id=doi, id_type=OCIManager.doi_type,\n",
    "                                                  use_api_service=use_api_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.6 storer/csvmanager.py <a class=\"anchor\" id=\"en_1.2.6\"></a>\n",
    "Nuovo metodo aggiunto a csv manager, per sostituire il valore associato ad un identificativo, nella colonna \"value\" di un file csv gestito dal csv manager. \n",
    "*Probabilmente non da aggiungere nel merge, perché pensato per il mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute_value(self, id_string, value):\n",
    "    \"\"\"Substitute the value of a csv line if the value associated with the id is not the expected one\"\"\"\n",
    "    if id_string in self.data and str( value ) not in self.data[id_string]:\n",
    "        self.data[id_string].clear()\n",
    "        self.data[id_string].add( str( value ) )\n",
    "        filename = self.csv_path\n",
    "        tempfile = NamedTemporaryFile(mode='w', newline='', delete=False)\n",
    "        fields = [\"id\", \"value\"]\n",
    "        with open( filename, 'r', encoding=\"utf8\", newline='') as csvfile, tempfile:\n",
    "            reader = csv.DictReader(csvfile, fieldnames=fields)\n",
    "            writer = csv.DictWriter(tempfile, fieldnames=fields)\n",
    "            for row in reader:\n",
    "                if row[\"id\"] == id_string and str(value) != row[\"value\"]:\n",
    "                    print( 'updating row', row['id'] )\n",
    "                    row[\"id\"], row[\"value\"] = id_string, str(value)\n",
    "                row = {\"id\": row[\"id\"], \"value\": row[\"value\"]}\n",
    "                writer.writerow(row)\n",
    "        shutil.move( tempfile.name, filename )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.7 storer/datahandler.py <a class=\"anchor\" id=\"en_1.2.7\"></a>\n",
    "1) Aggiunta di **\"noci\" (NIHCitationSource) tra le source classess del DataHandler** (vedi parametri di cnc)\n",
    "\n",
    "2) Aggiunta del parametro **id_type nel costruttore di FileDataHandler**, così da poter **attribuire i possibili resource finders in relazione al tipo di identificativo specificato** (crossref, datactie e orcid nel caso del DOI e NIH nel caso del PMID)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler(object):\n",
    "    \"\"\"A class acting as a proxy for accessing specific data useful to create citations.\"\"\"\n",
    "    _source_classes = {\n",
    "        \"csv\": CSVFileCitationSource,\n",
    "        \"crossref\": CrossrefCitationSource,\n",
    "        \"croci\": CrowdsourcedCitationSource,\n",
    "        \"noci\" : NIHCitationSource,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileDataHandler(DataHandler):\n",
    "    @staticmethod\n",
    "    def _create_csv(doi_file, date_file, orcid_file, issn_file):\n",
    "        valid_doi = CSVManager(csv_path=doi_file)\n",
    "        id_date = CSVManager(csv_path=date_file)\n",
    "        id_orcid = CSVManager(csv_path=orcid_file)\n",
    "        id_issn = CSVManager(csv_path=issn_file)\n",
    "\n",
    "        return valid_doi, id_date, id_orcid, id_issn\n",
    "\n",
    "    def init(self, data, doi_file, date_file, orcid_file, issn_file, orcid, no_api, id_type):\n",
    "        valid_doi, id_date, id_orcid, id_issn = \\\n",
    "            FileDataHandler._create_csv(doi_file, date_file, orcid_file, issn_file)\n",
    "\n",
    "        if id_type == OCIManager.doi_type:\n",
    "            self.id_manager = DOIManager(valid_doi, use_api_service=not no_api)\n",
    "            crossref_rf = CrossrefResourceFinder(\n",
    "                date=id_date, orcid=id_orcid, issn=id_issn, doi=valid_doi, use_api_service=not no_api )\n",
    "            datacite_rf = DataCiteResourceFinder(\n",
    "                date=id_date, orcid=id_orcid, issn=id_issn, doi=valid_doi, use_api_service=not no_api )\n",
    "            orcid_rf = ORCIDResourceFinder(\n",
    "                date=id_date, orcid=id_orcid, issn=id_issn, doi=valid_doi,\n",
    "                use_api_service=True if orcid is not None and not no_api else False, key=orcid )\n",
    "            self.rf_handler = ResourceFinderHandler( [crossref_rf, datacite_rf, orcid_rf] )\n",
    "\n",
    "\n",
    "        elif id_type == OCIManager.pmid_type:\n",
    "            self.id_manager = PMIDManager(valid_doi, use_api_service=not no_api)\n",
    "            nih_rf = NIHResourceFinder(\n",
    "                date=id_date, orcid=id_orcid, issn=id_issn, pmid=valid_doi, use_api_service=not no_api )\n",
    "            self.rf_handler = ResourceFinderHandler( [nih_rf] )\n",
    "\n",
    "        else:\n",
    "            print(\"the id_type specified is not compliant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.8 storer/update.py <a class=\"anchor\" id=\"en_1.2.8\"></a>\n",
    "Aggiunta di una nuova **funzione per rimuovere triple dal triplestore**.\n",
    "Conseguente aggiunta di un **ulteriore parametro che specifica ogni quante triple effettuare la rimozione dal triplestore**. L'aggiunta del nuovo parametro è giustificata dal fatto che in SPARQL esiste un'operazione per aggiungere con una sola query tutte le triple contenute in un file ma non l'operazione inversa. Di conseguenza, la rimozione richiede un parsing di un file in un grafo, che poi viene iterato. Le triple indicate vengono quindi eliminate singolarmente (o in gruppi) con l'operazione DELETE DATA. \n",
    "*Probabilmente non da aggiungere nel merge, perché pensato per il mapping*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove(server, g_url, f_n, date_str, type_file, n):\n",
    "    print(\"REMOVE\")\n",
    "    server = SPARQLWrapper(server)\n",
    "    server.method = 'POST'\n",
    "    file_path = pathlib.Path(abspath(f_n)).as_uri()\n",
    "\n",
    "    #remove all the triples from the specified file\n",
    "    g = Graph()\n",
    "    g.parse(file_path, format=\"nt11\" )\n",
    "\n",
    "    i = 0\n",
    "    triples_group = \"\"\n",
    "\n",
    "    for index, (s, p, o) in enumerate(g):\n",
    "        triple = \"<\" + str( s ) + \">\" + \"<\" + str( p ) + \">\" + \"<\" + str( o ) + \">\" + \".\"\n",
    "        i += 1\n",
    "        if i == int(n):\n",
    "            triples_group = triples_group + triple + \" \"\n",
    "            i = 0\n",
    "            my_query = 'DELETE DATA {GRAPH <' + g_url + '> {' + triples_group + '} }'\n",
    "            server.setQuery(my_query)\n",
    "            server.query()\n",
    "            triples_group = \"\"\n",
    "\n",
    "        else:\n",
    "            triples_group = triples_group + triple + \" \"\n",
    "\n",
    "    if triples_group != \"\":\n",
    "        triples_group = triples_group + triple + \" \"\n",
    "        my_query = 'DELETE DATA {GRAPH <' + g_url + '> {' + triples_group + '} }'\n",
    "        server.setQuery( my_query )\n",
    "        server.query()\n",
    "\n",
    "    with open(\"updatetp_report_%s_%s.txt\" % (type_file, date_str), \"a\",\n",
    "              encoding=\"utf8\") as h:\n",
    "        h.write(\"Removed triples from file '%s'\\n\" % f_n)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    arg_parser = ArgumentParser(\"updatetp.py\", description=\"Update a triplestore with a given \"\n",
    "                                                           \"input .nt/.ttl file of new triples and \"\n",
    "                                                           \"the graph enclosing them. Use .ttl file \"\n",
    "                                                           \"if you need to preserve UTF-8 encoding.\")\n",
    "    arg_parser.add_argument(\"-s\", \"--sparql_endpoint\",\n",
    "                            dest=\"se_url\", required=True,\n",
    "                            help=\"The URL of the SPARQL endpoint.\")\n",
    "    arg_parser.add_argument(\"-i\", \"--input_file\", dest=\"input_file\", required=True,\n",
    "                            help=\"The path to the NT file to upload on the triplestore.\")\n",
    "    arg_parser.add_argument(\"-i_r\", \"--input_file_r\", dest=\"input_file_r\", required=True,\n",
    "                            help=\"The path to the NT file whose triples are to remove from the triplestore.\")\n",
    "    arg_parser.add_argument(\"-g\", \"--graph\", dest=\"graph_name\", required=True,\n",
    "                            help=\"The graph URL to associate to the triples.\")\n",
    "    arg_parser.add_argument(\"-f\", \"--force\", dest=\"force\", default=False, action=\"store_true\",\n",
    "                            help=\"Force the creation of the triples associated to the input graph.\")\n",
    "    arg_parser.add_argument(\"-n\", \"--number\", dest=\"number\", required=True,\n",
    "                            help=\"Number of triples after which the query to remove triples from the triplestore \"\n",
    "                                 \"is performed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.9 cnc.py<a class=\"anchor\" id=\"en_1.2.9\"></a>\n",
    "Aggiunta della scelta \"noci\" per il parametro --pclass, per garantire il corretto recupero dei dati dalla datasource del NIH-OCC.\n",
    "CNC è stato testato con successo anche per NOCI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_parser.add_argument( \"-c\", \"--pclass\", required=True,\n",
    "                         help=\"The name of the class of data source to use to process citatation data.\",\n",
    "                         choices=['csv', 'crossref', 'croci', 'noci'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_cnc.py (estensione per NOCI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateNewCitationsTestPmid(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.idbaseurl = \"https://pubmed.ncbi.nlm.nih.gov/\"\n",
    "        self.baseurl = \"https://w3id.org/oc/index/noci/\"#per ora non porta a niente\n",
    "        self.python = \"index%scitation%scitationsource.py\" % (sep, sep)\n",
    "        self.pclass = \"csv\"\n",
    "        self.input = \"index%stest_data%scitations_partial_pmid.csv\" % (sep, sep)\n",
    "        self.pmid_file = \"index%stest_data%scnc_valid_pmid.csv\" % (sep, sep)\n",
    "        self.date_file = \"index%stest_data%scnc_id_date_pmid.csv\" % (sep, sep)\n",
    "        self.orcid_file = \"index%stest_data%scnc_id_orcid_pmid.csv\" % (sep, sep)\n",
    "        self.issn_file = \"index%stest_data%scnc_id_issn_pmid.csv\" % (sep, sep)\n",
    "        self.orcid = None\n",
    "        self.lookup = \"index%stest_data%slookup_full.csv\" % (sep, sep)\n",
    "        self.data = \"index%stest_data%stmp_workflow_pmid\" % (sep, sep)\n",
    "        self.prefix = \"0160\"\n",
    "        self.agent = \"https://w3id.org/oc/index/prov/ra/1\"\n",
    "        self.source = \"https://doi.org/10.35092/yhjc.c.4586573.v16\"\n",
    "        self.service = \"OpenCitations Index: NOCI\"\n",
    "        self.verbose = True\n",
    "        self.no_api = False\n",
    "        self.id_type = OCIManager.pmid_type\n",
    "\n",
    "\n",
    "        self.citation_list = self.__load_citations(\"index%stest_data%scitations_pmid_data.csv\" % (sep, sep),\n",
    "                                                   \"index%stest_data%scitations_pmid_prov.csv\" % (sep, sep))\n",
    "        self.data_path = self.data + sep + \"data\" + sep + \"**\" + sep + \"*.csv\"\n",
    "        self.prov_path = self.data + sep + \"prov\" + sep + \"**\" + sep + \"*.csv\"\n",
    "\n",
    "        if exists(self.data):\n",
    "            rmtree(self.data)\n",
    "\n",
    "    def __load_citations(self, data, prov):\n",
    "        return CitationStorer.load_citations_from_file(data, prov, baseurl=\"https://pubmed.ncbi.nlm.nih.gov/\",\n",
    "            service_name=self.service, id_type=\"pmid\",\n",
    "            id_shape=\"https://pubmed.ncbi.nlm.nih.gov/([[XXX]])\", citation_type=None) #NOTE: discuss id_shape -- il doi può arrivare con caratteri strani,, dvo decodarlo\n",
    "#xxx sostutuisce con l'identificativo di quella specifica citazione\n",
    "\n",
    "    def __citations_csv(self, origin_citation_list, stored_citation_list):\n",
    "        l1 = [cit.get_citation_csv() for cit in origin_citation_list]\n",
    "        l2 = [cit.get_citation_csv() for cit in stored_citation_list]\n",
    "        self.assertEqual(len(l1), len(l2))\n",
    "        self.assertEqual(set(l1), set(l2))\n",
    "\n",
    "    def __test_citations(self):\n",
    "        data_csv = glob(self.data_path, recursive=True)\n",
    "        prov_csv = glob(self.prov_path, recursive=True)\n",
    "        self.assertEqual(len(data_csv), 1)\n",
    "        self.assertEqual(len(prov_csv), 1)\n",
    "        self.__citations_csv(self.citation_list, self.__load_citations(data_csv[0], prov_csv[0]))\n",
    "\n",
    "    def test_execute_workflow(self):\n",
    "        new_citations_added, citations_already_present, error_in_pmids_existence = \\\n",
    "            execute_workflow( self.idbaseurl, self.baseurl, self.pclass, self.input, self.pmid_file,\n",
    "                              self.date_file, self.orcid_file, self.issn_file, self.orcid, self.lookup, self.data,\n",
    "                              self.prefix, self.agent, self.source, self.service, self.verbose, self.no_api, 1, self.id_type)\n",
    "\n",
    "        self.assertEqual(new_citations_added, 6)\n",
    "        self.assertEqual(citations_already_present, 0)\n",
    "        self.assertEqual(error_in_pmids_existence, 0)\n",
    "        self.__test_citations()\n",
    "\n",
    "        new_citations_added, citations_already_present, error_in_pmids_existence = \\\n",
    "            execute_workflow( self.idbaseurl, self.baseurl, self.pclass, self.input, self.pmid_file,\n",
    "                              self.date_file, self.orcid_file, self.issn_file, self.orcid, self.lookup, self.data,\n",
    "                              self.prefix, self.agent, self.source, self.service, self.verbose, self.no_api, 1, self.id_type)\n",
    "        self.assertEqual(new_citations_added, 0)\n",
    "        self.assertEqual(citations_already_present, 6)\n",
    "        self.assertEqual(error_in_pmids_existence, 0)\n",
    "        self.__test_citations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE\n",
    "Ricontrollare il processo di generazione OCI per PMID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAMOSE - NOCI configuration file<a class=\"anchor\" id=\"en_2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAMOSE - indexapi.py <a class=\"anchor\" id=\"en_2.2\"></a>\n",
    "Sviluppo di funzioni aggiuntive per l'operazione **metadata**. Le funzioni sviluppate permettono di recuperare metadati specifici per i PMID dal servizio API offerto dal NIH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __nih_parser(pmid):\n",
    "    api = \"https://pubmed.ncbi.nlm.nih.gov/%s\"\n",
    "    pmid_sep = str(pmid) + \"%s\"\n",
    "    display_opt = \"/?format=pubmed\"\n",
    "\n",
    "    try:\n",
    "        r = get(api % pmid_sep % display_opt,\n",
    "                headers={\"User-Agent\": \"NOCI REST API (via OpenCitations - \"\n",
    "                                       \"http://opencitations.net; mailto:contact@opencitations.net)\"}, timeout=30)\n",
    "        if r.status_code == 200:\n",
    "            r.encoding = \"utf-8\"\n",
    "            soup = BeautifulSoup(r.text, features=\"lxml\")\n",
    "            body = str(soup.find(id=\"article-details\"))\n",
    "\n",
    "            authors = _get_author_nih(body)\n",
    "\n",
    "\n",
    "            year = \"\"\n",
    "            nih_date = _get_date_nih(body)\n",
    "            if nih_date is not None:\n",
    "                year = __normalise(nih_date)\n",
    "\n",
    "            title = \"\"\n",
    "            nih_title = _get_title_nih(body)\n",
    "            if nih_title is not None:\n",
    "                title = __create_title(nih_title)\n",
    "\n",
    "            source_title = \"\"\n",
    "            nih_cont_title = _get_cont_title_nih(body)\n",
    "            if nih_cont_title is not None:\n",
    "                source_title = __create_title(nih_cont_title)\n",
    "\n",
    "            volume = \"\"\n",
    "            issue = \"\"\n",
    "            page = \"\"\n",
    "            source_id = \"\"\n",
    "\n",
    "            print ([\"; \".join(authors), year, title, source_title, volume, issue, page, source_id])\n",
    "            return [\"; \".join(authors), year, title, source_title, volume, issue, page, source_id]\n",
    "\n",
    "    except Exception as e:\n",
    "        pass  # do nothing\n",
    "\n",
    "def _get_author_nih(txt_obj):\n",
    "    result = []\n",
    "    authors = re.findall(\"FAU\\s+-\\s+((([A-Z])\\w*('|-|\\.)?)(\\s*([A-Z])\\w*('|-|\\.)?)*,\\s*(([A-Z])([^\\S\\r\\n][A-Z])*))\", txt_obj)\n",
    "    for i in authors:\n",
    "        author = re.search(\"(([A-Z])\\w*('|-|\\.)?)(\\s*([A-Z])\\w*('|-|\\.)?)*,\\s*(([A-Z])([^\\S\\r\\n][A-Z])*)\", str(i)).group(0)\n",
    "        result.append(__normalise(author))\n",
    "    return result\n",
    "\n",
    "def _get_title_nih(txt_obj):\n",
    "    title = re.search(\"TI\\s+-\\s+([^\\n]+)\", txt_obj).group(1)\n",
    "    re_search = re.search(\"([^\\n]+)\", title)\n",
    "    if re_search is not None:\n",
    "        result = re_search.group(0)\n",
    "    return result\n",
    "\n",
    "def _get_cont_title_nih(txt_obj):\n",
    "    cont_title = re.search(\"JT\\s+-\\s+([^\\n]+)\", txt_obj).group(1)\n",
    "    re_search = re.search(\"([^\\n]+)\", cont_title)\n",
    "    if re_search is not None:\n",
    "        result = re_search.group(0)\n",
    "    return result\n",
    "\n",
    "\n",
    "def _get_date_nih(txt_obj):\n",
    "    date = re.search(\"DP\\s+-\\s+(\\d{4}(\\s?(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec))?(\\s?((3[0-1])|([1-2][0-9])|([0]?[1-9])))?)\", txt_obj).group(1)\n",
    "    re_search = re.search(\"(\\d{4})\\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s+((3[0-1])|([1-2][0-9])|([0]?[1-9]))\", date)\n",
    "    if re_search is not None:\n",
    "        result = re_search.group(0)\n",
    "        datetime_object = datetime.strptime(result, '%Y %b %d')\n",
    "        return datetime.strftime(datetime_object, '%Y-%m-%d')\n",
    "    else:\n",
    "        re_search = re.search(\"(\\d{4})\\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\", date)\n",
    "        if re_search is not None:\n",
    "            result = re_search.group(0)\n",
    "            datetime_object = datetime.strptime(result, '%Y %b')\n",
    "            return datetime.strftime(datetime_object, '%Y-%m')\n",
    "        else:\n",
    "            re_search = re.search(\"(\\d{4})\", date)\n",
    "            if re_search is not None:\n",
    "                result = re.search(\"(\\d{4})\", date).group(0)\n",
    "                datetime_object = datetime.strptime(result, '%Y')\n",
    "                return datetime.strftime(datetime_object, '%Y')\n",
    "            else:\n",
    "                return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09/03 - 15/03 (_________) <a class=\"anchor\" id=\"entry_3\"></a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15/03 - 22/03 (Prometheus file format study and data extraction) <a class=\"anchor\" id=\"entry_4\"></a>\n",
    "\n",
    "Prometheus File Format -  metrics / OpenMetrics types,Spiegazione dei parametri del Prometheus file format in OC, data extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prometheus File Format -  metrics / OpenMetrics types\n",
    "\n",
    "<ul>\n",
    "    <li> <b>Counter</b>: cumulative metric that only increases over time, like the number of requests to an endpoint.</li>\n",
    "    <li><b>Gauge</b>: instantaneous measurements of a value. They can be arbitrary values which will be recorded. Gauges represent a random value that can increase and decrease randomly such as the load of your system. </li>\n",
    "    <li><b>Histogram</b>: A histogram samples observations (usually things like request durations or response sizes) and counts them in configurable buckets. It also provides a sum of all observed values. A histogram with a base metric name of exposes multiple time series during a scrape</li>\n",
    "    <li><b>Summary</b>: Similar to a histogram, a summary samples observations (usually things like request durations and response sizes). While it also provides a total count of observations and a sum of all observed values, it calculates configurable quantiles over a sliding time window. A summary with a base metric name of also exposes multiple time series during a scrape</li>\n",
    "</ul>\n",
    "\n",
    "#### Fonti:\n",
    "<ol>\n",
    "    <li><a href=\"https://sysdig.com/blog/prometheus-metrics/\">sysdig.com</a></li>\n",
    "    <li><a href=\"https://www.udemy.com/share/103iRG3@78CD2xvy-1vMXY-ZXPgzP9dG4nSXmHE9zDaRoUur8Hjc0sCTnKU2KEwoWDaqUaQJXg==/\">udemy.com</a></li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prometheus File Format - data extraction\n",
    "Codice per estrarre dati dal prometheus file format restituito dall'API per i dati di log in OC.\n",
    "Il codice permette di accedere al nome della metrica, alle labels associate e ai suoi valori. \n",
    "#### Fonti:\n",
    "<ol>\n",
    "    <li><a href=\"https://python.hotexamples.com/it/examples/prometheus_client.parser/-/text_string_to_metric_families/python-text_string_to_metric_families-function-examples.html\">python.hotexamples.com</a></li>\n",
    "    <li> stackoverflow.com for<a href=\"https://stackoverflow.com/questions/60050507/reading-prometheus-metric-using-python\"> reading prometheus metric</a> and for <a href=\"https://stackoverflow.com/questions/988228/convert-a-string-representation-of-a-dictionary-to-a-dictionary\"> reading a string dictionary as a dictionary</a></li>\n",
    "    <li><a href=\"https://www.robustperception.io/productive-prometheus-python-parsing\">/www.robustperception.io</a></li>\n",
    "    <li><a href=\"https://www.robustperception.io/productive-prometheus-python-parsing\">/www.robustperception.io</a></li>\n",
    "    \n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from urllib.parse import quote\n",
    "from json import loads\n",
    "import json\n",
    "from prometheus_api_client import PrometheusConnect\n",
    "import datetime\n",
    "import time\n",
    "from prometheus_client.parser import text_string_to_metric_families\n",
    "import requests\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric: opencitations_http_requests_total\n",
      "endpoint: /index/api/v1/\n",
      "metric: opencitations_http_requests_total\n",
      "endpoint: /ccc/\n",
      "metric: opencitations_http_requests_total\n",
      "endpoint: /ccc/sparql\n",
      "metric: opencitations_http_requests_total\n",
      "endpoint: /index/coci/ci/\n",
      "metric: opencitations_http_requests_total\n",
      "endpoint: /sparql\n",
      "metric: opencitations_http_requests_total\n",
      "endpoint: /index/coci/api/v1/\n",
      "metric: opencitations_http_requests_total\n",
      "endpoint: /api/v1/\n",
      "metric: opencitations_http_requests_total\n",
      "endpoint: /intrepid\n",
      "metric: opencitations_http_requests_total\n",
      "endpoint: /index/croci/ci/\n",
      "metric: opencitations_http_requests_total\n",
      "endpoint: /index/croci/api/v1/\n",
      "metric: opencitations_http_requests_total\n",
      "endpoint: /oci\n",
      "metric: opencitations_http_requests_total\n",
      "endpoint: /ccc/api/v1/\n",
      "metric: opencitations_http_requests_total\n",
      "endpoint: /corpus/\n",
      "metric: opencitations_http_requests_total\n",
      "endpoint: /index/sparql\n"
     ]
    }
   ],
   "source": [
    "url = \"http://opencitations.net/statistics/\"\n",
    "gen = \"01\"\n",
    "feb = \"02\"\n",
    "mar = \"03\"\n",
    "apr = \"04\"\n",
    "mag = \"05\"\n",
    "giu = \"06\"\n",
    "lug = \"07\"\n",
    "ago = \"08\"\n",
    "sep = \"09\"\n",
    "ott = \"10\"\n",
    "nov = \"11\"\n",
    "dic = \"12\"\n",
    "y_21 = \"2021\"\n",
    "y_22 = \"2022\"\n",
    "\n",
    "def call_api(year, month, api, metric, label):\n",
    "    PROMETHEUS = api + year + \"-\" + month\n",
    "    metrics = requests.get(PROMETHEUS).content.decode('utf-8')\n",
    "    #print(metrics)\n",
    "    for family in text_string_to_metric_families(metrics):\n",
    "        #print(family)\n",
    "        for sample in family.samples:\n",
    "            #print(\"Name: {0} Labels: {1} Value: {2}\".format(*sample))\n",
    "            if metric in \"Name:{0}\".format(*sample):\n",
    "                print(\"metric: opencitations_http_requests_total\")\n",
    "                res = \"{1}\".format(*sample)\n",
    "                labels_dict = ast.literal_eval(res)\n",
    "                for k,v in labels_dict.items():\n",
    "                    if k == label:\n",
    "                        print(\"endpoint:\", v)\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "call_api(y_22, gen, url, \"opencitations_http_requests_total\", \"endpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spiegazione dei parametri del Prometheus file format in OC\n",
    "\n",
    "Output file format\n",
    "The output file contains the following fields:\n",
    "\n",
    "<ol>\n",
    "    <li><b>opencitations_http_requests</b>: counter of http requests. It is represented by a Counter in prometheus where each label indicates a counter for a specific endpoint, e.g. opencitations_http_requests_total{endpoint=\"/index/croci/ci/\"} is the the counter for the endpoint /index/croci/ci/.</li>\n",
    "    <li><b>opencitations_http_requests_created</b>: contains the timestamp indicating the creation date of each counter opencitations_http_requests{*}.</li>\n",
    "        <li><b>opencitations_agg_counter_total</b>:  aggregate counter of http requests. It is represented by a Counter in prometheus where each label indicates a counter for a specific aggregation, endpoints are grouped as follows: \n",
    "            <ol>\n",
    "                <li><b>opencitations_agg_counter_total{category=\"sparql_requests\"}</b></li>\n",
    "                    <ol>\n",
    "                        <li>/sparql</li>\n",
    "                        <li>/index/sparql</li>\n",
    "                        <li>/ccc/sparql</li>\n",
    "                    </ol>\n",
    "                <li><b>opencitations_agg_counter_total{category=\"additional_services_requests\"}</b></li>\n",
    "                <ol>\n",
    "                    <li>/oci</li>\n",
    "                    <li>/intrepid</li>\n",
    "                </ol>\n",
    "            <li><b>opencitations_agg_counter_total{category=\"dataset_requests\"}</b></li>\n",
    "                <ol>\n",
    "                    <li>/corpus/</li>\n",
    "                    <li>/index/coci/ci/</li>\n",
    "                    <li>/index/croci/ci/</li>\n",
    "                    <li>/ccc/</li>\n",
    "                </ol>\n",
    "                <li><b>opencitations_agg_counter_total{category=\"oc_api_requests\"}</b></li>\n",
    "                <ol>\n",
    "                    <li>/index/api/v1/</li>\n",
    "                    <li>/index/coci/api/v1/</li>\n",
    "                    <li>/index/croci/api/v1/</li>\n",
    "                    <li>/ccc/api/v1/</li>\n",
    "                    <li>/api/v1/</li>\n",
    "                </ol>\n",
    "            </ol>\n",
    "    <li><b>agg_counter_created:</b>contains the timestamp indicating the creation date of each aggregated counter opencitations_agg_counter_total{*}. </li>\n",
    "        <li><b>opencitations_harvested_data_sources</b>: number of sources used for the entities creation. For now 4</li>\n",
    "        <li><b>opencitations_indexed_records</b>: number of entities, i.e. number of citations in our indexes.</li>\n",
    "    </ol>\n",
    "\n",
    "\n",
    "#### Fonte\n",
    "<a href=\"https://github.com/opencitations/statistics/tree/master/script\">github.com/opencitations/statistics</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domande\n",
    "<ol>\n",
    "    <li>Seguendo l'approccio adottato finora, pensavo di estrarre i dati dal file format e utilizzarli in delle visualizzazioni in d3.js. Non ho usato prometheus client library nell'approccio esposto sopra (ho fatto qualche tentativo ma ho capito meglio la parte per intervenire sul formato rispetto a quella per estrarre i dati). </li>\n",
    "       <li> Per le visualizzazioni sarebbe meglio utilizzare qualcosa di più specifico (Sysdig ?) o è sufficiente estrarre i dati e seguire un approccio generale (che avrei utilizzato con qualsiasi altro tipo di dati estratti da un altro tipo di file format?) </li>\n",
    "    <li>Dovrei fare un uso specifico di statistics/script? </li>\n",
    "    <li>opencitations_harvested_data_sources\n",
    "opencitations_indexed_records non hanno spiegazione : ir --> numero di entità, ovvero di citazioni nei nostri indici. ds --> n. di sorgenti usate per creare entità (4 per ora, costanti per ora)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prometheus file format visualizations - Python (22/03/22 - 29/03/22) <a class=\"anchor\" id=\"entry_5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Python Client Library \n",
    "Le librerie a disposizione sono pensate per manipolare le metriche con specifici linguaggi di programmazione. Tuttavia, ai fini di visualizzare dati, l'unica funzionalità della libreria utilizzabile è quella che è stata già sfruttata, ovvero il parser.\n",
    "\n",
    "#### Fonti:\n",
    "<a href=\"https://github.com/prometheus/client_python#parser\"> Parser della Python Clien Library </a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Estrazione valori mensili da labels\n",
    "Per le metriche che hanno labels e hanno più valori per prom mensile, differenziati dalle labels.\n",
    "<ol>\n",
    "    <li>opencitations_http_requests_total: un valore diverso per endpoint (counter)</li>\n",
    "    <li>opencitations_http_requests_created: un valore diverso per endpoint (gauge)</li>\n",
    "    <li>opencitations_agg_counter_total: un valore diverso per ogni category (counter)</li>\n",
    "    <li>opencitations_agg_counter_created: un valore diverso per ogni category (gauge)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1) Struttura concettuale delle richieste \n",
    "<a href = \"struttura_metriche.png\"><img src =\"struttura_metriche.png\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'others_requests': {'endpoints': {}, 'value': 0}, 'dataset_requests': {'endpoints': {'/corpus/': 0, '/index/coci/ci/': 0, '/index/croci/ci/': 0, '/ccc/': 0}, 'value': 0}, 'additional_services_requests': {'endpoints': {'/oci': 0, '/intrepid': 0}, 'value': 0}, 'sparql_requests': {'endpoints': {'/sparql': 0, '/index/sparql': 0, '/ccc/sparql': 0}, 'value': 0}, 'oc_api_requests': {'endpoints': {'/index/api/v1/': 0, '/index/coci/api/v1/': 0, '/index/croci/api/v1/': 0, '/ccc/api/v1/': 0, '/api/v1/': 0}, 'value': 0}}\n"
     ]
    }
   ],
   "source": [
    "counter_total_dict = {\"others_requests\": {\"endpoints\":{}, \"value\":0} ,\"dataset_requests\": {\"endpoints\":{\"/corpus/\":0, \"/index/coci/ci/\":0, \"/index/croci/ci/\":0, \"/ccc/\":0}, \"value\":0},\"additional_services_requests\": {\"endpoints\":{\"/oci\":0, \"/intrepid\":0}, \"value\":0}, \"sparql_requests\": {\"endpoints\":{\"/sparql\":0, \"/index/sparql\":0, \"/ccc/sparql\":0}, \"value\":0}, \"oc_api_requests\": {\"endpoints\":{ \"/index/api/v1/\":0, \"/index/coci/api/v1/\":0, \"/index/croci/api/v1/\":0, \"/ccc/api/v1/\":0, \"/api/v1/\":0}, \"value\":0}}\n",
    "print(counter_total_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'oc_api_requests': 1376426.0, 'sparql_requests': 1388241.0, 'additional_services_requests': 798.0, 'dataset_requests': 85843.0, 'others_requests': 187739.0}\n"
     ]
    }
   ],
   "source": [
    "url = \"http://opencitations.net/statistics/\"\n",
    "gen = \"01\"\n",
    "feb = \"02\"\n",
    "mar = \"03\"\n",
    "apr = \"04\"\n",
    "mag = \"05\"\n",
    "giu = \"06\"\n",
    "lug = \"07\"\n",
    "ago = \"08\"\n",
    "sep = \"09\"\n",
    "ott = \"10\"\n",
    "nov = \"11\"\n",
    "dic = \"12\"\n",
    "y_21 = \"2021\"\n",
    "y_22 = \"2022\"\n",
    "\n",
    "def get_metrics_value_by_label(year, month, api, metric, label):\n",
    "    result = dict()\n",
    "    PROMETHEUS = api + year + \"-\" + month\n",
    "    r = get(PROMETHEUS)\n",
    "    if r.status_code == 200:\n",
    "        metrics = requests.get(PROMETHEUS).content.decode('utf-8')\n",
    "        for family in text_string_to_metric_families(metrics):\n",
    "            for sample in family.samples:\n",
    "                if metric in \"Name:{0}\".format(*sample):\n",
    "                    res = \"{1}\".format(*sample)\n",
    "                    labels_dict = ast.literal_eval(res)\n",
    "                    for k,v in labels_dict.items():\n",
    "                        if k == label:\n",
    "                            result[v] = float(\"{2}\".format(*sample))\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "    return result\n",
    "\n",
    "#get_metrics_value_by_label(y_22, gen, url, \"opencitations_http_requests_total\", \"endpoint\")\n",
    "agg_counter_total_dict = get_metrics_value_by_label(y_22, gen, url, \"opencitations_agg_counter_total\", \"category\")\n",
    "print(agg_counter_total_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'others_requests': {'endpoints': {}, 'value': 187739.0}, 'dataset_requests': {'endpoints': {'/corpus/': 0, '/index/coci/ci/': 0, '/index/croci/ci/': 0, '/ccc/': 0}, 'value': 85843.0}, 'additional_services_requests': {'endpoints': {'/oci': 0, '/intrepid': 0}, 'value': 798.0}, 'sparql_requests': {'endpoints': {'/sparql': 0, '/index/sparql': 0, '/ccc/sparql': 0}, 'value': 1388241.0}, 'oc_api_requests': {'endpoints': {'/index/api/v1/': 0, '/index/coci/api/v1/': 0, '/index/croci/api/v1/': 0, '/ccc/api/v1/': 0, '/api/v1/': 0}, 'value': 1376426.0}}\n"
     ]
    }
   ],
   "source": [
    "for k,v in counter_total_dict.items():\n",
    "    for i,j in agg_counter_total_dict.items():\n",
    "        if k == i:\n",
    "            v[\"value\"] += j\n",
    "print(counter_total_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/index/api/v1/': 0.0, '/ccc/': 48668.0, '/ccc/sparql': 190.0, '/index/coci/ci/': 76.0, '/sparql': 7917.0, '/index/coci/api/v1/': 302336.0, '/api/v1/': 1074090.0, '/intrepid': 191.0, '/index/croci/ci/': 13.0, '/index/croci/api/v1/': 0.0, '/oci': 607.0, '/ccc/api/v1/': 0.0, '/corpus/': 37086.0, '/index/sparql': 1380134.0}\n"
     ]
    }
   ],
   "source": [
    "endpoints_requests_dict= get_metrics_value_by_label(y_22, gen, url, \"opencitations_http_requests_total\", \"endpoint\")\n",
    "print(endpoints_requests_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'others_requests': {'endpoints': {}, 'value': 187739.0}, 'dataset_requests': {'endpoints': {'/corpus/': 37086.0, '/index/coci/ci/': 76.0, '/index/croci/ci/': 13.0, '/ccc/': 48668.0}, 'value': 85843.0}, 'additional_services_requests': {'endpoints': {'/oci': 607.0, '/intrepid': 191.0}, 'value': 798.0}, 'sparql_requests': {'endpoints': {'/sparql': 7917.0, '/index/sparql': 1380134.0, '/ccc/sparql': 190.0}, 'value': 1388241.0}, 'oc_api_requests': {'endpoints': {'/index/api/v1/': 0.0, '/index/coci/api/v1/': 302336.0, '/index/croci/api/v1/': 0.0, '/ccc/api/v1/': 0.0, '/api/v1/': 1074090.0}, 'value': 1376426.0}}\n"
     ]
    }
   ],
   "source": [
    "for k,v in counter_total_dict.items():\n",
    "    for i,j in endpoints_requests_dict.items():\n",
    "        if i in (v[\"endpoints\"]).keys():\n",
    "            v[\"endpoints\"][i] += j\n",
    "            \n",
    "print(counter_total_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2) Visualizzazione a Torta delle categorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = []\n",
    "sizes = []\n",
    "for k,v in counter_total_dict.items():\n",
    "    labels.append(k)\n",
    "    sizes.append(v[\"value\"])\n",
    "\n",
    "explode = (0, 0, 0, 0.1, 0.1)\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', radius = 0.9,\n",
    "        shadow=True, startangle=90, pctdistance=0.8, labeldistance=1.3, textprops={'fontsize': 14})\n",
    "ax1.axis('equal')\n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3) Visualizzazione a Torta degli endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37086, 76, 13, 48668, 607, 191, 7917, 1380134, 190, 0, 302336, 0, 0, 1074090]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = []\n",
    "sizes = []\n",
    "for k,v in counter_total_dict.items():\n",
    "    for i,j in v.items():\n",
    "        if i == \"endpoints\":\n",
    "            for f,e in j.items():      \n",
    "                labels.append(f)\n",
    "                sizes.append(int(e))\n",
    "print(sizes)\n",
    "\n",
    "                \n",
    "y = np.array(sizes)\n",
    "\n",
    "\n",
    "colors = ['yellowgreen','red','gold','lightskyblue','white','lightcoral','blue','pink', 'darkgreen','yellow','grey','violet','magenta','cyan']\n",
    "\n",
    "porcent = 100.*y/y.sum()\n",
    "labels = ['{0} - {1:1.2f} %'.format(i,j) for i,j in zip(labels, porcent)]\n",
    "explode = (0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1, 0, 0, 0, 0.1)\n",
    "patches, texts = plt.pie(sizes, colors=colors, startangle=90, radius=1.2)\n",
    "sort_legend = True\n",
    "if sort_legend:\n",
    "    patches, labels, dummy =  zip(*sorted(zip(patches, labels, sizes),\n",
    "                                          key=lambda sizes: sizes[2],\n",
    "                                          reverse=True))\n",
    "\n",
    "plt.legend(patches, labels, loc='center left', bbox_to_anchor=(-0.1, 1.),\n",
    "           fontsize=8)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Estrazione valori mensili dal valore delle metriche\n",
    "Per le metriche che non hanno labels e hanno un solo valore per prom mensile\n",
    "<ol>\n",
    "    <li>opencitations_indexed_records: interessante vedere se cresce ad intervalli, magari con un barchart</li>\n",
    "    <li>opencitations_harvested_data_sources: costante, non è rilevante</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'opencitations_indexed_records_2022_01': 1271360867.0}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_metrics_value(year, month, api, metric):\n",
    "    result = dict()\n",
    "    PROMETHEUS = api + year + \"-\" + month\n",
    "    r = get(PROMETHEUS)\n",
    "    if r.status_code == 200:\n",
    "        metrics = requests.get(PROMETHEUS).content.decode('utf-8')\n",
    "        #print(metrics)\n",
    "        for family in text_string_to_metric_families(metrics):\n",
    "            #print(family)\n",
    "            for sample in family.samples:\n",
    "                #print(\"Name: {0} Labels: {1} Value: {2}\".format(*sample))\n",
    "                if metric in \"Name:{0}\".format(*sample):\n",
    "                    res = \"{2}\".format(*sample)\n",
    "                    metric = metric + \"_\" + year + \"_\" + month\n",
    "                    result[metric] = float(res)\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    return result\n",
    "\n",
    "get_metrics_value(y_22, gen, url, \"opencitations_indexed_records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Raggruppamento dei valori per gruppi di mesi (da valori mensili direttamente dalle metriche)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'opencitations_indexed_records_2021_01': 759516507.0,\n",
       "  'opencitations_indexed_records_2021_02': 759516507.0,\n",
       "  'opencitations_indexed_records_2021_03': 759516507.0},\n",
       " 1: {'opencitations_indexed_records_2021_04': 759516507.0,\n",
       "  'opencitations_indexed_records_2021_05': 759516507.0,\n",
       "  'opencitations_indexed_records_2021_06': 759516507.0},\n",
       " 2: {'opencitations_indexed_records_2021_07': 759516507.0,\n",
       "  'opencitations_indexed_records_2021_08': 1094394688.0,\n",
       "  'opencitations_indexed_records_2021_09': 1186958898.0},\n",
       " 3: {'opencitations_indexed_records_2021_10': 1186958898.0,\n",
       "  'opencitations_indexed_records_2021_11': 1235170583.0,\n",
       "  'opencitations_indexed_records_2021_12': 1235170583.0},\n",
       " 4: {'opencitations_indexed_records_2022_01': 1271360867.0,\n",
       "  'opencitations_indexed_records_2022_02': 1271360867.0}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collect_metrics_values(n, api, metric):\n",
    "    count = 0\n",
    "    result_dict = {}\n",
    "    metrics_values = dict()\n",
    "    months = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]\n",
    "    years = [\"2021\", \"2022\"]\n",
    "    for y in years:\n",
    "        for m in months:\n",
    "            res_values = get_metrics_value(y, m, api, metric)\n",
    "            if res_values is not None:\n",
    "                if len(metrics_values) == n:\n",
    "                    result_dict[count] = metrics_values\n",
    "                    metrics_values = dict()\n",
    "                    count += 1\n",
    "                    (metrics_values).update(res_values)\n",
    "                else:\n",
    "                    (metrics_values).update(res_values)\n",
    "            \n",
    "            else:\n",
    "                result_dict[count] = metrics_values\n",
    "                metrics_values = dict()\n",
    "                count += 1\n",
    "                return result_dict\n",
    "    return result_dict\n",
    "\n",
    "collect_metrics_values(3, url, \"opencitations_indexed_records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 759516507.0,\n",
       " 1: 759516507.0,\n",
       " 2: 1186958898.0,\n",
       " 3: 1235170583.0,\n",
       " 4: 1271360867.0}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def group_metrics_values(n, api, metric):\n",
    "    max_values_dict = dict()\n",
    "    metrics_nested_dicts = collect_metrics_values(n, api, metric)\n",
    "    for k,v in metrics_nested_dicts.items():\n",
    "        max_val = max(v.values())\n",
    "        max_values_dict[k] = max_val\n",
    "    return max_values_dict\n",
    "    \n",
    "group_metrics_values(3, url, \"opencitations_indexed_records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Visualizzazione della crescita trimestrale degli indexed records in OC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "records = [1271.3608670, 1235.1705830, 1186.9588980, 759.5165070, 759.5165070]\n",
    "\n",
    "records_series = pd.Series(records)\n",
    "y_labels = [\"01-03/22\", \"10-12/21\", \"07-09/21\", \"04-06/21\", \"01-03/21\"]\n",
    "\n",
    "# Plot the figure.\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = records_series.plot(kind='barh')\n",
    "ax.set_title('Indexed Records in OC - Gennaio 2021 / Febbraio 2022')\n",
    "ax.set_xlabel('indexed records in OC - in milioni')\n",
    "ax.set_ylabel('Date')\n",
    "ax.set_yticklabels(y_labels)\n",
    "ax.set_xlim(-40, 2000) # expand xlim to make labels easier to read\n",
    "\n",
    "rects = ax.patches\n",
    "\n",
    "for rect in rects:\n",
    "    # Get X and Y placement of label from rect.\n",
    "    x_value = rect.get_width()\n",
    "    y_value = rect.get_y() + rect.get_height() / 2\n",
    "\n",
    "    space = 5\n",
    "    ha = 'left'\n",
    "    if x_value < 0:\n",
    "        space *= -1\n",
    "        ha = 'right'\n",
    "    label = \"{:.1f}\".format(x_value)\n",
    "    plt.annotate(\n",
    "        label,                      # Use `label` as label\n",
    "        (x_value, y_value),         # Place label at end of the bar\n",
    "        xytext=(space, 0),          # Horizontally shift label by `space`\n",
    "        textcoords=\"offset points\", # Interpret `xytext` as offset in points\n",
    "        va='center',                # Vertically center label\n",
    "        ha=ha)                      # Horizontally align label differently for\n",
    "                                    # positive and negative values.\n",
    "\n",
    "#source: https://stackoverflow.com/questions/28931224/adding-value-labels-on-a-matplotlib-bar-chart\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(\"indexed_records_01_21-02_22.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In verticale si può fare per le classi delle richieste !!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "[759.5165070, 759.5165070, 1186.9588980, 1235.1705830, 1271.3608670]\n",
    "\n",
    "Data = {'Trimestri': [\"01-03/21\", \"04-06/21\", \"07-09/21\", \"10-12/21\", \"01-03/22\"],\n",
    "        'Indexed Records in OC (milioni)': [759.5165070, 759.5165070, 1186.9588980, 1235.1705830, 1271.3608670]\n",
    "       }\n",
    "  \n",
    "df = pd.DataFrame(Data,columns=['Trimestri','Indexed Records in OC (milioni)'])\n",
    "  \n",
    "plt.plot(df['Trimestri'], df['Indexed Records in OC (milioni)'], color='red', marker='*')\n",
    "    \n",
    "plt.title('Crescita Indexed Records in OC, Gennaio 2021 - Febbraio 2022', fontsize=14, x=0.5, y=1.1)\n",
    "plt.xlabel('Trimestri', fontsize=14)\n",
    "plt.ylabel('Indexed Records in OC (milioni)', fontsize=14)\n",
    "plt.grid(True)\n",
    "\n",
    "for x,y in zip(df['Trimestri'],df['Indexed Records in OC (milioni)']):\n",
    "    label = \"{:.2f}\".format(y)\n",
    "    plt.annotate(label,(x,y), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idee e Proposte\n",
    "#### Visualizzazioni \n",
    "<ol>\n",
    "    <li>Pie Chart gerarchico per visualizzare richieste a categorie di servizi e (nello specifico) ad endpoints (annuale)</li>\n",
    "    <li>Bar chart per visualizzare categorie di servizi(annuale)</li>\n",
    "    <li>Line graph per visualizzare andamento trimestrale nel corso di un anno (aumento degli indexed records)</li>\n",
    "    <li>Line graph runtime con axios dove l'utente specifica due date e vede la crescita del grafico (date selezionabili)</li>\n",
    "    <li>Pie chart runtime per visualizzare distribuzione delle richieste per categorie su base mensile (mensile)</li>\n",
    "</ol>\n",
    "\n",
    "#### Da Fare\n",
    "<ol>\n",
    "    <li>Landing Page HTML per visualizzazioni</li>\n",
    "    <li>Visualizzazioni in JS partendo da dati estratti con Python</li>\n",
    "    <li>Visualizzazioni JS con dati estratti con JS</li>\n",
    "</ol>\n",
    "\n",
    "#### Fonti \n",
    "<ol>\n",
    "    <li><a href=\"https://github.com/axios/axios\">https://github.com/axios/axios</a></li>    \n",
    "    <li><a href=\"https://github.com/yunyu/parse-prometheus-text-format\">https://github.com/yunyu/parse-prometheus-text-format</a></li>\n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Non includere le ultime due, la terza , dipendenza funzionale tra prima e seconda \n",
    "- pensare all'utente, no dettaglio tecnico, poche misure, rimani sulle due o tre \n",
    "- resta più sulle time series per vedere il trend delle richieste (barchart affiancate ? linee?)\n",
    "- resta bimestrale e non trimestrale\n",
    "- barra crescente per entità, linea per indexed records. \n",
    "- intregra l'axios.\n",
    "- partono su base annuale l'utente può interagire per estenderlo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prometheus file format visualizations - JS (29/03/22 - 08/04/22) <a class=\"anchor\" id=\"entry_6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Estrazione dati per visualizzazioni provvisorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'opencitations_indexed_records_2021_01': 759516507.0,\n",
       "  'opencitations_indexed_records_2021_02': 759516507.0},\n",
       " 1: {'opencitations_indexed_records_2021_03': 759516507.0,\n",
       "  'opencitations_indexed_records_2021_04': 759516507.0},\n",
       " 2: {'opencitations_indexed_records_2021_05': 759516507.0,\n",
       "  'opencitations_indexed_records_2021_06': 759516507.0},\n",
       " 3: {'opencitations_indexed_records_2021_07': 759516507.0,\n",
       "  'opencitations_indexed_records_2021_08': 1094394688.0},\n",
       " 4: {'opencitations_indexed_records_2021_09': 1186958898.0,\n",
       "  'opencitations_indexed_records_2021_10': 1186958898.0},\n",
       " 5: {'opencitations_indexed_records_2021_11': 1235170583.0,\n",
       "  'opencitations_indexed_records_2021_12': 1235170583.0},\n",
       " 6: {'opencitations_indexed_records_2022_01': 1271360867.0,\n",
       "  'opencitations_indexed_records_2022_02': 1271360867.0}}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collect_metrics_values(n, api, metric):\n",
    "    count = 0\n",
    "    result_dict = {}\n",
    "    metrics_values = dict()\n",
    "    months = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]\n",
    "    years = [\"2021\", \"2022\"]\n",
    "    for y in years:\n",
    "        for m in months:\n",
    "            res_values = get_metrics_value(y, m, api, metric)\n",
    "            if res_values is not None:\n",
    "                if len(metrics_values) == n:\n",
    "                    result_dict[count] = metrics_values\n",
    "                    metrics_values = dict()\n",
    "                    count += 1\n",
    "                    (metrics_values).update(res_values)\n",
    "                else:\n",
    "                    (metrics_values).update(res_values)\n",
    "            \n",
    "            else:\n",
    "                result_dict[count] = metrics_values\n",
    "                metrics_values = dict()\n",
    "                count += 1\n",
    "                return result_dict\n",
    "    return result_dict\n",
    "\n",
    "collect_metrics_values(2, url, \"opencitations_indexed_records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 759516507.0,\n",
       " 1: 759516507.0,\n",
       " 2: 759516507.0,\n",
       " 3: 1094394688.0,\n",
       " 4: 1186958898.0,\n",
       " 5: 1235170583.0,\n",
       " 6: 1271360867.0}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def group_metrics_values(n, api, metric):\n",
    "    max_values_dict = dict()\n",
    "    metrics_nested_dicts = collect_metrics_values(n, api, metric)\n",
    "    for k,v in metrics_nested_dicts.items():\n",
    "        max_val = max(v.values())\n",
    "        max_values_dict[k] = max_val\n",
    "    return max_values_dict\n",
    "    \n",
    "group_metrics_values(2, url, \"opencitations_indexed_records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "records = [1271.3608670, 1235.1705830, 1186.9588980, 1094.3946880, 759.5165070, 759.5165070, 759.5165070]\n",
    "\n",
    "records_series = pd.Series(records)\n",
    "y_labels = [\"gen 21\", \"mar 21\", \"mag 21\", \"lug 21\", \"set 21\", \"nov 21\", \"gen 22\"]\n",
    "\n",
    "# Plot the figure.\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = records_series.plot(kind='barh')\n",
    "ax.set_title('Indexed Records in OC - Gennaio 2021 / Febbraio 2022')\n",
    "ax.set_xlabel('indexed records in OC - in milioni')\n",
    "ax.set_ylabel('Date')\n",
    "ax.set_yticklabels(y_labels)\n",
    "ax.set_xlim(-40, 2000) # expand xlim to make labels easier to read\n",
    "\n",
    "rects = ax.patches\n",
    "\n",
    "for rect in rects:\n",
    "    # Get X and Y placement of label from rect.\n",
    "    x_value = rect.get_width()\n",
    "    y_value = rect.get_y() + rect.get_height() / 2\n",
    "\n",
    "    space = 5\n",
    "    ha = 'left'\n",
    "    if x_value < 0:\n",
    "        space *= -1\n",
    "        ha = 'right'\n",
    "    label = \"{:.1f}\".format(x_value)\n",
    "    plt.annotate(\n",
    "        label,                      # Use `label` as label\n",
    "        (x_value, y_value),         # Place label at end of the bar\n",
    "        xytext=(space, 0),          # Horizontally shift label by `space`\n",
    "        textcoords=\"offset points\", # Interpret `xytext` as offset in points\n",
    "        va='center',                # Vertically center label\n",
    "        ha=ha)                      # Horizontally align label differently for\n",
    "                                    # positive and negative values.\n",
    "\n",
    "#source: https://stackoverflow.com/questions/28931224/adding-value-labels-on-a-matplotlib-bar-chart\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(\"indexed_records_01_21-02_22_bim.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Data = {'Bimestri': [\"gen 21\", \"mar 21\", \"mag 21\", \"lug 21\", \"set 21\", \"nov 21\", \"gen 22\"],\n",
    "        'Indexed Records in OC (milioni)': [759.5165070, 759.5165070, 759.5165070, 1094.3946880, 1186.9588980, 1235.1705830, 1271.3608670]\n",
    "       }\n",
    "  \n",
    "df = pd.DataFrame(Data,columns=['Bimestri','Indexed Records in OC (milioni)'])\n",
    "  \n",
    "plt.plot(df['Bimestri'], df['Indexed Records in OC (milioni)'], color='red', marker='*')\n",
    "    \n",
    "plt.title('Crescita Indexed Records in OC, Gennaio 2021 - Febbraio 2022', fontsize=14, x=0.5, y=1.1)\n",
    "plt.xlabel('Bimestri', fontsize=14)\n",
    "plt.ylabel('Indexed Records in OC (milioni)', fontsize=14)\n",
    "plt.grid(True)\n",
    "\n",
    "for x,y in zip(df['Bimestri'],df['Indexed Records in OC (milioni)']):\n",
    "    label = \"{:.2f}\".format(y)\n",
    "    plt.annotate(label,(x,y), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1319211.0, 1429823.0, 2887899.0, 3447441.0, 1229705.0, 727251.0],\n",
       " [1325071.0, 1438340.0, 2912619.0, 3466690.0, 1235849.0, 734435.0],\n",
       " [9652.0, 17064.0, 30224.0, 35615.0, 54006.0, 54935.0])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_counter_total_dict_gen = get_metrics_value_by_label(y_21, gen, url, \"opencitations_agg_counter_total\", \"category\")\n",
    "agg_counter_total_dict_feb = get_metrics_value_by_label(y_21, feb, url, \"opencitations_agg_counter_total\", \"category\")\n",
    "agg_counter_total_dict_mar = get_metrics_value_by_label(y_21, mar, url, \"opencitations_agg_counter_total\", \"category\")\n",
    "agg_counter_total_dict_apr = get_metrics_value_by_label(y_21, apr, url, \"opencitations_agg_counter_total\", \"category\")\n",
    "agg_counter_total_dict_mag = get_metrics_value_by_label(y_21, mag, url, \"opencitations_agg_counter_total\", \"category\")\n",
    "agg_counter_total_dict_giu = get_metrics_value_by_label(y_21, giu, url, \"opencitations_agg_counter_total\", \"category\")\n",
    "\n",
    "def extract_data(months_list, year, api, metric, label):\n",
    "    api_req = []\n",
    "    sparql_req = []\n",
    "    dataset_req = []\n",
    "    for month in months_list:\n",
    "        agg_counter_dict = get_metrics_value_by_label(year, month, api, metric, label)\n",
    "        api_req.append(agg_counter_dict['oc_api_requests'])\n",
    "        sparql_req.append(agg_counter_dict['sparql_requests'])\n",
    "        dataset_req.append(agg_counter_dict['dataset_requests'])\n",
    "    return api_req, sparql_req, dataset_req\n",
    "\n",
    "\n",
    "extract_data([gen, feb, mar, apr, mag, giu], y_21, url, \"opencitations_agg_counter_total\", \"category\")\n",
    "\n",
    "\n",
    "             \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Creazione e pubblicazione della landing page contenente le visualizzazioni in JS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le visualizzazioni possono essere consultate su https://ariannamorettj.github.io/OC_log_viz/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1) Creazione Visualizzazioni JS con dati inseriti manualmente\n",
    "\n",
    "<ol>\n",
    "    <li><a href = \"https://ariannamorettj.github.io/OC_log_viz/index.html#indexed_records\">https://ariannamorettj.github.io/OC_log_viz/index.html#indexed_records</a></li>\n",
    "    <li><a href = \"https://ariannamorettj.github.io/OC_log_viz/index.html#used_services\">https://ariannamorettj.github.io/OC_log_viz/index.html#used_services</a></li>\n",
    "</ol>\n",
    "<a href = \"https://ariannamorettj.github.io/OC_log_viz/index.html#indexed_records\">https://ariannamorettj.github.io/OC_log_viz/index.html#indexed_records</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2) Valutazione Selettore Data (3 opzioni)\n",
    "<a href=\"https://ariannamorettj.github.io/OC_log_viz/samples.html#date_selection\">https://ariannamorettj.github.io/OC_log_viz/samples.html#date_selection</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3) Valutazione Modalità Estrazione Dati da API in JS (fetch e axios)\n",
    "\n",
    "<a href = \"https://ariannamorettj.github.io/OC_log_viz/samples.html#data_extraction\">https://ariannamorettj.github.io/OC_log_viz/samples.html#data_extraction</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4) Richieste parallele AXIOS\n",
    "<a href = \"https://ariannamorettj.github.io/OC_log_viz/samples.html#data_extraction\">https://ariannamorettj.github.io/OC_log_viz/samples.html#data_extraction</a> , vedi  **Visualizzazione: più richieste simultanee, risposte: liste di dizionari**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO:\n",
    "<ol>\n",
    "    <li>Riprodurre il procedimento con i prometheus, usando le librerie ( <a href = \"https://github.com/yunyu/parse-prometheus-text-format\" >https://github.com/yunyu/parse-prometheus-text-format</a> , <a href = \"https://github.com/prometheus/prom2json\">https://github.com/prometheus/prom2json</a> )</li>\n",
    "    <li>Collegare la selezione della data alla definizione del range di mesi presenti nella visualizzazione</li>\n",
    "    <li>Decidere se far scegliere all'utente l'intervallo di mesi per la visualizzazione o cambiarla automaticamente se il mese di inizio e di fine sono particolarmente lontani tra loro.</li>\n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prometheus data extraction JS (08/04 -12/04) <a class=\"anchor\" id=\"entry_7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Uncaught ReferenceError: require is not defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const express = require('express');\n",
    "const request = require('request');\n",
    "\n",
    "const app = express();\n",
    "\n",
    "app.use((req, res, next) => {\n",
    "res.header('Access-Control-Allow-Origin', '*');\n",
    "next();\n",
    "});\n",
    "\n",
    "app.get('/2022-01', (req, res) => {\n",
    "    request(\n",
    "    { url: \"http://opencitations.net/statistics/2022-01\" },\n",
    "    (error, response, body) => {\n",
    "    if (error || response.statusCode !== 200) {\n",
    "        return res.status(500).text({ type: 'error', message: err.message });\n",
    "    }\n",
    "\n",
    "    res.json(JSON.parse(body));\n",
    "    }\n",
    ")\n",
    "});\n",
    "\n",
    "const PORT = process.env.PORT || 3000;\n",
    "app.listen(PORT, () => console.log(`listening on ${PORT}`));\n",
    "\n",
    "#prom2json.html:92 Uncaught ReferenceError: require is not defined*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Con proxy funziona, integrato nell'HTML dà lo stesso errore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const uniqid = require(\"uniqid\");\n",
    "document.querySelector(\"#result\").innerHTML = uniqid(); \n",
    "const express = require(\"express\");\n",
    "const app = express();\n",
    "const axios = require(\"axios\");\n",
    "const cors = require(\"cors\");\n",
    "require(\"dotenv\").config();\n",
    "\n",
    "app.use(cors({\n",
    "    origin: \"*\"\n",
    "}))\n",
    "\n",
    "app.get(\":endpoint([\\\\/\\\\w\\\\.-]*)\", function(req, res){\n",
    "    let endpoint = \"http://opencitations.net\" + req.params.endpoint\n",
    "    axios.get(endpoint).then(response => {\n",
    "        res.send(response.data)\n",
    "    }).catch(error => {\n",
    "        res.send(error)\n",
    "\n",
    "    })    \n",
    "})\n",
    "\n",
    "app.listen(3000)\n",
    "\n",
    "#prom2json.html:92 Uncaught ReferenceError: require is not defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Uncaught TypeError: Cannot read properties of undefined (reading 'prototype')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tentativo con Browserify per risolvere require not defined\n",
    "\n",
    "**Cosa è Browserify**: Browsers don't have the require method defined, but Node.js does. With Browserify you can write code that uses require in the same way that you would use it in Node.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Access to XMLHttpRequest at 'http://opencitations.net/statistics/2022-01' from origin 'http://127.0.0.1:5500' has been blocked by CORS policy: Response to preflight request doesn't pass access control check: No 'Access-Control-Allow-Origin' header is present on the requested resource.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function getPromDataAxios() {\n",
    "    const url = \"http://opencitations.net/statistics/2022-01\";\n",
    "    const config = {\n",
    "        url,\n",
    "        headers: {\n",
    "            'Access-Control-Allow-Origin' : \"*\",\n",
    "            'Access-Control-Allow-Methods':'GET,PUT,POST,DELETE,PATCH,OPTIONS',\n",
    "\n",
    "        }\n",
    "    }\n",
    "    axios(config)\n",
    "    .then(response => {\n",
    "        console.log(response.data);\n",
    "        });"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 403 Forbidden  --> EVITARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function getPromDataAxios() {\n",
    "    const url = \"https://cors-anywhere.herokuapp.com/http://opencitations.net/statistics/2022-01\";\n",
    "    axios.get(url)\n",
    "    .then((response) => {\n",
    "    let datalist = [];\n",
    "    console.log(response.data);\n",
    "    const html = response.data\n",
    "    .map(function(item) {\n",
    "            datalist.push(\" \" + item.login);\n",
    "            }\n",
    "            )\n",
    "    console.log(html);\n",
    "    document.querySelector(\"#app_2\").insertAdjacentHTML(\"afterbegin\", datalist);\n",
    "    })\n",
    "    .catch(error => {\n",
    "        console.log(error); \n",
    "    });\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Va abilitato il cors in opecitations nel server web ---> essere flessibili. Problematica normale. sui TXT files il problema non si pone più. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Do\n",
    "<ol>\n",
    "    <li>Chiedere lato OC accesso ai dati da REST API</li>\n",
    "    <li>Tenere solo API  e Dataset, elimina SPARQL</li>\n",
    "    <li>Nei Grafici rendere la crescita logaritmica (asse y logaritmico)</li>\n",
    "    <li>Per visualizzazioni: default --> minimo un mese</li>\n",
    "    <li>Intervallo selezionabile: mensile, bimestrale, trimestrale</li>\n",
    "    <li>Collegare selezione data a richiesta api.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prometheus file format extraction, Visualization Refinement (12/04 - 20/04)\n",
    "<a id = \"entry_8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Estrazione stringa in formato (YYYY-MM) dalla data selezionata dal calendario\n",
    "\n",
    "<ul>\n",
    "    <li><b>OnAfterChooseMonth</b>: evento fornito dal plugin che permette di associare una funzione alla selezione di una data da calendario </li>\n",
    "    <li><b>function(selectedDate)</b>: funzione anonima che utilizza selectedDate per estrarre anno e mese dall'opzione selezionata dall'utente dal calendario </li>\n",
    "    <li><b>year = selectedDate.getFullYear();</b>: per ottenere l'anno in formato YYYY</li>\n",
    "    <li><b>month = (selectedDate.getMonth() + 1).toString().padStart(2, \"0\");\n",
    "</b>: per estrarre il mese in formato MM. Si somma +1 perché in default i mesi, come i giorni della settimana, sono rappresentati da indici che partono da 0, quindi gennaio sarebbe O. </li>\n",
    "    <li><b>date_for_query = year + \"-\" + month;\n",
    "        </b>: associo alla variabile <b>date_for_query</b> la stringa formata dall'anno YYYY e il mese MM separati da un trattino, in modo tale che sia già pronta per essere usata nella richiesta all'API (http://opencitations.net/statistics/2022-01)</li>\n",
    "    <li><b>return (date_for_query)</b>: La stringa è l'output della funzione. Ora bisogna salvare questor risultato in qualche modo, così che in corrispondenza di un dato evento possa essere associato alla seconda data selezionata (quella di inizio o di fine, a seconda di quale sia la prima data selezionata e quale la seconda).</li>\n",
    "    \n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$(document).ready(function() {\n",
    "    // Default functionality.\n",
    "    $('.Default').MonthPicker({\n",
    "\n",
    "        OnAfterChooseMonth: function(selectedDate) {\n",
    "            year = selectedDate.getFullYear();\n",
    "            month = (selectedDate.getMonth() + 1).toString().padStart(2, \"0\");\n",
    "            date_for_query = year + \"-\" + month;\n",
    "            console.log(date_for_query);\n",
    "            return (date_for_query);\n",
    "\n",
    "        }\n",
    "        \n",
    "    });"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Estrazione della lista degli url partendo dalla selezione dei mesi di inizio e di fine range per la visualizzazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h4>--- Proposta 3  ---</h4>\n",
    "  <!--http://kidsysco.github.io/jquery-ui-month-picker/-->\n",
    "<p> jQuery UI Month Picker Plugin. Go to <a href=\"http://kidsysco.github.io/jquery-ui-month-picker/\"> source </a></p>\n",
    "<div class=\"graph_cont\">\n",
    "  <br />Choose a start month:\n",
    "  <input id=\"Start\" class='Default' type=\"text\" />\n",
    "</div>\n",
    "\n",
    "<div class=\"graph_cont\">\n",
    "  <br />Choose a end month:\n",
    "  <input id=\"End\" class='Default' type=\"text\" />\n",
    "</div>\n",
    "\n",
    "\n",
    "<button id=\"Invio\">Calcola Risultati</button>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$(document).ready(function() {\n",
    "    // Default functionality.\n",
    "    let start = \"\";\n",
    "    let end = \"\"; \n",
    "    let StartDate = \"\";\n",
    "    let EndDate = \"\";\n",
    "    let Interval = 1;\n",
    "\n",
    "\n",
    "    $('#Start').MonthPicker({\n",
    "        OnAfterChooseMonth: function(selectedDate) {\n",
    "            StartDate = selectedDate;\n",
    "            year = selectedDate.getFullYear();\n",
    "            month = (selectedDate.getMonth() + 1).toString().padStart(2, \"0\");\n",
    "            let date_for_query = year + \"-\" + month;\n",
    "            console.log(date_for_query);\n",
    "            start = date_for_query;\n",
    "        }\n",
    "        \n",
    "    });\n",
    "\n",
    "    $('#End').MonthPicker({\n",
    "        OnAfterChooseMonth: function(selectedDate) {\n",
    "            EndDate = selectedDate;\n",
    "            year = selectedDate.getFullYear();\n",
    "            month = (selectedDate.getMonth() + 1).toString().padStart(2, \"0\");\n",
    "            let date_for_query = year + \"-\" + month;\n",
    "            console.log(date_for_query);\n",
    "            end = date_for_query;\n",
    "\n",
    "        }\n",
    "        \n",
    "    });\n",
    "\n",
    "    $('#Invio').click(function () {\n",
    "        if (StartDate == \"\" && EndDate == \"\") {\n",
    "            window.alert(\"Seleziona una data di inizio e una data di fine\")\n",
    "        } else if (StartDate == \"\"){\n",
    "            window.alert(\"Seleziona una data di inizio\")\n",
    "          } else if (EndDate == \"\"){\n",
    "            window.alert(\"Seleziona una data di fine\")\n",
    "          } else {\n",
    "            if (StartDate >= EndDate){\n",
    "                StartDate = \"\"\n",
    "                EndDate = \"\"\n",
    "                $('#Start').val(\"\")\n",
    "                $('#End').val(\"\")\n",
    "\n",
    "                window.alert(\"La data di inizio deve precedere la data di fine\")\n",
    "                throw \"La data di inizio deve precedere la data di fine\"\n",
    "            } else{\n",
    "                console.log(StartDate, EndDate)\n",
    "                var start_Date = moment(start);\n",
    "                var end_Date = moment(end);\n",
    "                var result = [];    \n",
    "                while (start_Date.isBefore(end_Date)) {\n",
    "                    result.push(\"http://opencitations.net/statistics/\" + start_Date.format(\"YYYY-MM\"));\n",
    "                    start_Date.add(1, 'month');\n",
    "                }\n",
    "                result.push(\"http://opencitations.net/statistics/\" + end_Date.format(\"YYYY-MM\"))\n",
    "                }\n",
    "                console.log(result)\n",
    "            }\n",
    "\n",
    "        });\n",
    "\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L'esecuzione Maggio 2022 - Settembre 2022 ritorna la lista qui sotto: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://opencitations.net/statistics/2022-05',\n",
       " 'http://opencitations.net/statistics/2022-06',\n",
       " 'http://opencitations.net/statistics/2022-07',\n",
       " 'http://opencitations.net/statistics/2022-08',\n",
       " 'http://opencitations.net/statistics/2022-09']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['http://opencitations.net/statistics/2022-05', 'http://opencitations.net/statistics/2022-06', 'http://opencitations.net/statistics/2022-07', 'http://opencitations.net/statistics/2022-08', 'http://opencitations.net/statistics/2022-09']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Select element per definire l'intervallo di mesi da includere nella visualizzazione, partendo dal range selezionato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HTML\n",
    "Elemento <b>Select</b> che permette di scegliere un'opzione tra quelle offerte (<b>options</b>). A ciascuna è associato un valore, che verrà poi usato al cambio della selezione per definire l'intervallo di mesi da includere nella visualizzazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<div class=\"graph_cont\">\n",
    "  <label for=\"Intervallo\">Scegli un intervallo</label>\n",
    "    <select name=\"Intervallo\" id=\"Intervallo\" required>\n",
    "      <option value=\"1\">Mensile</option>\n",
    "      <option value=\"2\">Bimestrale</option>\n",
    "      <option value=\"3\">Trimestrale</option>\n",
    "    </select>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JS\n",
    "Il primo script associa alla variabile \"Interval\" definita precedentemente il valore associato all'intervallo scelto (Mensile = 1, Bimestrale = 2, Trimestrale = 3). \n",
    "Il secondo script è un integrazione del codice mostrato precedentemente della funzione che si attiva al click sul tasto <b>\"#Invio\"</b>, che calcola i dati per le visualizzazioni. In particolare, ricava dalla lista <b>result</b> (che contiene tutti i mesi del range identificato) una sottolista <b>result_w_interval</b>, che nel caso di default (Mensile) è uguale a result, mentre negli altri due casi contiene rispettivamente la metà o un terzo dei mesi del range selezionato. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    $('#Intervallo').on('change', function() {\n",
    "        Interval = ($(this).val());\n",
    "        console.log(Interval);\n",
    "    });\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$('#Invio').click(function () {    ....\n",
    "    \n",
    "    if(Interval == 1){\n",
    "                result_w_interval = result;\n",
    "            } else{\n",
    "                for (const [index, element] of result.entries()) {\n",
    "                    if(index % Interval == 0){\n",
    "                        result_w_interval.push(element);\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "            //lista dati chiamate per per visualizzazione\n",
    "            console.log(result_w_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Cambio configurazioni per visualizzazioni Chart JS per rendere la scala logaritmica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  options: {\n",
    "    scales: {\n",
    "              y: {\n",
    "                  display: true,\n",
    "                  type: 'logarithmic',\n",
    "                }\n",
    "            }\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Nuove visualizzazioni con solo API  e Dataset, senza SPARQL\n",
    "Visualizzazioni aggiornate, SPARQL rimosso, mantenuta la palette principale di OC, scala logaritmica (y) per le visualizzazioni delle richieste, mentre l'ho lasciata lineare per la crescita degli indexed records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonti\n",
    "<ol>\n",
    "    <li><a href = \"http://jsfiddle.net/McCroskey42/1tp1hw8w/419/\">http://jsfiddle.net/McCroskey42/1tp1hw8w/419/</a> : estrazione lista dei mesi </li>\n",
    "    <li><a href = \"https://github.com/KidSysco/jquery-ui-month-picker/wiki\">https://github.com/KidSysco/jquery-ui-month-picker/wiki</a> : per il plugin del month picker</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domande\n",
    "<ol>\n",
    "    <li>Utilizzo delle funzioni anonime con parametri in JS:si usano nei casi in cui una funzione deve essere utilizzata all'interno di un'altra?</li>\n",
    "    <li> <b>utilizzo parse-prometheus-text-format</b> : FAILED TO LOAD MODULE SCRIPT: THE SERVER RESPONDED WITH A NON-JAVASCRIPT MIME TYPE OF “TEXT/HTML” IN NGINX WHEN DEPLOYING AN ANGULAR APPLICATION --> Come si risolve?</li>\n",
    "    <li>A quanto pare non c'è modo di modificare gli elementi option di un select con css (Vedi <a href=\"https://stackoverflow.com/a/35349934/15097248\">qui</a> ). Per ora le alternative perché sia visibile da cellulare sono (a) cambiare il select con un elemento che faccia la stessa cosa, (b) usare una libreria js, (c) allargare il margine inferiore o il padding del div in modo che non fuoriesca dalla schermata.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization - Code Finalization + DOCI - Preliminary work (20/04 - 26/04)\n",
    "<a id=\"entry_9\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Conclusione codice visualizzazioni\n",
    "Attualmente il codice funziona (https://ariannamorettj.github.io/OC_log_viz/) correttamente ma su dati locali (i file prometheus sono in una cartella nella repository del sito). Una volta risolto il CORS error resterà solo da sistemare la richiesta axios per verificare che funzioni tutto correttamente anche con le API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Creazione di grafici Default (gen - dic 2021, mensile) al caricamento del documento\n",
    "<b>Al caricamento del documento vengono creati due grafici Chart.js con dei dati di default</b>(che ho impostato con i dati <b>da gennaio a dicembre 2021 ad intervalli mensili</b>). <br>\n",
    "<b>!!</b> : Quando le visualizzazioni funzioneranno con le richieste alle API pensavo di impostare la visualizzazione di default su scala mensile, che copra l'anno dai 13 mesi precedenti al mese precedente quello corrente (quindi l'ultimo di cui l'API dovrebbe avere i dati a disposizione).<br>\n",
    "<b>??</b>: è rischioso? Ovvero, è possibile che per qualche motivo le API non funzionino, quindi sarebbe più prudente lasciare comunque dei dati locali per avere almeno le visualizzazioni di default?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Calcolo dei mesi trascorsi tra due date\n",
    "<ol>\n",
    "    <li>Definizione della <b>funzione che consente di calcolare il numero di mesi trascorsi tra due date</b>. Il codice è ripreso da <a href=\"https://stackoverflow.com/questions/2536379/difference-in-months-between-two-dates-in-javascript/2536445#2536445\">qui</a>.\n",
    "</li>\n",
    "    <li>Definizione di <b>due variabili per il mese di inizio e il mese di fine tra cui sarà possibile selezionare date dai calendari</b>. Per il momento la data di <b>inizio è al primo gennaio del 2021</b> (perché i file iniziano da lì) mentre quella di <b>fine è già impostata per il funzionamento con i dati delle API</b>, ovvero nella prospettiva che <b>l'ultimo mese i cui dati sono disponibili sia quello che precede il mese corrente</b>.Tuttavia i dati di riferimento sono comunque quelli attuali, quindi in questa versione i primi tre mesi del 2022 sono cliccabili ma non hanno dati associati, quindi non funzionano correttamente.</li>\n",
    "    <li>Salvataggio del valore numerico dei mesi trascorsi tra due date nella variabile <b>elapsed_record_months</b></li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function elapsedMonths(d1, d2) {\n",
    "    var months;\n",
    "    months = (d2.getFullYear() - d1.getFullYear()) * 12;\n",
    "    months -= d1.getMonth();\n",
    "    months += d2.getMonth();\n",
    "    return months <= 0 ? 0 : months;\n",
    "}\n",
    "\n",
    "let init_data_month = new Date('2021-01-01') // Inizializzato al gennaio 2021 perché per ora nell'API ci soni solo i resoconti mensili da quella data. Da aggiornare quando verranno caricati altri dati.\n",
    "let cur_data_month = new Date();\n",
    "\n",
    "let elapsed_record_months = elapsedMonths(init_data_month, cur_data_month);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Creazione degli elementi che consentono all'utente di scegliere i parametri per aggiornare la visualizzazione\n",
    "Per il funzionamento dei due <b>input</b> per la data di inizio e fine delle visualizzazioni, è stato utlizzato il plugin <a href=\"http://kidsysco.github.io/jquery-ui-month-picker/\">jquery-ui-month-picker</a>.\n",
    "<ul>\n",
    "    <li>Due <b>input</b>, uno per la selezione del mese di inizio uno per la selezione del mese di fine</li>\n",
    "    <li>Un <b>select</b> per la scelta dell'intervallo mernsile. Contiene tre <b>option</b> (1/2/3-month), ciascuna con un valore numerico associato.</li>\n",
    "    <li>I vari elementi sono dentro a dei <b>div</b> che permettessero di gestire meglio la visone da cellulare (in cui in due input passano uno sopra e uno sotto anziché restare uno di fianco all'altro.</li>\n",
    "    <li>Un elemento <b>button</b> che permette di avviare il processo di aggiornamento della visualizzazione.</li>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<div class=\"graph_cont\">\n",
    "\n",
    "  <div class=\"div_sx\" id=\"from_to_div\">\n",
    "    <div class=\"div_sx\">\n",
    "      From: <input id=\"Start\" class='Default' type=\"text\"/>\n",
    "    </div>\n",
    "    <div class=\"div_dx\">\n",
    "      To: <input id=\"End\" class='Default' type=\"text\"/>\n",
    "    </div>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"div_dx\" id =\"interval_div\">\n",
    "    <div id=\"int_container\">\n",
    "      <label for=\"Intervallo\">Interval:</label>\n",
    "      <select name=\"Intervallo\" id=\"Intervallo\" required>\n",
    "        <option value=\"1\">1-month</option>\n",
    "        <option value=\"2\">2-month</option>\n",
    "        <option value=\"3\">3-month</option>\n",
    "      </select>\n",
    "    </div>                \n",
    "\n",
    "  </div>\n",
    "  </div>\n",
    "\n",
    "  <button id=\"Invio\", class=\"btn\">Update Visualizations</button>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Codice JS per impostare i parametri della selezione delle date nei calendari\n",
    "<ol>\n",
    "    <li>Inizializzazione <b>variabili relative alle date di inzio e fine</b> (vuote), e l'intervallo impostato <b>mensile</b>.</li>\n",
    "        <li>Utilizzo del plugin<b>MonthPicker</b> per le impistazioni dei calendari di start e end. Il <b>MaxMonth</b> è impostato al mese precedente quello corrente, mentre il il <b>MinMonth</b> è indirettamente settato per essere Gennaio del 2021 (il mese attuale - i mesi che lo separano da gennaio 2021). <b>!!</b>Successivamente andrà modificato per fare in modo che il MinMonth selezionabile corrisponda al primo di cui abbiamo i dati. <b>Il valore della data corrispondente alla selezione dell'utente viene salvato nelle variabili (start e StartDate // end e EndDate)</b> sovrascrivendo le stringhe vuote inizializzate</li>\n",
    "    <li>Il valore della variabile <b>Interval</b> che era inizializzato a 1 viene sovrascritto con il valore associato all'opzione selezionata.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    // Default functionality.\n",
    "    let start = \"\";\n",
    "    let end = \"\"; \n",
    "    let StartDate = \"\";\n",
    "    let EndDate = \"\";\n",
    "    let Interval = 1;\n",
    "\n",
    "    $('#Start').MonthPicker({\n",
    "        MaxMonth: -1, // -1 rispetto al mese corrente assumendo che il resoconto mensile sia pubblicato a fine mese\n",
    "        MinMonth: - elapsed_record_months, // TUTTAVIA: per ora funziona fino al 12/2021. Il codice è pensato per funzionare con le richieste API, che sono aggiornate al penultimo mese.\n",
    "        OnAfterChooseMonth: function(selectedDate) {\n",
    "            StartDate = selectedDate;\n",
    "            year = selectedDate.getFullYear();\n",
    "            month = (selectedDate.getMonth() + 1).toString().padStart(2, \"0\");\n",
    "            let date_for_query = year + \"-\" + month;\n",
    "            console.log(date_for_query);\n",
    "            start = date_for_query;\n",
    "        }\n",
    "        \n",
    "    });\n",
    "\n",
    "    $('#End').MonthPicker({\n",
    "        MaxMonth: -1, // -1 rispetto al mese corrente assumendo che il resoconto mensile sia pubblicato a fine mese\n",
    "        MinMonth: - elapsed_record_months, // TUTTAVIA: per ora funziona fino al 12/2021. Il codice è pensato per funzionare con le richieste API, che sono aggiornate al penultimo mese.\n",
    "        OnAfterChooseMonth: function(selectedDate) {\n",
    "            EndDate = selectedDate;\n",
    "            year = selectedDate.getFullYear();\n",
    "            month = (selectedDate.getMonth() + 1).toString().padStart(2, \"0\");\n",
    "            let date_for_query = year + \"-\" + month;\n",
    "            console.log(date_for_query);\n",
    "            end = date_for_query;\n",
    "\n",
    "        }        \n",
    "    });\n",
    "    \n",
    "    \n",
    "    $('#Intervallo').on('change', function() {\n",
    "        Interval = ($(this).val());\n",
    "        console.log(Interval);\n",
    "    });"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Gestione di eventuali errori di selezione dell'utente\n",
    "Al click del bottone <b>Invio</b>, si procede all'update delle visualizzazioni con i parametri scelti dall'utente. L'<b>if-else</b> gestisce il caso in cui <b>i valori delle variabili di start e/o end date siano ancora stringhe vuote</b> (caso in cui l'utente non ha selezionato la data di inizio o di fine), e il caso in cui <b> la data di fine preceda la data di inzio.</b> Nel primo caso viene lanciato un messaggio di <b>alert</b>. Nel secondo caso un <b>throw</b> che interrompe l'esecuzione e risetta i parametri perché sia fatta una nuova selezione.\n",
    "Nel caso in cui <b>la data di inizio e di fine</b> siano state selezionate correttamente, inizia il processo per aggiornare le visualizzazioni. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$('#Invio').click(function () {\n",
    "    if (StartDate == \"\" && EndDate == \"\") {\n",
    "        window.alert(\"Select a Start Date and an End Date\")\n",
    "    } else if (StartDate == \"\"){\n",
    "        window.alert(\"Select a Start Date\")\n",
    "      } else if (EndDate == \"\"){\n",
    "        window.alert(\"Select an End Date\")\n",
    "      } else {\n",
    "\n",
    "\n",
    "        if (StartDate >= EndDate){\n",
    "            StartDate = \"\"\n",
    "            EndDate = \"\"\n",
    "            $('#Start').val(\"\")\n",
    "            $('#End').val(\"\")\n",
    "\n",
    "            window.alert(\"Start Date must precede End Date\")\n",
    "            throw \"Start Date must precede End Date\"\n",
    "        } else{\n",
    "            console.log(StartDate, EndDate) \n",
    "            ......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Estrazione della lista di mesi che intercorrono tra due date e composizione degli indirizzi (path) per le varie richieste\n",
    "<ul>\n",
    "    <li> Il codie per l'estrazione della lista di mesi è stato parzialmente ripreso e modificato da <a href=\"http://jsfiddle.net/McCroskey42/1tp1hw8w/419/\"> questa risposta su stackoverflow</a>.</li>\n",
    "    <li>Definizione di due nuove variabili <b>startDate e endDate</b>, il cui valore è il valore temporale delle stringhe start e end. </li>\n",
    "    <li>Definizione di una <b>lista vuota (result)</b> a cui verranno appesi tutte le stringhe che rappresentano i path di ciascun file prometheus. <b>Per ora il codice funziona con i path locali, ma nei commenti c'è la versione che andrà utilizzata nel momento in cui i dati verranno recuperati dalle API.</b></li>\n",
    "    <li>Definizione di una nuova lista vuota, <b>result_w_interval</b> che conterrà un sottoinsieme dei mesi della lista result, <b>a seconda del valore della variabile Interval</b>. Nel caso in cui il valore di Interval sia rimasto invariato o nel caso in cui l'utente abbia scelto l'intervallo mensile, result_w_interval sarà uguale a result.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    var start_Date = moment(start);\n",
    "    var end_Date = moment(end);\n",
    "    var result = [];    \n",
    "    while (start_Date.isBefore(end_Date)) {\n",
    "        result.push(\"summary/oc-\" + start_Date.format(\"YYYY-MM\")+ \".prom\");\n",
    "        //result.push(\"http://opencitations.net/statistics/\" + start_Date.format(\"YYYY-MM\"));\n",
    "        start_Date.add(1, 'month');\n",
    "    }\n",
    "    result.push(\"summary/oc-\" + end_Date.format(\"YYYY-MM\")+ \".prom\")\n",
    "    //result.push(\"http://opencitations.net/statistics/\" + end_Date.format(\"YYYY-MM\"))\n",
    "    }\n",
    "\n",
    "\n",
    "let result_w_interval = [];\n",
    "\n",
    "//Gestione dell'intervallo dei mesi\n",
    "\n",
    "if(Interval == 1){\n",
    "    result_w_interval = result;\n",
    "} else{\n",
    "    for (const [index, element] of result.entries()) {\n",
    "        if(index % Interval == 0){\n",
    "            result_w_interval.push(element);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "//lista dati chiamate per per visualizzazione\n",
    "console.log(result_w_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Estrazione dei dati dai prometheus file, con funzione asincrona (getMonthMetrics(month_query_list)).\n",
    "Cosa fa la funzione: \n",
    "<ul>\n",
    "    <li>Prende in <b>input la lista di path precedentemente elaborata</b></li>\n",
    "    <li><b>Trasforma ogni Prometheus in dizionario</b> </li>\n",
    "    <li>Da ogni dizionario <b>estrae: 1) il numero di chiamate ad API, 2) il numero di richieste ai DataSet 3)il numero di indexed records</b></li>\n",
    "    <li>Restituisce in <b>output un dizionario le cui chiavi sono le stringhe delle labels dei mesi (es. Jan_2021) e i valori dei dizionari con tre chiavi:\"indexed_records\", \"api_requests\", \"dataset_requests\". </b></li>\n",
    "    \n",
    "Il codice per l'estrazione di una sottostringa tra due caratteri o sequenze di caratteri è stato modificato da <a href=\"https://stackoverflow.com/a/19793380/15097248\">questo codice.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async function getMonthMetrics(month_query_list){\n",
    "var dict_name = {};\n",
    "months= {\"01\": \"Jan\",\"02\":\"Feb\",\"03\":\"Mar\",\"04\":\"Apr\", \"05\":\"May\", \"06\":\"Jun\", \"07\":\"Lug\", \"08\":\"Aug\", \"09\":\"Sep\", \"10\":\"Oct\", \"11\":\"Nov\", \"12\":\"Dec\" };\n",
    "let element;\n",
    "\n",
    "\n",
    "for (let i = 0; i < month_query_list.length; i++) {\n",
    "    element = [month_query_list[i]];\n",
    "    const datePattern = /(\\d{4})\\-(\\d{1,2})/;\n",
    "    const date = datePattern.exec(element);\n",
    "\n",
    "    let response = await axios.get(element);\n",
    "\n",
    "    this.markDownData = response.data;\n",
    "    const metricsStr = this.markDownData;\n",
    "\n",
    "\n",
    "    //dividi il prometheus in corrispondenza del \\n\n",
    "    var array1 = metricsStr.split(/\\r?\\n/);\n",
    "    // alternativa : var array = metricsStr.match(/[^\\r\\n]+/g);\n",
    "    var filtered = array1.filter(function(value, index, arr){ \n",
    "    return !value.startsWith(\"#\");\n",
    "    //Elimina gli elementi che iniziano con #\n",
    "    });\n",
    "\n",
    "    // costruisci il dizionario dal prometheus\n",
    "    prom_to_dict = {}\n",
    "\n",
    "    const pattern = /{/;\n",
    "    //reference: https://stackoverflow.com/a/19793380/15097248\n",
    "    function extractQuotedText(str){\n",
    "        const matches = str.match(/\"(.*?)\"/);\n",
    "        return (matches\n",
    "            ? matches[1]\n",
    "            : str);\n",
    "        };\n",
    "\n",
    "    for (let i = 0; i < filtered.length; i++) {\n",
    "        if(pattern.test(filtered[i]) == true){\n",
    "            let pos_open_par = filtered[i].indexOf('{')\n",
    "            let pos_close_par = filtered[i].indexOf('}')\n",
    "\n",
    "            let dict_key= filtered[i].substr(0, pos_open_par);\n",
    "            if (!(dict_key in prom_to_dict)){\n",
    "                prom_to_dict[dict_key] = {}\n",
    "            };\n",
    "\n",
    "            let nest_dict_key = extractQuotedText(filtered[i])\n",
    "            let nest_dict_val = filtered[i].substr(pos_close_par+2);\n",
    "\n",
    "            prom_to_dict[dict_key][nest_dict_key] = nest_dict_val\n",
    "\n",
    "        }else{\n",
    "            // considera lo spazio come separatore, quello che viene prima è la chiave, quello che viene dopo il valore\n",
    "            // verifica cosa succede quando c'è più di uno spazio\n",
    "            let pos_space = filtered[i].indexOf(' ');\n",
    "            let dict_key= filtered[i].substr(0, pos_space);\n",
    "            let dict_val = filtered[i].substr(pos_space + 1);\n",
    "            //aggiungi a prom_to_dict la coppia chiave valore (non puù essercene già una con lo stesso nome )\n",
    "            prom_to_dict[dict_key] = dict_val\n",
    "\n",
    "        };\n",
    "    }\n",
    "    // estrazione dei dati che servono \n",
    "    ind_rec = prom_to_dict.opencitations_indexed_records\n",
    "    api_req = prom_to_dict.opencitations_agg_counter_total.oc_api_requests\n",
    "    dataset_req = prom_to_dict.opencitations_agg_counter_total.dataset_requests\n",
    "    let result = {};\n",
    "    result[\"indexed_records\"] = Number(ind_rec);\n",
    "    result[\"api_requests\"] = Number(api_req);\n",
    "    result[\"dataset_requests\"] = Number(dataset_req);\n",
    "\n",
    "    key_name =  months[date[2]] + \"_\" + date[1];\n",
    "    dict_name[key_name] = result;\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "//console.log(\"This is the result\", dict_name);\n",
    "return dict_name;\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Esecuzione di getMonthMetrics con input result_w_interval , .then -> aggiornamento dei grafici.\n",
    "<ol>\n",
    "    <li>Esecuzione della funzione <b>getMonthMetrics con input result_w_interval</b> </li>\n",
    "    <li><b>.then</b>: esecuzione della <b>funzione che aggiorna i grafici con i dati raccolti dai prometheus</b>.</li>\n",
    "    <li>Con un'<b>iterazione per gli elementi del dizionario</b> vengono <b>riempite le liste per la popolazione delle visualizzazioni</b></li>\n",
    "    <li>Una volta terminata l'iterazione, <b>i grafici myLine e myBar vengono distrutti con .destroy()</b></li>\n",
    "    <li>I <b>grafici sono ricreati e ripopolati con i dati estratti dai prometheus</b>.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let a = getMonthMetrics(result_w_interval);\n",
    "\n",
    "a.then(function(result){\n",
    "    //console.log(result);\n",
    "    /// definisci le quattro liste: labels, indexed records, api requests, dataset requests\n",
    "    /// riempile con iterazione \n",
    "    ind_rec_list = [];\n",
    "    api_req_list = [];\n",
    "    dataset_req_list = [];\n",
    "    labels_list = [];\n",
    "\n",
    "\n",
    "    for (const key in result) {\n",
    "        labels_list.push(key);\n",
    "        api_req_list.push(result[key].api_requests);\n",
    "        dataset_req_list.push(result[key].dataset_requests);\n",
    "        ind_rec_list.push(result[key].indexed_records);\n",
    "        }\n",
    "\n",
    "\n",
    "console.log(\"labels_list\", labels_list);\n",
    "console.log(\"api_req_list\", api_req_list);\n",
    "console.log(\"dataset_req_list\", dataset_req_list);\n",
    "console.log(\"ind_rec_list\", ind_rec_list);\n",
    "\n",
    "\n",
    "\n",
    "/// UPDATE DEI GRAFICI\n",
    "\n",
    "\n",
    "//distruzione dei grafici default (o precedentemente generati)\n",
    "myLine.destroy()\n",
    "myBar.destroy()\n",
    "// I grafici vengono ripopolati con i dati raccolti nelle liste definite sopra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Aggiornamento READ.me\n",
    "Ho aggiornato il <a href=\"https://github.com/ariannamorettj/OC_log_viz/blob/main/README.md\">Read.me</a> con tutte le fonti da cui ho preso dei pezzi di codice che ho modificato o dei plugin che ho utilizzato (sempre modificandoli). Riporto qui sotto come appare ora: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OC_log_viz\n",
    "Landing page for testing JS visualizations about indexed records in OpenCitations and usage of OpenCitations services.\n",
    "\n",
    "\n",
    "### References\n",
    "<ol>\n",
    "    <li>month picker: <a href=\"http://kidsysco.github.io/jquery-ui-month-picker/\">http://kidsysco.github.io/jquery-ui-month-picker/</a></li>\n",
    "<li>template: <a href=\"https://github.com/StartBootstrap/startbootstrap-bare/blob/master/LICENSE\">https://github.com/StartBootstrap/startbootstrap-bare/blob/master/LICENSE</a></li>\n",
    "<li>data by: <a href=\"https://opencitations.net\">https://opencitations.net</a></li>\n",
    "<li>code to calculate months elapsed between two dates: <a href=\"https://stackoverflow.com/questions/2536379/difference-in-months-between-two-dates-in-javascript/2536445#2536445\">https://stackoverflow.com/questions/2536379/difference-in-months-between-two-dates-in-javascript/2536445#2536445</a></li>\n",
    "<li>code to compose the list of API requests: <a href=\"http://jsfiddle.net/McCroskey42/1tp1hw8w/419/\">http://jsfiddle.net/McCroskey42/1tp1hw8w/419/</a></li>\n",
    "<li>code to extract a string between two characters (used in prometheus text format manipulation): <a href=\"https://stackoverflow.com/a/19793380/15097248\">https://stackoverflow.com/a/19793380/15097248</a> </li>\n",
    "</ol>\n",
    "\n",
    "Step by step code documentation (ITA) available on my work <a href=\"https://github.com/ariannamorettj/OC_Notebook/blob/main/OC_AM_notebook.ipynb\">Jupyter Notebook</a> (see: 9. 20/04 - 26/04 (Visualization - Code Finalization + DOCI - Preliminary work))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Lavoro Preliminare per DOCI - materiale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataCite Dump\n",
    "Contiene \n",
    "<ol>\n",
    "    <li><b>datacite_dump_20211022.json.zst</b>, json compresso, data source effettiva</li>\n",
    "    <li>l'archivio <b>datacite_dump_20211022_archive.torrent</b></li>\n",
    "    <li><b>datacite_dump_20211022_files.xml</b> che elenca i files contenuti nel dump</li>\n",
    "    <li><b>datacite_dump_20211022_meta.sqlite</b>: datacite_dump_20211022.json.zstETag: \"7e854e8124056634b0db4f5a4f236bd2\"\n",
    "accept: */*\n",
    "accept-encoding: gzip, deflate\n",
    "authorization: LOW U4thOkTyojZeI9us:REDACTED_BY_IA_S3\n",
    "connection: close\n",
    "content-length: 9168882608\n",
    "content-md5: 7e854e8124056634b0db4f5a4f236bd2\n",
    "host: s3.us.archive.org\n",
    "user-agent: internetarchive/1.9.0 (Linux x86_64; N; en; U4thOkTyojZeI9us) Python/3.8.10\n",
    "x-archive-auto-make-bucket: 1\n",
    "x-archive-keep-old-version: 1\n",
    "x-archive-meta00-collection: ia_biblio_metadata\n",
    "x-archive-meta00-scanner: uri(Internet%20Archive%20Python%20library%201.9.0)\n",
    "x-archive-meta00-title: datacite_dump_20211022\n",
    "x-archive-queue-derive: 1\n",
    "x-archive-size-hint: 9168882608\n",
    "x-ias3-encoded-key: datacite_dump_20211022.json.zst\n",
    "x-ias3-upload-bytes-per-second: 47494078.826809\n",
    "x-ias3-upload-duration: 193.053173\n",
    "x-ias3-upload-mtime: 1635819992\n",
    "x-ias3-upload-start-time: 1635819799.769071\n",
    "x-upload-date: 2021-11-02T02:26:32.000Z</li>\n",
    "    <li><b>datacite_dump_20211022_meta.xml</b>: xml che contiene i metadati del dump</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doci Dropbox\n",
    "Contiene\n",
    "<ol>\n",
    "    <li>datacitecitationsource.py, dump novembre 2021 scaricato.</li>\n",
    "    <li>dump.py, recupera i JSON da <a href=\"https://api.datacite.org/dois?page[size]=1000&page[cursor]=0\">qui</a></li>\n",
    "    <li>glob.py per costruire i files di supporto</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index Farm Revision Code\n",
    "Codice <a href=\"https://github.com/opencitations/index/tree/farm_revision \n",
    "\">qui</a> \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appunti call con Giuseppe sul refactoring di Index (come procedere per DataCite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Nuovo sistema funziona <b>su db e non csv</b>. Prendiamo dati citazionali e li arricchiamo dai file glob o dalle API per creare l'oggetto citazione. </li>\n",
    "    <li>Tutta questa cosa venica fatta da operator. Ora è inserito dentro cnc.</li>\n",
    "    <li>Ha rimosso anche l'astrazione di runtime. ora ci sono solo degli script ognuno con i suoi argparser che vengono inseriti con gli installer. Non c 'è più l'astrazione runtime perché ogni programma (script, tipo glob di crossref) veniva rappresentato come classe. Ora basta installare index. Per runnare cnc basta che scrivo cnc nel terminal. </li>\n",
    "    <li>controllo esistenza oci: algoritmo. <b>Index è ora diviso in due cartelle</b> una che gestisce quel codice lì e una che gestisce python. prima si runna il comando make e poi pip install. tutti i programmi relativi a index vengono installati.</li>\n",
    "    <li><b>I manager degli id sono cambiati poco, ma non utilizzao più i csv</b>. data={} è dove prima veniva passato il csv manager. La <b>validità si prende da lì e i dati vengono caricati dal database</b> . Fare scrittura e lettura da file era molto lento, rallentava tutto. Allo stato attuale il processo più lungo è la generazione dei glob: degli otto giorni che ci sono messi per runnare il processo va capito quanto tempo prendono i glob. </li>\n",
    "    <li>Finder è l'ultima cartella di cui si sta occupando giuseppe quindi datacite resource finder non è disponibile ora. \n",
    "</li>\n",
    "    <li>Problema al momento: Giuseppe non ha la VPN al momento.\n",
    "</li>\n",
    "    <li><b>Parser ha sostituito citationsource</b>. Estende la classe citationParser e espone due metodi principali (is valid e parse). is valid restituisce true o false se il file deve essere parsato\n",
    "parse passa il filename e tu devi aprire il file. nel mio caso dictreader o altro modo per leggere da csv. <b>get next citation d ata deve restituire citing cited citing date cited date</b>. \n",
    "L'unica <b>differenza è che get next citation data può restituire sia un'unica tupla che un array di tuple</b>, perché <b>nel campo reference di crossref c'è l'array di tutte le citazioni</b>. datacite.py va compilato prendendo spunto dall'analogo sviluppato per crossref. <b>2 differenze rispetto a citationsource : (1) va restituito un array contenente tutte le citazioni contenute nel campo \"relatedIdentifiers\" (che é il corrispettivo di ref per crossref), (2) e non va chiamato self.update_status_file() </b>, perché basta usare la riga (variabile row) per estrarre le citazioni e restituirle\n",
    "facendo il pop: automaticamente alla chiamata dopo estrarrá la prossima riga. Il codice che quindi interessa va da riga 45 in poi</li>\n",
    "    <li>Giuseppe questo we cerca di completare il lavoro e di avere una versione stabile da usare a inizio settimana. \n",
    "per fine mese deve essere finito. Possiamo provarlo con datacite. <b>Io devo fare il parser di datacite e testare il glob dopo aver decompresso il dump.</b></li>\n",
    "\n",
    "</ul>\n",
    " \n",
    "\n",
    "\n",
    "#### Da fare\n",
    "<ol>\n",
    "    <li>modifica get next citation data e crea il parser di DataCite, dovrebbe funzionare come crossref</li>\n",
    "    <li>volendo posso scaricare index (farm revision sconsiglia). Master e farm revision sono a due punti diversi.</li>\n",
    "    <li>e testa il glob. (fondamentale.)</li>\n",
    "</ol>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATACITE PARSER (ex DataCiteCitationSource), Estratto da <a href=\"https://api.datacite.org/dois?page[size]=1000&page[cursor]=5\"> https://api.datacite.org/dois?page[size]=1000&page[cursor]=5 </a> , in attesa del download del dump.\n",
    "\n",
    "Sample della struttura gerarchica (che ci serve sapere per estrarre citante e citato della citazione):\n",
    "<ol>\n",
    "    <li><b>un dizionario</b> che contiene una coppia chiave-valore, la cui chiave è <b>data</b> e il valore una <b>lista di dizionari</b></li>\n",
    "    <li><b>data</b>, la <b>lista</b> che contiene <b>i dizionari che rappresentano le bibliographical entities</b></li>\n",
    "    <li><b>i dizionari: ogni dizionario</b> ha <b>4 coppie chiave valore: id, type, attributes, relationships</b></li>\n",
    "    <li><b>attributes è un dizionario</b>, di cui ci interessano due coppie chiave-valore: <b>'doi', CHE è UNA STRINGA CHE RAPPRESENTA IL CITING </b> (dopo essere stato normalizzato con self._doi_manager.normalise), e  <b>'relatedIdentifiers'</b>, che è una <b>lista di dizionari</b> </li>\n",
    "    <li><b>di questi dizionari, ciascuno rappresenta un identificativo connesso alla bibliograpgical entity</b>. Di questo dizionario ci interessano le seguenti coppie chiave-valore: <b>'relatedIdentifierType'</b> (stringa che identifica il tipo di id in relazione con la bibliographical entity in questione, a noi interessa il valore <i>\"doi\"</i>) <b>'relationType'</b> (stringa che spiega il tipo di rapporto - a noi interessa il valore <i>\"References\"</i>- che lega l'identificativo in questione a quello della bibliographical entity a cui è dedicato il dizionairo in esame), e <b>'relatedIdentifier'</b> (stringa dell'identificativo che è in relazione alla bibliographical entity a cui è dedicato il dizionairo in esame). <b>IL VALORE DI  'relatedIdentifier' è IL DOI CITATO</b> (nel caso in cui il relationType sia \"References\" e il relatedIdentifierType sia \"doi\" ).</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"data\":\n",
    " \n",
    "    [\n",
    "        {\"id\":\"10.5259/20050726120000/http://www.dur.ac.uk/ian.smail/colmag/colmag_top.html\",\n",
    "         \"type\":\"dois\",\n",
    "         \"attributes\":{\n",
    "             \"doi\":\"10.5259/20050726120000/http://www.dur.ac.uk/ian.smail/colmag/colmag_top.html\",\n",
    "             \"identifiers\":[\n",
    "                 {\"identifier\":null,\n",
    "                  \"identifierType\":\"DOI\"\n",
    "                 }],\n",
    "             \"creators\":[],\n",
    "             \"titles\":[],\n",
    "             \"publisher\":null,\n",
    "             \"container\":{},\n",
    "             \"publicationYear\":null,\n",
    "             \"subjects\":[],\n",
    "             \"contributors\":[],\n",
    "             \"dates\":[],\n",
    "             \"language\":null,\n",
    "             \"types\":{\"ris\":\"GEN\",\n",
    "                      \"bibtex\":\"misc\",\n",
    "                      \"citeproc\":\"article\",\n",
    "                      \"schemaOrg\":\"CreativeWork\"},\n",
    "             \"relatedIdentifiers\":[],\n",
    "             \"sizes\":[],\n",
    "             \"formats\":[],\n",
    "             \"version\":null,\n",
    "             \"rightsList\":[],\n",
    "             \"descriptions\":[],\n",
    "             \"geoLocations\":[],\n",
    "             \"fundingReferences\":[],\n",
    "             \"url\":\"http://www.webarchive.org.uk/wayback/archive/20050726120000/http://www.dur.ac.uk/ian.smail/colMag/colMag_top.html\",\n",
    "             \"contentUrl\":null,\n",
    "             \"metadataVersion\":0,\n",
    "             \"schemaVersion\":\"http://datacite.org/schema/kernel-4\",\n",
    "             \"source\":null,\n",
    "             \"isActive\":true,\n",
    "             \"state\":\"findable\",\n",
    "             \"reason\":null,\n",
    "             \"viewCount\":0,\n",
    "             \"downloadCount\":0,\n",
    "             \"referenceCount\":0,\n",
    "             \"citationCount\":0,\n",
    "             \"partCount\":0,\n",
    "             \"partOfCount\":0,\n",
    "             \"versionCount\":0,\n",
    "             \"versionOfCount\":0,\n",
    "             \"created\":\"2011-03-04T14:18:47.000Z\",\n",
    "             \"registered\":\"2011-03-04T14:18:47.000Z\",\n",
    "             \"published\":\"\",\n",
    "             \"updated\":\"2011-03-04T14:18:47.000Z\"\n",
    "         },\n",
    "         \n",
    "         \"relationships\":{\n",
    "             \"client\":{\n",
    "                 \"data\":{\n",
    "                     \"id\":\"bl.wap\",\n",
    "                     \"type\":\"clients\"\n",
    "                 }\n",
    "             }\n",
    "         }\n",
    "        },\n",
    "        \n",
    "        \n",
    "        \n",
    "        {\"id\":\"10.5259/20050509230000/http://www.jr2.ox.ac.uk/bandolier/booth/hliving/allium.html\",\n",
    "         \"type\":\"dois\",\n",
    "         \"attributes\":{\n",
    "             \"doi\":\"10.5259/20050509230000/http://www.jr2.ox.ac.uk/bandolier/booth/hliving/allium.html\",\n",
    "             \"identifiers\":[\n",
    "                 {\"identifier\":null,\n",
    "                  \"identifierType\":\"DOI\"\n",
    "                 }\n",
    "             ],\n",
    "             \"creators\":[],\n",
    "             \"titles\":[],\n",
    "             \"publisher\":null,\n",
    "             \"container\":{},\n",
    "             \"publicationYear\":null,\n",
    "             \"subjects\":[],\n",
    "             \"contributors\":[],\n",
    "             \"dates\":[],\n",
    "             \"language\":null,\n",
    "             \"types\":{\"ris\":\"GEN\",\n",
    "                      \"bibtex\":\"misc\",\n",
    "                      \"citeproc\":\"article\",\n",
    "                      \"schemaOrg\":\"CreativeWork\"},\n",
    "             \"relatedIdentifiers\":[],\n",
    "             \"sizes\":[],\n",
    "             \"formats\":[],\n",
    "             \"version\":null,\n",
    "             \"rightsList\":[],\n",
    "             \"descriptions\":[],\n",
    "             \"geoLocations\":[],\n",
    "             \"fundingReferences\":[],\n",
    "             \"url\":\"http://www.webarchive.org.uk/wayback/archive/20050509230000/http://www.jr2.ox.ac.uk/bandolier/booth/hliving/Allium.html\",\n",
    "             \"contentUrl\":null,\n",
    "             \"metadataVersion\":0,\n",
    "             \"schemaVersion\":\"http://datacite.org/schema/kernel-4\",\n",
    "             \"source\":null,\n",
    "             \"isActive\":true,\n",
    "             \"state\":\"findable\",\n",
    "             \"reason\":null,\n",
    "             \"viewCount\":0,\n",
    "             \"downloadCount\":0,\n",
    "             \"referenceCount\":0,\n",
    "             \"citationCount\":0,\n",
    "             \"partCount\":0,\n",
    "             \"partOfCount\":0,\n",
    "             \"versionCount\":0,\n",
    "             \"versionOfCount\":0,\n",
    "             \"created\":\"2011-03-04T15:37:46.000Z\",\n",
    "             \"registered\":\"2011-03-04T15:37:46.000Z\",\n",
    "             \"published\":\"\",\n",
    "             \"updated\":\"2011-03-04T15:37:46.000Z\"},\n",
    "         \"relationships\":{\n",
    "             \"client\":{\"data\":\n",
    "                       {\"id\":\"bl.wap\",\n",
    "                        \"type\":\"clients\"}\n",
    "                      }\n",
    "         }\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### datacite.py (DataCite Parser, adattato da DataCiteCitationSource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import load\n",
    "\n",
    "from oc.index.identifier.doi import DOIManager\n",
    "from oc.index.parsing.parser import CitationParser\n",
    "\n",
    "\n",
    "class DataciteParser(CitationParser):\n",
    "    def __init__(self):\n",
    "        self._rows = []\n",
    "        self._doi_manager = DOIManager()\n",
    "\n",
    "    def is_valid(self, filename: str):\n",
    "        super().is_valid(filename)\n",
    "        return filename.endswith(\".json\")\n",
    "\n",
    "    def parse(self, filename: str):\n",
    "        super().parse(filename)\n",
    "        json_content = None\n",
    "        with open(filename, encoding=\"utf8\") as fp:\n",
    "            json_content = load(fp)\n",
    "\n",
    "        if \"data\" in json_content:\n",
    "            self._rows = json_content.get(\"data\")\n",
    "            self._items = len(self._rows)\n",
    "\n",
    "    def get_next_citation_data(self):\n",
    "        if len(self._rows) == 0:\n",
    "            return None\n",
    "\n",
    "        row = self._rows.pop()\n",
    "        self._current_item += 1\n",
    "\n",
    "        # from here: parse the row and return citation data\n",
    "\n",
    "        citing = self._doi_manager.normalise(row['attributes']['doi'])\n",
    "        if citing is not None and \"attributes\" in row:\n",
    "\n",
    "            citations = []\n",
    "\n",
    "            attr = row[\"attributes\"]\n",
    "            if 'relatedIdentifiers' in attr:\n",
    "                relatedIdentifier = attr['relatedIdentifiers']\n",
    "                # esempio: \"relatedIdentifiers\" : [{\"relationType\":\"IsCitedBy\",\"relatedIdentifier\":\"10.1234/testpub\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"Cites\",\"relatedIdentifier\":\"http://testing.ts/testpub\",\"relatedIdentifierType\":\"URN\"}]\n",
    "                if relatedIdentifier:\n",
    "                    for related in relatedIdentifier:\n",
    "                            relatedIdentifierType = str(related['relatedIdentifierType'])\n",
    "                            relatedIdentifierType = relatedIdentifierType.lower()\n",
    "                            if relatedIdentifierType:\n",
    "                                if relatedIdentifierType == 'doi':\n",
    "                                    relationType = related['relationType']\n",
    "                                    if relationType:\n",
    "                                        if relationType == 'References':\n",
    "                                            if related['relatedIdentifier']:\n",
    "\n",
    "                                                cited = self._doi_manager.normalise(related['relatedIdentifier'])\n",
    "\n",
    "                                                if cited is not None:\n",
    "                                                    citations.append((citing, cited, None, None, None, None))\n",
    "\n",
    "                    # tendenzialmente non ritornerà niente perché spesso \"relatedIdentifiers\" è una lista vuota\n",
    "                    # (no elementi su cui iterare)\n",
    "                    return citations\n",
    "                    # controlla che sia indentato correttamente:\n",
    "                    # nel codice ci crossref si allinea con for ref in row[\"reference\"],\n",
    "                    # quindi \"per ogni citato\". Così dovrebbe funzionare perché \"relatedIdentifiers\"\n",
    "                    # è una lista che contiene un dizionario per ogni id related con l'id in questione,\n",
    "                    # di cui poi, attraverso le coppie chiave-valore, specifica: il tipo di relazione (NB:\n",
    "                    # COME ESISTONO SIA \"isReferencedBy\" che \"isCitedBy\", oltre a \"References\"\n",
    "                    # esiste anche un \"Cites\": che senso ha?), l'identificativo stesso, e il tipo di identificativo.\n",
    "\n",
    "        return self.get_next_citation_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataCite dump download e decompressione + glob.py (da testare con il vero dump e non quello generato da API -- IN PROGRESSO) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>Decompressione: <b>da 9GB a 120GB</b></li>\n",
    "    <li>Ho utilizzato <b>ijson per risolvere errore di memoria</b></li>\n",
    "    <li><b>Da risolvere: UnicodeDecodeError </b>: 'charmap' codec can't decode byte 0x90 in position 16466: character maps to undefined. <b>RISOLTO: con encoding = utf-8 anche nell'apertura del file con ijson.parse()</b> </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index.storer.csvmanager import CSVManager\n",
    "from index.identifier.doimanager import DOIManager\n",
    "from index.identifier.issnmanager import ISSNManager\n",
    "from index.identifier.orcidmanager import ORCIDManager\n",
    "from os import sep, makedirs, walk\n",
    "from os.path import exists\n",
    "from json import load\n",
    "import datetime\n",
    "from alive_progress import alive_it\n",
    "import ijson\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "#Arianna: calcolo tempo impiegato + monitoraggio\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_all_files(i_dir):\n",
    "    result = []\n",
    "    for cur_dir, cur_subdir, cur_files in walk(i_dir):\n",
    "        for file in alive_it(cur_files):\n",
    "            print(\"file is\", file)\n",
    "            if file.lower().endswith('.json'):\n",
    "                result.append(cur_dir + sep + file)\n",
    "    return result\n",
    "\n",
    "\n",
    "def valiDate(date_text):\n",
    "    date_text = str(date_text)\n",
    "    try:\n",
    "        return datetime.datetime.strptime(date_text, '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return datetime.datetime.strptime(date_text, '%Y-%m').strftime('%Y-%m')\n",
    "        except ValueError:\n",
    "            try:\n",
    "                return datetime.datetime.strptime(date_text, '%Y').strftime('%Y')\n",
    "            except ValueError:\n",
    "                if '-' in date_text:\n",
    "                    possibiliDate = date_text.split('-')\n",
    "                    while possibiliDate:\n",
    "                        possibiliDate.pop()\n",
    "                        seperator = '-'\n",
    "                        data = seperator.join(possibiliDate)\n",
    "                        try:\n",
    "                            return datetime.datetime.strptime(data, '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "                        except ValueError:\n",
    "                            try:\n",
    "                                return datetime.datetime.strptime(data, '%Y-%m').strftime('%Y-%m')\n",
    "                            except ValueError:\n",
    "                                try:\n",
    "                                    return datetime.datetime.strptime(data, '%Y').strftime('%Y')\n",
    "                                except ValueError:\n",
    "                                    pass\n",
    "\n",
    "\n",
    "\n",
    "def process(input_dir, output_dir):\n",
    "    if not exists(output_dir):\n",
    "        makedirs(output_dir)\n",
    "\n",
    "    citing_doi_with_no_date = set()\n",
    "\n",
    "    #variabili identificano i csv (directory + nome csv)\n",
    "    valid_doi = CSVManager(output_dir + sep + \"valid_doi.csv\")\n",
    "    id_date = CSVManager(output_dir + sep + \"id_date.csv\")\n",
    "    # doi + data\n",
    "    id_issn = CSVManager(output_dir + sep + \"id_issn.csv\")\n",
    "    # doi + issn\n",
    "    id_orcid = CSVManager(output_dir + sep + \"id_orcid.csv\")\n",
    "    # doi + orcid\n",
    "\n",
    "    doi_manager = DOIManager(valid_doi)\n",
    "    issn_manager = ISSNManager()\n",
    "    orcid_manager = ORCIDManager()\n",
    "\n",
    "    all_files = get_all_files(input_dir)\n",
    "    #output lista con ogni csv (directory + nome csv)\n",
    "\n",
    "    for file_idx, file in enumerate(all_files):\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f: #qui F è '_io.TextIOWrapper'\n",
    "            f = f.name #qui F è stringa del pathname\n",
    "            for prefix, theType, value in ijson.parse(open(f, encoding=\"utf-8\"), multiple_values=True):\n",
    "                print (\"TYPE\", theType, \"VALUE\", value)\n",
    "                \n",
    "                # FINO A QUI!!!! -- dove smetteva di funzionare\n",
    "                # DA RIVEDERE DA QUI IN AVANTI\n",
    "                \n",
    "                \n",
    "            #obj = load(f)\n",
    "\n",
    "            #creation of a dictionary where the keys are the journalID and the values thier issn\n",
    "\n",
    "            issnDict = {}\n",
    "            objIncluded = obj['included']\n",
    "            for item in objIncluded:\n",
    "                if 'issn' in item['attributes']:\n",
    "                    attributes = item['attributes']\n",
    "                    idProvider = item['id']\n",
    "                    issn = attributes['issn']\n",
    "                    if issn:\n",
    "                        issnValues = set()\n",
    "                        if type(issn) is str:\n",
    "                            issnValues.add(issn)\n",
    "                        else:\n",
    "                            if 'electronic' in issn:\n",
    "                                issnValues.add(str(issn['electronic']))\n",
    "                            if 'print' in issn:\n",
    "                                issnValues.add(str(issn['print']))\n",
    "                        issnDict[idProvider] = issnValues\n",
    "\n",
    "            if 'data' in obj:\n",
    "\n",
    "                #Collecting DOI\n",
    "\n",
    "                for item in obj['data']:\n",
    "                    attributes = item['attributes']\n",
    "                    citing_doi = attributes['doi']\n",
    "                    citing_doi = doi_manager.normalise(citing_doi, True)\n",
    "                    doi_manager.set_valid(citing_doi)\n",
    "\n",
    "                    #if one journalID is in the dictionary, collect issn\n",
    "\n",
    "                    idClient = item['relationships']['client']['data']['id']\n",
    "                    if idClient in issnDict:\n",
    "                        issnSet = issnDict[idClient]\n",
    "                        if issnSet:\n",
    "                            for issn in issnSet:\n",
    "                                if issn_manager.is_valid(issn):\n",
    "                                    id_issn.add_value(citing_doi, issn)\n",
    "\n",
    "                    #collect the date of issue if there is, otherwise the year of publciation\n",
    "\n",
    "                    if id_date.get_value(citing_doi) is None:\n",
    "                        listDates = item['attributes']['dates']\n",
    "                        publicationYear = item['attributes']['publicationYear']\n",
    "                        if listDates:\n",
    "                            for data in listDates:\n",
    "                                tipo = str(data['dateType'])\n",
    "                                if tipo == 'Issued':\n",
    "                                    obj_date = str(data['date'])\n",
    "                                    citing_date = valiDate(obj_date)\n",
    "                                    if valiDate(citing_date):\n",
    "                                        id_date.add_value(citing_doi, citing_date)\n",
    "                                        if citing_doi in citing_doi_with_no_date:\n",
    "                                            citing_doi_with_no_date.remove(citing_doi)\n",
    "                                else:\n",
    "                                    if publicationYear:\n",
    "                                        publicationYear = valiDate(str(publicationYear))\n",
    "                                        if publicationYear:\n",
    "                                            id_date.add_value(citing_doi, publicationYear)\n",
    "                                            if citing_doi in citing_doi_with_no_date:\n",
    "                                                citing_doi_with_no_date.remove(citing_doi)\n",
    "                        else:\n",
    "                            if publicationYear:\n",
    "                                publicationYear = valiDate(str(publicationYear))\n",
    "                                if publicationYear:\n",
    "                                    id_date.add_value(citing_doi, publicationYear)\n",
    "                                    if citing_doi in citing_doi_with_no_date:\n",
    "                                        citing_doi_with_no_date.remove(citing_doi)\n",
    "\n",
    "                    #collect the orcid of the contributors\n",
    "\n",
    "                    if id_orcid.get_value(citing_doi) is None:\n",
    "                        contributorList = item['attributes']['creators']\n",
    "                        if contributorList:\n",
    "                            if contributorList != []:\n",
    "                                for author in contributorList:\n",
    "                                    if 'nameIdentifiers' in author:\n",
    "                                        infoAuthor = author['nameIdentifiers']\n",
    "                                        for element in infoAuthor:\n",
    "                                            if 'nameIdentifier' in element:\n",
    "                                                if element['nameIdentifierScheme'] == 'ORCID':\n",
    "                                                    orcid = element['nameIdentifier']\n",
    "                                                    if orcid is not None:\n",
    "                                                        orcid = orcid_manager.normalise(orcid)\n",
    "                                                        if orcid_manager.is_valid(orcid):\n",
    "                                                            id_orcid.add_value(citing_doi, orcid)\n",
    "            #collect cited and citated by doi\n",
    "    for file_idx, file in enumerate(all_files):\n",
    "        with open(file, encoding=\"utf8\") as f:\n",
    "            obj = load(f)\n",
    "            if 'data' in obj:\n",
    "                for element in obj['data']:\n",
    "                    attribute = element['attributes']\n",
    "                    relatedIdentifier = attribute['relatedIdentifiers']\n",
    "                    if relatedIdentifier:\n",
    "                        for related in relatedIdentifier:\n",
    "                            relationType = related['relationType']\n",
    "                            if relationType:\n",
    "                                if relationType == 'References' or 'IsReferencedBy':\n",
    "\n",
    "                                    # Att! Qui salviamo DOI citati e citanti\n",
    "\n",
    "                                    relatedIdentifierType = str(related['relatedIdentifierType'])\n",
    "                                    relatedIdentifierType = relatedIdentifierType.lower()\n",
    "                                    if relatedIdentifierType:\n",
    "                                        if relatedIdentifierType == 'doi':\n",
    "                                            if related['relatedIdentifier']:\n",
    "                                                relatedDOI = str(related['relatedIdentifier'])\n",
    "                                                if relatedDOI:\n",
    "                                                    doi_manager.is_valid(relatedDOI)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start = timer()\n",
    "dumpFolder = \"E:\\LAVORO\\DOCI\\dump_doci\\datacite_dump_20211022\\input_test\"\n",
    "resultFolder = \"E:\\LAVORO\\DOCI\\dump_doci\\datacite_dump_20211022\\output_test\"\n",
    "process(dumpFolder, 'resultFolder')\n",
    "end = timer()\n",
    "print(\"elapsed time, in seconds:\", (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !!\n",
    "<ul>\n",
    "    <li>Una volta che i dati verranno recuperati dalle API, le richieste con axios dovrebbero essere parallele</li>\n",
    "    <li>Quando le visualizzazioni funzioneranno con le richieste alle API pensavo di impostare la visualizzazione di default su scala mensile, che copra l'anno dai 13 mesi precedenti al mese precedente quello corrente (quindi l'ultimo di cui l'API dovrebbe avere i dati a disposizione).\n",
    "??: è rischioso? Ovvero, è possibile che per qualche motivo le API non funzionino, quindi sarebbe più prudente lasciare comunque dei dati locali per avere almeno le visualizzazioni di default?</li>\n",
    "    <li>Nel dump di DataCite controllare questione References</li>\n",
    "    <li>\"https://opencitations.net/statistics/last-month\" va messa in stastistics get</li>\n",
    "    <li>Sto testando il glob di datacite con ijson perché non riesce a caricarlo tutto (120GB).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Final Fix - DOCI + NOCI (citation source parser e glob))\n",
    "<a id=\"entry_10\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Visualizzazioni: recupero dati da API + aggiornamento visualizzazioni di Default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0) Aggiornamento indipendente dei grafici\n",
    "<b>Modifica modalità update dei grafici</b>: Nella versione precedente i grafici venivano aggiornati con gli stessi parametri. Nella versione attuale, <b>l'aggiornamento di ciascuno dei due grafici è diventato indipendente</b> (possono essere scelti parametri diversi per la visualizzazione relativa al numero di indexed records rispetto a quelli per la visualizzazione relativa all'utilizzo dei servizi)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1) Visualizzazioni: recupero dati da API \n",
    "<ul>\n",
    "    <li>Step 0: Correzione errore in estrazione dati</li>\n",
    "    <li><b>Step 1:</b> Aggiornamento delle visualizzazioni con recupero dati da API (non in parallelo), con AXIOS</li>\n",
    "    <li><b>Step 2:</b> Aggiornamento delle visualizzazioni con recupero dati da API in parallelo, con <b>axios.all</b> e <b>axios.spread</b></li>\n",
    "    <li><b>Step 3:</b> Correzione del Mixed Content Error (http/https) </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2) Aggiornamento visualizzazioni di Default\n",
    "<b>Richiesta</b>: Attualmente, al caricare della pagina <a href=\"https://ariannamorettj.github.io/OC_log_viz/\">https://ariannamorettj.github.io/OC_log_viz/</a> i dati caricati nelle visualizzazioni sono inseriti manualmente. Nella prossima versione devono aggiornarsi automaticamente con i seguenti parametri:\n",
    "<ol>\n",
    "    <li><b>To</b>: (default) <b>last-month</b>. La richiesta opencitations/statistics/last-month conduce automaticamente agli ultimi dati caricati. Da questo file bisogna ricavare la data in formato corretto. Inoltre, questo dato va utilizzato anche per ricavare l'ultimo mese selezionabile del calendario.</li>\n",
    "    <li><b>From</b>: (default) <b> last-month - 12</b></li>\n",
    "    <li><b>Intervalli:</b> <b>mensile</b> per le richieste ai servizi e <b>bimestrale</b> per crescita indexed records</li>\n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! Da completare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Index (Glob e Parser)  - DATACITE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1) Glob DataCite\n",
    "##### 2.1.1) Struttura risposta API vs struttura DUMP\n",
    "<ol>\n",
    "    <li><b>Risposta API:</b> è un dizionario con 4 chiavi (non una lista, come scritto in documentazione). <b><u>Da Documentazione</u></b>: What's in a list?\n",
    "        A list has four parts: <b>data</b>, which will contain the items matching the query or filter.\n",
    "        <b>included</b>, which will contain side-loaded associations, via the ?include=x parameter.\n",
    "        <b>meta</b>, which includes information about the query, e.g. number of results returned.\n",
    "        <b>links</b>, which includes links to the current and next page.</li>\n",
    "    <li><b>DUMP</b> Serie di dizionari. Ogni dizionario ha le seguenti chiavi: <b>id (str), type (str), attributes (dict), relationships (dict)</b>. Praticamente contiene gli <b>elementi della lista associata alla chiave \"data\" nella risposta dell'API, ma non separati da virgole</b></li>\n",
    "</ol>\n",
    "\n",
    "<b>Implicazioni:</b> Nel codice precedentemente sviluppato c'è un <b>passaggio preliminare</b> in cui vengono salvate delle informazioni relative agli ISSN in un dizionario, sfruttando il valore della chiave <b>\"included\"</b>\n",
    "\n",
    "##### 2.1.2) \"Included\" Key\n",
    "I dati di DataCite che abbiamo attualmente a disposizione provengono dal <b>dump</b> e dalle <b>API</b>. Il dump è strutturato come una <b>sequenza di dizionari</b>,  mentre la risposta delle API è un dizionario che contiene le quattro chiavi sopracitate. Di conseguenza, sfruttando il dump, non si possono più usare i valori della chiave included, da cui venivano recuperate delle informazioni relative agli ISSN. <b>Inoltre sembra che la chiave included non sia nemmeno più presente nelle risposte delle API. è possibile che sia stata rimossa senza che venisse aggiornata la documentazione?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemp_API_resp = {\n",
    "  \"data\": [{\n",
    "      \"id\": \"10.15468/dl.ydqssk\",\n",
    "      \"type\": \"dois\",\n",
    "      \"attributes\": {\n",
    "        \"doi\": \"10.15468/dl.ydqssk\",\n",
    "        \"identifiers\": [{\n",
    "            \"identifier\": \"https://doi.org/10.15468/dl.ydqssk\",\n",
    "            \"identifierType\": \"DOI\"\n",
    "          },\n",
    "          {\n",
    "            \"identifier\": \"0036778-181108115102211\",\n",
    "            \"identifierType\": \"GBIF\"\n",
    "          }\n",
    "        ],\n",
    "        \"creators\": [{\n",
    "          \"name\": \"Occdownload Gbif.Org\"\n",
    "        }],\n",
    "        \"titles\": [{\n",
    "          \"title\": \"GBIF Occurrence Download\"\n",
    "        }],\n",
    "        \"publisher\": \"The Global Biodiversity Information Facility\",\n",
    "        \"container\": \"null\",\n",
    "        \"publicationYear\": 2019,\n",
    "        \"subjects\": [{\n",
    "            \"lang\": \"eng\",\n",
    "            \"subject\": \"GBIF\"\n",
    "          },\n",
    "          {\n",
    "            \"lang\": \"eng\",\n",
    "            \"subject\": \"biodiversity\"\n",
    "          },\n",
    "          {\n",
    "            \"lang\": \"eng\",\n",
    "            \"subject\": \"species occurrences\"\n",
    "          }\n",
    "        ],\n",
    "        \"contributors\": \"null\",\n",
    "        \"dates\": [{\n",
    "            \"date\": \"2019-02-06\",\n",
    "            \"dateType\": \"Created\"\n",
    "          },\n",
    "          {\n",
    "            \"date\": \"2019-02-06\",\n",
    "            \"dateType\": \"Updated\"\n",
    "          },\n",
    "          {\n",
    "            \"date\": \"2019\",\n",
    "            \"dateType\": \"Issued\"\n",
    "          }\n",
    "        ],\n",
    "        \"language\": \"null\",\n",
    "        \"types\": {\n",
    "          \"ris\": \"DATA\",\n",
    "          \"bibtex\": \"misc\",\n",
    "          \"citeproc\": \"dataset\",\n",
    "          \"schemaOrg\": \"Dataset\",\n",
    "          \"resourceTypeGeneral\": \"Dataset\"\n",
    "        },\n",
    "        \"relatedIdentifiers\": [{\n",
    "            \"relationType\": \"References\",\n",
    "            \"relatedIdentifier\": \"10.15468/xtjld4\",\n",
    "            \"relatedIdentifierType\": \"DOI\"\n",
    "          },\n",
    "          {\n",
    "            \"relationType\": \"References\",\n",
    "            \"relatedIdentifier\": \"10.15468/xmki52\",\n",
    "            \"relatedIdentifierType\": \"DOI\"\n",
    "          },\n",
    "          {\n",
    "            \"relationType\": \"References\",\n",
    "            \"relatedIdentifier\": \"10.15468/ul946t\",\n",
    "            \"relatedIdentifierType\": \"DOI\"\n",
    "          },\n",
    "          {\n",
    "            \"relationType\": \"References\",\n",
    "            \"relatedIdentifier\": \"10.15468/dg1xxz\",\n",
    "            \"relatedIdentifierType\": \"DOI\"\n",
    "          },\n",
    "          {\n",
    "            \"relationType\": \"References\",\n",
    "            \"relatedIdentifier\": \"10.15468/jxs9rn\",\n",
    "            \"relatedIdentifierType\": \"DOI\"\n",
    "          },\n",
    "          {\n",
    "            \"relationType\": \"References\",\n",
    "            \"relatedIdentifier\": \"10.15468/cpnhcc\",\n",
    "            \"relatedIdentifierType\": \"DOI\"\n",
    "          },\n",
    "          {\n",
    "            \"relationType\": \"References\",\n",
    "            \"relatedIdentifier\": \"10.15468/hnhrg3\",\n",
    "            \"relatedIdentifierType\": \"DOI\"\n",
    "          },\n",
    "          {\n",
    "            \"relationType\": \"References\",\n",
    "            \"relatedIdentifier\": \"10.15468/ypoair\",\n",
    "            \"relatedIdentifierType\": \"DOI\"\n",
    "          },\n",
    "          {\n",
    "            \"relationType\": \"References\",\n",
    "            \"relatedIdentifier\": \"10.15468/nc6rxy\",\n",
    "            \"relatedIdentifierType\": \"DOI\"\n",
    "          },\n",
    "          {\n",
    "            \"relationType\": \"References\",\n",
    "            \"relatedIdentifier\": \"10.15468/rvjdu1\",\n",
    "            \"relatedIdentifierType\": \"DOI\"\n",
    "          },\n",
    "          {\n",
    "            \"relationType\": \"References\",\n",
    "            \"relatedIdentifier\": \"10.15468/tqcbr0\",\n",
    "            \"relatedIdentifierType\": \"DOI\"\n",
    "          },\n",
    "          {\n",
    "            \"relationType\": \"References\",\n",
    "            \"relatedIdentifier\": \"10.15468/mug7kr\",\n",
    "            \"relatedIdentifierType\": \"DOI\"\n",
    "          },\n",
    "          {\n",
    "            \"relationType\": \"References\",\n",
    "            \"relatedIdentifier\": \"10.15468/ly60bx\",\n",
    "            \"relatedIdentifierType\": \"DOI\"\n",
    "          }\n",
    "        ],\n",
    "        \"sizes\": [\n",
    "          \"2926\"\n",
    "        ],\n",
    "        \"formats\": [\n",
    "          \"Darwin Core Archive\"\n",
    "        ],\n",
    "        \"version\": \"null\",\n",
    "        \"rightsList\": [{\n",
    "          \"rights\": \"Creative Commons Attribution Non Commercial (CC-BY-NC) 4.0\",\n",
    "          \"rightsUri\": \"http://creativecommons.org/licenses/by-nc/4.0/legalcode\"\n",
    "        }],\n",
    "        \"descriptions\": [{\n",
    "          \"lang\": \"eng\",\n",
    "          \"description\": \"A dataset containing 19 species occurrences available in GBIF matching the query: TaxonKey: Oxytropis fominii Grossh.. The dataset includes 19 records from 13 constituent datasets: \\n 1 records from Universidad del Paí­s Vasco/EHU, Bilbao: Herbario BIO. \\n 1 records from Colección de plantas vasculares del herbario de la Universitat de València (VAL).. \\n 1 records from Herbario de Plantas Vasculares de la Universidad de Salamanca: SALA. \\n 1 records from Herbaria of the University and ETH Zürich. \\n 1 records from Aranzadi Zientzi Elkartea. \\n 2 records from Moscow University Herbarium (MW). \\n 1 records from NMNH Extant Specimen Records. \\n 6 records from Royal Botanic Garden Edinburgh Herbarium (E). \\n 1 records from The vascular plants collection (P) at the Herbarium of the Muséum national d'Histoire Naturelle (MNHN - Paris). \\n 1 records from Geneva Herbarium – General Collection (G). \\n 1 records from VIT Herbarium - Vascular Plants (The Natural History Museum of Alava). \\n 1 records from CSIC-Real Jardín Botánico-Colección de Plantas Vasculares (MA). \\n 1 records from Royal Botanic Gardens, Kew - Herbarium Specimens. Data from some individual datasets included in this download may be licensed under less restrictive terms.\",\n",
    "          \"descriptionType\": \"Abstract\"\n",
    "        }],\n",
    "        \"geoLocations\": \"null\",\n",
    "        \"fundingReferences\": \"null\",\n",
    "        \"url\": \"https://www.gbif.org/occurrence/download/0036778-181108115102211\",\n",
    "        \"contentUrl\": \"null\",\n",
    "        \"metadataVersion\": 0,\n",
    "        \"schemaVersion\": \"http://datacite.org/schema/kernel-3\",\n",
    "        \"source\": \"mds\",\n",
    "        \"isActive\": True,\n",
    "        \"state\": \"findable\",\n",
    "        \"reason\": \"null\",\n",
    "        \"created\": \"2019-02-06T19:42:33.000Z\",\n",
    "        \"registered\": \"2019-02-06T19:42:33.000Z\",\n",
    "        \"updated\": \"2019-02-06T19:42:34.000Z\"\n",
    "      },\n",
    "      \"relationships\": {\n",
    "        \"client\": {\n",
    "          \"data\": {\n",
    "            \"id\": \"gbif.gbif\",\n",
    "            \"type\": \"clients\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"10.21994/loar160\",\n",
    "      \"type\": \"dois\",\n",
    "      \"attributes\": {\n",
    "        \"doi\": \"10.21994/loar160\",\n",
    "        \"identifiers\": [{\n",
    "            \"identifier\": \"https://doi.org/10.21994/loar160\",\n",
    "            \"identifierType\": \"DOI\"\n",
    "          },\n",
    "          {\n",
    "            \"identifier\": \"https://loar.kb.dk/handle/1902/330\",\n",
    "            \"identifierType\": \"uri\"\n",
    "          }\n",
    "        ],\n",
    "        \"creators\": [{\n",
    "          \"name\": \"Meyer-Helmund, Erik\",\n",
    "          \"nameType\": \"Personal\",\n",
    "          \"givenName\": \"Erik\",\n",
    "          \"familyName\": \"Meyer-Helmund\"\n",
    "        }],\n",
    "        \"titles\": [{\n",
    "          \"title\": \"Zauberlied\"\n",
    "        }],\n",
    "        \"publisher\": \"Royal Danish Library\",\n",
    "        \"container\": {},\n",
    "        \"publicationYear\": 2018,\n",
    "        \"subjects\": [{\n",
    "          \"subject\": \"valse\"\n",
    "        }],\n",
    "        \"contributors\": [{\n",
    "            \"name\": \"Management, Royal Danish Library Data\",\n",
    "            \"nameType\": \"Personal\",\n",
    "            \"givenName\": \"Royal Danish Library Data\",\n",
    "            \"familyName\": \"Management\",\n",
    "            \"contributorType\": \"DataManager\"\n",
    "          },\n",
    "          {\n",
    "            \"name\": \"Library, Royal Danish\",\n",
    "            \"nameType\": \"Personal\",\n",
    "            \"givenName\": \"Royal Danish\",\n",
    "            \"familyName\": \"Library\",\n",
    "            \"contributorType\": \"HostingInstitution\"\n",
    "          }\n",
    "        ],\n",
    "        \"dates\": [{\n",
    "            \"date\": \"2018-08-16\",\n",
    "            \"dateType\": \"Accepted\"\n",
    "          },\n",
    "          {\n",
    "            \"date\": \"2018-08-16\",\n",
    "            \"dateType\": \"Available\"\n",
    "          },\n",
    "          {\n",
    "            \"date\": \"2018\",\n",
    "            \"dateType\": \"Issued\"\n",
    "          }\n",
    "        ],\n",
    "        \"language\": \"null\",\n",
    "        \"types\": {\n",
    "          \"ris\": \"GEN\",\n",
    "          \"bibtex\": \"misc\",\n",
    "          \"citeproc\": \"article\",\n",
    "          \"schemaOrg\": \"CreativeWork\"\n",
    "        },\n",
    "        \"relatedIdentifiers\": [],\n",
    "        \"sizes\": [],\n",
    "        \"formats\": [],\n",
    "        \"version\": \"null\",\n",
    "        \"rightsList\": [{\n",
    "            \"rights\": \"Attribution-NonCommercial-ShareAlike 2.5 Denmark\"\n",
    "          },\n",
    "          {\n",
    "            \"rightsUri\": \"http://creativecommons.org/licenses/by-nc-sa/2.5/dk\"\n",
    "          }\n",
    "        ],\n",
    "        \"descriptions\": [{\n",
    "          \"description\": \"Af den klaverakkompagnerede sang synges første vers og andet omkvæd. Sanger senere kendt som Peter Cornelius.\",\n",
    "          \"descriptionType\": \"Abstract\"\n",
    "        }],\n",
    "        \"geoLocations\": [],\n",
    "        \"fundingReferences\": [],\n",
    "        \"url\": \"null\",\n",
    "        \"contentUrl\": \"null\",\n",
    "        \"metadataVersion\": 13,\n",
    "        \"schemaVersion\": \"http://datacite.org/schema/kernel-3\",\n",
    "        \"source\": \"mds\",\n",
    "        \"isActive\": False,\n",
    "        \"state\": \"registered\",\n",
    "        \"reason\": \"null\",\n",
    "        \"created\": \"2018-08-16T18:00:44.000Z\",\n",
    "        \"registered\": \"null\",\n",
    "        \"updated\": \"2019-02-06T19:42:22.000Z\"\n",
    "      },\n",
    "      \"relationships\": {\n",
    "        \"client\": {\n",
    "          \"data\": {\n",
    "            \"id\": \"dk.sb\",\n",
    "            \"type\": \"clients\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"included\": [{\n",
    "      \"id\": \"gbif.gbif\",\n",
    "      \"type\": \"clients\",\n",
    "      \"attributes\": {\n",
    "        \"name\": \"Global Biodiversity Information Facility\",\n",
    "        \"symbol\": \"GBIF.GBIF\",\n",
    "        \"year\": 2018,\n",
    "        \"contactName\": \"Daniel Noesgaard\",\n",
    "        \"contactEmail\": \"dnoesgaard@gbif.org\",\n",
    "        \"description\": \"GBIF is an international organisation that is working to make the world's biodiversity data accessible everywhere in the world. GBIF and its many partners work to mobilize the data, and to improve search mechanisms, data and metadata standards, web services, and the other components of an Internet-based information infrastructure for biodiversity.\\r\\nGBIF makes available data that are shared by hundreds of data publishers from around the world. These data are shared according to the GBIF Data Use Agreement, which includes the provision that users of any data accessed through or retrieved via the GBIF Portal will always give credit to the original data publishers.\",\n",
    "        \"domains\": \"*\",\n",
    "        \"url\": \"https://www.gbif.org/\",\n",
    "        \"created\": \"2018-12-20T14:03:45.000Z\",\n",
    "        \"updated\": \"2018-12-20T15:48:55.000Z\",\n",
    "        \"isActive\": True,\n",
    "        \"hasPassword\": True\n",
    "      },\n",
    "      \"relationships\": {\n",
    "        \"provider\": {\n",
    "          \"data\": {\n",
    "            \"id\": \"gbif\",\n",
    "            \"type\": \"providers\"\n",
    "          }\n",
    "        },\n",
    "        \"repository\": {\n",
    "          \"data\": {\n",
    "            \"id\": \"10.17616/R3J014\",\n",
    "            \"type\": \"repositories\"\n",
    "          }\n",
    "        },\n",
    "        \"prefixes\": {\n",
    "          \"data\": [{\n",
    "              \"id\": \"10.15469\",\n",
    "              \"type\": \"prefixes\"\n",
    "            },\n",
    "            {\n",
    "              \"id\": \"10.15468\",\n",
    "              \"type\": \"prefixes\"\n",
    "            },\n",
    "            {\n",
    "              \"id\": \"10.26161\",\n",
    "              \"type\": \"prefixes\"\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"meta\": {\n",
    "    \"total\": 16163585,\n",
    "    \"totalPages\": 400,\n",
    "    \"page\": 1,\n",
    "    \"states\": [{\n",
    "        \"id\": \"findable\",\n",
    "        \"title\": \"Findable\",\n",
    "        \"count\": 13988297\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"registered\",\n",
    "        \"title\": \"Registered\",\n",
    "        \"count\": 2038055\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"draft\",\n",
    "        \"title\": \"Draft\",\n",
    "        \"count\": 137233\n",
    "      }\n",
    "    ],\n",
    "    \"resourceTypes\": [{\n",
    "        \"id\": \"dataset\",\n",
    "        \"title\": \"Dataset\",\n",
    "        \"count\": 5638256\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"text\",\n",
    "        \"title\": \"Text\",\n",
    "        \"count\": 3677624\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"other\",\n",
    "        \"title\": \"Other\",\n",
    "        \"count\": 1329137\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"image\",\n",
    "        \"title\": \"Image\",\n",
    "        \"count\": 1136857\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"physical-object\",\n",
    "        \"title\": \"PhysicalObject\",\n",
    "        \"count\": 879433\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"collection\",\n",
    "        \"title\": \"Collection\",\n",
    "        \"count\": 595510\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"audiovisual\",\n",
    "        \"title\": \"Audiovisual\",\n",
    "        \"count\": 85732\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"workflow\",\n",
    "        \"title\": \"Workflow\",\n",
    "        \"count\": 83144\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"software\",\n",
    "        \"title\": \"Software\",\n",
    "        \"count\": 82965\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"interactive-resource\",\n",
    "        \"title\": \"InteractiveResource\",\n",
    "        \"count\": 55409\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"event\",\n",
    "        \"title\": \"Event\",\n",
    "        \"count\": 8446\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"sound\",\n",
    "        \"title\": \"Sound\",\n",
    "        \"count\": 5586\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"model\",\n",
    "        \"title\": \"Model\",\n",
    "        \"count\": 3229\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"film\",\n",
    "        \"title\": \"Film\",\n",
    "        \"count\": 1630\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"data-paper\",\n",
    "        \"title\": \"DataPaper\",\n",
    "        \"count\": 756\n",
    "      }\n",
    "    ],\n",
    "    \"created\": [{\n",
    "        \"id\": \"2011\",\n",
    "        \"title\": \"2011\",\n",
    "        \"count\": 748443\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2012\",\n",
    "        \"title\": \"2012\",\n",
    "        \"count\": 665761\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2013\",\n",
    "        \"title\": \"2013\",\n",
    "        \"count\": 948008\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2014\",\n",
    "        \"title\": \"2014\",\n",
    "        \"count\": 1894065\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2015\",\n",
    "        \"title\": \"2015\",\n",
    "        \"count\": 2565786\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2016\",\n",
    "        \"title\": \"2016\",\n",
    "        \"count\": 2340736\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2017\",\n",
    "        \"title\": \"2017\",\n",
    "        \"count\": 3109411\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2018\",\n",
    "        \"title\": \"2018\",\n",
    "        \"count\": 3682899\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2019\",\n",
    "        \"title\": \"2019\",\n",
    "        \"count\": 208476\n",
    "      }\n",
    "    ],\n",
    "    \"registered\": [{\n",
    "        \"id\": \"2004\",\n",
    "        \"title\": \"2004\",\n",
    "        \"count\": 24\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2005\",\n",
    "        \"title\": \"2005\",\n",
    "        \"count\": 255104\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2006\",\n",
    "        \"title\": \"2006\",\n",
    "        \"count\": 216729\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2007\",\n",
    "        \"title\": \"2007\",\n",
    "        \"count\": 78837\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2008\",\n",
    "        \"title\": \"2008\",\n",
    "        \"count\": 35176\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2009\",\n",
    "        \"title\": \"2009\",\n",
    "        \"count\": 82492\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2010\",\n",
    "        \"title\": \"2010\",\n",
    "        \"count\": 332088\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2011\",\n",
    "        \"title\": \"2011\",\n",
    "        \"count\": 156156\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2012\",\n",
    "        \"title\": \"2012\",\n",
    "        \"count\": 494205\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2013\",\n",
    "        \"title\": \"2013\",\n",
    "        \"count\": 713764\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2014\",\n",
    "        \"title\": \"2014\",\n",
    "        \"count\": 1891581\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2015\",\n",
    "        \"title\": \"2015\",\n",
    "        \"count\": 2563675\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2016\",\n",
    "        \"title\": \"2016\",\n",
    "        \"count\": 2335420\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2017\",\n",
    "        \"title\": \"2017\",\n",
    "        \"count\": 3104446\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2018\",\n",
    "        \"title\": \"2018\",\n",
    "        \"count\": 3600461\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2019\",\n",
    "        \"title\": \"2019\",\n",
    "        \"count\": 169411\n",
    "      }\n",
    "    ],\n",
    "    \"providers\": [{\n",
    "        \"id\": \"ethz\",\n",
    "        \"title\": \"ETH Zurich\",\n",
    "        \"count\": 1861598\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"sage\",\n",
    "        \"title\": \"SAGE Publishing\",\n",
    "        \"count\": 1686336\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"tib\",\n",
    "        \"title\": \"German National Library of Science and Technology\",\n",
    "        \"count\": 1503525\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"bl\",\n",
    "        \"title\": \"British Library\",\n",
    "        \"count\": 1210667\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"figshare\",\n",
    "        \"title\": \"figshare\",\n",
    "        \"count\": 1202643\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"fao\",\n",
    "        \"title\": \"FAO\",\n",
    "        \"count\": 829032\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"cdl\",\n",
    "        \"title\": \"California Digital Library\",\n",
    "        \"count\": 826959\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"cern\",\n",
    "        \"title\": \"CERN - European Organization for Nuclear Research\",\n",
    "        \"count\": 809016\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"rg\",\n",
    "        \"title\": \"ResearchGate\",\n",
    "        \"count\": 771107\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"gesis\",\n",
    "        \"title\": \"GESIS - Leibniz Institute for the Social Sciences\",\n",
    "        \"count\": 695568\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"estdoi\",\n",
    "        \"title\": \"Tartu University\",\n",
    "        \"count\": 679720\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"gbif\",\n",
    "        \"title\": \"Global Biodiversity Information Facility\",\n",
    "        \"count\": 546932\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"usc\",\n",
    "        \"title\": \"University of Southern California\",\n",
    "        \"count\": 446178\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"cul\",\n",
    "        \"title\": \"Columbia University Libraries\",\n",
    "        \"count\": 431649\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"cisti\",\n",
    "        \"title\": \"National Research Council Canada\",\n",
    "        \"count\": 344324\n",
    "      }\n",
    "    ],\n",
    "    \"clients\": [{\n",
    "        \"id\": \"sage.dplanet\",\n",
    "        \"title\": \"Data Planet\",\n",
    "        \"count\": 1686336\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"figshare.ars\",\n",
    "        \"title\": \"figshare Academic Research System\",\n",
    "        \"count\": 1148737\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"fao.itpgrfa\",\n",
    "        \"title\": \"International Treaty on Plant Genetic Resources for Food and Agriculture\",\n",
    "        \"count\": 829027\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"rg.rg\",\n",
    "        \"title\": \"ResearchGate\",\n",
    "        \"count\": 771107\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"bl.ccdc\",\n",
    "        \"title\": \"The Cambridge Crystallographic Data Centre\",\n",
    "        \"count\": 768734\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"ethz.seals\",\n",
    "        \"title\": \"E-Periodica\",\n",
    "        \"count\": 758570\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"tib.pangaea\",\n",
    "        \"title\": \"PANGAEA\",\n",
    "        \"count\": 742307\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"estdoi.bio\",\n",
    "        \"title\": \"Plutof.  Data Management and Publishing Platform\",\n",
    "        \"count\": 675463\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"cern.zenodo\",\n",
    "        \"title\": \"Zenodo\",\n",
    "        \"count\": 610448\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"gbif.gbif\",\n",
    "        \"title\": \"Global Biodiversity Information Facility\",\n",
    "        \"count\": 546932\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"usc.dl\",\n",
    "        \"title\": \"University of Southern California Digital Library\",\n",
    "        \"count\": 446165\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"ethz.epics-ba\",\n",
    "        \"title\": \"E-Pics Bildarchiv\",\n",
    "        \"count\": 434457\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"cul.columbia\",\n",
    "        \"title\": \"Columbia University Libraries\",\n",
    "        \"count\": 404859\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"gesis.die\",\n",
    "        \"title\": \"Deutsches Institut für Erwachsenenbildung\",\n",
    "        \"count\": 373236\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"gdcc.harvard-dv\",\n",
    "        \"title\": \"Harvard IQSS Dataverse\",\n",
    "        \"count\": 308640\n",
    "      }\n",
    "    ],\n",
    "    \"prefixes\": [{\n",
    "        \"id\": \"10.6068\",\n",
    "        \"title\": \"10.6068\",\n",
    "        \"count\": 1686336\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"10.6084\",\n",
    "        \"title\": \"10.6084\",\n",
    "        \"count\": 1148753\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"10.18730\",\n",
    "        \"title\": \"10.18730\",\n",
    "        \"count\": 829027\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"10.1594\",\n",
    "        \"title\": \"10.1594\",\n",
    "        \"count\": 797692\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"10.13140\",\n",
    "        \"title\": \"10.13140\",\n",
    "        \"count\": 771107\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"10.5517\",\n",
    "        \"title\": \"10.5517\",\n",
    "        \"count\": 764938\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"10.5169\",\n",
    "        \"title\": \"10.5169\",\n",
    "        \"count\": 758570\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"10.15156\",\n",
    "        \"title\": \"10.15156\",\n",
    "        \"count\": 675463\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"10.5281\",\n",
    "        \"title\": \"10.5281\",\n",
    "        \"count\": 609722\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"10.15468\",\n",
    "        \"title\": \"10.15468\",\n",
    "        \"count\": 547861\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"10.25549\",\n",
    "        \"title\": \"10.25549\",\n",
    "        \"count\": 446165\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"10.3932\",\n",
    "        \"title\": \"10.3932\",\n",
    "        \"count\": 434457\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"10.7916\",\n",
    "        \"title\": \"10.7916\",\n",
    "        \"count\": 404859\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"10.12764\",\n",
    "        \"title\": \"10.12764\",\n",
    "        \"count\": 373236\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"10.7910\",\n",
    "        \"title\": \"10.7910\",\n",
    "        \"count\": 308551\n",
    "      }\n",
    "    ],\n",
    "    \"schemaVersions\": [{\n",
    "        \"id\": \"3\",\n",
    "        \"title\": \"Schema 3\",\n",
    "        \"count\": 9033486\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"4\",\n",
    "        \"title\": \"Schema 4\",\n",
    "        \"count\": 5938542\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2.2\",\n",
    "        \"title\": \"Schema 2.2\",\n",
    "        \"count\": 1179453\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2.1\",\n",
    "        \"title\": \"Schema 2.1\",\n",
    "        \"count\": 7582\n",
    "      }\n",
    "    ],\n",
    "    \"sources\": [{\n",
    "        \"id\": \"mds\",\n",
    "        \"title\": \"Mds\",\n",
    "        \"count\": 3903491\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"legacy\",\n",
    "        \"title\": \"Legacy\",\n",
    "        \"count\": 111233\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"ez\",\n",
    "        \"title\": \"Ez\",\n",
    "        \"count\": 86898\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"fabrica\",\n",
    "        \"title\": \"Fabrica\",\n",
    "        \"count\": 12458\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"fabricaForm\",\n",
    "        \"title\": \"Fabrica Form\",\n",
    "        \"count\": 1974\n",
    "      }\n",
    "    ],\n",
    "    \"linkChecksStatus\": [{\n",
    "        \"id\": \"200\",\n",
    "        \"title\": \"200\",\n",
    "        \"count\": 213000\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"404\",\n",
    "        \"title\": \"404\",\n",
    "        \"count\": 2735\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"400\",\n",
    "        \"title\": \"400\",\n",
    "        \"count\": 846\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"429\",\n",
    "        \"title\": \"429\",\n",
    "        \"count\": 836\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"403\",\n",
    "        \"title\": \"403\",\n",
    "        \"count\": 577\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"500\",\n",
    "        \"title\": \"500\",\n",
    "        \"count\": 477\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"503\",\n",
    "        \"title\": \"503\",\n",
    "        \"count\": 208\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"401\",\n",
    "        \"title\": \"401\",\n",
    "        \"count\": 61\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"502\",\n",
    "        \"title\": \"502\",\n",
    "        \"count\": 30\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"410\",\n",
    "        \"title\": \"410\",\n",
    "        \"count\": 29\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"504\",\n",
    "        \"title\": \"504\",\n",
    "        \"count\": 2\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"408\",\n",
    "        \"title\": \"408\",\n",
    "        \"count\": 1\n",
    "      }\n",
    "    ],\n",
    "    \"linksChecked\": 77854,\n",
    "    \"linksWithSchemaOrg\": [{\n",
    "        \"id\": \"0\",\n",
    "        \"title\": \"0\",\n",
    "        \"count\": 230056\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"1\",\n",
    "        \"title\": \"1\",\n",
    "        \"count\": 16527\n",
    "      }\n",
    "    ],\n",
    "    \"linkChecksSchemaOrgId\": 10898,\n",
    "    \"linkChecksDcIdentifier\": 49202,\n",
    "    \"linkChecksCitationDoi\": 0,\n",
    "    \"subjects\": [{\n",
    "        \"id\": \"Plant Genetic Resource for Food and Agriculture\",\n",
    "        \"title\": \"Plant Genetic Resource For Food And Agriculture\",\n",
    "        \"count\": 804370\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"Crystallography\",\n",
    "        \"title\": \"Crystallography\",\n",
    "        \"count\": 764946\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"Cell Parameters\",\n",
    "        \"title\": \"Cell Parameters\",\n",
    "        \"count\": 764807\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"Crystal System\",\n",
    "        \"title\": \"Crystal System\",\n",
    "        \"count\": 764807\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"Space Group\",\n",
    "        \"title\": \"Space Group\",\n",
    "        \"count\": 764807\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"Crystal Structure\",\n",
    "        \"title\": \"Crystal Structure\",\n",
    "        \"count\": 764729\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"Experimental 3D Coordinates\",\n",
    "        \"title\": \"Experimental 3 D Coordinates\",\n",
    "        \"count\": 764688\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"biodiversity\",\n",
    "        \"title\": \"Biodiversity\",\n",
    "        \"count\": 509050\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"GBIF\",\n",
    "        \"title\": \"Gbif\",\n",
    "        \"count\": 500120\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"species occurrences\",\n",
    "        \"title\": \"Species Occurrences\",\n",
    "        \"count\": 500087\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"69999 Biological Sciences not elsewhere classified\",\n",
    "        \"title\": \"69999 Biological Sciences Not Elsewhere Classified\",\n",
    "        \"count\": 303719\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"Medicine\",\n",
    "        \"title\": \"Medicine\",\n",
    "        \"count\": 255970\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"Genetics\",\n",
    "        \"title\": \"Genetics\",\n",
    "        \"count\": 245211\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"Strain-linked information about bacterial and archaeal biodiversity\",\n",
    "        \"title\": \"Strain Linked Information About Bacterial And Archaeal Biodiversity\",\n",
    "        \"count\": 238459\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"Molecular Biology\",\n",
    "        \"title\": \"Molecular Biology\",\n",
    "        \"count\": 208642\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"links\": {\n",
    "    \"self\": \"https://api.datacite.org/dois\",\n",
    "    \"next\": \"https://api.datacite.org/dois?page%5Bcursor%5D=1549482093000&page%5Bsize%5D=25\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Included è in Object\n",
      "Il valore di included è <class 'list'>\n",
      "item in exemp_API_resp[included] {'id': 'gbif.gbif', 'type': 'clients', 'attributes': {'name': 'Global Biodiversity Information Facility', 'symbol': 'GBIF.GBIF', 'year': 2018, 'contactName': 'Daniel Noesgaard', 'contactEmail': 'dnoesgaard@gbif.org', 'description': \"GBIF is an international organisation that is working to make the world's biodiversity data accessible everywhere in the world. GBIF and its many partners work to mobilize the data, and to improve search mechanisms, data and metadata standards, web services, and the other components of an Internet-based information infrastructure for biodiversity.\\r\\nGBIF makes available data that are shared by hundreds of data publishers from around the world. These data are shared according to the GBIF Data Use Agreement, which includes the provision that users of any data accessed through or retrieved via the GBIF Portal will always give credit to the original data publishers.\", 'domains': '*', 'url': 'https://www.gbif.org/', 'created': '2018-12-20T14:03:45.000Z', 'updated': '2018-12-20T15:48:55.000Z', 'isActive': True, 'hasPassword': True}, 'relationships': {'provider': {'data': {'id': 'gbif', 'type': 'providers'}}, 'repository': {'data': {'id': '10.17616/R3J014', 'type': 'repositories'}}, 'prefixes': {'data': [{'id': '10.15469', 'type': 'prefixes'}, {'id': '10.15468', 'type': 'prefixes'}, {'id': '10.26161', 'type': 'prefixes'}]}}}\n",
      "item[attributes] {'name': 'Global Biodiversity Information Facility', 'symbol': 'GBIF.GBIF', 'year': 2018, 'contactName': 'Daniel Noesgaard', 'contactEmail': 'dnoesgaard@gbif.org', 'description': \"GBIF is an international organisation that is working to make the world's biodiversity data accessible everywhere in the world. GBIF and its many partners work to mobilize the data, and to improve search mechanisms, data and metadata standards, web services, and the other components of an Internet-based information infrastructure for biodiversity.\\r\\nGBIF makes available data that are shared by hundreds of data publishers from around the world. These data are shared according to the GBIF Data Use Agreement, which includes the provision that users of any data accessed through or retrieved via the GBIF Portal will always give credit to the original data publishers.\", 'domains': '*', 'url': 'https://www.gbif.org/', 'created': '2018-12-20T14:03:45.000Z', 'updated': '2018-12-20T15:48:55.000Z', 'isActive': True, 'hasPassword': True}\n"
     ]
    }
   ],
   "source": [
    "issnDict = {}\n",
    "if \"included\" in exemp_API_resp:\n",
    "    print(\"Included è in Object\")\n",
    "    objIncluded = exemp_API_resp['included']\n",
    "    print(\"Il valore di included è\", type(objIncluded))\n",
    "    for item in objIncluded:\n",
    "        print(\"item in exemp_API_resp[included]\", item)\n",
    "        print(\"item[attributes]\", item[\"attributes\"])\n",
    "        if 'issn' in item['attributes']:\n",
    "            print(\"item[attributes][issn]\", item['attributes'][\"issn\"] )\n",
    "            attributes = item['attributes']\n",
    "            idProvider = item['id']\n",
    "            issn = attributes['issn']\n",
    "            if issn:\n",
    "                print(\"ci sono delle informazioni su ISSN\")\n",
    "                issnValues = set()\n",
    "                if type(issn) is str:\n",
    "                    print(\"aggiungo la stringa issn\", issn, \"ai valori issnValues\")\n",
    "                    issnValues.add(issn)\n",
    "                else:\n",
    "                    print(\"issn dovrebbe essere un dizionario,\", issn)\n",
    "                    if 'electronic' in issn:\n",
    "                        print(\"recuperato dalla chiave electronic\", str(issn['electronic']), \"e aggiunto ai valori issnValues\" )\n",
    "                        issnValues.add(str(issn['electronic']))\n",
    "                    if 'print' in issn:\n",
    "                        print(\"recuperato dalla chiave print\", str(issn['print']), \"e aggiunto ai valori issnValues\" )\n",
    "                        issnValues.add(str(issn['print']))\n",
    "                print(\"AGGIUNGO AL DIZIONARIO issnDict la chiave idProvider\", idProvider, \"e il valore issnValues\", issnValues)\n",
    "                issnDict[idProvider] = issnValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusioni:\n",
    "<ul>\n",
    "    <li><b>included</b> non è in nessuna risposta dell'API tra le 15 che ho testato</li>\n",
    "    <li>Nel sample di risposta messo come esempio nella documentazione non ci sono i dati che venivano cercati nel dump</li>\n",
    "    <li>Ho eliminato il passaggio nel codice: l'<b>issnDict</b> si aggiorna solo quando viene incontrato un ISSN in relazione ai dizionari delle pubblicazioni stesse, con le modalità utilizzate precedentemente</li>\n",
    "    <li><b>Domanda:</b> è possibile che le risposte dell'API abbiano cambiato struttura ma la documentazione non sia stata aggiornata? Teoricamente non dovrebbe essere così, visto che la <b>Version History</b> è la seguente: <b>v.1</b>: June 25, 2016, first draft, <b>v.1.1</b>: October 10, 2016, follow JSONAPI spec for side-loading associations, <b>v.1.2</b>: December 9, 2017, follow JSONAPI spec for pagination, <b>v.2.0</b>: January 7, 2019, new API endpoints, using camelCase for attributes</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.3) Recupero ISSN\n",
    "Gestione del processo per ISSN (compilazione del <b>dizionario ancillare</b> e <b> files di supporto</b>. \n",
    "<br>\n",
    " <b>Osservazioni</b>\n",
    "<ul>\n",
    "    <li>Sembra che l'<b>issn</b> possa essere fornito sia <b>in container</b>, dove troviamo anche il nome del giornale, sia in <b>related identifiers</b>.</li>\n",
    "    <li>Allo stato attuale non sembra più fattibile recuperare ISSN secondo la procedura implementata nella versione originaria del glob (non trova issn dove venivano cercati prima, né in <b>\"included\"</b> (che 1- <b>non è presente nel dump come chiave</b> 2- non\n",
    "mi pare sia più presente nemmeno nelle risposte dell'API), <b>né in relationships -> client -> data -> id </b> dove a quanto pare trova solo :\"relationships\":{\"client\":{\"data\":{\"id\":\"<b>crossref.citations</b>\",\"type\":\"clients\"}}}</li>\n",
    "</ul>\n",
    "\n",
    "<b>Domande</b>\n",
    "<ul>\n",
    "    <li> Cosa faccio <b>se i due issn (container e related identifiers) sono diversi</b>? li aggiungo entrambi in relazione al DOI nei support files senza dedurre che facciano riferimento necessariamente allo stesso Journal, quindi aggiorno il dizionario di supporto solo nel caso in cui l'ISSN sia stato trovato in container? </li>\n",
    "    <li>Come veniva svolta questa procedura originariamente?\n",
    "sono cambiati i dati?</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.4) Struttura Glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<ol>\n",
    "<li><b>issn_data_recover e issn_data_to_cache</b>: funzioni ancillari per il recupero e il salvataggio dei dati relativi alle associazioni nome giornale - ISSN su file JSON (cache)</li>\n",
    "<li><b>get_all_files</b>: (rimasta come era nella versione precedente del glob) funzione ancillare per recuperare tutti i file json dalla cartella di input</li>\n",
    "<li><b>valiDate</b>: (rimasta invariata rispetto alla precedente versione del glob di datacite) funzione ancillare per ottenere la stringa della data nel formato richiesto</li>\n",
    "<li><b>process</b>: funzione principale a cui ho aggiunto un terzo parametro (oltre alle due directories di input e output)</li>\n",
    "</ol>\n",
    "\n",
    "<b>Struttura process(input_dir, output_dir, n)</b>\n",
    "<ol>\n",
    "<li><b>Parametri</b>: due directories (input e output), a cui è stato aggiunto un numero intero che determina ogni quante entità processate i dati relativi alla mappatura nomi di riviste - ISSN vengono trascritti su file JSON</li>\n",
    "<li><b>Inizializzazione</b>: dichiarazione di tutte le variabili relative agli ID managers e ai File Managers</li>\n",
    "<li><b>Iterazione per files</b>: una volta recuperati tutti i files json con \"get_all_files\" inizia l'iterazione. Nel caso del dump di datacite c'è un solo grande JSON.</li>\n",
    "<li><b>Iterazzione per elementi dell'json con ijson.parse</b>. Visto che i dizionari non sono separati da virgole e non fanno parte di una struttura dati, ijson itera per ogni tripla <b>prefisso-evento-valore</b>. L'inizio di un dizionario rappresentante un'entità è delimitato da <b>(prefix, event, value) == ('', 'start_map', None)</b>, mentre la fine dalla stessa tripla ma con evento <b>end_map</b>. All'apertura del dizionario viene (re)inizializzato il processo di compilazione di un <b>dizionario ridotto</b>, che tiene conto solo delle informazioni utili al fine della compilazione dei support files. La chiusura del dizionario relativo all'entità bibliografica avvia il processo della vera e propria <b>compilazione dei files di supporto</b>, a partire dal dizionario ridotto.</li>\n",
    "    <li><b>Gestione references / referenced by -- cites / citedby</b>: la validazione di citanti e citati non avviene più nel corso della della seconda iterazione per l'intero file ma è stata integrata nel processo principale, visto che l'informazione è nella chiave \"RelatedIdentifiers\", il cui contenuto va comunque parsato per recuperare l'informazione relativa all'ISSN.</li>\n",
    "</ol>\n",
    "<b></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.5) Preprocessing\n",
    "Il dump iniziale va di viso in parti minori in modo tale che possa essere utilizzato dal parser. Per quanto riguarda il glob, ci sono più alternative possibili, ma potrebbe anche sfruttare il dump per intero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1) Versione 1 con ndjson (scartata, memory error)\n",
    "Questa versione del codice risolve il problema del parsing ma non il memory error\n",
    "libreria usata: ndjson\n",
    "Problema installazione : yajl-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index.storer.csvmanager import CSVManager\n",
    "from index.identifier.doimanager import DOIManager\n",
    "from index.identifier.issnmanager import ISSNManager\n",
    "from index.identifier.orcidmanager import ORCIDManager\n",
    "from os.path import exists\n",
    "import datetime\n",
    "from alive_progress import alive_it\n",
    "import ijson\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer as timer\n",
    "import json\n",
    "import os\n",
    "from os import sep, makedirs, walk\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from alive_progress import alive_it\n",
    "import ijson\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer as timer\n",
    "import json\n",
    "import os\n",
    "from os import sep, makedirs, walk\n",
    "import ndjson\n",
    "from zipfile import ZipFile\n",
    "from tarfile import TarFile\n",
    "\n",
    "\n",
    "def get_all_files(i_dir):\n",
    "    result = []\n",
    "    for cur_dir, cur_subdir, cur_files in walk(i_dir):\n",
    "        for file in alive_it(cur_files):\n",
    "            if file.lower().endswith('.json'):\n",
    "                result.append(cur_dir + sep + file)\n",
    "    return result\n",
    "\n",
    "\n",
    "def getJsonFile(input_dir, output_dir, numJF):\n",
    "    count = 0\n",
    "    all_files = get_all_files(input_dir)\n",
    "    print(all_files)\n",
    "\n",
    "    for file_idx, file in enumerate(all_files):\n",
    "        print(file)\n",
    "        support_list = []\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            # load from file-like objects\n",
    "            data = ndjson.load(f)\n",
    "            len_data = len(data)\n",
    "            for i in tqdm(data, total=len_data):\n",
    "                if int(count) != 0 and int(count) % int(numJF) == 0:\n",
    "                    support_dict = {}\n",
    "                    support_dict[\"data\"] = support_list\n",
    "                    with open(output_dir +'/jSonFile' + str(count//numJF) + '.json', 'w', encoding=\"utf8\") as json_file:\n",
    "                        json.dump(support_dict, json_file)\n",
    "                    support_list = []\n",
    "                count += 1\n",
    "                support_list.append(i)\n",
    "            if len(support_list) > 0:\n",
    "                with open( output_dir + '/jSonFile' + '_rest' + '.json', 'w', encoding=\"utf8\" ) as json_file:\n",
    "                    json.dump( support_dict, json_file )\n",
    "\n",
    "\n",
    "    print(numJF)\n",
    "\n",
    "#inp_fol = \"E:\\LAVORO\\DOCI\\dump_doci\\datacite_dump_20211022\\input_test\"\n",
    "\n",
    "out_fol = \"splitted_jsons\"\n",
    "inp_fol = \"dump_fol_split\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    getJsonFile(inp_fol, out_fol, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2) Versione 2  (funziona correttamente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alive_progress import alive_it\n",
    "import json\n",
    "from os import sep, makedirs, walk\n",
    "from tqdm import tqdm\n",
    "import os.path\n",
    "\n",
    "\n",
    "def get_all_files(i_dir):\n",
    "    result = []\n",
    "    for cur_dir, cur_subdir, cur_files in walk(i_dir):\n",
    "        for file in alive_it(cur_files):\n",
    "            if file.lower().endswith('.json'):\n",
    "                result.append(cur_dir + sep + file)\n",
    "    return result\n",
    "\n",
    "\n",
    "def getJsonFile(input_dir, output_dir, numJF):\n",
    "    all_files = get_all_files(input_dir)\n",
    "    print(all_files)\n",
    "\n",
    "    for file_idx, file in enumerate(all_files):\n",
    "        print(file)\n",
    "        data = []\n",
    "        datadict = {}\n",
    "        count = 0\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in tqdm(f):\n",
    "                data.append(json.loads(line))\n",
    "                count += 1\n",
    "                if int(count) != 0 and int(count) % int(numJF) == 0:\n",
    "                    print(\"Processed lines:\", count, \". Reduced json nr.\", count//numJF)\n",
    "                    #with open((output_dir +'%s' + 'jSonFile' + str(count//numJF) + '.json') % (sep), 'w', encoding=\"utf8\") as json_file:\n",
    "                    filename = \"jSonFile_\" + str(count//numJF) + \".json\"\n",
    "                    with (open(os.path.join(output_dir, filename), 'w', encoding=\"utf8\")) as json_file:\n",
    "                        datadict[\"data\"] = data\n",
    "                        json.dump(datadict, json_file)\n",
    "                        data = []\n",
    "                        datadict = {}\n",
    "\n",
    "            if len(data) > 0:\n",
    "                filename = \"jSonFile_rest.json\"\n",
    "                with (open( os.path.join(output_dir, filename), 'w', encoding=\"utf8\")) as json_file:\n",
    "                    datadict[\"data\"] = data\n",
    "                    json.dump(datadict, json_file)\n",
    "\n",
    "\n",
    "inp_fol = \"E:\\LAVORO\\DOCI\\dump_doci\\datacite_dump_20211022\\input_test\"\n",
    "#out_fol = \"splitted_jsons\"\n",
    "#out_fol = \"E:%sLAVORO%sDOCI%sdump_doci%sdatacite_dump_20211022%soutput_test%ssplitted_jsons\" % (sep, sep, sep, sep, sep, sep)\n",
    "#out_fol = os.path.join(\"E:\", \"LAVORO\", \"DOCI\", \"dump_doci\", \"datacite_dump_20211022\", \"output_test\", \"splitted_jsons\")\n",
    "out_fol = \"E:\\LAVORO\\DOCI\\dump_doci\\datacite_dump_20211022\\output_test\\splitted_json\"\n",
    "#inp_fol = \"dump_fol_split\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    getJsonFile(inp_fol, out_fol, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NOTE</b>\n",
    "rifare lo stesso lavoro per NIH --> (glob e parser) \n",
    "\n",
    "<b>parser</b>: <b>vanno gestiti anche gli inversi</b>. se carico un dato che viene citato da un certo articolo che non è di datacite. Le citazioni vanno estratte sia in entrata che in uscita. \n",
    "\n",
    "Divedere il JSON in file minori. Evitare streaming oppure fare una lettura in streaming e usarla per splittare in files. \n",
    "Ci sono due problemi diversi \n",
    "Si va in streaming col JSON, ne bastano 300 opportunamente grossi da processare in streaming. Caricarli tutti in memoria non è vantaggioso. <b>Per il parser tenere solo le entities che hanno dei related identifiers</b>. \n",
    "prima si fa il trim poi teniamo solo le risorse che hanno related id non lista vuota e che abbiano un related id del tipo di interesse (\"DOI\").(vedi scholix di giuseppe)\n",
    "Il glob deve processare tutto quello che c'è dentro json. Sono due step diversi. Il glob deve andare tutto insieme. \n",
    "\n",
    "Ci vorrà il file che serve a fare lo split, processa tutto e tiene solo quello che ci interessa, per replicare la struttura di crossref per il glob \n",
    "\n",
    "tqdm per barra caricamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Valutazione Alternative per Glob + Parser DataCite\n",
    "<ol>\n",
    "    <li><b>Preprocessing selettivo per Parser + Glob Indipendente</b>: (A) <b>preprocessing conserva solo le entità che hanno RelatedIdentifiers con DOI</b> e produce dei json ridotti che contengono i dati relativi a quelle entità che sono rilevanti in termini di citazioni. Il (B) <b>parser lavora solo con i files prodotti dal preprocessing selettivo</b>, che potrebbe essere vantaggioso dal momento che la maggior parte delle entità non hanno references. Il <b>Glob resta indipendente</b>, con tre possibilità: (1)<b>Partendo dal dump intero, sfruttando ijson</b> per il parsing in streaming, (2) <b>Partendo dal dump intero, caricando riga per riga (dizionario per dizionario) </b>, sfruttando le proprietà del formato JSON lines, che adotta il separator '\\n' per dividere i dizionari tra loro, (2)</li>\n",
    "    <li><b>Preprocessing inclusivo per Parser e Glob</b>: (A) La fase di <b>preprocessing divide semplicemente il dump in files minori</b>: non è selettiva: tutti i dizionari presenti nel dump vengono riportati anche nei json di output. (B) il <b>parser seleziona successivamente solo i dizionari che hanno RelatedId di tipo DOI</b>. (C)Il <b>glob utilizza gli stessi json del parser</b> da cui ricava e informazioni necessarie, o <b>caricandolo direttamente tutto in memoria</b>.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3) Preprocessing selettivo x parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alive_progress import alive_it\n",
    "import json\n",
    "from os import sep, makedirs, walk\n",
    "from tqdm import tqdm\n",
    "import os.path\n",
    "\n",
    "\n",
    "def get_all_files(i_dir):\n",
    "    result = []\n",
    "    for cur_dir, cur_subdir, cur_files in walk(i_dir):\n",
    "        for file in alive_it(cur_files):\n",
    "            if file.lower().endswith('.json'):\n",
    "                result.append(cur_dir + sep + file)\n",
    "    return result\n",
    "\n",
    "\n",
    "def getJsonFile(input_dir, output_dir, numJF):\n",
    "    relevant_relations = [\"references\", \"isreferencedby\", \"cites\", \"iscitedby\"]\n",
    "    all_files = get_all_files(input_dir)\n",
    "    print(all_files)\n",
    "    for file_idx, file in enumerate(all_files):\n",
    "        print(file)\n",
    "        data = []\n",
    "        datadict = {}\n",
    "        count = 0\n",
    "\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in tqdm(f):\n",
    "\n",
    "                #aggiunta per selezionare solo entità che hanno related identifiers di tipo DOI tra citanti e citati\n",
    "                linedict = json.loads(line)\n",
    "                if \"relatedIdentifiers\" in (linedict[\"attributes\"]).keys():\n",
    "                    rel_ids = linedict[\"attributes\"][\"relatedIdentifiers\"]\n",
    "                    if rel_ids != []:\n",
    "                        for i in rel_ids:\n",
    "                            if \"relationType\" in i.keys() and (i[\"relationType\"]).lower() in relevant_relations:\n",
    "                                if \"relatedIdentifierType\" in i.keys() and (i[\"relatedIdentifierType\"]).lower() == \"doi\":\n",
    "                                    #da qui riprende processo come nella versione non selettiva\n",
    "\n",
    "                                    data.append(json.loads(line))\n",
    "                                    count += 1\n",
    "                                    if int(count) != 0 and int(count) % int(numJF) == 0:\n",
    "                                        print(\"Processed lines:\", count, \". Reduced json nr.\", count//numJF)\n",
    "                                        filename = \"jSonFile_\" + str(count//numJF) + \".json\"\n",
    "                                        with (open(os.path.join(output_dir, filename), 'w', encoding=\"utf8\")) as json_file:\n",
    "                                            datadict[\"data\"] = data\n",
    "                                            json.dump(datadict, json_file)\n",
    "                                            data = []\n",
    "                                            datadict = {}\n",
    "\n",
    "            if len(data) > 0:\n",
    "                filename = \"jSonFile_rest.json\"\n",
    "                with (open( os.path.join(output_dir, filename), 'w', encoding=\"utf8\")) as json_file:\n",
    "                    datadict[\"data\"] = data\n",
    "                    json.dump(datadict, json_file)\n",
    "\n",
    "\n",
    "inp_fol = \"E:\\LAVORO\\DOCI\\dump_doci\\datacite_dump_20211022\\input_test\"\n",
    "#out_fol = \"splitted_jsons\"\n",
    "#out_fol = \"E:%sLAVORO%sDOCI%sdump_doci%sdatacite_dump_20211022%soutput_test%ssplitted_jsons\" % (sep, sep, sep, sep, sep, sep)\n",
    "#out_fol = os.path.join(\"E:\", \"LAVORO\", \"DOCI\", \"dump_doci\", \"datacite_dump_20211022\", \"output_test\", \"splitted_jsons\")\n",
    "out_fol = \"E:\\LAVORO\\DOCI\\dump_doci\\datacite_dump_20211022\\output_test\\splitted_json_sel\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    getJsonFile(inp_fol, out_fol, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3) Parser non selettivo (lavora solo su dato significativi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ritrova parser nella conversazione con giuseppe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3) Glob (versione 1 : ijson)\n",
    "tempo stimato : più di 10 giorni per processare l'intero dump (26 milioni di entità)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index.storer.csvmanager import CSVManager\n",
    "from index.identifier.doimanager import DOIManager\n",
    "from index.identifier.issnmanager import ISSNManager\n",
    "from index.identifier.orcidmanager import ORCIDManager\n",
    "from os.path import exists\n",
    "import datetime\n",
    "from alive_progress import alive_it\n",
    "import ijson\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer as timer\n",
    "import json\n",
    "import os\n",
    "from os import sep, makedirs, walk\n",
    "\n",
    "\n",
    "def issn_data_recover(directory):\n",
    "    journal_issn_dict = dict()\n",
    "    filename = directory + sep + 'journal_issn.json'\n",
    "    if not os.path.exists(filename):\n",
    "        return journal_issn_dict\n",
    "    else:\n",
    "        with open(filename, 'r', encoding='utf8') as fd:\n",
    "            journal_issn_dict = json.load(fd)\n",
    "            types = type(journal_issn_dict)\n",
    "            return journal_issn_dict\n",
    "\n",
    "\n",
    "def issn_data_to_cache(name_issn_dict, directory):\n",
    "    filename = directory + sep + 'journal_issn.json'\n",
    "    with open(filename, 'w', encoding='utf-8' ) as fd:\n",
    "        json.dump(name_issn_dict, fd, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "def get_all_files(i_dir):\n",
    "    result = []\n",
    "    for cur_dir, cur_subdir, cur_files in walk(i_dir):\n",
    "        for file in alive_it(cur_files):\n",
    "            if file.lower().endswith('.json'):\n",
    "                result.append(cur_dir + sep + file)\n",
    "    return result\n",
    "\n",
    "\n",
    "def valiDate(date_text):\n",
    "    date_text = str(date_text)\n",
    "    try:\n",
    "        return datetime.datetime.strptime(date_text, '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return datetime.datetime.strptime(date_text, '%Y-%m').strftime('%Y-%m')\n",
    "        except ValueError:\n",
    "            try:\n",
    "                return datetime.datetime.strptime(date_text, '%Y').strftime('%Y')\n",
    "            except ValueError:\n",
    "                if '-' in date_text:\n",
    "                    possibiliDate = date_text.split('-')\n",
    "                    while possibiliDate:\n",
    "                        possibiliDate.pop()\n",
    "                        seperator = '-'\n",
    "                        data = seperator.join(possibiliDate)\n",
    "                        try:\n",
    "                            return datetime.datetime.strptime(data, '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "                        except ValueError:\n",
    "                            try:\n",
    "                                return datetime.datetime.strptime(data, '%Y-%m').strftime('%Y-%m')\n",
    "                            except ValueError:\n",
    "                                try:\n",
    "                                    return datetime.datetime.strptime(data, '%Y').strftime('%Y')\n",
    "                                except ValueError:\n",
    "                                    pass\n",
    "\n",
    "\n",
    "def process(input_dir, output_dir, n):\n",
    "    if not exists(output_dir):\n",
    "        makedirs(output_dir)\n",
    "\n",
    "    citing_doi_with_no_date = set()\n",
    "\n",
    "    #variabili identificano i csv (directory + nome csv)\n",
    "    valid_doi = CSVManager(output_dir + sep + \"valid_doi.csv\")\n",
    "    id_date = CSVManager(output_dir + sep + \"id_date.csv\")\n",
    "    # doi + data\n",
    "    id_issn = CSVManager(output_dir + sep + \"id_issn.csv\")\n",
    "    # doi + issn\n",
    "    id_orcid = CSVManager(output_dir + sep + \"id_orcid.csv\")\n",
    "    # doi + orcid\n",
    "\n",
    "    journal_issn_dict = issn_data_recover(output_dir) #just an empty dict, in case of a code break\n",
    "\n",
    "    doi_manager = DOIManager(valid_doi)\n",
    "    issn_manager = ISSNManager()\n",
    "    orcid_manager = ORCIDManager()\n",
    "\n",
    "    all_files = get_all_files(input_dir)\n",
    "    #output lista con ogni csv (directory + nome csv)\n",
    "\n",
    "    for file_idx, file in enumerate(all_files):\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f: #qui F è '_io.TextIOWrapper'\n",
    "            f = f.name #qui F è stringa del pathname\n",
    "            data = ijson.parse(open(f, encoding=\"utf-8\"), multiple_values=True)\n",
    "            issnDict = {}\n",
    "            relevant_relations = [\"references\", \"isreferencedby\", \"cites\", \"iscitedby\"]\n",
    "\n",
    "            #inside_dict = False\n",
    "            pbar = tqdm(data)\n",
    "            count = 0\n",
    "            for prefix, event, value in pbar:\n",
    "                pbar.set_description( \"Loading\" )\n",
    "                #print(prefix, event, value)\n",
    "                if (prefix, event, value) == ('', 'start_map', None):\n",
    "                    count += 1\n",
    "                    inside_dict = True\n",
    "                    date_dict = {}\n",
    "                    orcid_dict = {}\n",
    "                    reduced_dict = {}\n",
    "                    issn_set_tmp = set()\n",
    "                    related_dois = set()\n",
    "                    #reduced_dict[\"relationships\"] = {\"client\": {\"data\": {\"id\": \"\"}}}\n",
    "                    reduced_dict[\"attributes\"] = {}\n",
    "                    reduced_dict[\"attributes\"][\"dates\"] = []\n",
    "                    reduced_dict[\"attributes\"][\"creators\"] = []\n",
    "                    #reduced_dict[\"attributes\"][\"container\"] = {}\n",
    "                    reduced_dict[\"attributes\"][\"relatedIdentifiers\"] = {}\n",
    "                    reduced_dict[\"attributes\"][\"publicationYear\"] = \"\"\n",
    "\n",
    "                elif (prefix, event, value) == ('', 'end_map', None):\n",
    "                    inside_dict = False\n",
    "\n",
    "                #ALL'INTERNO DEL DIZIONARIO SI RACCOLGONO I DATI\n",
    "                if inside_dict:\n",
    "                    # Collecting DOI\n",
    "                    if prefix == 'attributes.doi':\n",
    "                        if value != \"\":\n",
    "                            reduced_dict[\"id\"] = value\n",
    "\n",
    "                    # if one journalID is in the dictionary, collect issn\n",
    "                    #ARIANNA: per uniformità ho aggiunto if id_issn.get_value(citing_doi) is None:\n",
    "                    #elif prefix == 'relationships.client.data.id' and value != \"\":\n",
    "                        #reduced_dict[\"relationships\"][\"client\"][\"data\"][\"id\"] = value\n",
    "\n",
    "                    elif prefix == 'attributes.container' and event == 'start_map':\n",
    "                        cont_title = \"\"\n",
    "                        cont_id = \"\"\n",
    "                        cont_id_type = \"\"\n",
    "\n",
    "                    elif prefix == 'attributes.container.identifier':\n",
    "                        cont_id = value\n",
    "                    elif prefix == 'attributes.container.identifierType':\n",
    "                        cont_id_type = value.lower()\n",
    "                    elif prefix == 'attributes.container.title':\n",
    "                        cont_title = value.lower()\n",
    "\n",
    "                    #questa parte confluisce in relatedIdentifiers ISSN, visto che gli identificativi vengono aggiunti\n",
    "                    # al set issn_set_tmp, che diventa il valore della chiave ISSN di RelatedIdentifiers\n",
    "                    elif prefix == 'attributes.container' and event == 'end_map':\n",
    "                        if cont_id_type == \"issn\" and cont_title != \"\" and cont_id != \"\":\n",
    "                            if cont_title in issnDict:\n",
    "                                issnList = issnDict[cont_title]\n",
    "                                if issnList:\n",
    "                                    if cont_id not in issnList:\n",
    "                                        issnDict[cont_title].append(cont_id)\n",
    "                                        issn_set_tmp.update(set(issnDict[cont_title]))\n",
    "                                else:\n",
    "                                    issnDict[cont_title] = []\n",
    "                                    issnDict[cont_title].append(cont_id)\n",
    "                                    issn_set_tmp.add(cont_id)\n",
    "                            else:\n",
    "                                issnDict[cont_title] = []\n",
    "                                issnDict[cont_title].append(cont_id)\n",
    "                                issn_set_tmp.add(cont_id)\n",
    "\n",
    "                        elif cont_id_type == \"issn\" and cont_title == \"\" and cont_id != \"\":\n",
    "                            issn_set_tmp.add(cont_id)\n",
    "\n",
    "                    elif prefix == 'attributes.relatedIdentifiers.item' and event == 'start_map':\n",
    "                        rel_id_rel = \"\"\n",
    "                        rel_id = \"\"\n",
    "                        rel_id_type = \"\"\n",
    "                    elif prefix == 'attributes.relatedIdentifiers.item.relationType':\n",
    "                        rel_id_rel = value.lower()\n",
    "                    elif prefix == 'attributes.relatedIdentifiers.item.relatedIdentifier':\n",
    "                        rel_id = value\n",
    "                    elif prefix == 'attributes.relatedIdentifiers.item.relatedIdentifierType':\n",
    "                        rel_id_type = value.lower()\n",
    "                    elif prefix == 'attributes.relatedIdentifiers.item' and event == 'end_map':\n",
    "                        if rel_id != \"\" and rel_id_type == \"issn\" and rel_id_rel == \"ispartof\":\n",
    "                            issn_set_tmp.add(rel_id)\n",
    "                        elif rel_id != \"\" and rel_id_type == \"doi\" and rel_id_rel in relevant_relations:\n",
    "                            related_dois.add(rel_id)\n",
    "\n",
    "                    elif prefix == 'attributes.dates.item.date':\n",
    "                        date_dict[\"date\"] = value\n",
    "\n",
    "                    elif prefix == 'attributes.dates.item.dateType' and value == \"Issued\":\n",
    "                        if \"date\" in date_dict.keys() and date_dict[\"date\"] != \"\":\n",
    "                            reduced_dict[\"attributes\"][\"dates\"].append(date_dict)\n",
    "                            date_dict = {}\n",
    "\n",
    "                    # svuota dizionario sia nel caso in cui incontri un dateType diverso da Issue sia nel caso in cui il dizionario relativo alla data venga chiuso\n",
    "                    # in questo modo, nel caso in cui venga specificata una data ma non sia dichiarato il dateType, l'informazione viene cancellata alla chiusura\n",
    "                    # del dizionario relativo alla data stessa\n",
    "\n",
    "                    elif (prefix == 'attributes.dates.item.dateType' and value != \"Issued\") or (prefix == 'attributes.dates.item' and event == 'end_map') :\n",
    "                        date_dict = {}\n",
    "\n",
    "                    elif prefix == 'attributes.publicationYear':\n",
    "                        reduced_dict[\"attributes\"][\"publicationYear\"] = value\n",
    "\n",
    "                    elif prefix == 'attributes.creators.item.nameIdentifiers.item' and event == 'start_map':\n",
    "                        orcid_dict = {}\n",
    "                        orcid = \"\"\n",
    "                        scheme = \"\"\n",
    "\n",
    "                    elif prefix == 'attributes.creators.item.nameIdentifiers.item.nameIdentifier':\n",
    "                        if value != \"\":\n",
    "                            orcid_dict['nameIdentifier'] = value\n",
    "\n",
    "                    elif prefix == 'attributes.creators.item.nameIdentifiers.item.nameIdentifierScheme' and value == \"ORCID\":\n",
    "                        if 'nameIdentifier' in orcid_dict.keys():\n",
    "                            reduced_dict[\"attributes\"][\"creators\"].append(orcid_dict)\n",
    "\n",
    "                    elif (prefix == 'attributes.creators.item.nameIdentifiers.item' and event == 'end_map') or (prefix == 'attributes.creators.item.nameIdentifiers.item.nameIdentifierScheme' and value != \"ORCID\"):\n",
    "                        orcid_dict = {}\n",
    "\n",
    "                else:\n",
    "                    #print(\"processing id\", citing_doi)\n",
    "                    reduced_dict[\"attributes\"][\"relatedIdentifiers\"][\"DOIS\"] = related_dois\n",
    "                    reduced_dict[\"attributes\"][\"relatedIdentifiers\"][\"ISSNS\"] = issn_set_tmp\n",
    "\n",
    "                    if \"id\" in reduced_dict.keys():\n",
    "                        print(\"processing \", reduced_dict[\"id\"], \"dict:\", reduced_dict)\n",
    "                        citing_doi = reduced_dict[\"id\"]\n",
    "                        citing_doi = doi_manager.normalise( citing_doi, True )\n",
    "                        doi_manager.set_valid(citing_doi)\n",
    "\n",
    "\n",
    "                        #if reduced_dict['relationships']['client']['data']['id'] != \"\":\n",
    "                            #idClient = reduced_dict['relationships']['client']['data']['id']\n",
    "                            #if idClient in issnDict:\n",
    "                                #issnSet = issnDict[idClient]\n",
    "                                #if issnSet:\n",
    "                                    #for issn in issnSet:\n",
    "                                        #if issn_manager.is_valid(issn):\n",
    "                                            #id_issn.add_value(citing_doi, issn)\n",
    "                            #else:\n",
    "                                #print(\"vanno aggiunti i valori a issnDict?\")\n",
    "\n",
    "\n",
    "                        if id_date.get_value(citing_doi) is None: #Necessario?\n",
    "                            listDates = reduced_dict['attributes']['dates']\n",
    "                            publicationYear = reduced_dict['attributes']['publicationYear']\n",
    "                            if listDates != []:\n",
    "                                for data in listDates:\n",
    "                                    citing_date = valiDate(str(data['date']))\n",
    "                                    if citing_date:\n",
    "                                        id_date.add_value(citing_doi, citing_date)\n",
    "                                        if citing_doi in citing_doi_with_no_date:\n",
    "                                            citing_doi_with_no_date.remove(citing_doi)\n",
    "\n",
    "                            elif publicationYear != \"\":\n",
    "                                publicationYear = valiDate(str(publicationYear))\n",
    "                                if publicationYear:\n",
    "                                    id_date.add_value(citing_doi, publicationYear)\n",
    "                                    if citing_doi in citing_doi_with_no_date:\n",
    "                                        citing_doi_with_no_date.remove(citing_doi)\n",
    "\n",
    "                        if id_orcid.get_value(citing_doi) is None: #Necessario?\n",
    "                            contributorList = reduced_dict['attributes']['creators']\n",
    "                            if contributorList != []:\n",
    "                                for author in contributorList:\n",
    "                                    orcid = orcid_manager.normalise(author['nameIdentifier'])\n",
    "                                    if orcid_manager.is_valid(orcid):\n",
    "                                        id_orcid.add_value(citing_doi, orcid)\n",
    "\n",
    "                        if id_issn.get_value(citing_doi) is None: # --> Non necessario perché un doi può avere più issns (?)\n",
    "                            normalised_issn_set = set()\n",
    "                            for issn in issn_set_tmp:\n",
    "                                norm_issn = issn_manager.normalise(issn)\n",
    "                                normalised_issn_set.add(norm_issn)\n",
    "                            for issn in normalised_issn_set:\n",
    "                                if issn_manager.is_valid(issn):\n",
    "                                    id_issn.add_value(citing_doi, issn)\n",
    "\n",
    "                            for doi in related_dois:\n",
    "                                doi_manager.is_valid(str(doi))\n",
    "\n",
    "                    if int(count) !=0 and int(count) % int(n) == 0:\n",
    "                        print(\"trasferimento cash dati issn. Entità processate:\", count, \". Trascrizione cache n.\", (count//n))\n",
    "                        print(\"issnDict\", issnDict)\n",
    "                        issn_data_to_cache(issnDict, output_dir)\n",
    "\n",
    "            issn_data_to_cache(issnDict, output_dir)\n",
    "\n",
    "\n",
    "start = timer()\n",
    "#dumpFolder = \"dumpFolderNuova\"\n",
    "dumpFolder = \"E:\\LAVORO\\DOCI\\dump_doci\\datacite_dump_20211022\\input_test\"\n",
    "resultFolder = \"E:\\LAVORO\\DOCI\\dump_doci\\datacite_dump_20211022\\output_test_1000\"\n",
    "#resultFolder = \"resultFolderNuova\"\n",
    "process(dumpFolder, resultFolder, 1000)\n",
    "end = timer()\n",
    "print(\"elapsed time, in seconds:\", (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3) Glob (versione 2 : caricamento line by line da dump intero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index.storer.csvmanager import CSVManager\n",
    "from index.identifier.doimanager import DOIManager\n",
    "from index.identifier.issnmanager import ISSNManager\n",
    "from index.identifier.orcidmanager import ORCIDManager\n",
    "from os import sep, makedirs, walk\n",
    "from os.path import exists\n",
    "import os\n",
    "from json import load\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def issn_data_recover(directory):\n",
    "    journal_issn_dict = dict()\n",
    "    filename = directory + sep + 'journal_issn.json'\n",
    "    if not os.path.exists(filename):\n",
    "        return journal_issn_dict\n",
    "    else:\n",
    "        with open(filename, 'r', encoding='utf8') as fd:\n",
    "            journal_issn_dict = json.load(fd)\n",
    "            types = type(journal_issn_dict)\n",
    "            return journal_issn_dict\n",
    "\n",
    "\n",
    "def issn_data_to_cache(name_issn_dict, directory):\n",
    "    filename = directory + sep + 'journal_issn.json'\n",
    "    with open(filename, 'w', encoding='utf-8' ) as fd:\n",
    "        json.dump(name_issn_dict, fd, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "def get_all_files(i_dir):\n",
    "    result = []\n",
    "    for cur_dir, cur_subdir, cur_files in walk(i_dir):\n",
    "        for file in tqdm(cur_files):\n",
    "            if file.lower().endswith('.json'):\n",
    "                result.append(cur_dir + sep + file)\n",
    "    return result\n",
    "\n",
    "\n",
    "def valiDate(date_text):\n",
    "    date_text = str(date_text)\n",
    "    try:\n",
    "        return datetime.datetime.strptime(date_text, '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return datetime.datetime.strptime(date_text, '%Y-%m').strftime('%Y-%m')\n",
    "        except ValueError:\n",
    "            try:\n",
    "                return datetime.datetime.strptime(date_text, '%Y').strftime('%Y')\n",
    "            except ValueError:\n",
    "                if '-' in date_text:\n",
    "                    possibiliDate = date_text.split('-')\n",
    "                    while possibiliDate:\n",
    "                        possibiliDate.pop()\n",
    "                        seperator = '-'\n",
    "                        data = seperator.join(possibiliDate)\n",
    "                        try:\n",
    "                            return datetime.datetime.strptime(data, '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "                        except ValueError:\n",
    "                            try:\n",
    "                                return datetime.datetime.strptime(data, '%Y-%m').strftime('%Y-%m')\n",
    "                            except ValueError:\n",
    "                                try:\n",
    "                                    return datetime.datetime.strptime(data, '%Y').strftime('%Y')\n",
    "                                except ValueError:\n",
    "                                    pass\n",
    "\n",
    "\n",
    "\n",
    "def process(input_dir, output_dir, n):\n",
    "    if not exists(output_dir):\n",
    "        makedirs(output_dir)\n",
    "\n",
    "    citing_doi_with_no_date = set()\n",
    "\n",
    "    #variabili identificano i csv (directory + nome csv)\n",
    "    valid_doi = CSVManager(output_dir + sep + \"valid_doi.csv\")\n",
    "    id_date = CSVManager(output_dir + sep + \"id_date.csv\")\n",
    "    # doi + data\n",
    "    id_issn = CSVManager(output_dir + sep + \"id_issn.csv\")\n",
    "    # doi + issn\n",
    "    id_orcid = CSVManager(output_dir + sep + \"id_orcid.csv\")\n",
    "    # doi + orcid\n",
    "\n",
    "    journal_issn_dict = issn_data_recover(output_dir) #just an empty dict, in case of a code break\n",
    "\n",
    "    doi_manager = DOIManager(valid_doi)\n",
    "    issn_manager = ISSNManager()\n",
    "    orcid_manager = ORCIDManager()\n",
    "\n",
    "    all_files = get_all_files(input_dir)\n",
    "    #output lista con ogni csv (directory + nome csv)\n",
    "\n",
    "    issnDict = {}\n",
    "    relevant_relations = [\"references\", \"isreferencedby\", \"cites\", \"iscitedby\"]\n",
    "\n",
    "    print(\"PROCESS PART 1\")\n",
    "    for file_idx, file in enumerate(all_files):\n",
    "        with open(file, encoding=\"utf8\") as f:\n",
    "            count = 0\n",
    "            for line in tqdm(f):\n",
    "                count += 1\n",
    "                item = json.loads(line)\n",
    "                print(\"item:\", item)\n",
    "                attributes = item['attributes']\n",
    "                citing_doi = attributes['doi']\n",
    "                relatedIdentifiers = attributes['relatedIdentifiers']\n",
    "                citing_doi = doi_manager.normalise(citing_doi, True)\n",
    "                doi_manager.set_valid(citing_doi)\n",
    "\n",
    "                #collect the date of issue if there is, otherwise the year of publciation\n",
    "                if id_date.get_value(citing_doi) is None:\n",
    "                    listDates = attributes['dates']\n",
    "                    publicationYear = attributes['publicationYear']\n",
    "\n",
    "                    if listDates != []:\n",
    "                        for data in listDates:\n",
    "                            tipo = str(data['dateType'])\n",
    "                            if tipo.lower() == 'issued':\n",
    "                                citing_date = valiDate(str(data['date']))\n",
    "                                if citing_date:\n",
    "                                    id_date.add_value(citing_doi, citing_date)\n",
    "                                    if citing_doi in citing_doi_with_no_date:\n",
    "                                        citing_doi_with_no_date.remove(citing_doi)\n",
    "                                # dateType è Issued ma citing_date non ha dato risultati\n",
    "                                else:\n",
    "                                    if publicationYear:\n",
    "                                        publicationYear = valiDate(str(publicationYear))\n",
    "                                        if publicationYear:\n",
    "                                            id_date.add_value(citing_doi, publicationYear)\n",
    "                                            if citing_doi in citing_doi_with_no_date:\n",
    "                                                citing_doi_with_no_date.remove(citing_doi)\n",
    "                            # c'è listDates ma datetype non è Issued\n",
    "                            else:\n",
    "                                if publicationYear:\n",
    "                                    publicationYear = valiDate(str(publicationYear))\n",
    "                                    if publicationYear:\n",
    "                                        id_date.add_value(citing_doi, publicationYear)\n",
    "                                        if citing_doi in citing_doi_with_no_date:\n",
    "                                            citing_doi_with_no_date.remove(citing_doi)\n",
    "                    #Non c'è listDates\n",
    "                    else:\n",
    "                        if publicationYear:\n",
    "                            publicationYear = valiDate(str(publicationYear))\n",
    "                            if publicationYear:\n",
    "                                id_date.add_value(citing_doi, publicationYear)\n",
    "                                if citing_doi in citing_doi_with_no_date:\n",
    "                                    citing_doi_with_no_date.remove(citing_doi)\n",
    "\n",
    "                #collect the orcid of the contributors\n",
    "\n",
    "                if id_orcid.get_value(citing_doi) is None:\n",
    "                    contributorList = attributes['creators']\n",
    "                    if contributorList != []:\n",
    "                        for author in contributorList:\n",
    "                            if 'nameIdentifiers' in author.keys():\n",
    "                                infoAuthor = author['nameIdentifiers']\n",
    "                                for element in infoAuthor:\n",
    "                                    if 'nameIdentifier' in element.keys() and 'nameIdentifierScheme' in element.keys():\n",
    "                                        if (element['nameIdentifierScheme']).lower() == 'orcid':\n",
    "                                            orcid = element['nameIdentifier']\n",
    "                                            if orcid is not None and orcid != \"\":\n",
    "                                                orcid = orcid_manager.normalise(orcid)\n",
    "                                                if orcid_manager.is_valid(orcid):\n",
    "                                                    id_orcid.add_value(citing_doi, orcid)\n",
    "\n",
    "                relatedISSN = \"\"\n",
    "                if relatedIdentifiers != []:\n",
    "\n",
    "                    #validazione dei dois citati e citanti\n",
    "                    for related in relatedIdentifiers:\n",
    "                        relationType = related['relationType']\n",
    "                        if relationType:\n",
    "                            if relationType.lower() in relevant_relations:\n",
    "                                # Att! Qui salviamo DOI citati e citanti\n",
    "                                if 'relatedIdentifierType' in related.keys():\n",
    "                                    relatedIdentifierType = (str(related['relatedIdentifierType'])).lower()\n",
    "                                    if relatedIdentifierType == 'doi':\n",
    "                                        if 'relatedIdentifier' in related.keys():\n",
    "                                            relatedDOI = str(related['relatedIdentifier'])\n",
    "                                            doi_manager.is_valid(relatedDOI)\n",
    "\n",
    "                            elif relationType.lower() == \"ispartof\":\n",
    "                                if 'relatedIdentifierType' in related.keys():\n",
    "                                    relatedIdentifierType = (str(related['relatedIdentifierType'])).lower()\n",
    "                                    if relatedIdentifierType == 'issn':\n",
    "                                        if 'relatedIdentifier' in related.keys():\n",
    "                                            relatedISSN = str(related['relatedIdentifier'])\n",
    "\n",
    "                issn_set = set()\n",
    "                if id_issn.get_value(citing_doi) is None:\n",
    "                    container = attributes['container']\n",
    "                    if 'identifier' in container.keys() and 'identifierType' in container.keys():\n",
    "                        if container['identifier'] != \"\" and (container['identifier']).lower() == \"issn\":\n",
    "                            if 'title' in container.keys():\n",
    "                                journal_title = (container['title']).lower()\n",
    "                                if journal_title in issnDict.keys():\n",
    "                                    issnList = issnDict[journal_title]\n",
    "                                    if issnList != []:\n",
    "                                        if container['identifier'] not in issnList:\n",
    "                                            issnDict[journal_title].append(container['identifier'])\n",
    "                                            issn_set.update(set(issnDict[journal_title]))\n",
    "                                    else:\n",
    "                                        issnDict[journal_title].append(container['identifier'])\n",
    "                                        issn_set.add(container['identifier'])\n",
    "                                else:\n",
    "                                    issnDict[journal_title] = []\n",
    "                                    issnDict[journal_title].append(container['identifier'])\n",
    "                                    issn_set.add(container['identifier'])\n",
    "\n",
    "                    if relatedISSN != \"\":\n",
    "                        issn_set.add(relatedISSN)\n",
    "\n",
    "                    normalised_issn_set = set()\n",
    "                    for issn in issn_set:\n",
    "                        norm_issn = issn_manager.normalise(issn)\n",
    "                        normalised_issn_set.add(norm_issn)\n",
    "                    for issn in normalised_issn_set:\n",
    "                        if issn_manager.is_valid(issn):\n",
    "                            id_issn.add_value(citing_doi, issn)\n",
    "\n",
    "                if int(count) != 0 and int(count ) % int( n ) == 0:\n",
    "                    print( \"trasferimento cash dati issn. Entità processate:\", count, \". Trascrizione cache n.\",\n",
    "                           (count // n) )\n",
    "                    print( \"issnDict\", issnDict )\n",
    "                    issn_data_to_cache(issnDict, output_dir)\n",
    "\n",
    "            issn_data_to_cache(issnDict, output_dir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inp_fol = \"E:\\LAVORO\\DOCI\\dump_doci\\datacite_dump_20211022\\input_test\"\n",
    "out_fol = \"E:\\LAVORO\\DOCI\\dump_doci\\datacite_dump_20211022\\output_test\\glob_totale_lines\"\n",
    "\n",
    "process(inp_fol, out_fol, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3) Preprocess Inclusivo (divide semplicemente il dump in files minori, senza scartare dati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alive_progress import alive_it\n",
    "import json\n",
    "from os import sep, makedirs, walk\n",
    "from tqdm import tqdm\n",
    "import os.path\n",
    "\n",
    "\n",
    "def get_all_files(i_dir):\n",
    "    result = []\n",
    "    for cur_dir, cur_subdir, cur_files in walk(i_dir):\n",
    "        for file in alive_it(cur_files):\n",
    "            if file.lower().endswith('.json'):\n",
    "                result.append(cur_dir + sep + file)\n",
    "    return result\n",
    "\n",
    "\n",
    "def getJsonFile(input_dir, output_dir, numJF):\n",
    "    all_files = get_all_files(input_dir)\n",
    "    print(all_files)\n",
    "\n",
    "    for file_idx, file in enumerate(all_files):\n",
    "        print(file)\n",
    "        data = []\n",
    "        datadict = {}\n",
    "        count = 0\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in tqdm(f):\n",
    "                data.append(json.loads(line))\n",
    "                count += 1\n",
    "                if int(count) != 0 and int(count) % int(numJF) == 0:\n",
    "                    print(\"Processed lines:\", count, \". Reduced json nr.\", count//numJF)\n",
    "                    filename = \"jSonFile_\" + str(count//numJF) + \".json\"\n",
    "                    with (open(os.path.join(output_dir, filename), 'w', encoding=\"utf8\")) as json_file:\n",
    "                        datadict[\"data\"] = data\n",
    "                        json.dump(datadict, json_file)\n",
    "                        data = []\n",
    "                        datadict = {}\n",
    "\n",
    "            if len(data) > 0:\n",
    "                filename = \"jSonFile_rest.json\"\n",
    "                with (open( os.path.join(output_dir, filename), 'w', encoding=\"utf8\")) as json_file:\n",
    "                    datadict[\"data\"] = data\n",
    "                    json.dump(datadict, json_file)\n",
    "\n",
    "\n",
    "inp_fol = \"E:\\LAVORO\\DOCI\\dump_doci\\datacite_dump_20211022\\input_test\"\n",
    "out_fol = \"E:\\LAVORO\\DOCI\\dump_doci\\datacite_dump_20211022\\output_test\\splitted_json\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    getJsonFile(inp_fol, out_fol, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3) Parser Selettivo (lavora su json che contengono tutti i dati scartando quelli non pertinenti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3) Glob utilizza gli stessi json del parser, caricando tutto il json in memoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index.storer.csvmanager import CSVManager\n",
    "from index.identifier.doimanager import DOIManager\n",
    "from index.identifier.issnmanager import ISSNManager\n",
    "from index.identifier.orcidmanager import ORCIDManager\n",
    "from os import sep, makedirs, walk\n",
    "from os.path import exists\n",
    "import os\n",
    "from json import load\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def issn_data_recover(directory):\n",
    "    journal_issn_dict = dict()\n",
    "    filename = directory + sep + 'journal_issn.json'\n",
    "    if not os.path.exists(filename):\n",
    "        return journal_issn_dict\n",
    "    else:\n",
    "        with open(filename, 'r', encoding='utf8') as fd:\n",
    "            journal_issn_dict = json.load(fd)\n",
    "            types = type(journal_issn_dict)\n",
    "            return journal_issn_dict\n",
    "\n",
    "\n",
    "def issn_data_to_cache(name_issn_dict, directory):\n",
    "    filename = directory + sep + 'journal_issn.json'\n",
    "    with open(filename, 'w', encoding='utf-8' ) as fd:\n",
    "        json.dump(name_issn_dict, fd, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "def get_all_files(i_dir):\n",
    "    result = []\n",
    "    for cur_dir, cur_subdir, cur_files in walk(i_dir):\n",
    "        for file in tqdm(cur_files):\n",
    "            if file.lower().endswith('.json'):\n",
    "                result.append(cur_dir + sep + file)\n",
    "    return result\n",
    "\n",
    "\n",
    "def valiDate(date_text):\n",
    "    date_text = str(date_text)\n",
    "    try:\n",
    "        return datetime.datetime.strptime(date_text, '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return datetime.datetime.strptime(date_text, '%Y-%m').strftime('%Y-%m')\n",
    "        except ValueError:\n",
    "            try:\n",
    "                return datetime.datetime.strptime(date_text, '%Y').strftime('%Y')\n",
    "            except ValueError:\n",
    "                if '-' in date_text:\n",
    "                    possibiliDate = date_text.split('-')\n",
    "                    while possibiliDate:\n",
    "                        possibiliDate.pop()\n",
    "                        seperator = '-'\n",
    "                        data = seperator.join(possibiliDate)\n",
    "                        try:\n",
    "                            return datetime.datetime.strptime(data, '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "                        except ValueError:\n",
    "                            try:\n",
    "                                return datetime.datetime.strptime(data, '%Y-%m').strftime('%Y-%m')\n",
    "                            except ValueError:\n",
    "                                try:\n",
    "                                    return datetime.datetime.strptime(data, '%Y').strftime('%Y')\n",
    "                                except ValueError:\n",
    "                                    pass\n",
    "\n",
    "\n",
    "\n",
    "def process(input_dir, output_dir, n):\n",
    "    if not exists(output_dir):\n",
    "        makedirs(output_dir)\n",
    "\n",
    "    citing_doi_with_no_date = set()\n",
    "\n",
    "    #variabili identificano i csv (directory + nome csv)\n",
    "    valid_doi = CSVManager(output_dir + sep + \"valid_doi.csv\")\n",
    "    id_date = CSVManager(output_dir + sep + \"id_date.csv\")\n",
    "    # doi + data\n",
    "    id_issn = CSVManager(output_dir + sep + \"id_issn.csv\")\n",
    "    # doi + issn\n",
    "    id_orcid = CSVManager(output_dir + sep + \"id_orcid.csv\")\n",
    "    # doi + orcid\n",
    "\n",
    "    journal_issn_dict = issn_data_recover(output_dir) #just an empty dict, in case of a code break\n",
    "\n",
    "    doi_manager = DOIManager(valid_doi)\n",
    "    issn_manager = ISSNManager()\n",
    "    orcid_manager = ORCIDManager()\n",
    "\n",
    "    all_files = get_all_files(input_dir)\n",
    "    #output lista con ogni csv (directory + nome csv)\n",
    "\n",
    "    issnDict = {}\n",
    "    relevant_relations = [\"references\", \"isreferencedby\", \"cites\", \"iscitedby\"]\n",
    "\n",
    "    print(\"PROCESS PART 1\")\n",
    "    for file_idx, file in enumerate(all_files):\n",
    "        with open(file, encoding=\"utf8\") as f:\n",
    "            obj = json.load(f)\n",
    "            data_list = obj[\"data\"]\n",
    "            count = 0\n",
    "            for item in tqdm(data_list):\n",
    "                count += 1\n",
    "                print(\"item:\", item)\n",
    "                attributes = item['attributes']\n",
    "                citing_doi = attributes['doi']\n",
    "                relatedIdentifiers = attributes['relatedIdentifiers']\n",
    "                citing_doi = doi_manager.normalise(citing_doi, True)\n",
    "                doi_manager.set_valid(citing_doi)\n",
    "\n",
    "                #collect the date of issue if there is, otherwise the year of publciation\n",
    "                if id_date.get_value(citing_doi) is None:\n",
    "                    listDates = attributes['dates']\n",
    "                    publicationYear = attributes['publicationYear']\n",
    "\n",
    "                    if listDates != []:\n",
    "                        for data in listDates:\n",
    "                            tipo = str(data['dateType'])\n",
    "                            if tipo.lower() == 'issued':\n",
    "                                citing_date = valiDate(str(data['date']))\n",
    "                                if citing_date:\n",
    "                                    id_date.add_value(citing_doi, citing_date)\n",
    "                                    if citing_doi in citing_doi_with_no_date:\n",
    "                                        citing_doi_with_no_date.remove(citing_doi)\n",
    "                                # dateType è Issued ma citing_date non ha dato risultati\n",
    "                                else:\n",
    "                                    if publicationYear:\n",
    "                                        publicationYear = valiDate(str(publicationYear))\n",
    "                                        if publicationYear:\n",
    "                                            id_date.add_value(citing_doi, publicationYear)\n",
    "                                            if citing_doi in citing_doi_with_no_date:\n",
    "                                                citing_doi_with_no_date.remove(citing_doi)\n",
    "                            # c'è listDates ma datetype non è Issued\n",
    "                            else:\n",
    "                                if publicationYear:\n",
    "                                    publicationYear = valiDate(str(publicationYear))\n",
    "                                    if publicationYear:\n",
    "                                        id_date.add_value(citing_doi, publicationYear)\n",
    "                                        if citing_doi in citing_doi_with_no_date:\n",
    "                                            citing_doi_with_no_date.remove(citing_doi)\n",
    "                    #Non c'è listDates\n",
    "                    else:\n",
    "                        if publicationYear:\n",
    "                            publicationYear = valiDate(str(publicationYear))\n",
    "                            if publicationYear:\n",
    "                                id_date.add_value(citing_doi, publicationYear)\n",
    "                                if citing_doi in citing_doi_with_no_date:\n",
    "                                    citing_doi_with_no_date.remove(citing_doi)\n",
    "\n",
    "                #collect the orcid of the contributors\n",
    "\n",
    "                if id_orcid.get_value(citing_doi) is None:\n",
    "                    contributorList = attributes['creators']\n",
    "                    if contributorList != []:\n",
    "                        for author in contributorList:\n",
    "                            if 'nameIdentifiers' in author.keys():\n",
    "                                infoAuthor = author['nameIdentifiers']\n",
    "                                for element in infoAuthor:\n",
    "                                    if 'nameIdentifier' in element.keys() and 'nameIdentifierScheme' in element.keys():\n",
    "                                        if (element['nameIdentifierScheme']).lower() == 'orcid':\n",
    "                                            orcid = element['nameIdentifier']\n",
    "                                            if orcid is not None and orcid != \"\":\n",
    "                                                orcid = orcid_manager.normalise(orcid)\n",
    "                                                if orcid_manager.is_valid(orcid):\n",
    "                                                    id_orcid.add_value(citing_doi, orcid)\n",
    "\n",
    "                relatedISSN = \"\"\n",
    "                if relatedIdentifiers != []:\n",
    "\n",
    "                    #validazione dei dois citati e citanti\n",
    "                    for related in relatedIdentifiers:\n",
    "                        relationType = related['relationType']\n",
    "                        if relationType:\n",
    "                            if relationType.lower() in relevant_relations:\n",
    "                                # Att! Qui salviamo DOI citati e citanti\n",
    "                                if 'relatedIdentifierType' in related.keys():\n",
    "                                    relatedIdentifierType = (str(related['relatedIdentifierType'])).lower()\n",
    "                                    if relatedIdentifierType == 'doi':\n",
    "                                        if 'relatedIdentifier' in related.keys():\n",
    "                                            relatedDOI = str(related['relatedIdentifier'])\n",
    "                                            doi_manager.is_valid(relatedDOI)\n",
    "\n",
    "                            elif relationType.lower() == \"ispartof\":\n",
    "                                if 'relatedIdentifierType' in related.keys():\n",
    "                                    relatedIdentifierType = (str(related['relatedIdentifierType'])).lower()\n",
    "                                    if relatedIdentifierType == 'issn':\n",
    "                                        if 'relatedIdentifier' in related.keys():\n",
    "                                            relatedISSN = str(related['relatedIdentifier'])\n",
    "\n",
    "                issn_set = set()\n",
    "                if id_issn.get_value(citing_doi) is None:\n",
    "                    container = attributes['container']\n",
    "                    if 'identifier' in container.keys() and 'identifierType' in container.keys():\n",
    "                        if container['identifier'] != \"\" and (container['identifier']).lower() == \"issn\":\n",
    "                            if 'title' in container.keys():\n",
    "                                journal_title = (container['title']).lower()\n",
    "                                if journal_title in issnDict.keys():\n",
    "                                    issnList = issnDict[journal_title]\n",
    "                                    if issnList != []:\n",
    "                                        if container['identifier'] not in issnList:\n",
    "                                            issnDict[journal_title].append(container['identifier'])\n",
    "                                            issn_set.update(set(issnDict[journal_title]))\n",
    "                                    else:\n",
    "                                        issnDict[journal_title].append(container['identifier'])\n",
    "                                        issn_set.add(container['identifier'])\n",
    "                                else:\n",
    "                                    issnDict[journal_title] = []\n",
    "                                    issnDict[journal_title].append(container['identifier'])\n",
    "                                    issn_set.add(container['identifier'])\n",
    "\n",
    "                    if relatedISSN != \"\":\n",
    "                        issn_set.add(relatedISSN)\n",
    "\n",
    "                    normalised_issn_set = set()\n",
    "                    for issn in issn_set:\n",
    "                        norm_issn = issn_manager.normalise(issn)\n",
    "                        normalised_issn_set.add(norm_issn)\n",
    "                    for issn in normalised_issn_set:\n",
    "                        if issn_manager.is_valid(issn):\n",
    "                            id_issn.add_value(citing_doi, issn)\n",
    "\n",
    "                if int(count) != 0 and int(count ) % int( n ) == 0:\n",
    "                    print( \"trasferimento cash dati issn. Entità processate:\", count, \". Trascrizione cache n.\",\n",
    "                           (count // n) )\n",
    "                    print( \"issnDict\", issnDict )\n",
    "                    issn_data_to_cache(issnDict, output_dir)\n",
    "\n",
    "            issn_data_to_cache(issnDict, output_dir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inp_fol = \"E:\\LAVORO\\DOCI\\dump_doci\\datacite_dump_20211022\\output_test\\splitted_json\"\n",
    "out_fol = \"E:\\LAVORO\\DOCI\\dump_doci\\datacite_dump_20211022\\output_test\\glob_splitted_lines\"\n",
    "\n",
    "process(inp_fol, out_fol, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domande\n",
    "<ul>\n",
    "    <li> Cosa faccio <b>se i due issn (container e related identifiers) sono diversi</b>? li aggiungo entrambi in relazione al DOI nei support files senza dedurre che facciano riferimento necessariamente allo stesso Journal, quindi aggiorno il dizionario di supporto solo nel caso in cui l'ISSN sia stato trovato in container? </li>\n",
    "    <li>Come veniva svolta questa procedura originariamente?\n",
    "sono cambiati i dati?</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "posso propagare l'informazione anche al dizionario (quella di ispartof)\n",
    "la validazione devo farla solo per i doi che non sono di datacite. quando processo le refrences lo faccio in un secondo momento. \n",
    "attzione i doi di datacite non vanno validati. sono validi. \n",
    "controlla solo i doi che non sono di datacite\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (06/05 - 13/05) Visualization: Final Version + DOCI and NOCI parser and glob for farm_revision\n",
    "<a id=\"entry_11\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)  Visualization Final Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li><b>last_month as latest selectable month</b>: In the previous version of the js script for the visualizations the last selectable month in the calendar was the current one - 1. However, this choice could be risky, since the update of statistics/last_moth file is not yet automatic. For this reason, the date of the last month available is now extracted from the prometheus metric <b>opencitations_date_info{month=\"04\",year=\"2022\"}</b>, and used as last selectable month in the calendar for the visualization customizations.</li>\n",
    "    <li><b>input preselection</b>: in the previous version the input got a value in the moment when the user chose a date from the calendar. In this version, instead, there is a preselection, which is the date of the last month available as end date and the same date -12 months for the start date. The only case in which the inputs are emptied is that in which the user selects a start date which follows the end date: in this case the system deletes the input and ask the user to make a new selection.</li>\n",
    "    <li><b>new default visualizations</b>: in the previous version, the default visualization were created from manually provided data. In the current version, also the default visualizations are generated from data retrieved from the opecitations API. The end month is retrieved from the response of the api call opencitations/statistics/last_month, while the start month is this latter value - 12 months. The default interval for the barchart is 1-month, while for the linechart is 2-months.  </li>\n",
    "    <li><b>ISSUE:</b> Since the default data aren't manually updated anymore, the current version performs several https calls to obtain the data for the visualizations before the page is fully loaded. For this reason, ther is a visible buffer which lasts for some seconds, in which the window is loaded but not all the components are ready. I tried both window.load and document.ready, but in both cases the loading process of the visualizations was visible. I don't know if it may be an issue. In this case it should be possible to hide the content of the body element until all the components haven't finished loading (but I didn't succeed when I tried.) Another option is the fadeOut but I'm not sure about it, since it covers a given amount of seconds which can be lesser or bigger than the time of the components loading. Check it out at : <a href = \"https://ariannamorettj.github.io/OC_log_viz/\">https://ariannamorettj.github.io/OC_log_viz/</a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)  DOCI and NOCI parser and glob for farm_revision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li><b>DOCI GLOBs FIX</b>: The previous versions were very slow not because the is_valid method was used to check with API the validity of all the DOIs provided as citing entities in the dump (given for granted and stated as such with set_valid method), but because the check of the validity of the cited dois (with is_valid method) was performed in the same iteration in which all the other tasks are performed. Indeed, since the check of the validity of a cited doi (with is_valid method) is performed only in case it is not included in the valid_doi file (which is updated during the main process), it is quite likely that a large part of the cited dois are already present in the valid_doi file at the end of the first iteration (having been considered valid by default as citing dois), and no further API checks are needed. For this reason, the main process is managed in the first iteration, while the check of the validity of the cited dois in a second iteration.</li>\n",
    "    <li><b>Test the execution speed of the three versions of the dump</b>: i generated a reduced input so to be able to consider also the validation time of the cited dois. note: the time is supposed to be overextimated, since when the glob will be run on real data, by the time of the cited dois validation the most of the dois will be present in the valid_dois table. <b>note:</b> only 2 out of 3 versions were tested - fixed - tested again. I still have to check the last one.</li>\n",
    "    <li><b>noci glob fix</b>: started, not finished. I addressed the orcid recovering by the use of the mapping table but I still have to finish managing the issn management through NIH finder fpr pmids.\n",
    "</li>\n",
    "    <li><b>inverse citations management DATACITE parser:</b> done. To do: testing</li>\n",
    "    <li><b>reduced dump generation</b> done. To do: testing</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modifica glob Noci per gestione ORCID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if id_orcid.get_value(citing_pmid) is None:\n",
    "    if citing_doi is not None:\n",
    "        all_files_orcid_doi, op = get_all_files(doi_orcid_mapping)\n",
    "        for f_idx, f in enumerate(all_files_orcid_doi, 1):\n",
    "            csv_man_f = CSVManager(f)\n",
    "            if csv_man_f.get_value(citing_doi) is not None:\n",
    "                orcid_set = csv_man_f.get_value(citing_doi)\n",
    "                if len(orcid_set)>0:\n",
    "                    for orcid in orcid_set:\n",
    "                        orcid_norm = orcid_manager.normalise(orcid)\n",
    "                        id_orcid.add_value(citing_pmid, orcid_norm)\n",
    "                break #perché se ha trovato il doi con l'orcid associato non deve valutare tutti gli altri\n",
    "\n",
    "\n",
    "    #if citing_doi is not None:\n",
    "        #json_res = orcid_resource_finder._call_api(citing_doi)\n",
    "        #if json_res is not None:\n",
    "            #orcid_set = orcid_resource_finder._get_orcid(json_res)\n",
    "            #for orcid in orcid_set:\n",
    "               #orcid_norm = orcid_manager.normalise( orcid )\n",
    "                #id_orcid.add_value(citing_pmid, orcid_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performances DOCI glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### glob_ver1 (senza lista doi validati) - testato su 300 entità -- 1run\n",
    "<ul>\n",
    "    <li>cited dois: 99 ????????????????</li>\n",
    "    <li>first process duration: : 7.5036893000000005 (300it [00:07, 40.23it/s])</li>\n",
    "    <li>second process duration:  1420.5105029000001 (300it [23:40,  4.74s/it])</li>\n",
    "    <li>full process duration:  1428.0141922</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### glob_ver2 (senza lista doi validati) - testato su 300 entità -- 1 run\n",
    "<ul>\n",
    "    <li>related dois: 6091</li>\n",
    "    <li>first process duration: : 37.626591 (229618it [00:37, 6126.96it/s])</li>\n",
    "    <li>second process duration:  1348.5393282 (229618it [22:28, 170.27it/s])</li>\n",
    "    <li>full process duration:  1386.1659192</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note sui due processi: \n",
    "il primo non salva informazioni nel json per cache\n",
    "il secondo ha delle incoerenze sulle date e ne salva di meno.\n",
    "vanno ritestati entrambi\n",
    "Hanno stesso numero di entità validate (6075 x 300 entità) ma in ordine diverso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### glob_ver1: gestione ISSN --> bug fix  e propagazione dell'informazione relativa al titolo della rivista a tutti gli ISSN collezionati, compresi quelli da relatedIdentifiers, isPartOf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                issn_set = set()\n",
    "                if relatedIdentifiers != []:\n",
    "                    for related in relatedIdentifiers:\n",
    "                        if 'relationType' in related.keys():\n",
    "                            relationType = related['relationType']\n",
    "                            if relationType.lower() == \"ispartof\":\n",
    "                                if 'relatedIdentifierType' in related.keys():\n",
    "                                    relatedIdentifierType = (str(related['relatedIdentifierType'])).lower()\n",
    "                                    if relatedIdentifierType == 'issn':\n",
    "                                        if 'relatedIdentifier' in related.keys():\n",
    "                                            relatedISSN = str(related['relatedIdentifier'])\n",
    "                                            if relatedISSN:\n",
    "                                                issn_set.add(relatedISSN)\n",
    "\n",
    "                if id_issn.get_value(citing_doi) is None:\n",
    "                    container = attributes['container']\n",
    "                    if 'identifier' in container.keys() and 'identifierType' in container.keys():\n",
    "                        if container['identifier'] != \"\" and (container['identifierType']).lower() == \"issn\":\n",
    "                            cont_issn = container['identifier']\n",
    "                            issn_set.add(cont_issn)\n",
    "                            if 'title' in container.keys():\n",
    "                                journal_title = (container['title']).lower()\n",
    "                                if journal_title in issnDict.keys():\n",
    "                                    issnList = issnDict[journal_title]\n",
    "                                    if issnList != []:\n",
    "                                        if not all(elem in issnList for elem in issn_set):\n",
    "                                            issn_set.update(set(issnDict[journal_title]))\n",
    "                                            issnDict[journal_title] = list(issn_set)\n",
    "                                    else:\n",
    "                                        issnDict[journal_title] = list(issn_set)\n",
    "                                else:\n",
    "                                    issnDict[journal_title] = list(issn_set)\n",
    "\n",
    "\n",
    "                    normalised_issn_set = set()\n",
    "                    for issn in issn_set:\n",
    "                        norm_issn = issn_manager.normalise(issn)\n",
    "                        normalised_issn_set.add(norm_issn)\n",
    "                    for issn in normalised_issn_set:\n",
    "                        if issn_manager.is_valid(issn):\n",
    "                            id_issn.add_value(citing_doi, issn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### glob_ver1 (senza lista doi validati) - testato su 300 entità -- 2run\n",
    "<ul>\n",
    "    <li>cited dois: 6125</li>\n",
    "    <li>first process duration: : 8.044269499999999 (300it [00:07, 37.60it/s])</li>\n",
    "    <li>second process duration:  1299.3006421 (300it [21:39,  4.33s/it])</li>\n",
    "    <li>full process duration:  1307.3449116000002</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### glob_ver2: gestione ISSN --> propagazione dell'informazione relativa al titolo della rivista a tutti gli ISSN collezionati, compresi quelli da relatedIdentifiers, isPartOf  + correzione DATE --> se non trovo l'informazione in date, utilizzo l'anno di pubblicazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### recupero informazione : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    elif prefix == 'attributes.container' and event == 'start_map':\n",
    "                        cont_title = \"\"\n",
    "                        cont_id = \"\"\n",
    "                        cont_id_type = \"\"\n",
    "\n",
    "                    elif prefix == 'attributes.container.identifier':\n",
    "                        cont_id = value\n",
    "                    elif prefix == 'attributes.container.identifierType':\n",
    "                        cont_id_type = value.lower()\n",
    "                    elif prefix == 'attributes.container.title':\n",
    "                        cont_title = value.lower()\n",
    "\n",
    "                    #questa parte confluisce in relatedIdentifiers ISSN, visto che gli identificativi vengono aggiunti\n",
    "                    # al set issn_set_tmp, che diventa il valore della chiave ISSN di RelatedIdentifiers\n",
    "                    elif prefix == 'attributes.container' and event == 'end_map':\n",
    "                        if cont_id_type == \"issn\" and cont_title != \"\" and cont_id != \"\":\n",
    "                            reduced_dict[\"attributes\"][\"contentTitle\"] = cont_title\n",
    "                            if cont_title in issnDict.keys():\n",
    "                                issnList = issnDict[cont_title]\n",
    "                                if issnList != []:\n",
    "                                    if cont_id not in issnList:\n",
    "                                        issnDict[cont_title].append(cont_id)\n",
    "                                        issn_set_tmp.update(set(issnDict[cont_title]))\n",
    "                                else:\n",
    "                                    issnDict[cont_title].append(cont_id)\n",
    "                                    issn_set_tmp.add(cont_id)\n",
    "                            else:\n",
    "                                issnDict[cont_title] = []\n",
    "                                issnDict[cont_title].append(cont_id)\n",
    "                                issn_set_tmp.add(cont_id)\n",
    "\n",
    "                        elif cont_id_type == \"issn\" and cont_title == \"\" and cont_id != \"\":\n",
    "                            issn_set_tmp.add(cont_id)\n",
    "\n",
    "                    elif prefix == 'attributes.relatedIdentifiers.item' and event == 'start_map':\n",
    "                        rel_id_rel = \"\"\n",
    "                        rel_id = \"\"\n",
    "                        rel_id_type = \"\"\n",
    "                    elif prefix == 'attributes.relatedIdentifiers.item.relationType':\n",
    "                        rel_id_rel = value.lower()\n",
    "                    elif prefix == 'attributes.relatedIdentifiers.item.relatedIdentifier':\n",
    "                        rel_id = value\n",
    "                    elif prefix == 'attributes.relatedIdentifiers.item.relatedIdentifierType':\n",
    "                        rel_id_type = value.lower()\n",
    "                    elif prefix == 'attributes.relatedIdentifiers.item' and event == 'end_map':\n",
    "                        if rel_id != \"\" and rel_id_type == \"issn\" and rel_id_rel == \"ispartof\":\n",
    "                            issn_set_tmp.add(rel_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### gestione informazione : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                else:\n",
    "                    #gestisce il caso in cui l'issn di \"ispartof\" non fosse = a quello presente nel container\n",
    "\n",
    "                    if reduced_dict[\"attributes\"][\"contentTitle\"] != \"\":\n",
    "                        cont_tit = reduced_dict[\"attributes\"][\"contentTitle\"]\n",
    "                        issnList_final = issnDict[cont_tit]\n",
    "                        if not all (elem in issnList_final for elem in issn_set_tmp): #conferma?\n",
    "                            issn_set_tmp.update(set(issnDict[cont_title]))\n",
    "                            issnDict[cont_title] = list(issn_set_tmp)\n",
    "                    reduced_dict[\"attributes\"][\"relatedIdentifiers\"][\"ISSNS\"] = issn_set_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### date e anno di pubblicazione (fix) -- estrazione "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                    elif prefix == 'attributes.dates.item.date':\n",
    "                        date_dict[\"date\"] = value\n",
    "\n",
    "                    elif prefix == 'attributes.dates.item.dateType' and value == \"Issued\":\n",
    "                        if \"date\" in date_dict.keys() and date_dict[\"date\"] != \"\":\n",
    "                            reduced_dict[\"attributes\"][\"dates\"].append(date_dict)\n",
    "                            date_dict = {}\n",
    "\n",
    "                    # svuota dizionario sia nel caso in cui incontri un dateType diverso da Issue sia nel caso in cui il dizionario relativo alla data venga chiuso\n",
    "                    # in questo modo, nel caso in cui venga specificata una data ma non sia dichiarato il dateType, l'informazione viene cancellata alla chiusura\n",
    "                    # del dizionario relativo alla data stessa\n",
    "\n",
    "                    elif (prefix == 'attributes.dates.item.dateType' and value != \"Issued\") or (prefix == 'attributes.dates.item' and event == 'end_map') :\n",
    "                        date_dict = {}\n",
    "\n",
    "                    elif prefix == 'attributes.publicationYear':\n",
    "                        reduced_dict[\"attributes\"][\"publicationYear\"] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### date e anno di pubblicazione (fix) -- gestione "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                        if id_date.get_value(citing_doi) is None: #Necessario?\n",
    "                            listDates = reduced_dict['attributes']['dates']\n",
    "                            publicationYear = reduced_dict['attributes']['publicationYear']\n",
    "                            if listDates != []:\n",
    "                                for data in listDates:\n",
    "                                    citing_date = valiDate(str(data['date']))\n",
    "                                    if citing_date:\n",
    "                                        id_date.add_value(citing_doi, citing_date)\n",
    "                                        if citing_doi in citing_doi_with_no_date:\n",
    "                                            citing_doi_with_no_date.remove(citing_doi)\n",
    "                                    else:\n",
    "                                        if publicationYear != \"\":\n",
    "                                            publicationYear = valiDate( str( publicationYear ) )\n",
    "                                            if publicationYear:\n",
    "                                                id_date.add_value( citing_doi, publicationYear )\n",
    "                                                if citing_doi in citing_doi_with_no_date:\n",
    "                                                    citing_doi_with_no_date.remove( citing_doi )\n",
    "                            else:\n",
    "                                if publicationYear != \"\":\n",
    "                                    publicationYear = valiDate(str(publicationYear))\n",
    "                                    if publicationYear:\n",
    "                                        id_date.add_value(citing_doi, publicationYear)\n",
    "                                        if citing_doi in citing_doi_with_no_date:\n",
    "                                            citing_doi_with_no_date.remove(citing_doi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### glob_ver2 (senza lista doi validati) - testato su 300 entità -- 2run\n",
    "<ul>\n",
    "    <li>cited dois: ____</li>\n",
    "    <li>first process duration: ________ (____________)</li>\n",
    "    <li>second process duration: ________ (____________)</li>\n",
    "    <li>full process duration:  __________</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading: : 229618it [00:37, 6130.48it/s]<br>\n",
    "0it [00:00, ?it/s]first process duration: : 37.6505436 <br>\n",
    "related dois: 6091 <br>\n",
    "Loading: : 229618it [00:37, 6130.48it/s] <br>\n",
    "0it [00:00, ?it/s]first process duration: : 37.6505436 <br>\n",
    "Loading: : 228827it [21:02, 205.87it/s]these are related dois: set() <br>\n",
    "second process duration:  1262.8776333 <br>\n",
    "full process duration:  1300.5281769 <br>\n",
    "Loading: : 229618it [21:02, 181.82it/s] <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATACITE PARSER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample data (con tutti i casi di citanti e citati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"data\": [{\"id\":\"10.11570/13.0001\",\"type\":\"dois\",\"attributes\":{\"doi\":\"10.11570/13.0001\",\"identifiers\":[],\"creators\":[{\"name\":\"Wilson, C. D.\",\"nameType\":\"Personal\",\"givenName\":\"C. D.\",\"familyName\":\"Wilson\",\"affiliation\":[],\"nameIdentifiers\":[]}],\"titles\":[{\"lang\":\"en-US\",\"title\":\"Nearby Galaxies Legacy Survey\"},{\"lang\":\"en-US\",\"title\":\"NGLS\",\"titleType\":\"AlternativeTitle\"}],\"publisher\":\"CADC\",\"container\":{},\"publicationYear\":2013,\"subjects\":[],\"contributors\":[{\"name\":\"CADC\",\"affiliation\":[],\"contributorType\":\"DataManager\",\"nameIdentifiers\":[]},{\"name\":\"Schade, David\",\"nameType\":\"Personal\",\"givenName\":\"David\",\"familyName\":\"Schade\",\"affiliation\":[],\"contributorType\":\"ContactPerson\",\"nameIdentifiers\":[{\"schemeUri\":\"https://orcid.org\",\"nameIdentifier\":\"https://orcid.org/0000-0002-4677-1586\",\"nameIdentifierScheme\":\"ORCID\"}]}],\"dates\":[{\"date\":\"2013\",\"dateType\":\"Issued\"}],\"language\":\"en\",\"types\":{\"ris\":\"DATA\",\"bibtex\":\"misc\",\"citeproc\":\"dataset\",\"schemaOrg\":\"Dataset\",\"resourceTypeGeneral\":\"Dataset\"},\"relatedIdentifiers\":[{\"relationType\":\"IsCitedBy\",\"relatedIdentifier\":\"10.1093/mnras/stv2808\",\"relatedIdentifierType\":\"DOI\"}],\"sizes\":[],\"formats\":[],\"version\":null,\"rightsList\":[],\"descriptions\":[{\"lang\":\"en-US\",\"description\":\"This contains data, plots, and information of observations of galaxies in the JCMT Nearby Galaxies Legaxy Survey.\",\"descriptionType\":\"Other\"}],\"geoLocations\":[],\"fundingReferences\":[],\"url\":\"http://www.canfar.net/citation/landing?doi=13.0001\",\"contentUrl\":[],\"metadataVersion\":2,\"schemaVersion\":\"http://datacite.org/schema/kernel-4\",\"source\":\"mds\",\"isActive\":true,\"state\":\"findable\",\"reason\":null,\"viewCount\":0,\"downloadCount\":0,\"referenceCount\":0,\"citationCount\":1,\"partCount\":0,\"partOfCount\":0,\"versionCount\":0,\"versionOfCount\":0,\"created\":\"2013-04-19T21:33:33.000Z\",\"registered\":\"2013-04-19T21:33:33.000Z\",\"published\":\"2013\",\"updated\":\"2020-11-05T10:14:30.000Z\"},\"relationships\":{\"client\":{\"data\":{\"id\":\"nrc.cadc\",\"type\":\"clients\"}}}}, {\"id\":\"10.1007/s13346-017-0376-5\",\"type\":\"dois\",\"attributes\":{\"doi\":\"10.1007/s13346-017-0376-5\",\"identifiers\":[{\"identifier\":\"https://doi.org/10.1007/s13346-017-0376-5\",\"identifierType\":\"DOI\"}],\"creators\":[{\"name\":\"Boustta, Mahfoud\",\"nameType\":\"Personal\",\"givenName\":\"Mahfoud\",\"familyName\":\"Boustta\",\"affiliation\":[],\"nameIdentifiers\":[]},{\"name\":\"Vert, Michel\",\"nameType\":\"Personal\",\"givenName\":\"Michel\",\"familyName\":\"Vert\",\"affiliation\":[],\"nameIdentifiers\":[]}],\"titles\":[{\"title\":\"A method to slow down the ionization-dependent release of risperidone loaded in a thermoresponsive poly(N-acryloyl glycinamide) hydrogel\"}],\"publisher\":\"Springer Science and Business Media LLC\",\"container\":{\"type\":\"Journal\",\"issue\":\"3\",\"title\":\"Drug Delivery and Translational Research\",\"volume\":\"7\",\"lastPage\":\"464\",\"firstPage\":\"460\",\"identifier\":\"2190-3948\",\"identifierType\":\"ISSN\"},\"publicationYear\":2017,\"subjects\":[],\"contributors\":[],\"dates\":[{\"date\":\"2017-04-07\",\"dateType\":\"Issued\"},{\"date\":\"2017-04-25T15:35:34Z\",\"dateType\":\"Updated\"}],\"language\":null,\"types\":{\"ris\":\"JOUR\",\"bibtex\":\"article\",\"citeproc\":\"article-journal\",\"schemaOrg\":\"ScholarlyArticle\",\"resourceType\":\"JournalArticle\",\"resourceTypeGeneral\":\"Text\"},\"relatedIdentifiers\":[{\"relationType\":\"IsPartOf\",\"relatedIdentifier\":\"2190-3948\",\"resourceTypeGeneral\":\"Collection\",\"relatedIdentifierType\":\"ISSN\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1002/pol.1964.110021203\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1002/pol.1967.160050509\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1002/pol.1970.150080509\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.jconrel.2013.10.040\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1615/critrevtherdrugcarriersyst.2016015798\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1134/s1990793116070022\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.jconrel.2010.03.024\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.schres.2007.08.003\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1007/s11095-010-0152-4\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1080/00914037.2015.1099100\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1039/c5ra03535j\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.colsurfb.2011.03.043\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1097/00007691-199808000-00004\",\"relatedIdentifierType\":\"DOI\"}],\"sizes\":[],\"formats\":[],\"version\":null,\"rightsList\":[{\"rightsUri\":\"http://www.springer.com/tdm\"}],\"descriptions\":[],\"geoLocations\":[],\"fundingReferences\":[],\"url\":\"http://link.springer.com/10.1007/s13346-017-0376-5\",\"contentUrl\":null,\"metadataVersion\":0,\"schemaVersion\":\"http://datacite.org/schema/kernel-4\",\"source\":\"levriero\",\"isActive\":true,\"state\":\"findable\",\"reason\":null,\"viewCount\":0,\"downloadCount\":0,\"referenceCount\":0,\"citationCount\":1,\"partCount\":0,\"partOfCount\":0,\"versionCount\":0,\"versionOfCount\":0,\"created\":\"2020-02-28T01:35:59.000Z\",\"registered\":\"2020-02-28T01:35:59.000Z\",\"published\":\"2017\",\"updated\":\"2020-02-28T01:36:06.000Z\"},\"relationships\":{\"client\":{\"data\":{\"id\":\"crossref.citations\",\"type\":\"clients\"}}}}, {\"id\":\"10.11577/1236752\",\"type\":\"dois\",\"attributes\":{\"doi\":\"10.11577/1236752\",\"identifiers\":[{\"identifier\":\"1236752\",\"identifierType\":\"OSTI ID\"},{\"identifier\":\"AC02-05CH11231\",\"identifierType\":\"DOE Contract Number\"},{\"identifier\":\"CXIDB ID 30\",\"identifierType\":\"Product Number\"}],\"creators\":[{\"name\":\"Ekeberg, Tomas\",\"nameType\":\"Personal\",\"givenName\":\"Tomas\",\"familyName\":\"Ekeberg\",\"affiliation\":[],\"nameIdentifiers\":[]}],\"titles\":[{\"title\":\"Three-Dimensional Reconstruction of the Giant Mimivirus Particle with an X-Ray Free-Electron Laser (CXIDB ID 30)\"}],\"publisher\":\"Coherent X-ray Imaging Data Bank (Lawrence Berkeley National Laboratory); Uppsala University, SLAC National \\nAccelerator Laboratory, Yale University, Diamond Light Source, Lawrence Berkeley National Laboratory\",\"container\":{},\"publicationYear\":2015,\"subjects\":[{\"subject\":\"Mimivirus\"},{\"subject\":\"XFEL\"},{\"subject\":\"AMO\"},{\"subject\":\"Single Particle X-ray Diffraction Imaging\"},{\"subject\":\"X-ray Free-electorn Lasers\"},{\"subject\":\"LCLS\"}],\"contributors\":[],\"dates\":[{\"date\":\"2015\",\"dateType\":\"Issued\"}],\"language\":\"en\",\"types\":{\"ris\":\"DATA\",\"bibtex\":\"misc\",\"citeproc\":\"dataset\",\"schemaOrg\":\"Dataset\",\"resourceType\":\"Still Images or Photos\",\"resourceTypeGeneral\":\"Dataset\"},\"relatedIdentifiers\":[{\"relationType\":\"IsReferencedBy\",\"relatedIdentifier\":\"10.1038/sdata.2016.60\",\"relatedIdentifierType\":\"DOI\"}],\"sizes\":[],\"formats\":[],\"version\":null,\"rightsList\":[],\"descriptions\":[{\"description\":\"This dataset contains the diffraction patterns that were used for the first three-dimensional reconstruction of a virus using FEL data. The sample was the giant mimivirus particle, which is one of the largest known viruses with a diameter of 450 nm. The dataset consists of the 198 diffraction patterns that were used in the analysis.\",\"descriptionType\":\"Abstract\"}],\"geoLocations\":[],\"fundingReferences\":[],\"url\":\"https://www.osti.gov/servlets/purl/1236752/\",\"contentUrl\":null,\"metadataVersion\":2,\"schemaVersion\":\"http://datacite.org/schema/kernel-4\",\"source\":\"mds\",\"isActive\":true,\"state\":\"findable\",\"reason\":null,\"viewCount\":0,\"downloadCount\":0,\"referenceCount\":0,\"citationCount\":1,\"partCount\":0,\"partOfCount\":0,\"versionCount\":0,\"versionOfCount\":0,\"created\":\"2016-02-05T03:28:36Z\",\"registered\":\"2016-02-05T03:28:37Z\",\"published\":null,\"updated\":\"2021-07-15T02:12:02Z\"},\"relationships\":{\"client\":{\"data\":{\"id\":\"doe.lbnl\",\"type\":\"clients\"}}}}, {\"id\":\"10.11578/1480643\",\"type\":\"dois\",\"attributes\":{\"doi\":\"10.11578/1480643\",\"identifiers\":[{\"identifier\":\"1480643\",\"identifierType\":\"OSTI ID\"},{\"identifier\":\"ostiprod\",\"identifierType\":\"DOE Contract Number\"},{\"identifier\":\"datasetpn\",\"identifierType\":\"Product Number\"}],\"creators\":[{\"name\":\"Last, First\",\"nameType\":\"Personal\",\"givenName\":\"First\",\"familyName\":\"Last\",\"affiliation\":[],\"nameIdentifiers\":[]}],\"titles\":[{\"title\":\"Dataset Title - Award\"}],\"publisher\":\"Desert Research Institute (DRI), Nevada System of Higher Education, Reno,NV (United States)\",\"container\":{},\"publicationYear\":2018,\"subjects\":[],\"contributors\":[],\"dates\":[{\"date\":\"2018\",\"dateType\":\"Issued\"}],\"language\":\"en\",\"types\":{\"ris\":\"GEN\",\"bibtex\":\"misc\",\"citeproc\":\"article\",\"schemaOrg\":\"CreativeWork\",\"resourceType\":\"Award\",\"resourceTypeGeneral\":\"Other\"},\"relatedIdentifiers\":[{\"relationType\":\"Cites\",\"relatedIdentifier\":\"10.15407/scin11.06.057\",\"relatedIdentifierType\":\"DOI\"}],\"sizes\":[],\"formats\":[],\"version\":null,\"rightsList\":[],\"descriptions\":[{\"description\":\"description/abstract\",\"descriptionType\":\"Abstract\"}],\"geoLocations\":[{\"geoLocationPlace\":\"geolocation\",\"geoLocationPoint\":{\"pointLatitude\":\"1.1111\",\"pointLongitude\":\"2.2222\"}}],\"fundingReferences\":[],\"url\":\"https://www.osti.gov/servlets/purl/1480643/\",\"contentUrl\":null,\"metadataVersion\":0,\"schemaVersion\":null,\"source\":\"mds\",\"isActive\":true,\"state\":\"findable\",\"reason\":null,\"viewCount\":0,\"downloadCount\":0,\"referenceCount\":0,\"citationCount\":0,\"partCount\":0,\"partOfCount\":0,\"versionCount\":0,\"versionOfCount\":0,\"created\":\"2018-11-03T14:38:53.000Z\",\"registered\":\"2018-11-03T14:38:55.000Z\",\"published\":\"2018\",\"updated\":\"2020-09-20T08:19:49.000Z\"},\"relationships\":{\"client\":{\"data\":{\"id\":\"doe.osti\",\"type\":\"clients\"}}}}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"id\":\"10.11570/13.0001\",\"type\":\"dois\",\"attributes\":{\"doi\":\"10.11570/13.0001\",\"identifiers\":[],\"creators\":[{\"name\":\"Wilson, C. D.\",\"nameType\":\"Personal\",\"givenName\":\"C. D.\",\"familyName\":\"Wilson\",\"affiliation\":[],\"nameIdentifiers\":[]}],\"titles\":[{\"lang\":\"en-US\",\"title\":\"Nearby Galaxies Legacy Survey\"},{\"lang\":\"en-US\",\"title\":\"NGLS\",\"titleType\":\"AlternativeTitle\"}],\"publisher\":\"CADC\",\"container\":{},\"publicationYear\":2013,\"subjects\":[],\"contributors\":[{\"name\":\"CADC\",\"affiliation\":[],\"contributorType\":\"DataManager\",\"nameIdentifiers\":[]},{\"name\":\"Schade, David\",\"nameType\":\"Personal\",\"givenName\":\"David\",\"familyName\":\"Schade\",\"affiliation\":[],\"contributorType\":\"ContactPerson\",\"nameIdentifiers\":[{\"schemeUri\":\"https://orcid.org\",\"nameIdentifier\":\"https://orcid.org/0000-0002-4677-1586\",\"nameIdentifierScheme\":\"ORCID\"}]}],\"dates\":[{\"date\":\"2013\",\"dateType\":\"Issued\"}],\"language\":\"en\",\"types\":{\"ris\":\"DATA\",\"bibtex\":\"misc\",\"citeproc\":\"dataset\",\"schemaOrg\":\"Dataset\",\"resourceTypeGeneral\":\"Dataset\"},\"relatedIdentifiers\":[{\"relationType\":\"IsCitedBy\",\"relatedIdentifier\":\"10.1093/mnras/stv2808\",\"relatedIdentifierType\":\"DOI\"}],\"sizes\":[],\"formats\":[],\"version\":null,\"rightsList\":[],\"descriptions\":[{\"lang\":\"en-US\",\"description\":\"This contains data, plots, and information of observations of galaxies in the JCMT Nearby Galaxies Legaxy Survey.\",\"descriptionType\":\"Other\"}],\"geoLocations\":[],\"fundingReferences\":[],\"url\":\"http://www.canfar.net/citation/landing?doi=13.0001\",\"contentUrl\":[],\"metadataVersion\":2,\"schemaVersion\":\"http://datacite.org/schema/kernel-4\",\"source\":\"mds\",\"isActive\":true,\"state\":\"findable\",\"reason\":null,\"viewCount\":0,\"downloadCount\":0,\"referenceCount\":0,\"citationCount\":1,\"partCount\":0,\"partOfCount\":0,\"versionCount\":0,\"versionOfCount\":0,\"created\":\"2013-04-19T21:33:33.000Z\",\"registered\":\"2013-04-19T21:33:33.000Z\",\"published\":\"2013\",\"updated\":\"2020-11-05T10:14:30.000Z\"},\"relationships\":{\"client\":{\"data\":{\"id\":\"nrc.cadc\",\"type\":\"clients\"}}}}\n",
    "{\"id\":\"10.1007/s13346-017-0376-5\",\"type\":\"dois\",\"attributes\":{\"doi\":\"10.1007/s13346-017-0376-5\",\"identifiers\":[{\"identifier\":\"https://doi.org/10.1007/s13346-017-0376-5\",\"identifierType\":\"DOI\"}],\"creators\":[{\"name\":\"Boustta, Mahfoud\",\"nameType\":\"Personal\",\"givenName\":\"Mahfoud\",\"familyName\":\"Boustta\",\"affiliation\":[],\"nameIdentifiers\":[]},{\"name\":\"Vert, Michel\",\"nameType\":\"Personal\",\"givenName\":\"Michel\",\"familyName\":\"Vert\",\"affiliation\":[],\"nameIdentifiers\":[]}],\"titles\":[{\"title\":\"A method to slow down the ionization-dependent release of risperidone loaded in a thermoresponsive poly(N-acryloyl glycinamide) hydrogel\"}],\"publisher\":\"Springer Science and Business Media LLC\",\"container\":{\"type\":\"Journal\",\"issue\":\"3\",\"title\":\"Drug Delivery and Translational Research\",\"volume\":\"7\",\"lastPage\":\"464\",\"firstPage\":\"460\",\"identifier\":\"2190-3948\",\"identifierType\":\"ISSN\"},\"publicationYear\":2017,\"subjects\":[],\"contributors\":[],\"dates\":[{\"date\":\"2017-04-07\",\"dateType\":\"Issued\"},{\"date\":\"2017-04-25T15:35:34Z\",\"dateType\":\"Updated\"}],\"language\":null,\"types\":{\"ris\":\"JOUR\",\"bibtex\":\"article\",\"citeproc\":\"article-journal\",\"schemaOrg\":\"ScholarlyArticle\",\"resourceType\":\"JournalArticle\",\"resourceTypeGeneral\":\"Text\"},\"relatedIdentifiers\":[{\"relationType\":\"IsPartOf\",\"relatedIdentifier\":\"2190-3948\",\"resourceTypeGeneral\":\"Collection\",\"relatedIdentifierType\":\"ISSN\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1002/pol.1964.110021203\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1002/pol.1967.160050509\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1002/pol.1970.150080509\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.jconrel.2013.10.040\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1615/critrevtherdrugcarriersyst.2016015798\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1134/s1990793116070022\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.jconrel.2010.03.024\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.schres.2007.08.003\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1007/s11095-010-0152-4\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1080/00914037.2015.1099100\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1039/c5ra03535j\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.colsurfb.2011.03.043\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1097/00007691-199808000-00004\",\"relatedIdentifierType\":\"DOI\"}],\"sizes\":[],\"formats\":[],\"version\":null,\"rightsList\":[{\"rightsUri\":\"http://www.springer.com/tdm\"}],\"descriptions\":[],\"geoLocations\":[],\"fundingReferences\":[],\"url\":\"http://link.springer.com/10.1007/s13346-017-0376-5\",\"contentUrl\":null,\"metadataVersion\":0,\"schemaVersion\":\"http://datacite.org/schema/kernel-4\",\"source\":\"levriero\",\"isActive\":true,\"state\":\"findable\",\"reason\":null,\"viewCount\":0,\"downloadCount\":0,\"referenceCount\":0,\"citationCount\":1,\"partCount\":0,\"partOfCount\":0,\"versionCount\":0,\"versionOfCount\":0,\"created\":\"2020-02-28T01:35:59.000Z\",\"registered\":\"2020-02-28T01:35:59.000Z\",\"published\":\"2017\",\"updated\":\"2020-02-28T01:36:06.000Z\"},\"relationships\":{\"client\":{\"data\":{\"id\":\"crossref.citations\",\"type\":\"clients\"}}}}\n",
    "{\"id\":\"10.11577/1236752\",\"type\":\"dois\",\"attributes\":{\"doi\":\"10.11577/1236752\",\"identifiers\":[{\"identifier\":\"1236752\",\"identifierType\":\"OSTI ID\"},{\"identifier\":\"AC02-05CH11231\",\"identifierType\":\"DOE Contract Number\"},{\"identifier\":\"CXIDB ID 30\",\"identifierType\":\"Product Number\"}],\"creators\":[{\"name\":\"Ekeberg, Tomas\",\"nameType\":\"Personal\",\"givenName\":\"Tomas\",\"familyName\":\"Ekeberg\",\"affiliation\":[],\"nameIdentifiers\":[]}],\"titles\":[{\"title\":\"Three-Dimensional Reconstruction of the Giant Mimivirus Particle with an X-Ray Free-Electron Laser (CXIDB ID 30)\"}],\"publisher\":\"Coherent X-ray Imaging Data Bank (Lawrence Berkeley National Laboratory); Uppsala University, SLAC National \\nAccelerator Laboratory, Yale University, Diamond Light Source, Lawrence Berkeley National Laboratory\",\"container\":{},\"publicationYear\":2015,\"subjects\":[{\"subject\":\"Mimivirus\"},{\"subject\":\"XFEL\"},{\"subject\":\"AMO\"},{\"subject\":\"Single Particle X-ray Diffraction Imaging\"},{\"subject\":\"X-ray Free-electorn Lasers\"},{\"subject\":\"LCLS\"}],\"contributors\":[],\"dates\":[{\"date\":\"2015\",\"dateType\":\"Issued\"}],\"language\":\"en\",\"types\":{\"ris\":\"DATA\",\"bibtex\":\"misc\",\"citeproc\":\"dataset\",\"schemaOrg\":\"Dataset\",\"resourceType\":\"Still Images or Photos\",\"resourceTypeGeneral\":\"Dataset\"},\"relatedIdentifiers\":[{\"relationType\":\"IsReferencedBy\",\"relatedIdentifier\":\"10.1038/sdata.2016.60\",\"relatedIdentifierType\":\"DOI\"}],\"sizes\":[],\"formats\":[],\"version\":null,\"rightsList\":[],\"descriptions\":[{\"description\":\"This dataset contains the diffraction patterns that were used for the first three-dimensional reconstruction of a virus using FEL data. The sample was the giant mimivirus particle, which is one of the largest known viruses with a diameter of 450 nm. The dataset consists of the 198 diffraction patterns that were used in the analysis.\",\"descriptionType\":\"Abstract\"}],\"geoLocations\":[],\"fundingReferences\":[],\"url\":\"https://www.osti.gov/servlets/purl/1236752/\",\"contentUrl\":null,\"metadataVersion\":2,\"schemaVersion\":\"http://datacite.org/schema/kernel-4\",\"source\":\"mds\",\"isActive\":true,\"state\":\"findable\",\"reason\":null,\"viewCount\":0,\"downloadCount\":0,\"referenceCount\":0,\"citationCount\":1,\"partCount\":0,\"partOfCount\":0,\"versionCount\":0,\"versionOfCount\":0,\"created\":\"2016-02-05T03:28:36Z\",\"registered\":\"2016-02-05T03:28:37Z\",\"published\":null,\"updated\":\"2021-07-15T02:12:02Z\"},\"relationships\":{\"client\":{\"data\":{\"id\":\"doe.lbnl\",\"type\":\"clients\"}}}}\n",
    "{\"id\":\"10.11578/1480643\",\"type\":\"dois\",\"attributes\":{\"doi\":\"10.11578/1480643\",\"identifiers\":[{\"identifier\":\"1480643\",\"identifierType\":\"OSTI ID\"},{\"identifier\":\"ostiprod\",\"identifierType\":\"DOE Contract Number\"},{\"identifier\":\"datasetpn\",\"identifierType\":\"Product Number\"}],\"creators\":[{\"name\":\"Last, First\",\"nameType\":\"Personal\",\"givenName\":\"First\",\"familyName\":\"Last\",\"affiliation\":[],\"nameIdentifiers\":[]}],\"titles\":[{\"title\":\"Dataset Title - Award\"}],\"publisher\":\"Desert Research Institute (DRI), Nevada System of Higher Education, Reno,NV (United States)\",\"container\":{},\"publicationYear\":2018,\"subjects\":[],\"contributors\":[],\"dates\":[{\"date\":\"2018\",\"dateType\":\"Issued\"}],\"language\":\"en\",\"types\":{\"ris\":\"GEN\",\"bibtex\":\"misc\",\"citeproc\":\"article\",\"schemaOrg\":\"CreativeWork\",\"resourceType\":\"Award\",\"resourceTypeGeneral\":\"Other\"},\"relatedIdentifiers\":[{\"relationType\":\"Cites\",\"relatedIdentifier\":\"10.15407/scin11.06.057\",\"relatedIdentifierType\":\"DOI\"}],\"sizes\":[],\"formats\":[],\"version\":null,\"rightsList\":[],\"descriptions\":[{\"description\":\"description/abstract\",\"descriptionType\":\"Abstract\"}],\"geoLocations\":[{\"geoLocationPlace\":\"geolocation\",\"geoLocationPoint\":{\"pointLatitude\":\"1.1111\",\"pointLongitude\":\"2.2222\"}}],\"fundingReferences\":[],\"url\":\"https://www.osti.gov/servlets/purl/1480643/\",\"contentUrl\":null,\"metadataVersion\":0,\"schemaVersion\":null,\"source\":\"mds\",\"isActive\":true,\"state\":\"findable\",\"reason\":null,\"viewCount\":0,\"downloadCount\":0,\"referenceCount\":0,\"citationCount\":0,\"partCount\":0,\"partOfCount\":0,\"versionCount\":0,\"versionOfCount\":0,\"created\":\"2018-11-03T14:38:53.000Z\",\"registered\":\"2018-11-03T14:38:55.000Z\",\"published\":\"2018\",\"updated\":\"2020-09-20T08:19:49.000Z\"},\"relationships\":{\"client\":{\"data\":{\"id\":\"doe.osti\",\"type\":\"clients\"}}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "from json import load\n",
    "\n",
    "from oc.index.identifier.doi import DOIManager\n",
    "from oc.index.parsing.base import CitationParser\n",
    "\n",
    "\n",
    "class DataciteParser(CitationParser):\n",
    "    def __init__(self):\n",
    "        self._rows = []\n",
    "        self._doi_manager = DOIManager()\n",
    "\n",
    "    def is_valid(self, filename: str):\n",
    "        super().is_valid(filename)\n",
    "        return filename.endswith(\".json\")\n",
    "\n",
    "    def parse(self, filename: str):\n",
    "        super().parse(filename)\n",
    "        json_content = None\n",
    "        with open(filename, encoding=\"utf8\") as fp:\n",
    "            json_content = load(fp)\n",
    "\n",
    "        if \"data\" in json_content:\n",
    "            self._rows = json_content.get(\"data\")\n",
    "            self._items = len(self._rows)\n",
    "\n",
    "    def get_next_citation_data(self):\n",
    "        if len(self._rows) == 0:\n",
    "            return None\n",
    "\n",
    "        row = self._rows.pop()\n",
    "        self._current_item += 1\n",
    "\n",
    "        # from here: parse the row and return citation data\n",
    "\n",
    "        citing = self._doi_manager.normalise(row[\"attributes\"][\"doi\"])\n",
    "        if citing is not None and \"attributes\" in row:\n",
    "            citations = []\n",
    "\n",
    "            attr = row[\"attributes\"]\n",
    "            if \"relatedIdentifiers\" in attr:\n",
    "                relatedIdentifier = attr[\"relatedIdentifiers\"]\n",
    "                # esempio: \"relatedIdentifiers\" : [{\"relationType\":\"IsCitedBy\",\"relatedIdentifier\":\"10.1234/testpub\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"Cites\",\"relatedIdentifier\":\"http://testing.ts/testpub\",\"relatedIdentifierType\":\"URN\"}]\n",
    "                if relatedIdentifier:\n",
    "                    for related in relatedIdentifier:\n",
    "                        relatedIdentifierType = str(related[\"relatedIdentifierType\"])\n",
    "                        relatedIdentifierType = relatedIdentifierType.lower()\n",
    "                        if relatedIdentifierType:\n",
    "                            if relatedIdentifierType == \"doi\":\n",
    "                                relationType = related[\"relationType\"]\n",
    "                                if relationType:\n",
    "                                    if relationType == \"References\" or relationType == \"Cites\":\n",
    "                                        if related[\"relatedIdentifier\"]:\n",
    "                                            cited = self._doi_manager.normalise(\n",
    "                                                related[\"relatedIdentifier\"]\n",
    "                                            )\n",
    "\n",
    "                                            if cited is not None:\n",
    "                                                citations.append(\n",
    "                                                    (\n",
    "                                                        citing,\n",
    "                                                        cited,\n",
    "                                                        None,\n",
    "                                                        None,\n",
    "                                                        None,\n",
    "                                                        None,\n",
    "                                                    )\n",
    "                                                )\n",
    "                                    elif relationType == \"isReferencedBy\" or relationType == \"isCitedBy\":\n",
    "                                        print(\"gestisci i casi opposti\")\n",
    "                                        cited_inv = citing\n",
    "                                        citing_inv = self._doi_manager.normalise(\n",
    "                                                related[\"relatedIdentifier\"]\n",
    "                                            )\n",
    "                                        if citing_inv is not None:\n",
    "                                            citations.append(\n",
    "                                                (\n",
    "                                                    citing_inv,\n",
    "                                                    cited_inv,\n",
    "                                                    None,\n",
    "                                                    None,\n",
    "                                                    None,\n",
    "                                                    None,\n",
    "                                                )\n",
    "                                            )\n",
    "\n",
    "                    # tendenzialmente non ritornerà niente perché spesso \"relatedIdentifiers\" è una lista vuota\n",
    "                    # (no elementi su cui iterare)\n",
    "                    return citations\n",
    "                    # controlla che sia indentato correttamente:\n",
    "                    # nel cocdice ci crossref si allinea con for ref in row[\"reference\"],\n",
    "                    # quindi \"per ogni citato\". Così dovrebbe funzionare perché \"relatedIdentifiers\"\n",
    "                    # è una lista che contiene un dizionario per ogni id related con l'id in questione,\n",
    "                    # di cui poi, attraverso le coppie chiave-valore, specifica: il tipo di relazione (NB:\n",
    "                    # COME ESISTONO SIA \"isReferencedBy\" che \"isCitedBy\", oltre a \"References\"\n",
    "                    # esiste anche un \"Cites\": che senso ha?), l'identificativo stesso, e il tipo di identificativo.\n",
    "\n",
    "        return self.get_next_citation_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13/05 - 17/05 (NOCI parser and glob for farm_revision bug fix)\n",
    "<a id=\"entry_12\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datacite Parser : bug to fix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Tentativo con files nella stessa directory e allo stesso livello gerarchico del parser e del test, che sono inclusi nello stesso file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONTENUTO DI INPUT {\"data\": [{\"id\":\"10.1007/s13346-017-0376-5\",\"type\":\"dois\",\"attributes\":{\"doi\":\"10.1007/s13346-017-0376-5\",\"identifiers\":[{\"identifier\":\"https://doi.org/10.1007/s13346-017-0376-5\",\"identifierType\":\"DOI\"}],\"creators\":[{\"name\":\"Boustta, Mahfoud\",\"nameType\":\"Personal\",\"givenName\":\"Mahfoud\",\"familyName\":\"Boustta\",\"affiliation\":[],\"nameIdentifiers\":[]},{\"name\":\"Vert, Michel\",\"nameType\":\"Personal\",\"givenName\":\"Michel\",\"familyName\":\"Vert\",\"affiliation\":[],\"nameIdentifiers\":[]}],\"titles\":[{\"title\":\"A method to slow down the ionization-dependent release of risperidone loaded in a thermoresponsive poly(N-acryloyl glycinamide) hydrogel\"}],\"publisher\":\"Springer Science and Business Media LLC\",\"container\":{\"type\":\"Journal\",\"issue\":\"3\",\"title\":\"Drug Delivery and Translational Research\",\"volume\":\"7\",\"lastPage\":\"464\",\"firstPage\":\"460\",\"identifier\":\"2190-3948\",\"identifierType\":\"ISSN\"},\"publicationYear\":2017,\"subjects\":[],\"contributors\":[],\"dates\":[{\"date\":\"2017-04-07\",\"dateType\":\"Issued\"},{\"date\":\"2017-04-25T15:35:34Z\",\"dateType\":\"Updated\"}],\"language\":null,\"types\":{\"ris\":\"JOUR\",\"bibtex\":\"article\",\"citeproc\":\"article-journal\",\"schemaOrg\":\"ScholarlyArticle\",\"resourceType\":\"JournalArticle\",\"resourceTypeGeneral\":\"Text\"},\"relatedIdentifiers\":[{\"relationType\":\"IsPartOf\",\"relatedIdentifier\":\"2190-3948\",\"resourceTypeGeneral\":\"Collection\",\"relatedIdentifierType\":\"ISSN\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1002/pol.1964.110021203\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1002/pol.1967.160050509\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1002/pol.1970.150080509\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.jconrel.2013.10.040\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1615/critrevtherdrugcarriersyst.2016015798\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1134/s1990793116070022\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.jconrel.2010.03.024\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.schres.2007.08.003\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1007/s11095-010-0152-4\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1080/00914037.2015.1099100\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1039/c5ra03535j\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.colsurfb.2011.03.043\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1097/00007691-199808000-00004\",\"relatedIdentifierType\":\"DOI\"}],\"sizes\":[],\"formats\":[],\"version\":null,\"rightsList\":[{\"rightsUri\":\"http://www.springer.com/tdm\"}],\"descriptions\":[],\"geoLocations\":[],\"fundingReferences\":[],\"url\":\"http://link.springer.com/10.1007/s13346-017-0376-5\",\"contentUrl\":null,\"metadataVersion\":0,\"schemaVersion\":\"http://datacite.org/schema/kernel-4\",\"source\":\"levriero\",\"isActive\":true,\"state\":\"findable\",\"reason\":null,\"viewCount\":0,\"downloadCount\":0,\"referenceCount\":0,\"citationCount\":1,\"partCount\":0,\"partOfCount\":0,\"versionCount\":0,\"versionOfCount\":0,\"created\":\"2020-02-28T01:35:59.000Z\",\"registered\":\"2020-02-28T01:35:59.000Z\",\"published\":\"2017\",\"updated\":\"2020-02-28T01:36:06.000Z\"},\"relationships\":{\"client\":{\"data\":{\"id\":\"crossref.citations\",\"type\":\"clients\"}}}}, {\"id\":\"10.11577/1236752\",\"type\":\"dois\",\"attributes\":{\"doi\":\"10.11577/1236752\",\"identifiers\":[{\"identifier\":\"1236752\",\"identifierType\":\"OSTI ID\"},{\"identifier\":\"AC02-05CH11231\",\"identifierType\":\"DOE Contract Number\"},{\"identifier\":\"CXIDB ID 30\",\"identifierType\":\"Product Number\"}],\"creators\":[{\"name\":\"Ekeberg, Tomas\",\"nameType\":\"Personal\",\"givenName\":\"Tomas\",\"familyName\":\"Ekeberg\",\"affiliation\":[],\"nameIdentifiers\":[]}],\"titles\":[{\"title\":\"Three-Dimensional Reconstruction of the Giant Mimivirus Particle with an X-Ray Free-Electron Laser (CXIDB ID 30)\"}],\"publisher\":\"Coherent X-ray Imaging Data Bank (Lawrence Berkeley National Laboratory); Uppsala University, SLAC National \\nAccelerator Laboratory, Yale University, Diamond Light Source, Lawrence Berkeley National Laboratory\",\"container\":{},\"publicationYear\":2015,\"subjects\":[{\"subject\":\"Mimivirus\"},{\"subject\":\"XFEL\"},{\"subject\":\"AMO\"},{\"subject\":\"Single Particle X-ray Diffraction Imaging\"},{\"subject\":\"X-ray Free-electorn Lasers\"},{\"subject\":\"LCLS\"}],\"contributors\":[],\"dates\":[{\"date\":\"2015\",\"dateType\":\"Issued\"}],\"language\":\"en\",\"types\":{\"ris\":\"DATA\",\"bibtex\":\"misc\",\"citeproc\":\"dataset\",\"schemaOrg\":\"Dataset\",\"resourceType\":\"Still Images or Photos\",\"resourceTypeGeneral\":\"Dataset\"},\"relatedIdentifiers\":[{\"relationType\":\"IsReferencedBy\",\"relatedIdentifier\":\"10.1038/sdata.2016.60\",\"relatedIdentifierType\":\"DOI\"}],\"sizes\":[],\"formats\":[],\"version\":null,\"rightsList\":[],\"descriptions\":[{\"description\":\"This dataset contains the diffraction patterns that were used for the first three-dimensional reconstruction of a virus using FEL data. The sample was the giant mimivirus particle, which is one of the largest known viruses with a diameter of 450 nm. The dataset consists of the 198 diffraction patterns that were used in the analysis.\",\"descriptionType\":\"Abstract\"}],\"geoLocations\":[],\"fundingReferences\":[],\"url\":\"https://www.osti.gov/servlets/purl/1236752/\",\"contentUrl\":null,\"metadataVersion\":2,\"schemaVersion\":\"http://datacite.org/schema/kernel-4\",\"source\":\"mds\",\"isActive\":true,\"state\":\"findable\",\"reason\":null,\"viewCount\":0,\"downloadCount\":0,\"referenceCount\":0,\"citationCount\":1,\"partCount\":0,\"partOfCount\":0,\"versionCount\":0,\"versionOfCount\":0,\"created\":\"2016-02-05T03:28:36Z\",\"registered\":\"2016-02-05T03:28:37Z\",\"published\":null,\"updated\":\"2021-07-15T02:12:02Z\"},\"relationships\":{\"client\":{\"data\":{\"id\":\"doe.lbnl\",\"type\":\"clients\"}}}}, {\"id\":\"10.11578/1480643\",\"type\":\"dois\",\"attributes\":{\"doi\":\"10.11578/1480643\",\"identifiers\":[{\"identifier\":\"1480643\",\"identifierType\":\"OSTI ID\"},{\"identifier\":\"ostiprod\",\"identifierType\":\"DOE Contract Number\"},{\"identifier\":\"datasetpn\",\"identifierType\":\"Product Number\"}],\"creators\":[{\"name\":\"Last, First\",\"nameType\":\"Personal\",\"givenName\":\"First\",\"familyName\":\"Last\",\"affiliation\":[],\"nameIdentifiers\":[]}],\"titles\":[{\"title\":\"Dataset Title - Award\"}],\"publisher\":\"Desert Research Institute (DRI), Nevada System of Higher Education, Reno,NV (United States)\",\"container\":{},\"publicationYear\":2018,\"subjects\":[],\"contributors\":[],\"dates\":[{\"date\":\"2018\",\"dateType\":\"Issued\"}],\"language\":\"en\",\"types\":{\"ris\":\"GEN\",\"bibtex\":\"misc\",\"citeproc\":\"article\",\"schemaOrg\":\"CreativeWork\",\"resourceType\":\"Award\",\"resourceTypeGeneral\":\"Other\"},\"relatedIdentifiers\":[{\"relationType\":\"Cites\",\"relatedIdentifier\":\"10.15407/scin11.06.057\",\"relatedIdentifierType\":\"DOI\"}],\"sizes\":[],\"formats\":[],\"version\":null,\"rightsList\":[],\"descriptions\":[{\"description\":\"description/abstract\",\"descriptionType\":\"Abstract\"}],\"geoLocations\":[{\"geoLocationPlace\":\"geolocation\",\"geoLocationPoint\":{\"pointLatitude\":\"1.1111\",\"pointLongitude\":\"2.2222\"}}],\"fundingReferences\":[],\"url\":\"https://www.osti.gov/servlets/purl/1480643/\",\"contentUrl\":null,\"metadataVersion\":0,\"schemaVersion\":null,\"source\":\"mds\",\"isActive\":true,\"state\":\"findable\",\"reason\":null,\"viewCount\":0,\"downloadCount\":0,\"referenceCount\":0,\"citationCount\":0,\"partCount\":0,\"partOfCount\":0,\"versionCount\":0,\"versionOfCount\":0,\"created\":\"2018-11-03T14:38:53.000Z\",\"registered\":\"2018-11-03T14:38:55.000Z\",\"published\":\"2018\",\"updated\":\"2020-09-20T08:19:49.000Z\"},\"relationships\":{\"client\":{\"data\":{\"id\":\"doe.osti\",\"type\":\"clients\"}}}}, {\"id\":\"10.11570/13.0001\",\"type\":\"dois\",\"attributes\":{\"doi\":\"10.11570/13.0001\",\"identifiers\":[],\"creators\":[{\"name\":\"Wilson, C. D.\",\"nameType\":\"Personal\",\"givenName\":\"C. D.\",\"familyName\":\"Wilson\",\"affiliation\":[],\"nameIdentifiers\":[]}],\"titles\":[{\"lang\":\"en-US\",\"title\":\"Nearby Galaxies Legacy Survey\"},{\"lang\":\"en-US\",\"title\":\"NGLS\",\"titleType\":\"AlternativeTitle\"}],\"publisher\":\"CADC\",\"container\":{},\"publicationYear\":2013,\"subjects\":[],\"contributors\":[{\"name\":\"CADC\",\"affiliation\":[],\"contributorType\":\"DataManager\",\"nameIdentifiers\":[]},{\"name\":\"Schade, David\",\"nameType\":\"Personal\",\"givenName\":\"David\",\"familyName\":\"Schade\",\"affiliation\":[],\"contributorType\":\"ContactPerson\",\"nameIdentifiers\":[{\"schemeUri\":\"https://orcid.org\",\"nameIdentifier\":\"https://orcid.org/0000-0002-4677-1586\",\"nameIdentifierScheme\":\"ORCID\"}]}],\"dates\":[{\"date\":\"2013\",\"dateType\":\"Issued\"}],\"language\":\"en\",\"types\":{\"ris\":\"DATA\",\"bibtex\":\"misc\",\"citeproc\":\"dataset\",\"schemaOrg\":\"Dataset\",\"resourceTypeGeneral\":\"Dataset\"},\"relatedIdentifiers\":[{\"relationType\":\"IsCitedBy\",\"relatedIdentifier\":\"10.1093/mnras/stv2808\",\"relatedIdentifierType\":\"DOI\"}],\"sizes\":[],\"formats\":[],\"version\":null,\"rightsList\":[],\"descriptions\":[{\"lang\":\"en-US\",\"description\":\"This contains data, plots, and information of observations of galaxies in the JCMT Nearby Galaxies Legaxy Survey.\",\"descriptionType\":\"Other\"}],\"geoLocations\":[],\"fundingReferences\":[],\"url\":\"http://www.canfar.net/citation/landing?doi=13.0001\",\"contentUrl\":[],\"metadataVersion\":2,\"schemaVersion\":\"http://datacite.org/schema/kernel-4\",\"source\":\"mds\",\"isActive\":true,\"state\":\"findable\",\"reason\":null,\"viewCount\":0,\"downloadCount\":0,\"referenceCount\":0,\"citationCount\":1,\"partCount\":0,\"partOfCount\":0,\"versionCount\":0,\"versionOfCount\":0,\"created\":\"2013-04-19T21:33:33.000Z\",\"registered\":\"2013-04-19T21:33:33.000Z\",\"published\":\"2013\",\"updated\":\"2020-11-05T10:14:30.000Z\"},\"relationships\":{\"client\":{\"data\":{\"id\":\"nrc.cadc\",\"type\":\"clients\"}}}}]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Launching unittests with arguments python -m unittest test_dataciteparser.DOCITest in C:\\Users\\arimoretti\\Documents\\GitHub\\index\\index\\python\\src\\parsing\n",
    "\n",
    "CIT: [('10.1093/mnras/stv2808', '10.11570/13.0001', None, None, None, None)]\n",
    "citation_data in cit: ('10.1093/mnras/stv2808', '10.11570/13.0001', None, None, None, None)\n",
    "CIT: [('10.11578/1480643', '10.15407/scin11.06.057', None, None, None, None)]\n",
    "citation_data in cit: ('10.11578/1480643', '10.15407/scin11.06.057', None, None, None, None)\n",
    "CIT: [('10.1038/sdata.2016.60', '10.11577/1236752', None, None, None, None)]\n",
    "citation_data in cit: ('10.1038/sdata.2016.60', '10.11577/1236752', None, None, None, None)\n",
    "CIT: [('10.1007/s13346-017-0376-5', '10.1002/pol.1964.110021203', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1002/pol.1967.160050509', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1002/pol.1970.150080509', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1016/j.jconrel.2013.10.040', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1615/critrevtherdrugcarriersyst.2016015798', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1134/s1990793116070022', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1016/j.jconrel.2010.03.024', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1016/j.schres.2007.08.003', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1007/s11095-010-0152-4', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1080/00914037.2015.1099100', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1039/c5ra03535j', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1016/j.colsurfb.2011.03.043', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1097/00007691-199808000-00004', None, None, None, None)]\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1002/pol.1964.110021203', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1002/pol.1967.160050509', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1002/pol.1970.150080509', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1016/j.jconrel.2013.10.040', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1615/critrevtherdrugcarriersyst.2016015798', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1134/s1990793116070022', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1016/j.jconrel.2010.03.024', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1016/j.schres.2007.08.003', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1007/s11095-010-0152-4', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1080/00914037.2015.1099100', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1039/c5ra03535j', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1016/j.colsurfb.2011.03.043', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1097/00007691-199808000-00004', None, None, None, None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "<li>lanciato dal file stesso, che attualmente include sia il parser che il test</li>\n",
    "<li>i files si trovano allo stesso livello rispetto allo script</li>\n",
    "<li>funziona correttamente </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Tentativo standard (per corretto inserimento nella versione farm_revision di index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONTENUTO DI INPUT {\"data\": [{\"id\":\"10.1007/s13346-017-0376-5\",\"type\":\"dois\",\"attributes\":{\"doi\":\"10.1007/s13346-017-0376-5\",\"identifiers\":[{\"identifier\":\"https://doi.org/10.1007/s13346-017-0376-5\",\"identifierType\":\"DOI\"}],\"creators\":[{\"name\":\"Boustta, Mahfoud\",\"nameType\":\"Personal\",\"givenName\":\"Mahfoud\",\"familyName\":\"Boustta\",\"affiliation\":[],\"nameIdentifiers\":[]},{\"name\":\"Vert, Michel\",\"nameType\":\"Personal\",\"givenName\":\"Michel\",\"familyName\":\"Vert\",\"affiliation\":[],\"nameIdentifiers\":[]}],\"titles\":[{\"title\":\"A method to slow down the ionization-dependent release of risperidone loaded in a thermoresponsive poly(N-acryloyl glycinamide) hydrogel\"}],\"publisher\":\"Springer Science and Business Media LLC\",\"container\":{\"type\":\"Journal\",\"issue\":\"3\",\"title\":\"Drug Delivery and Translational Research\",\"volume\":\"7\",\"lastPage\":\"464\",\"firstPage\":\"460\",\"identifier\":\"2190-3948\",\"identifierType\":\"ISSN\"},\"publicationYear\":2017,\"subjects\":[],\"contributors\":[],\"dates\":[{\"date\":\"2017-04-07\",\"dateType\":\"Issued\"},{\"date\":\"2017-04-25T15:35:34Z\",\"dateType\":\"Updated\"}],\"language\":null,\"types\":{\"ris\":\"JOUR\",\"bibtex\":\"article\",\"citeproc\":\"article-journal\",\"schemaOrg\":\"ScholarlyArticle\",\"resourceType\":\"JournalArticle\",\"resourceTypeGeneral\":\"Text\"},\"relatedIdentifiers\":[{\"relationType\":\"IsPartOf\",\"relatedIdentifier\":\"2190-3948\",\"resourceTypeGeneral\":\"Collection\",\"relatedIdentifierType\":\"ISSN\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1002/pol.1964.110021203\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1002/pol.1967.160050509\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1002/pol.1970.150080509\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.jconrel.2013.10.040\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1615/critrevtherdrugcarriersyst.2016015798\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1134/s1990793116070022\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.jconrel.2010.03.024\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.schres.2007.08.003\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1007/s11095-010-0152-4\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1080/00914037.2015.1099100\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1039/c5ra03535j\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.colsurfb.2011.03.043\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1097/00007691-199808000-00004\",\"relatedIdentifierType\":\"DOI\"}],\"sizes\":[],\"formats\":[],\"version\":null,\"rightsList\":[{\"rightsUri\":\"http://www.springer.com/tdm\"}],\"descriptions\":[],\"geoLocations\":[],\"fundingReferences\":[],\"url\":\"http://link.springer.com/10.1007/s13346-017-0376-5\",\"contentUrl\":null,\"metadataVersion\":0,\"schemaVersion\":\"http://datacite.org/schema/kernel-4\",\"source\":\"levriero\",\"isActive\":true,\"state\":\"findable\",\"reason\":null,\"viewCount\":0,\"downloadCount\":0,\"referenceCount\":0,\"citationCount\":1,\"partCount\":0,\"partOfCount\":0,\"versionCount\":0,\"versionOfCount\":0,\"created\":\"2020-02-28T01:35:59.000Z\",\"registered\":\"2020-02-28T01:35:59.000Z\",\"published\":\"2017\",\"updated\":\"2020-02-28T01:36:06.000Z\"},\"relationships\":{\"client\":{\"data\":{\"id\":\"crossref.citations\",\"type\":\"clients\"}}}}, {\"id\":\"10.11577/1236752\",\"type\":\"dois\",\"attributes\":{\"doi\":\"10.11577/1236752\",\"identifiers\":[{\"identifier\":\"1236752\",\"identifierType\":\"OSTI ID\"},{\"identifier\":\"AC02-05CH11231\",\"identifierType\":\"DOE Contract Number\"},{\"identifier\":\"CXIDB ID 30\",\"identifierType\":\"Product Number\"}],\"creators\":[{\"name\":\"Ekeberg, Tomas\",\"nameType\":\"Personal\",\"givenName\":\"Tomas\",\"familyName\":\"Ekeberg\",\"affiliation\":[],\"nameIdentifiers\":[]}],\"titles\":[{\"title\":\"Three-Dimensional Reconstruction of the Giant Mimivirus Particle with an X-Ray Free-Electron Laser (CXIDB ID 30)\"}],\"publisher\":\"Coherent X-ray Imaging Data Bank (Lawrence Berkeley National Laboratory); Uppsala University, SLAC National \\nAccelerator Laboratory, Yale University, Diamond Light Source, Lawrence Berkeley National Laboratory\",\"container\":{},\"publicationYear\":2015,\"subjects\":[{\"subject\":\"Mimivirus\"},{\"subject\":\"XFEL\"},{\"subject\":\"AMO\"},{\"subject\":\"Single Particle X-ray Diffraction Imaging\"},{\"subject\":\"X-ray Free-electorn Lasers\"},{\"subject\":\"LCLS\"}],\"contributors\":[],\"dates\":[{\"date\":\"2015\",\"dateType\":\"Issued\"}],\"language\":\"en\",\"types\":{\"ris\":\"DATA\",\"bibtex\":\"misc\",\"citeproc\":\"dataset\",\"schemaOrg\":\"Dataset\",\"resourceType\":\"Still Images or Photos\",\"resourceTypeGeneral\":\"Dataset\"},\"relatedIdentifiers\":[{\"relationType\":\"IsReferencedBy\",\"relatedIdentifier\":\"10.1038/sdata.2016.60\",\"relatedIdentifierType\":\"DOI\"}],\"sizes\":[],\"formats\":[],\"version\":null,\"rightsList\":[],\"descriptions\":[{\"description\":\"This dataset contains the diffraction patterns that were used for the first three-dimensional reconstruction of a virus using FEL data. The sample was the giant mimivirus particle, which is one of the largest known viruses with a diameter of 450 nm. The dataset consists of the 198 diffraction patterns that were used in the analysis.\",\"descriptionType\":\"Abstract\"}],\"geoLocations\":[],\"fundingReferences\":[],\"url\":\"https://www.osti.gov/servlets/purl/1236752/\",\"contentUrl\":null,\"metadataVersion\":2,\"schemaVersion\":\"http://datacite.org/schema/kernel-4\",\"source\":\"mds\",\"isActive\":true,\"state\":\"findable\",\"reason\":null,\"viewCount\":0,\"downloadCount\":0,\"referenceCount\":0,\"citationCount\":1,\"partCount\":0,\"partOfCount\":0,\"versionCount\":0,\"versionOfCount\":0,\"created\":\"2016-02-05T03:28:36Z\",\"registered\":\"2016-02-05T03:28:37Z\",\"published\":null,\"updated\":\"2021-07-15T02:12:02Z\"},\"relationships\":{\"client\":{\"data\":{\"id\":\"doe.lbnl\",\"type\":\"clients\"}}}}, {\"id\":\"10.11578/1480643\",\"type\":\"dois\",\"attributes\":{\"doi\":\"10.11578/1480643\",\"identifiers\":[{\"identifier\":\"1480643\",\"identifierType\":\"OSTI ID\"},{\"identifier\":\"ostiprod\",\"identifierType\":\"DOE Contract Number\"},{\"identifier\":\"datasetpn\",\"identifierType\":\"Product Number\"}],\"creators\":[{\"name\":\"Last, First\",\"nameType\":\"Personal\",\"givenName\":\"First\",\"familyName\":\"Last\",\"affiliation\":[],\"nameIdentifiers\":[]}],\"titles\":[{\"title\":\"Dataset Title - Award\"}],\"publisher\":\"Desert Research Institute (DRI), Nevada System of Higher Education, Reno,NV (United States)\",\"container\":{},\"publicationYear\":2018,\"subjects\":[],\"contributors\":[],\"dates\":[{\"date\":\"2018\",\"dateType\":\"Issued\"}],\"language\":\"en\",\"types\":{\"ris\":\"GEN\",\"bibtex\":\"misc\",\"citeproc\":\"article\",\"schemaOrg\":\"CreativeWork\",\"resourceType\":\"Award\",\"resourceTypeGeneral\":\"Other\"},\"relatedIdentifiers\":[{\"relationType\":\"Cites\",\"relatedIdentifier\":\"10.15407/scin11.06.057\",\"relatedIdentifierType\":\"DOI\"}],\"sizes\":[],\"formats\":[],\"version\":null,\"rightsList\":[],\"descriptions\":[{\"description\":\"description/abstract\",\"descriptionType\":\"Abstract\"}],\"geoLocations\":[{\"geoLocationPlace\":\"geolocation\",\"geoLocationPoint\":{\"pointLatitude\":\"1.1111\",\"pointLongitude\":\"2.2222\"}}],\"fundingReferences\":[],\"url\":\"https://www.osti.gov/servlets/purl/1480643/\",\"contentUrl\":null,\"metadataVersion\":0,\"schemaVersion\":null,\"source\":\"mds\",\"isActive\":true,\"state\":\"findable\",\"reason\":null,\"viewCount\":0,\"downloadCount\":0,\"referenceCount\":0,\"citationCount\":0,\"partCount\":0,\"partOfCount\":0,\"versionCount\":0,\"versionOfCount\":0,\"created\":\"2018-11-03T14:38:53.000Z\",\"registered\":\"2018-11-03T14:38:55.000Z\",\"published\":\"2018\",\"updated\":\"2020-09-20T08:19:49.000Z\"},\"relationships\":{\"client\":{\"data\":{\"id\":\"doe.osti\",\"type\":\"clients\"}}}}, {\"id\":\"10.11570/13.0001\",\"type\":\"dois\",\"attributes\":{\"doi\":\"10.11570/13.0001\",\"identifiers\":[],\"creators\":[{\"name\":\"Wilson, C. D.\",\"nameType\":\"Personal\",\"givenName\":\"C. D.\",\"familyName\":\"Wilson\",\"affiliation\":[],\"nameIdentifiers\":[]}],\"titles\":[{\"lang\":\"en-US\",\"title\":\"Nearby Galaxies Legacy Survey\"},{\"lang\":\"en-US\",\"title\":\"NGLS\",\"titleType\":\"AlternativeTitle\"}],\"publisher\":\"CADC\",\"container\":{},\"publicationYear\":2013,\"subjects\":[],\"contributors\":[{\"name\":\"CADC\",\"affiliation\":[],\"contributorType\":\"DataManager\",\"nameIdentifiers\":[]},{\"name\":\"Schade, David\",\"nameType\":\"Personal\",\"givenName\":\"David\",\"familyName\":\"Schade\",\"affiliation\":[],\"contributorType\":\"ContactPerson\",\"nameIdentifiers\":[{\"schemeUri\":\"https://orcid.org\",\"nameIdentifier\":\"https://orcid.org/0000-0002-4677-1586\",\"nameIdentifierScheme\":\"ORCID\"}]}],\"dates\":[{\"date\":\"2013\",\"dateType\":\"Issued\"}],\"language\":\"en\",\"types\":{\"ris\":\"DATA\",\"bibtex\":\"misc\",\"citeproc\":\"dataset\",\"schemaOrg\":\"Dataset\",\"resourceTypeGeneral\":\"Dataset\"},\"relatedIdentifiers\":[{\"relationType\":\"IsCitedBy\",\"relatedIdentifier\":\"10.1093/mnras/stv2808\",\"relatedIdentifierType\":\"DOI\"}],\"sizes\":[],\"formats\":[],\"version\":null,\"rightsList\":[],\"descriptions\":[{\"lang\":\"en-US\",\"description\":\"This contains data, plots, and information of observations of galaxies in the JCMT Nearby Galaxies Legaxy Survey.\",\"descriptionType\":\"Other\"}],\"geoLocations\":[],\"fundingReferences\":[],\"url\":\"http://www.canfar.net/citation/landing?doi=13.0001\",\"contentUrl\":[],\"metadataVersion\":2,\"schemaVersion\":\"http://datacite.org/schema/kernel-4\",\"source\":\"mds\",\"isActive\":true,\"state\":\"findable\",\"reason\":null,\"viewCount\":0,\"downloadCount\":0,\"referenceCount\":0,\"citationCount\":1,\"partCount\":0,\"partOfCount\":0,\"versionCount\":0,\"versionOfCount\":0,\"created\":\"2013-04-19T21:33:33.000Z\",\"registered\":\"2013-04-19T21:33:33.000Z\",\"published\":\"2013\",\"updated\":\"2020-11-05T10:14:30.000Z\"},\"relationships\":{\"client\":{\"data\":{\"id\":\"nrc.cadc\",\"type\":\"clients\"}}}}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(base) C:\\Users\\arimoretti\\Documents\\GitHub\\index>python -m unittest discover -s ./index/python/test -p \"test_doci.py\"\n",
    "CIT: []\n",
    "CIT: []\n",
    "CIT: []\n",
    "CIT: [('10.1007/s13346-017-0376-5', '10.1002/pol.1964.110021203', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1002/pol.1967.160050509', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1002/pol.1970.150080509', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1016/j.jconrel.2013.10.040', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1615/critrevtherdrugcarriersyst.2016015798', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1134/s1990793116070022', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1016/j.jconrel.2010.03.024', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1016/j.schres.2007.08.003', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1007/s11095-010-0152-4', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1080/00914037.2015.1099100', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1039/c5ra03535j', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1016/j.colsurfb.2011.03.043', None, None, None, None), ('10.1007/s13346-017-0376-5', '10.1097/00007691-199808000-00004', None, None, None, None)]\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1002/pol.1964.110021203', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1002/pol.1967.160050509', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1002/pol.1970.150080509', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1016/j.jconrel.2013.10.040', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1615/critrevtherdrugcarriersyst.2016015798', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1134/s1990793116070022', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1016/j.jconrel.2010.03.024', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1016/j.schres.2007.08.003', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1007/s11095-010-0152-4', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1080/00914037.2015.1099100', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1039/c5ra03535j', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1016/j.colsurfb.2011.03.043', None, None, None, None)\n",
    "citation_data in cit: ('10.1007/s13346-017-0376-5', '10.1097/00007691-199808000-00004', None, None, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "<li>i files si trovano dove previsto (test/data)  e il test viene lanciato da bash seguendo i comandi del read.me</li>\n",
    "<li>ignora tutte le citazioni tranne quelle del campo references </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataCite glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ho testato i risultato delle due versioni: \n",
    "<ol>\n",
    "    <li>id_orcid: The two files are identical</li>\n",
    "    <li>id_issn : -3 removals (su 297 dati) \t\"doi:10.1007/978-3-319-41321-1_11\",\"1611-3349\", \"doi:10.1007/978-3-642-42051-1_31\",\"1611-3349\", \"doi:10.1007/bfb0054868\",\"1611-3349\" non compaiono nella versione generata con ijson</li>\n",
    "    <li>valid_doi: The two files are identical</li>\n",
    "    <li>id_date : The ijson version does not save the date info of the field publicationYear</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizzazioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "caricamento sul sito con Ivan dopo il 22 Maggio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TO DO:\n",
    "- overleaf \n",
    "- powershell di windows è deprecata (utilizza powershell)\n",
    "- controlla tutti i path \n",
    "- eventualmente riprova da mac\n",
    "- leggi articolo ivan e giuseppe, aggiungere fonti o spunti se necessario\n",
    "- sistema issn (prova a rilanciare)\n",
    "- sistema publication year per ijson\n",
    "- ricorda che unittest esegue in ordine arbitrario i test (il test è indipendente?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17/05 - 26/05 (Doci, Noci, PMID, Visualizzazioni)\n",
    "<a id=\"entry_13\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizzazioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Ho documentato il codice e aggiornato il readme</li>\n",
    "    <li>Ho aggiunto una gif per coprire il caricamento della pagina</li>\n",
    "    <li>Con Ivan abbiamo ricontrollato il codice e fatto una correzione in modo tale che la gif sparisse non dopo un numero prestabilito di secondi, ma al completamento del caricamento della pagina. Abbiamo adattato i files alla struttura del sito di opecitations e pubblicato la pagina delle visualizzazioni nella versione di test del sito.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toward a Model for the Definition of a Containerized and Distributed Open Science Infrastructure\n",
    "Letto e commentato l'articolo (versione precedente a venerdì)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataCite Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ho provato ad aggiungere un'altra entità al dump per testare il parser (nella versione precedente c'erano quattro elemenenti, uno per ognuna delle quattro casistiche: cites, iscitedby, references, isreferencedby).\n",
    "<br>\n",
    "<b>Note:</b>Aggiungendo un altra entità che presenta le citazioni con relationtyoe: \"references\", il parser riesce a leggerla correttamente.<br> \n",
    "<b>Soluzione:</b> Il problema era dovuto al fatto che avendo installato index come libreria le modifiche locali al parser non venivano testate perché la versione di riferimento rimaneva quella installata. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PARSER TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "import unittest\n",
    "from os import makedirs\n",
    "from os.path import join, exists\n",
    "from os.path import join\n",
    "from csv import DictReader\n",
    "from oc.index.parsing.datacite import DataciteParser\n",
    "import json\n",
    "\n",
    "class DOCITest(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        if not exists(\"tmp\"):\n",
    "            makedirs(\"tmp\")\n",
    "        test_dir = join(\"index\", \"python\", \"test\", \"data\")\n",
    "        self.input = join(test_dir, \"doci_dump.json\")\n",
    "        self.citations = join(test_dir, \"doci_citations.csv\")\n",
    "\n",
    "\n",
    "    def test_citation_source(self):\n",
    "        parser = DataciteParser()\n",
    "        parser.parse(self.input)\n",
    "        new = []\n",
    "        cit = parser.get_next_citation_data()\n",
    "\n",
    "        while cit is not None:\n",
    "            for citation_data in cit:\n",
    "                citing, cited, creation, timespan, journal_sc, author_sc = citation_data\n",
    "                new.append(\n",
    "                    {\n",
    "                        \"citing\": citing,\n",
    "                        \"cited\": cited,\n",
    "                        \"creation\": \"\" if creation is None else creation,\n",
    "                        \"timespan\": \"\" if timespan is None else timespan,\n",
    "                        \"journal_sc\": \"\" if journal_sc is None else journal_sc,\n",
    "                        \"author_sc\": \"\" if author_sc is None else author_sc,\n",
    "                    }\n",
    "                )\n",
    "            cit = parser.get_next_citation_data()\n",
    "\n",
    "        with open(self.citations, encoding=\"utf-8\") as f:\n",
    "            csv_to_dict = list(DictReader(f))\n",
    "            old = json.loads(json.dumps(csv_to_dict))\n",
    "\n",
    "        self.assertTrue([x for x in new if x not in old] == [])\n",
    "        self.assertCountEqual(new, old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PARSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "from json import load\n",
    "from oc.index.identifier.doi import DOIManager\n",
    "from oc.index.parsing.base import CitationParser\n",
    "\n",
    "\n",
    "class DataciteParser(CitationParser):\n",
    "    def __init__(self):\n",
    "        self._rows = []\n",
    "        self._doi_manager = DOIManager()\n",
    "\n",
    "    def is_valid(self, filename: str):\n",
    "        super().is_valid(filename)\n",
    "        return filename.endswith(\".json\")\n",
    "\n",
    "    def parse(self, filename: str):\n",
    "        super().parse(filename)\n",
    "        json_content = None\n",
    "        with open(filename, mode=\"r\", encoding=\"utf-8\") as fp:\n",
    "            json_content = load(fp)\n",
    "\n",
    "        if \"data\" in json_content:\n",
    "            self._rows = json_content[\"data\"]\n",
    "            self._items = len(self._rows)\n",
    "\n",
    "    def get_next_citation_data(self):\n",
    "        needed_info = [\"relationType\", \"relatedIdentifierType\", \"relatedIdentifier\"]\n",
    "        if len(self._rows) == 0:\n",
    "            return None\n",
    "        row = self._rows.pop()\n",
    "        self._current_item += 1\n",
    "        attr = row.get(\"attributes\")\n",
    "        citing = self._doi_manager.normalise(attr.get(\"doi\"))\n",
    "        if citing is not None and \"relatedIdentifiers\" in attr:\n",
    "            citations = []\n",
    "            for ref in attr[\"relatedIdentifiers\"]:\n",
    "                if [x for x in needed_info if x in ref]:\n",
    "                    relatedIdentifierType = (str(ref[\"relatedIdentifierType\"])).lower()\n",
    "                    rel_id = self._doi_manager.normalise(ref[\"relatedIdentifier\"])\n",
    "                    relationType = str(ref[\"relationType\"]).lower()\n",
    "                    if relatedIdentifierType == \"doi\":\n",
    "                        if relationType == \"references\" or relationType == \"cites\":\n",
    "                            if rel_id is not None:\n",
    "                                cited = rel_id\n",
    "                                citations.append((citing, cited, None, None, None, None))\n",
    "                        elif relationType == \"isreferencedby\" or relationType == \"iscitedby\":\n",
    "                            if rel_id is not None:\n",
    "                                cited = citing\n",
    "                                citations.append((rel_id, cited, None, None, None, None))\n",
    "\n",
    "            return citations\n",
    "        return self.get_next_citation_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DUMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\"data\": [{\"id\":\"10.1007/s13346-017-0376-5\",\"type\":\"dois\",\"attributes\":{\"doi\":\"10.1007/s13346-017-0376-5\",\"identifiers\":[{\"identifier\":\"https://doi.org/10.1007/s13346-017-0376-5\",\"identifierType\":\"DOI\"}],\"creators\":[{\"name\":\"Boustta, Mahfoud\",\"nameType\":\"Personal\",\"givenName\":\"Mahfoud\",\"familyName\":\"Boustta\",\"affiliation\":[],\"nameIdentifiers\":[]},{\"name\":\"Vert, Michel\",\"nameType\":\"Personal\",\"givenName\":\"Michel\",\"familyName\":\"Vert\",\"affiliation\":[],\"nameIdentifiers\":[]}],\"titles\":[{\"title\":\"A method to slow down the ionization-dependent release of risperidone loaded in a thermoresponsive poly(N-acryloyl glycinamide) hydrogel\"}],\"publisher\":\"Springer Science and Business Media LLC\",\"container\":{\"type\":\"Journal\",\"issue\":\"3\",\"title\":\"Drug Delivery and Translational Research\",\"volume\":\"7\",\"lastPage\":\"464\",\"firstPage\":\"460\",\"identifier\":\"2190-3948\",\"identifierType\":\"ISSN\"},\"publicationYear\":2017,\"subjects\":[],\"contributors\":[],\"dates\":[{\"date\":\"2017-04-07\",\"dateType\":\"Issued\"},{\"date\":\"2017-04-25T15:35:34Z\",\"dateType\":\"Updated\"}],\"language\":null,\"types\":{\"ris\":\"JOUR\",\"bibtex\":\"article\",\"citeproc\":\"article-journal\",\"schemaOrg\":\"ScholarlyArticle\",\"resourceType\":\"JournalArticle\",\"resourceTypeGeneral\":\"Text\"},\"relatedIdentifiers\":[{\"relationType\":\"IsPartOf\",\"relatedIdentifier\":\"2190-3948\",\"resourceTypeGeneral\":\"Collection\",\"relatedIdentifierType\":\"ISSN\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1002/pol.1964.110021203\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1002/pol.1967.160050509\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1002/pol.1970.150080509\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.jconrel.2013.10.040\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1615/critrevtherdrugcarriersyst.2016015798\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1134/s1990793116070022\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.jconrel.2010.03.024\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.schres.2007.08.003\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1007/s11095-010-0152-4\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1080/00914037.2015.1099100\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1039/c5ra03535j\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.colsurfb.2011.03.043\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1097/00007691-199808000-00004\",\"relatedIdentifierType\":\"DOI\"}],\"sizes\":[],\"formats\":[],\"version\":null,\"rightsList\":[{\"rightsUri\":\"http://www.springer.com/tdm\"}],\"descriptions\":[],\"geoLocations\":[],\"fundingReferences\":[],\"url\":\"http://link.springer.com/10.1007/s13346-017-0376-5\",\"contentUrl\":null,\"metadataVersion\":0,\"schemaVersion\":\"http://datacite.org/schema/kernel-4\",\"source\":\"levriero\",\"isActive\":true,\"state\":\"findable\",\"reason\":null,\"viewCount\":0,\"downloadCount\":0,\"referenceCount\":0,\"citationCount\":1,\"partCount\":0,\"partOfCount\":0,\"versionCount\":0,\"versionOfCount\":0,\"created\":\"2020-02-28T01:35:59.000Z\",\"registered\":\"2020-02-28T01:35:59.000Z\",\"published\":\"2017\",\"updated\":\"2020-02-28T01:36:06.000Z\"},\"relationships\":{\"client\":{\"data\":{\"id\":\"crossref.citations\",\"type\":\"clients\"}}}}, {\"id\":\"10.11577/1236752\",\"type\":\"dois\",\"attributes\":{\"doi\":\"10.11577/1236752\",\"identifiers\":[{\"identifier\":\"1236752\",\"identifierType\":\"OSTI ID\"},{\"identifier\":\"AC02-05CH11231\",\"identifierType\":\"DOE Contract Number\"},{\"identifier\":\"CXIDB ID 30\",\"identifierType\":\"Product Number\"}],\"creators\":[{\"name\":\"Ekeberg, Tomas\",\"nameType\":\"Personal\",\"givenName\":\"Tomas\",\"familyName\":\"Ekeberg\",\"affiliation\":[],\"nameIdentifiers\":[]}],\"titles\":[{\"title\":\"Three-Dimensional Reconstruction of the Giant Mimivirus Particle with an X-Ray Free-Electron Laser (CXIDB ID 30)\"}],\"publisher\":\"Coherent X-ray Imaging Data Bank (Lawrence Berkeley National Laboratory); Uppsala University, SLAC National \\nAccelerator Laboratory, Yale University, Diamond Light Source, Lawrence Berkeley National Laboratory\",\"container\":{},\"publicationYear\":2015,\"subjects\":[{\"subject\":\"Mimivirus\"},{\"subject\":\"XFEL\"},{\"subject\":\"AMO\"},{\"subject\":\"Single Particle X-ray Diffraction Imaging\"},{\"subject\":\"X-ray Free-electorn Lasers\"},{\"subject\":\"LCLS\"}],\"contributors\":[],\"dates\":[{\"date\":\"2015\",\"dateType\":\"Issued\"}],\"language\":\"en\",\"types\":{\"ris\":\"DATA\",\"bibtex\":\"misc\",\"citeproc\":\"dataset\",\"schemaOrg\":\"Dataset\",\"resourceType\":\"Still Images or Photos\",\"resourceTypeGeneral\":\"Dataset\"},\"relatedIdentifiers\":[{\"relationType\":\"IsReferencedBy\",\"relatedIdentifier\":\"10.1038/sdata.2016.60\",\"relatedIdentifierType\":\"DOI\"}],\"sizes\":[],\"formats\":[],\"version\":null,\"rightsList\":[],\"descriptions\":[{\"description\":\"This dataset contains the diffraction patterns that were used for the first three-dimensional reconstruction of a virus using FEL data. The sample was the giant mimivirus particle, which is one of the largest known viruses with a diameter of 450 nm. The dataset consists of the 198 diffraction patterns that were used in the analysis.\",\"descriptionType\":\"Abstract\"}],\"geoLocations\":[],\"fundingReferences\":[],\"url\":\"https://www.osti.gov/servlets/purl/1236752/\",\"contentUrl\":null,\"metadataVersion\":2,\"schemaVersion\":\"http://datacite.org/schema/kernel-4\",\"source\":\"mds\",\"isActive\":true,\"state\":\"findable\",\"reason\":null,\"viewCount\":0,\"downloadCount\":0,\"referenceCount\":0,\"citationCount\":1,\"partCount\":0,\"partOfCount\":0,\"versionCount\":0,\"versionOfCount\":0,\"created\":\"2016-02-05T03:28:36Z\",\"registered\":\"2016-02-05T03:28:37Z\",\"published\":null,\"updated\":\"2021-07-15T02:12:02Z\"},\"relationships\":{\"client\":{\"data\":{\"id\":\"doe.lbnl\",\"type\":\"clients\"}}}}, {\"id\":\"10.11578/1480643\",\"type\":\"dois\",\"attributes\":{\"doi\":\"10.11578/1480643\",\"identifiers\":[{\"identifier\":\"1480643\",\"identifierType\":\"OSTI ID\"},{\"identifier\":\"ostiprod\",\"identifierType\":\"DOE Contract Number\"},{\"identifier\":\"datasetpn\",\"identifierType\":\"Product Number\"}],\"creators\":[{\"name\":\"Last, First\",\"nameType\":\"Personal\",\"givenName\":\"First\",\"familyName\":\"Last\",\"affiliation\":[],\"nameIdentifiers\":[]}],\"titles\":[{\"title\":\"Dataset Title - Award\"}],\"publisher\":\"Desert Research Institute (DRI), Nevada System of Higher Education, Reno,NV (United States)\",\"container\":{},\"publicationYear\":2018,\"subjects\":[],\"contributors\":[],\"dates\":[{\"date\":\"2018\",\"dateType\":\"Issued\"}],\"language\":\"en\",\"types\":{\"ris\":\"GEN\",\"bibtex\":\"misc\",\"citeproc\":\"article\",\"schemaOrg\":\"CreativeWork\",\"resourceType\":\"Award\",\"resourceTypeGeneral\":\"Other\"},\"relatedIdentifiers\":[{\"relationType\":\"Cites\",\"relatedIdentifier\":\"10.15407/scin11.06.057\",\"relatedIdentifierType\":\"DOI\"}],\"sizes\":[],\"formats\":[],\"version\":null,\"rightsList\":[],\"descriptions\":[{\"description\":\"description/abstract\",\"descriptionType\":\"Abstract\"}],\"geoLocations\":[{\"geoLocationPlace\":\"geolocation\",\"geoLocationPoint\":{\"pointLatitude\":\"1.1111\",\"pointLongitude\":\"2.2222\"}}],\"fundingReferences\":[],\"url\":\"https://www.osti.gov/servlets/purl/1480643/\",\"contentUrl\":null,\"metadataVersion\":0,\"schemaVersion\":null,\"source\":\"mds\",\"isActive\":true,\"state\":\"findable\",\"reason\":null,\"viewCount\":0,\"downloadCount\":0,\"referenceCount\":0,\"citationCount\":0,\"partCount\":0,\"partOfCount\":0,\"versionCount\":0,\"versionOfCount\":0,\"created\":\"2018-11-03T14:38:53.000Z\",\"registered\":\"2018-11-03T14:38:55.000Z\",\"published\":\"2018\",\"updated\":\"2020-09-20T08:19:49.000Z\"},\"relationships\":{\"client\":{\"data\":{\"id\":\"doe.osti\",\"type\":\"clients\"}}}}, {\"id\":\"10.11570/13.0001\",\"type\":\"dois\",\"attributes\":{\"doi\":\"10.11570/13.0001\",\"identifiers\":[],\"creators\":[{\"name\":\"Wilson, C. D.\",\"nameType\":\"Personal\",\"givenName\":\"C. D.\",\"familyName\":\"Wilson\",\"affiliation\":[],\"nameIdentifiers\":[]}],\"titles\":[{\"lang\":\"en-US\",\"title\":\"Nearby Galaxies Legacy Survey\"},{\"lang\":\"en-US\",\"title\":\"NGLS\",\"titleType\":\"AlternativeTitle\"}],\"publisher\":\"CADC\",\"container\":{},\"publicationYear\":2013,\"subjects\":[],\"contributors\":[{\"name\":\"CADC\",\"affiliation\":[],\"contributorType\":\"DataManager\",\"nameIdentifiers\":[]},{\"name\":\"Schade, David\",\"nameType\":\"Personal\",\"givenName\":\"David\",\"familyName\":\"Schade\",\"affiliation\":[],\"contributorType\":\"ContactPerson\",\"nameIdentifiers\":[{\"schemeUri\":\"https://orcid.org\",\"nameIdentifier\":\"https://orcid.org/0000-0002-4677-1586\",\"nameIdentifierScheme\":\"ORCID\"}]}],\"dates\":[{\"date\":\"2013\",\"dateType\":\"Issued\"}],\"language\":\"en\",\"types\":{\"ris\":\"DATA\",\"bibtex\":\"misc\",\"citeproc\":\"dataset\",\"schemaOrg\":\"Dataset\",\"resourceTypeGeneral\":\"Dataset\"},\"relatedIdentifiers\":[{\"relationType\":\"IsCitedBy\",\"relatedIdentifier\":\"10.1093/mnras/stv2808\",\"relatedIdentifierType\":\"DOI\"}],\"sizes\":[],\"formats\":[],\"version\":null,\"rightsList\":[],\"descriptions\":[{\"lang\":\"en-US\",\"description\":\"This contains data, plots, and information of observations of galaxies in the JCMT Nearby Galaxies Legaxy Survey.\",\"descriptionType\":\"Other\"}],\"geoLocations\":[],\"fundingReferences\":[],\"url\":\"http://www.canfar.net/citation/landing?doi=13.0001\",\"contentUrl\":[],\"metadataVersion\":2,\"schemaVersion\":\"http://datacite.org/schema/kernel-4\",\"source\":\"mds\",\"isActive\":true,\"state\":\"findable\",\"reason\":null,\"viewCount\":0,\"downloadCount\":0,\"referenceCount\":0,\"citationCount\":1,\"partCount\":0,\"partOfCount\":0,\"versionCount\":0,\"versionOfCount\":0,\"created\":\"2013-04-19T21:33:33.000Z\",\"registered\":\"2013-04-19T21:33:33.000Z\",\"published\":\"2013\",\"updated\":\"2020-11-05T10:14:30.000Z\"},\"relationships\":{\"client\":{\"data\":{\"id\":\"nrc.cadc\",\"type\":\"clients\"}}}}, {\"id\":\"10.1016/j.soscij.2015.08.001\",\"type\":\"dois\",\"attributes\":{\"doi\":\"10.1016/j.soscij.2015.08.001\",\"identifiers\":[{\"identifier\":\"https://doi.org/10.1016/j.soscij.2015.08.001\",\"identifierType\":\"DOI\"},{\"identifier\":\"10\",\"identifierType\":\"Publisher ID\"}],\"creators\":[{\"name\":\"Koch, Jerome R.\",\"nameType\":\"Personal\",\"givenName\":\"Jerome R.\",\"familyName\":\"Koch\",\"affiliation\":[\"Department of Sociology, Anthropology and Social Work, Texas Tech University, Lubbock, TX, USA\"],\"nameIdentifiers\":[]},{\"name\":\"Roberts, Alden E.\",\"nameType\":\"Personal\",\"givenName\":\"Alden E.\",\"familyName\":\"Roberts\",\"affiliation\":[\"Department of Sociology, Anthropology and Social Work, Texas Tech University, Lubbock, TX, USA\"],\"nameIdentifiers\":[]},{\"name\":\"Armstrong, Myrna L.\",\"nameType\":\"Personal\",\"givenName\":\"Myrna L.\",\"familyName\":\"Armstrong\",\"affiliation\":[\"Faculty of Emerita, School of Nursing, Texas Tech University Health Sciences Center, Lubbock, TX, USA\"],\"nameIdentifiers\":[]},{\"name\":\"Owen, Donna C.\",\"nameType\":\"Personal\",\"givenName\":\"Donna C.\",\"familyName\":\"Owen\",\"affiliation\":[\"Nursing, School of Nursing, Texas Tech University Health Sciences Center, Lubbock, TX, USA\"],\"nameIdentifiers\":[]}],\"titles\":[{\"title\":\"Tattoos, gender, and well-being among American college students\"}],\"publisher\":\"Informa UK Limited\",\"container\":{\"type\":\"Journal\",\"issue\":\"4\",\"title\":\"The Social Science Journal\",\"volume\":\"52\",\"lastPage\":\"541\",\"firstPage\":\"536\",\"identifier\":\"1873-5355\",\"identifierType\":\"ISSN\"},\"publicationYear\":2019,\"subjects\":[],\"contributors\":[],\"dates\":[{\"date\":\"2019-12-09\",\"dateType\":\"Issued\"},{\"date\":\"2019-12-09T17:02:49Z\",\"dateType\":\"Updated\"}],\"language\":null,\"types\":{\"ris\":\"JOUR\",\"bibtex\":\"article\",\"citeproc\":\"article-journal\",\"schemaOrg\":\"ScholarlyArticle\",\"resourceType\":\"JournalArticle\",\"resourceTypeGeneral\":\"Text\"},\"relatedIdentifiers\":[{\"relationType\":\"IsPartOf\",\"relatedIdentifier\":\"1873-5355\",\"resourceTypeGeneral\":\"Collection\",\"relatedIdentifierType\":\"ISSN\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1521/suli.2007.37.4.467\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1111/j.1552-6356.2006.00034.x\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1001/archderm.144.7.879\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1215/9780822396147\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.2466/pr0.86.2.475-481\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1111/j.1943-278x.2012.00092.x\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1177/10547739922158368\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1037/0022-3514.60.6.895\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1186/1471-244x-13-278\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.soscij.2013.09.009\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.2466/pr0.97.7.887-890\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.soscij.2009.10.001\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1080/016396290950677\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1177/019027250406700304\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1080/10926771.2012.630340\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.soscij.2013.07.012\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.urology.2011.05.066\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.3928/02793695-20130731-03\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1177/014662167700100306\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1111/j.1467-9566.2007.00499.x\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1007/s007370050018\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1521/suli.2006.36.3.329\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1086/679190\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.paid.2008.04.011\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1016/j.bodyim.2011.03.007\",\"relatedIdentifierType\":\"DOI\"},{\"relationType\":\"References\",\"relatedIdentifier\":\"10.1111/j.1745-7599.2009.00479.x\",\"relatedIdentifierType\":\"DOI\"}],\"sizes\":[],\"formats\":[],\"version\":null,\"rightsList\":[{\"rightsUri\":\"https://www.elsevier.com/tdm/userlicense/1.0\"}],\"descriptions\":[],\"geoLocations\":[],\"fundingReferences\":[{\"funderName\":\"E.A. Franklin Charitable Trust\"}],\"url\":\"https://www.tandfonline.com/doi/full/10.1016/j.soscij.2015.08.001\",\"contentUrl\":null,\"metadataVersion\":0,\"schemaVersion\":\"http://datacite.org/schema/kernel-4\",\"source\":\"levriero\",\"isActive\":true,\"state\":\"findable\",\"reason\":null,\"viewCount\":0,\"downloadCount\":0,\"referenceCount\":0,\"citationCount\":1,\"partCount\":0,\"partOfCount\":0,\"versionCount\":0,\"versionOfCount\":0,\"created\":\"2020-02-28T01:34:09.000Z\",\"registered\":\"2020-02-28T01:34:09.000Z\",\"published\":\"2019\",\"updated\":\"2020-02-28T01:34:09.000Z\"},\"relationships\":{\"client\":{\"data\":{\"id\":\"crossref.citations\",\"type\":\"clients\"}}}}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CITATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"citing\",\"cited\",\"creation\",\"timespan\",\"journal_sc\",\"author_sc\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1521/suli.2007.37.4.467\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1111/j.1552-6356.2006.00034.x\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1001/archderm.144.7.879\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1215/9780822396147\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.2466/pr0.86.2.475-481\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1111/j.1943-278x.2012.00092.x\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1177/10547739922158368\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1037/0022-3514.60.6.895\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1186/1471-244x-13-278\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1016/j.soscij.2013.09.009\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.2466/pr0.97.7.887-890\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1016/j.soscij.2009.10.001\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1080/016396290950677\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1177/019027250406700304\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1080/10926771.2012.630340\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1016/j.soscij.2013.07.012\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1016/j.urology.2011.05.066\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.3928/02793695-20130731-03\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1177/014662167700100306\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1111/j.1467-9566.2007.00499.x\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1007/s007370050018\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1521/suli.2006.36.3.329\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1086/679190\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1016/j.paid.2008.04.011\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1016/j.bodyim.2011.03.007\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1111/j.1745-7599.2009.00479.x\",\"\",\"\",\"\",\"\"\n",
    "\"10.1093/mnras/stv2808\",\"10.11570/13.0001\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1002/pol.1964.110021203\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1002/pol.1967.160050509\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1002/pol.1970.150080509\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1016/j.jconrel.2013.10.040\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1615/critrevtherdrugcarriersyst.2016015798\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1134/s1990793116070022\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1016/j.jconrel.2010.03.024\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1016/j.schres.2007.08.003\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1007/s11095-010-0152-4\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1080/00914037.2015.1099100\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1039/c5ra03535j\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1016/j.colsurfb.2011.03.043\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1097/00007691-199808000-00004\",\"\",\"\",\"\",\"\"\n",
    "\"10.1038/sdata.2016.60\",\"10.11577/1236752\",\"\",\"\",\"\",\"\"\n",
    "\"10.11578/1480643\",\"10.15407/scin11.06.057\",\"\",\"\",\"\",\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datacite Preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parlando con Giuseppe abbiamo deciso di fare un preprocessor che sia unico per Glob e Parser, quindi che divida il dump iniziale in dei json più piccoli, scartando le entità che non hanno informazioni utili né per il parser né per il glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DOCI PREPROCESSOR SCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alive_progress import alive_it\n",
    "import json\n",
    "from os import sep, makedirs, walk\n",
    "from tqdm import tqdm\n",
    "import os.path\n",
    "import datetime\n",
    "\n",
    "class DatacitePreProcessing():\n",
    "    \"\"\"This class aims at pre-processing DataCite dumps.\n",
    "    In particular, DatacitePreProcessing splits the original nldJSON in many JSON files,\n",
    "    each one containing the number of entities specified in input by the user.\n",
    "    Further, the class discards those entities that do not provide useful information\n",
    "    (neither for the parser, nor for the glob). \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._req_type = \".json\"\n",
    "\n",
    "    def valiDate(self, date_text):\n",
    "        date_text = str(date_text)\n",
    "        try:\n",
    "            return datetime.datetime.strptime(date_text, '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "        except ValueError:\n",
    "            try:\n",
    "                return datetime.datetime.strptime(date_text, '%Y-%m').strftime('%Y-%m')\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    return datetime.datetime.strptime(date_text, '%Y').strftime('%Y')\n",
    "                except ValueError:\n",
    "                    if '-' in date_text:\n",
    "                        possibiliDate = date_text.split('-')\n",
    "                        while possibiliDate:\n",
    "                            possibiliDate.pop()\n",
    "                            seperator = '-'\n",
    "                            data = seperator.join(possibiliDate)\n",
    "                            try:\n",
    "                                return datetime.datetime.strptime(data, '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "                            except ValueError:\n",
    "                                try:\n",
    "                                    return datetime.datetime.strptime(data, '%Y-%m').strftime('%Y-%m')\n",
    "                                except ValueError:\n",
    "                                    try:\n",
    "                                        return datetime.datetime.strptime(data, '%Y').strftime('%Y')\n",
    "                                    except ValueError:\n",
    "                                        pass\n",
    "\n",
    "\n",
    "    def get_all_files(self, i_dir):\n",
    "        result = []\n",
    "        for cur_dir, cur_subdir, cur_files in walk(i_dir):\n",
    "            for file in alive_it(cur_files):\n",
    "                if file.lower().endswith(self._req_type):\n",
    "                    result.append(cur_dir + sep + file)\n",
    "        return result\n",
    "\n",
    "    def counter_check(self, cur_n, target_n, out_dir, dict_to_json, data_values):\n",
    "        if int(cur_n) != 0 and int(cur_n) % int(target_n) == 0:\n",
    "            print( \"Processed lines:\", cur_n, \". Reduced json nr.\", cur_n //target_n)\n",
    "            filename = \"jSonFile_\" + str(cur_n//target_n) + self._req_type\n",
    "            with (open( os.path.join(out_dir, filename ), 'w', encoding=\"utf8\" )) as json_file:\n",
    "                dict_to_json[\"data\"] = data_values\n",
    "                json.dump(dict_to_json, json_file )\n",
    "                empt_list = []\n",
    "                empt_dict = {}\n",
    "                return empt_list, empt_dict\n",
    "        else:\n",
    "            return data_values, dict_to_json\n",
    "\n",
    "\n",
    "    def dump_filter_and_split(self, input_dir, output_dir, numJF):\n",
    "        relevant_relations = [\"references\", \"isreferencedby\", \"cites\", \"iscitedby\"]\n",
    "        all_files = self.get_all_files(input_dir)\n",
    "        for file_idx, file in enumerate(all_files):\n",
    "            data = []\n",
    "            datadict = {}\n",
    "            count = 0\n",
    "\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                n_lines = 0\n",
    "                for line in tqdm(f):\n",
    "                    n_lines += 1\n",
    "                    print(\"ENTITIES:\", n_lines)\n",
    "\n",
    "                    linedict = json.loads(line)\n",
    "                    attributes = linedict[\"attributes\"]\n",
    "                    rel_ids = attributes[\"relatedIdentifiers\"]\n",
    "\n",
    "                    # Default settings\n",
    "                    creatorsWithOrcid = False\n",
    "                    issnsFromRelId = False\n",
    "                    issnsFromCont = False\n",
    "\n",
    "                    # Check if the entity provides info for support files (DATES)\n",
    "                    listDates = attributes['dates'] != []\n",
    "                    publicationYear = self.valiDate(str(attributes['publicationYear']))\n",
    "\n",
    "                    # Check if the entity provides info for support files (ORCID)\n",
    "                    creators = attributes['creators']\n",
    "                    if creators != []:\n",
    "                        creatorsWithIds = [author for author in creators if 'nameIdentifiers' in author.keys()]\n",
    "                        if creatorsWithIds != []:\n",
    "                            creatorsWithIdScheme = [nameId for nameId in creatorsWithIds if 'nameIdentifier' in nameId.keys() and 'nameIdentifierScheme' in nameId.keys()]\n",
    "                            if creatorsWithIdScheme != []:\n",
    "                                creatorsWithOrcid = any(idInfo['nameIdentifierScheme'].lower() == \"orcid\" for idInfo in creatorsWithIdScheme)\n",
    "\n",
    "                    # Check if the entity provides info for support files (ISSN)\n",
    "                    if rel_ids != []:\n",
    "                        idsWithType = [relId for relId in rel_ids if 'relationType' in relId.keys() and 'relatedIdentifierType' in relId.keys() and 'relatedIdentifier' in relId.keys()]\n",
    "                        if idsWithType != []:\n",
    "                            issnsFromRelId = [relId for relId in idsWithType if relId['relationType'].lower() == \"ispartof\" and relId['relatedIdentifierType'].lower() == \"issn\"] != []\n",
    "                    elif 'container' in attributes.keys():\n",
    "                        container = attributes['container']\n",
    "                        if 'identifier' in container.keys() and 'identifierType' in container.keys():\n",
    "                            issnsFromCont = container['identifier'] != \"\" and (container['identifierType']).lower() == \"issn\"\n",
    "\n",
    "                    # Check if the entity provides citations\n",
    "                    if rel_ids != []:\n",
    "                        for i in rel_ids:\n",
    "                            if \"relationType\" in i.keys() and (i[\"relationType\"]).lower() in relevant_relations:\n",
    "                                if \"relatedIdentifierType\" in i.keys() and (i[\"relatedIdentifierType\"]).lower() == \"doi\":\n",
    "                                    data.append(linedict)\n",
    "                                    count += 1\n",
    "                                    break\n",
    "\n",
    "                                # Keep the entity if it provides at least info for the support files\n",
    "                                elif creatorsWithOrcid or listDates or publicationYear or issnsFromRelId or issnsFromCont:\n",
    "                                    data.append(linedict)\n",
    "                                    count += 1\n",
    "                                    break\n",
    "\n",
    "                            # Keep the entity if it provides at least info for the support files\n",
    "                            elif creatorsWithOrcid or listDates or publicationYear or issnsFromRelId or issnsFromCont:\n",
    "                                data.append(linedict)\n",
    "                                count += 1\n",
    "                                break\n",
    "\n",
    "                            data, datadict = self.counter_check(count, numJF, output_dir, datadict, data)\n",
    "\n",
    "\n",
    "                    # Keep the entity if it provides at least info for the support files\n",
    "                    elif creatorsWithOrcid or listDates or publicationYear or issnsFromRelId or issnsFromCont:\n",
    "                        data.append(linedict)\n",
    "                        count += 1\n",
    "\n",
    "\n",
    "                    data, datadict = self.counter_check(count, numJF, output_dir, datadict, data)\n",
    "\n",
    "                if len(data) > 0:\n",
    "                    filename = \"jSonFile_rest\" + self._req_type\n",
    "                    with (open( os.path.join(output_dir, filename), 'w', encoding=\"utf8\")) as json_file:\n",
    "                        datadict[\"data\"] = data\n",
    "                        json.dump(datadict, json_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DOCI PREPROCESSOR TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il test verifica che il dump sia diviso correttamente, creando files JSON contenenti ciascuno il numero di entità specificato in input dall'utente. Inoltre, verifica anche che le entità prive di informazioni utili sia per il dump che per il parser vengano scartate. \n",
    "<br>\n",
    "<b>Domanda;</b> Credo che sia impossibile o quasi incontrare (quindi scartare) un'entità che non abbia nemmeno l'anno di pubblicazione. Manteniamo comunque questa forma (perché abbiamo un'utilità a conservare le informazioni elaborate con il glob anche per le entità di cui non abbiamo citazioni) o rendiamo il preprocessing più selettivo? (Ovvero tenere solo le informazioni di glob di quelle entità che hanno quantomeno un dato citazionale)\n",
    "<br>\n",
    "<b>Nota:</b> from index.python.src.preprocessing.datacite_pp import DatacitePreProcessing\n",
    " <b>to be changed in<b> from oc.index.preprocessing.datacite_pp import DatacitePreProcessing, in vista dell'integrazione nel software\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "import unittest\n",
    "from os import makedirs\n",
    "from os.path import join, exists\n",
    "from index.python.src.preprocessing.datacite_pp import DatacitePreProcessing\n",
    "#to be changed in : from oc.index.preprocessing.datacite_pp import DatacitePreProcessing\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "class DOCIPPTest(unittest.TestCase):\n",
    "    \"\"\"This class aims at testing the methods of the class DatacitePreProcessing.\"\"\"\n",
    "    def setUp(self):\n",
    "        test_dir = join(\"index\", \"python\", \"test\", \"data\")\n",
    "        self.input_dir = join(test_dir, \"doci_pp_dump_input\")\n",
    "        self.output_dir = join(test_dir, \"doci_pp_dump_output\")\n",
    "        if exists(self.output_dir):\n",
    "            shutil.rmtree(self.output_dir)\n",
    "        self.assertFalse(exists(self.output_dir))\n",
    "        makedirs(self.output_dir)\n",
    "        self.assertTrue(exists(self.output_dir))\n",
    "        self.num = 77\n",
    "        self.DatacitePP = DatacitePreProcessing()\n",
    "\n",
    "        #note: data concerning the dois listed below were modified for testing purposes.\n",
    "        self.ent_glob_only = \"10.1001/jama.289.8.989\"\n",
    "        self.ent_parser_only = \"10.1002/2015jc010802\"\n",
    "        self.ent_no_data = \"10.1016/j.gene.2017.10.006\"\n",
    "\n",
    "\n",
    "\n",
    "    def test_dump_filter_and_split(self):\n",
    "        self.DatacitePP.dump_filter_and_split(self.input_dir, self.output_dir, self.num)\n",
    "        all_files = self.DatacitePP.get_all_files(self.output_dir)\n",
    "        for_parser_only = False\n",
    "        for_glob_only = False\n",
    "        for file_idx, file in enumerate(all_files):\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                dict_from_json = json.load(f)\n",
    "                for dict in dict_from_json[\"data\"]:\n",
    "                    # check that the entities with neither related identifiers nor other information for the glob were discarded\n",
    "                    self.assertNotEqual(self.ent_no_data, dict[\"id\"])\n",
    "                    # check that the entities with at least either related identifiers or other information for the glob were kept\n",
    "                    if dict[\"id\"] == self.ent_glob_only:\n",
    "                        for_glob_only = True\n",
    "                    elif dict[\"id\"] == self.ent_parser_only:\n",
    "                        for_parser_only = True\n",
    "        self.assertTrue(for_parser_only)\n",
    "        self.assertTrue(for_glob_only)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def test_counter_check(self):\n",
    "        self.DatacitePP.dump_filter_and_split(self.input_dir, self.output_dir, self.num)\n",
    "        # check that all the output files contain the number of entities specified in input, except for the last one\n",
    "        all_files = self.DatacitePP.get_all_files(self.output_dir)\n",
    "        for file_idx, file in enumerate(all_files):\n",
    "            if \"rest\" not in file:\n",
    "                with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                    dict_from_json = json.load(f)\n",
    "                    self.assertEqual(len(dict_from_json[\"data\"]), self.num)\n",
    "            else:\n",
    "                with open( file, \"r\", encoding=\"utf-8\" ) as f:\n",
    "                    dict_from_json = json.load(f)\n",
    "                    self.assertLessEqual(len(dict_from_json[\"data\"]), self.num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataCite Glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Io e Giuseppe abbiamo scelto di utilizzare la versione che lavora su dump ridotto in formato JSON standard (non nld) e carica in memoria un intero json alla volta (non dizionario per dizionario)</li>\n",
    "    <li>Questa versione è stata testata esternamente a farm_revision e funziona correttamente</li>\n",
    "    <li>La versione precedente è stata aggiornata per funzionare in index_farm revision, <b>ma non è ancora stata testata</b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GLOB DOCI TESTATO (VERSIONE INDEX PRECEDENTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sep, makedirs, walk\n",
    "from os.path import exists\n",
    "import os\n",
    "from json import load\n",
    "import datetime\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from os import sep, makedirs, walk\n",
    "from os.path import exists, basename, isdir\n",
    "from json import load, loads\n",
    "from collections import Counter\n",
    "from datetime import date\n",
    "from re import sub\n",
    "import tarfile\n",
    "\n",
    "\n",
    "from oc.index.oci.citation import Citation\n",
    "from oc.index.legacy.csv import CSVManager\n",
    "from oc.index.identifier.doi import DOIManager\n",
    "from oc.index.identifier.issn import ISSNManager\n",
    "from oc.index.identifier.orcid import ORCIDManager\n",
    "\n",
    "def issn_data_recover(directory):\n",
    "    journal_issn_dict = dict()\n",
    "    filename = directory + sep + 'journal_issn.json'\n",
    "    if not os.path.exists(filename):\n",
    "        return journal_issn_dict\n",
    "    else:\n",
    "        with open(filename, 'r', encoding='utf8') as fd:\n",
    "            journal_issn_dict = json.load(fd)\n",
    "            types = type(journal_issn_dict)\n",
    "            return journal_issn_dict\n",
    "\n",
    "\n",
    "def issn_data_to_cache(name_issn_dict, directory):\n",
    "    filename = directory + sep + 'journal_issn.json'\n",
    "    with open(filename, 'w', encoding='utf-8' ) as fd:\n",
    "        json.dump(name_issn_dict, fd, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "def get_all_files(i_dir_or_targz_file):\n",
    "    result = []\n",
    "    targz_fd = None\n",
    "\n",
    "    if isdir(i_dir_or_targz_file):\n",
    "        for cur_dir, cur_subdir, cur_files in walk(i_dir_or_targz_file):\n",
    "            for cur_file in cur_files:\n",
    "                if cur_file.endswith(\".json\") and not basename(cur_file).startswith(\n",
    "                    \".\"\n",
    "                ):\n",
    "                    result.append(cur_dir + sep + cur_file)\n",
    "    elif i_dir_or_targz_file.endswith(\"tar.gz\"):\n",
    "        targz_fd = tarfile.open(i_dir_or_targz_file, \"r:gz\", encoding=\"utf-8\")\n",
    "        for cur_file in targz_fd:\n",
    "            if cur_file.name.endswith(\".json\") and not basename(\n",
    "                cur_file.name\n",
    "            ).startswith(\".\"):\n",
    "                result.append(cur_file)\n",
    "    else:\n",
    "        print(\"It is not possible to process the input path.\")\n",
    "    return result, targz_fd\n",
    "\n",
    "\n",
    "def valiDate(date_text):\n",
    "    date_text = str(date_text)\n",
    "    try:\n",
    "        return datetime.datetime.strptime(date_text, '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return datetime.datetime.strptime(date_text, '%Y-%m').strftime('%Y-%m')\n",
    "        except ValueError:\n",
    "            try:\n",
    "                return datetime.datetime.strptime(date_text, '%Y').strftime('%Y')\n",
    "            except ValueError:\n",
    "                if '-' in date_text:\n",
    "                    possibiliDate = date_text.split('-')\n",
    "                    while possibiliDate:\n",
    "                        possibiliDate.pop()\n",
    "                        seperator = '-'\n",
    "                        data = seperator.join(possibiliDate)\n",
    "                        try:\n",
    "                            return datetime.datetime.strptime(data, '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "                        except ValueError:\n",
    "                            try:\n",
    "                                return datetime.datetime.strptime(data, '%Y-%m').strftime('%Y-%m')\n",
    "                            except ValueError:\n",
    "                                try:\n",
    "                                    return datetime.datetime.strptime(data, '%Y').strftime('%Y')\n",
    "                                except ValueError:\n",
    "                                    pass\n",
    "\n",
    "\n",
    "\n",
    "def process(input_dir, output_dir, n):\n",
    "    start = timer()\n",
    "    if not exists(output_dir):\n",
    "        makedirs(output_dir)\n",
    "\n",
    "    citing_doi_with_no_date = set()\n",
    "    valid_doi = CSVManager(output_dir + sep + \"valid_doi.csv\")\n",
    "    id_date = CSVManager(output_dir + sep + \"id_date.csv\")\n",
    "    id_issn = CSVManager(output_dir + sep + \"id_issn.csv\")\n",
    "    id_orcid = CSVManager(output_dir + sep + \"id_orcid.csv\")\n",
    "\n",
    "    journal_issn_dict = issn_data_recover(output_dir)\n",
    "\n",
    "    doi_manager = DOIManager(valid_doi)\n",
    "    issn_manager = ISSNManager()\n",
    "    orcid_manager = ORCIDManager()\n",
    "\n",
    "    all_files = get_all_files(input_dir)\n",
    "    issnDict = {}\n",
    "    relevant_relations = [\"references\", \"isreferencedby\", \"cites\", \"iscitedby\"]\n",
    "\n",
    "    print(\"PROCESS PART 1\")\n",
    "    count = 0\n",
    "    # Read all the JSON files in the DataCite dump to create the main information of all the indexes\n",
    "    print(\"\\n\\n# Add valid DOIs from DataCite metadata\")\n",
    "    for file_idx, file in enumerate(all_files):\n",
    "        with open(file, encoding=\"utf8\") as f:\n",
    "            obj = json.load(f)\n",
    "            data_list = obj[\"data\"]\n",
    "            for item in tqdm( data_list ):\n",
    "                count += 1\n",
    "                print(\"item:\", item)\n",
    "                attributes = item['attributes']\n",
    "                citing_doi = attributes['doi']\n",
    "                relatedIdentifiers = attributes['relatedIdentifiers']\n",
    "                citing_doi = doi_manager.normalise(citing_doi, True)\n",
    "                doi_manager.set_valid(citing_doi)\n",
    "\n",
    "                #collect the date of issue if there is, otherwise the year of publciation\n",
    "                if id_date.get_value(citing_doi) is None:\n",
    "                    listDates = attributes['dates']\n",
    "                    publicationYear = attributes['publicationYear']\n",
    "\n",
    "                    if listDates != []:\n",
    "                        for data in listDates:\n",
    "                            tipo = str(data['dateType'])\n",
    "                            if tipo.lower() == 'issued':\n",
    "                                citing_date = valiDate(str(data['date']))\n",
    "                                if citing_date:\n",
    "                                    id_date.add_value(citing_doi, citing_date)\n",
    "                                    if citing_doi in citing_doi_with_no_date:\n",
    "                                        citing_doi_with_no_date.remove(citing_doi)\n",
    "                                # dateType è Issued ma citing_date non ha dato risultati\n",
    "                                else:\n",
    "                                    if publicationYear:\n",
    "                                        publicationYear = valiDate(str(publicationYear))\n",
    "                                        if publicationYear:\n",
    "                                            id_date.add_value(citing_doi, publicationYear)\n",
    "                                            if citing_doi in citing_doi_with_no_date:\n",
    "                                                citing_doi_with_no_date.remove(citing_doi)\n",
    "                            # c'è listDates ma datetype non è Issued\n",
    "                            else:\n",
    "                                if publicationYear:\n",
    "                                    publicationYear = valiDate(str(publicationYear))\n",
    "                                    if publicationYear:\n",
    "                                        id_date.add_value(citing_doi, publicationYear)\n",
    "                                        if citing_doi in citing_doi_with_no_date:\n",
    "                                            citing_doi_with_no_date.remove(citing_doi)\n",
    "                    #Non c'è listDates\n",
    "                    else:\n",
    "                        if publicationYear:\n",
    "                            publicationYear = valiDate(str(publicationYear))\n",
    "                            if publicationYear:\n",
    "                                id_date.add_value(citing_doi, publicationYear)\n",
    "                                if citing_doi in citing_doi_with_no_date:\n",
    "                                    citing_doi_with_no_date.remove(citing_doi)\n",
    "\n",
    "                #collect the orcid of the contributors\n",
    "\n",
    "                if id_orcid.get_value(citing_doi) is None:\n",
    "                    contributorList = attributes['creators']\n",
    "                    if contributorList != []:\n",
    "                        for author in contributorList: #da qui!!\n",
    "                            if 'nameIdentifiers' in author.keys():\n",
    "                                infoAuthor = author['nameIdentifiers']\n",
    "                                for element in infoAuthor:\n",
    "                                    if 'nameIdentifier' in element.keys() and 'nameIdentifierScheme' in element.keys():\n",
    "                                        if (element['nameIdentifierScheme']).lower() == 'orcid':\n",
    "                                            orcid = element['nameIdentifier']\n",
    "                                            if orcid is not None and orcid != \"\":\n",
    "                                                orcid = orcid_manager.normalise(orcid)\n",
    "                                                if orcid_manager.is_valid(orcid):\n",
    "                                                    id_orcid.add_value(citing_doi, orcid)\n",
    "                issn_set = set()\n",
    "                if relatedIdentifiers != []:\n",
    "                    for related in relatedIdentifiers:\n",
    "                        if 'relationType' in related.keys():\n",
    "                            relationType = related['relationType']\n",
    "                            if relationType.lower() == \"ispartof\":\n",
    "                                if 'relatedIdentifierType' in related.keys():\n",
    "                                    relatedIdentifierType = (str(related['relatedIdentifierType'])).lower()\n",
    "                                    if relatedIdentifierType == 'issn':\n",
    "                                        if 'relatedIdentifier' in related.keys():\n",
    "                                            relatedISSN = str(related['relatedIdentifier'])\n",
    "                                            if relatedISSN:\n",
    "                                                issn_set.add(relatedISSN)\n",
    "\n",
    "                if id_issn.get_value(citing_doi) is None:\n",
    "                    container = attributes['container']\n",
    "                    if 'identifier' in container.keys() and 'identifierType' in container.keys():\n",
    "                        if container['identifier'] != \"\" and (container['identifierType']).lower() == \"issn\":\n",
    "                            cont_issn = container['identifier']\n",
    "                            issn_set.add(cont_issn)\n",
    "                            if 'title' in container.keys():\n",
    "                                journal_title = (container['title']).lower()\n",
    "                                if journal_title in issnDict.keys():\n",
    "                                    issnList = issnDict[journal_title]\n",
    "                                    if issnList != []:\n",
    "                                        if not all(elem in issnList for elem in issn_set): #conferma?\n",
    "                                            issn_set.update(set(issnDict[journal_title]))\n",
    "                                            issnDict[journal_title] = list(issn_set)\n",
    "                                    else:\n",
    "                                        issnDict[journal_title] = list(issn_set)\n",
    "                                else:\n",
    "                                    issnDict[journal_title] = list(issn_set)\n",
    "\n",
    "\n",
    "                    normalised_issn_set = set()\n",
    "                    for issn in issn_set:\n",
    "                        norm_issn = issn_manager.normalise(issn)\n",
    "                        normalised_issn_set.add(norm_issn)\n",
    "                    for issn in normalised_issn_set:\n",
    "                        if issn_manager.is_valid(issn):\n",
    "                            id_issn.add_value(citing_doi, issn)\n",
    "\n",
    "                if int(count) != 0 and int(count) % int(n) == 0:\n",
    "                    print(\"trasferimento cash dati issn. Entità processate:\", count, \". Trascrizione cache n.\", (count // n))\n",
    "                    print(\"issnDict\", issnDict) #come mai resta vuoto?\n",
    "                    issn_data_to_cache(issnDict, output_dir)\n",
    "\n",
    "    issn_data_to_cache(issnDict, output_dir)\n",
    "    middle =timer()\n",
    "    print(\"first process duration: :\", (middle - start))\n",
    "    print(\"PROCESS PART 2\")\n",
    "\n",
    "    cited_dois = 0\n",
    "    count = 0\n",
    "    for file_idx, file in enumerate( all_files ):\n",
    "        print( \"ALL FILES\", all_files )\n",
    "        with open( file, encoding=\"utf8\" ) as f:\n",
    "            obj = json.load( f )\n",
    "            data_list = obj[\"data\"]\n",
    "            for item in tqdm( data_list ):\n",
    "                count += 1\n",
    "                print(\"processing entity n.\", count, \"for cited dois\")\n",
    "                if count != 0 and count % int(n) == 0:\n",
    "                    print(\"processed entities:\", count)\n",
    "                attributes = item['attributes']\n",
    "                relatedIdentifiers = attributes['relatedIdentifiers']\n",
    "                if relatedIdentifiers != []:\n",
    "                    for related in relatedIdentifiers:\n",
    "                        relationType = related['relationType']\n",
    "                        if relationType:\n",
    "                            if relationType.lower() in relevant_relations:\n",
    "                                if 'relatedIdentifierType' in related.keys():\n",
    "                                    relatedIdentifierType = (str(related['relatedIdentifierType'])).lower()\n",
    "                                    if relatedIdentifierType == 'doi':\n",
    "                                        if 'relatedIdentifier' in related.keys():\n",
    "                                            relatedDOI = str(related['relatedIdentifier'])\n",
    "                                            doi_manager.is_valid(relatedDOI)\n",
    "                                            cited_dois += 1\n",
    "                                            print(\"cited doi n.\", cited_dois, \":\", relatedDOI)\n",
    "\n",
    "    end = timer()\n",
    "    print(\"second process duration: \", end-middle)\n",
    "    print(\"full process duration: \", end-start)\n",
    "\n",
    "def main():\n",
    "    arg_parser = ArgumentParser(\n",
    "        \"Global files creator for DOCI\",\n",
    "        description=\"Process DataCite JSON files and create global indexes to enable \"\n",
    "        \"the creation of DOCI.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-i\",\n",
    "        \"--input_dir\",\n",
    "        dest=\"input_dir\",\n",
    "        required=True,\n",
    "        help=\"Either the directory or the zip file that contains the DataCite data dump \"\n",
    "        \"of JSON files.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-o\",\n",
    "        \"--output_dir\",\n",
    "        dest=\"output_dir\",\n",
    "        required=True,\n",
    "        help=\"The directory where the indexes are stored.\",\n",
    "    )\n",
    "\n",
    "    args = arg_parser.parse_args()\n",
    "    process(args.input_dir, args.output_dir)\n",
    "\n",
    "\n",
    "\n",
    "#inp_fol = \"E:\\LAVORO\\DOCI\\dump_doci\\datacite_dump_20211022\\input_test\"\n",
    "#inp_fol = \"doci_pp_dump_output\"\n",
    "#out_fol = \"E:\\LAVORO\\DOCI\\dump_doci\\datacite_dump_20211022\\output_test\\glob_totale_lines\"\n",
    "#if __name__ == '__main__':\n",
    "    #process(inp_fol, out_fol, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GLOB DOCI NON TESTATO (PER INDEX FARM_REVISION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from os import sep, makedirs, walk\n",
    "from os.path import exists, basename, isdir\n",
    "from json import load, loads\n",
    "from collections import Counter\n",
    "from datetime import date\n",
    "from re import sub\n",
    "import tarfile\n",
    "\n",
    "\n",
    "from oc.index.oci.citation import Citation\n",
    "from oc.index.legacy.csv import CSVManager\n",
    "from oc.index.identifier.doi import DOIManager\n",
    "from oc.index.identifier.issn import ISSNManager\n",
    "from oc.index.identifier.orcid import ORCIDManager\n",
    "\n",
    "\n",
    "def build_pubdate(obj):\n",
    "    if \"issued\" in obj:  # Main citing object\n",
    "        if \"date-parts\" in obj[\"issued\"]:\n",
    "            # is an array of parts of dates\n",
    "            try:\n",
    "                obj_date = obj[\"issued\"][\"date-parts\"][0]\n",
    "\n",
    "                # lisdate[year,month,day]\n",
    "                listdate = [1, 1, 1]\n",
    "                dateparts = []\n",
    "                for i in range(0, len(obj_date)):\n",
    "                    try:\n",
    "                        dateparts.append(obj_date[i])\n",
    "                        intvalue = int(obj_date[i])\n",
    "                        listdate[i] = intvalue\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                # I have a date, so generate it\n",
    "                if (\n",
    "                    (1 < listdate[0] < 3000)\n",
    "                    and (0 < listdate[1] <= 12)\n",
    "                    and (0 < listdate[2] <= 31)\n",
    "                ):\n",
    "                    date_val = date(listdate[0], listdate[1], listdate[2])\n",
    "                    dformat = \"%Y\"\n",
    "\n",
    "                    # only month is specified\n",
    "                    if len(dateparts) == 2:\n",
    "                        dformat = \"%Y-%m\"\n",
    "                    elif len(dateparts) == 3 and (\n",
    "                        dateparts[1] != 1 or (dateparts[1] == 1 and dateparts[2] != 1)\n",
    "                    ):\n",
    "                        dformat = \"%Y-%m-%d\"\n",
    "\n",
    "                    date_in_str = date_val.strftime(dformat)\n",
    "                    return date_in_str\n",
    "            except:\n",
    "                pass\n",
    "    elif \"year\" in obj:  # Reference object\n",
    "        ref_year = sub(\"[^\\d]\", \"\", obj[\"year\"])[:4]\n",
    "        if ref_year:\n",
    "            return ref_year\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_all_files(i_dir_or_targz_file):\n",
    "    result = []\n",
    "    targz_fd = None\n",
    "\n",
    "    if isdir(i_dir_or_targz_file):\n",
    "        for cur_dir, cur_subdir, cur_files in walk(i_dir_or_targz_file):\n",
    "            for cur_file in cur_files:\n",
    "                if cur_file.endswith(\".json\") and not basename(cur_file).startswith(\n",
    "                    \".\"\n",
    "                ):\n",
    "                    result.append(cur_dir + sep + cur_file)\n",
    "    elif i_dir_or_targz_file.endswith(\"tar.gz\"):\n",
    "        targz_fd = tarfile.open(i_dir_or_targz_file, \"r:gz\", encoding=\"utf-8\")\n",
    "        for cur_file in targz_fd:\n",
    "            if cur_file.name.endswith(\".json\") and not basename(\n",
    "                cur_file.name\n",
    "            ).startswith(\".\"):\n",
    "                result.append(cur_file)\n",
    "    else:\n",
    "        print(\"It is not possible to process the input path.\")\n",
    "    return result, targz_fd\n",
    "\n",
    "\n",
    "def load_json(file, targz_fd, file_idx, len_all_files):\n",
    "    result = None\n",
    "\n",
    "    if targz_fd is None:\n",
    "        print(\"Open file %s of %s\" % (file_idx, len_all_files))\n",
    "        with open(file, encoding=\"utf8\") as f:\n",
    "            result = load(f)\n",
    "    else:\n",
    "        print(\"Open file %s of %s (in tar.gz archive)\" % (file_idx, len_all_files))\n",
    "        cur_tar_file = targz_fd.extractfile(file)\n",
    "        json_str = cur_tar_file.read()\n",
    "\n",
    "        # In Python 3.5 it seems that, for some reason, the extractfile method returns an\n",
    "        # object 'bytes' that cannot be managed by the function 'load' in the json package.\n",
    "        # Thus, to avoid issues, in case an object having type 'bytes' is return, it is\n",
    "        # transformed as a string before passing it to the function 'loads'. Please note\n",
    "        # that Python 3.9 does not show this behaviour, and it works correctly without\n",
    "        # any transformation.\n",
    "        if type(json_str) is bytes:\n",
    "            json_str = json_str.decode(\"utf-8\")\n",
    "\n",
    "        result = loads(json_str)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def process(input_dir, output_dir):\n",
    "    if not exists(output_dir):\n",
    "        makedirs(output_dir)\n",
    "\n",
    "    citing_doi_with_no_date = set()\n",
    "    valid_doi = CSVManager(output_dir + sep + \"valid_doi.csv\")\n",
    "    id_date = CSVManager(output_dir + sep + \"id_date.csv\")\n",
    "    id_issn = CSVManager(output_dir + sep + \"id_issn.csv\")\n",
    "    id_orcid = CSVManager(output_dir + sep + \"id_orcid.csv\")\n",
    "\n",
    "    doi_manager = DOIManager()\n",
    "    issn_manager = ISSNManager()\n",
    "    orcid_manager = ORCIDManager()\n",
    "\n",
    "    all_files, targz_fd = get_all_files(input_dir)\n",
    "    len_all_files = len(all_files)\n",
    "\n",
    "    # Read all the JSON file in the Crossref dump to create the main information of all the indexes\n",
    "    print(\"\\n\\n# Add valid DOIs from Crossref metadata\")\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        data = load_json(file, targz_fd, file_idx, len_all_files)\n",
    "\n",
    "        if \"items\" in data:\n",
    "            for obj in data[\"items\"]:\n",
    "                if \"DOI\" in obj:\n",
    "                    citing_doi = doi_manager.normalise(obj[\"DOI\"], True)\n",
    "                    valid_doi.add_value(\n",
    "                        citing_doi, \"v\" if doi_manager.is_valid(citing_doi) else \"i\"\n",
    "                    )\n",
    "\n",
    "                    if id_date.get_value(citing_doi) is None:\n",
    "                        citing_date = Citation.check_date(build_pubdate(obj))\n",
    "                        if citing_date is not None:\n",
    "                            id_date.add_value(citing_doi, citing_date)\n",
    "                            if citing_doi in citing_doi_with_no_date:\n",
    "                                citing_doi_with_no_date.remove(citing_doi)\n",
    "                        else:\n",
    "                            citing_doi_with_no_date.add(citing_doi)\n",
    "\n",
    "                    if id_issn.get_value(citing_doi) is None:\n",
    "                        if \"type\" in obj:\n",
    "                            cur_type = obj[\"type\"]\n",
    "                            if (\n",
    "                                cur_type is not None\n",
    "                                and \"journal\" in cur_type\n",
    "                                and \"ISSN\" in obj\n",
    "                            ):\n",
    "                                cur_issn = obj[\"ISSN\"]\n",
    "                                if cur_issn is not None:\n",
    "                                    for issn in [\n",
    "                                        issn_manager.normalise(issn)\n",
    "                                        for issn in cur_issn\n",
    "                                    ]:\n",
    "                                        if issn is not None:\n",
    "                                            id_issn.add_value(citing_doi, issn)\n",
    "\n",
    "                    if id_orcid.get_value(citing_doi) is None:\n",
    "                        if \"author\" in obj:\n",
    "                            cur_author = obj[\"author\"]\n",
    "                            if cur_author is not None:\n",
    "                                for author in cur_author:\n",
    "                                    if \"ORCID\" in author:\n",
    "                                        orcid = orcid_manager.normalise(author[\"ORCID\"])\n",
    "                                        if orcid is not None:\n",
    "                                            id_orcid.add_value(citing_doi, orcid)\n",
    "\n",
    "    # Do it again for updating the dates of the cited DOIs, if these are valid\n",
    "    print(\"\\n\\n# Check cited DOIs from Crossref reference field\")\n",
    "    doi_date = {}\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        data = load_json(file, targz_fd, file_idx, len_all_files)\n",
    "\n",
    "        if \"items\" in data:\n",
    "            for obj in data[\"items\"]:\n",
    "                if \"DOI\" in obj and \"reference\" in obj:\n",
    "                    for ref in obj[\"reference\"]:\n",
    "                        if \"DOI\" in ref:\n",
    "                            cited_doi = doi_manager.normalise(ref[\"DOI\"], True)\n",
    "                            if (\n",
    "                                doi_manager.is_valid(cited_doi)\n",
    "                                and id_date.get_value(cited_doi) is None\n",
    "                            ):\n",
    "                                if cited_doi not in doi_date:\n",
    "                                    doi_date[cited_doi] = []\n",
    "                                cited_date = Citation.check_date(build_pubdate(ref))\n",
    "                                if cited_date is not None:\n",
    "                                    doi_date[cited_doi].append(cited_date)\n",
    "                                    if cited_doi in citing_doi_with_no_date:\n",
    "                                        citing_doi_with_no_date.remove(cited_doi)\n",
    "\n",
    "    # Add the date to the DOI if such date is the most adopted one in the various references.\n",
    "    # In case two distinct dates are used the most, select the older one.\n",
    "    for doi in doi_date:\n",
    "        count = Counter(doi_date[doi])\n",
    "        if len(count):\n",
    "            top_value = count.most_common(1)[0][1]\n",
    "            selected_dates = []\n",
    "            for date in count:\n",
    "                if count[date] == top_value:\n",
    "                    selected_dates.append(date)\n",
    "            best_date = sorted(selected_dates)[0]\n",
    "            id_date.add_value(doi, best_date)\n",
    "        else:\n",
    "            id_date.add_value(doi, \"\")\n",
    "\n",
    "    # Add emtpy dates for the remaining DOIs\n",
    "    for doi in citing_doi_with_no_date:\n",
    "        id_date.add_value(doi, \"\")\n",
    "\n",
    "    # Close the file descriptor of the tar.gz archive if it was used\n",
    "    if targz_fd is not None:\n",
    "        targz_fd.close()\n",
    "\n",
    "\n",
    "def main():\n",
    "    arg_parser = ArgumentParser(\n",
    "        \"Global files creator for COCI\",\n",
    "        description=\"Process Crossref JSON files and create global indexes to enable \"\n",
    "        \"the creation of COCI.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-i\",\n",
    "        \"--input_dir\",\n",
    "        dest=\"input_dir\",\n",
    "        required=True,\n",
    "        help=\"Either the directory or the zip file that contains the Crossref data dump \"\n",
    "        \"of JSON files.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-o\",\n",
    "        \"--output_dir\",\n",
    "        dest=\"output_dir\",\n",
    "        required=True,\n",
    "        help=\"The directory where the indexes are stored.\",\n",
    "    )\n",
    "\n",
    "    args = arg_parser.parse_args()\n",
    "    process(args.input_dir, args.output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PMID Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Adattamento PMID Manager per farm_revision, Estensione test_identifier, Estensione glob.json con dati per test.</b><br>\n",
    "Nota: Sostituire nel test identifier che verrà aggiunto alla versione ufficiale \"from index.python.src.identifier.pmid import PMIDManager\" con **\"from oc.index.identifier.pmid import PMIDManager\"**.\n",
    "Il codice è stato testato e funziona correttamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PMID MANAGER SCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "from re import sub, match\n",
    "from urllib.parse import unquote, quote\n",
    "from requests import get\n",
    "from json import loads\n",
    "from requests import ReadTimeout\n",
    "from requests.exceptions import ConnectionError\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from oc.index.identifier.base import IdentifierManager\n",
    "\n",
    "class PMIDManager(IdentifierManager):\n",
    "    \"\"\"This class implements an identifier manager for pmid identifier\"\"\"\n",
    "\n",
    "    def __init__(self, data={}, use_api_service=True):\n",
    "        \"\"\"PMID manager constructor.\"\"\"\n",
    "        super().__init__()\n",
    "        self._api = \"https://pubmed.ncbi.nlm.nih.gov/\"\n",
    "        self._use_api_service = use_api_service\n",
    "        self._p = \"pmid:\"\n",
    "        self._data = data\n",
    "\n",
    "    def is_valid(self, pmid):\n",
    "        \"\"\"Check if a pmid is valid.\n",
    "\n",
    "        Args:\n",
    "            id_string (str): the pmid to check\n",
    "\n",
    "        Returns:\n",
    "            bool: true if the doi is valid, false otherwise.\n",
    "        \"\"\"\n",
    "        pmid = self.normalise(pmid, include_prefix=True)\n",
    "\n",
    "        if pmid is None or match(\"^pmid:[1-9]\\d*$\", pmid) is None:\n",
    "            return False\n",
    "        else:\n",
    "            if not pmid in self._data or self._data[pmid] is None:\n",
    "                return self.__pmid_exists(pmid)\n",
    "            return self._data[pmid].get(\"valid\")\n",
    "\n",
    "    def normalise(self, id_string, include_prefix=False):\n",
    "        \"\"\"It returns the pmid normalized.\n",
    "\n",
    "        Args:\n",
    "            id_string (str): the pmid to normalize.\n",
    "            include_prefix (bool, optional): indicates if include the prefix. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            str: the normalized pmid\n",
    "        \"\"\"\n",
    "        id_string = str(id_string)\n",
    "        try:\n",
    "            pmid_string = sub(\"^0+\", \"\", sub(\"\\0+\", \"\", (sub( \"[^\\d+]\", \"\", id_string))))\n",
    "            return \"%s%s\" % (self._p if include_prefix else \"\", pmid_string)\n",
    "        except:\n",
    "            # Any error in processing the PMID will return None\n",
    "            return None\n",
    "\n",
    "\n",
    "    def __pmid_exists(self, pmid_full):\n",
    "        if self._use_api_service:\n",
    "            pmid = self.normalise(pmid_full)\n",
    "            tentative = 3\n",
    "            while tentative:\n",
    "                tentative -= 1\n",
    "                try:\n",
    "                    r = get(self._api + quote(pmid) + \"/?format=pmid\", headers=self._headers, timeout=30)\n",
    "                    if r.status_code == 200:\n",
    "                        r.encoding = \"utf-8\"\n",
    "                        soup = BeautifulSoup(r.content, features=\"lxml\")\n",
    "                        for i in soup.find_all(\"meta\", {\"name\": \"uid\"}):\n",
    "                            id = i[\"content\"]\n",
    "                            if id == pmid:\n",
    "                                return True\n",
    "\n",
    "                except ReadTimeout:\n",
    "                    # Do nothing, just try again\n",
    "                    pass\n",
    "                except ConnectionError:\n",
    "                    # Sleep 5 seconds, then try again\n",
    "                    sleep(5)\n",
    "\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PMID MANAGER TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "import unittest\n",
    "import json\n",
    "\n",
    "from os import makedirs\n",
    "from os.path import join, exists\n",
    "\n",
    "from oc.index.identifier.doi import DOIManager\n",
    "from index.python.src.identifier.pmid import PMIDManager # from oc.index.identifier.pmid import PMIDManager\n",
    "from oc.index.identifier.issn import ISSNManager\n",
    "from oc.index.identifier.orcid import ORCIDManager\n",
    "\n",
    "\n",
    "class IdentifierManagerTest(unittest.TestCase):\n",
    "    \"\"\"This class aim at testing identifiers manager.\"\"\"\n",
    "\n",
    "    def setUp(self):\n",
    "        if not exists(\"tmp\"):\n",
    "            makedirs(\"tmp\")\n",
    "        self.valid_doi_1 = \"10.1108/jd-12-2013-0166\"\n",
    "        self.valid_doi_2 = \"10.1130/2015.2513(00)\"\n",
    "        self.invalid_doi_1 = \"10.1108/12-2013-0166\"\n",
    "        self.invalid_doi_2 = \"10.1371\"\n",
    "\n",
    "        # class extension for pubmedid\n",
    "        self.valid_pmid_1 = \"2942070\"\n",
    "        self.valid_pmid_2 = \"1509982\"\n",
    "        self.invalid_pmid_1 = \"0067308798798\"\n",
    "        self.invalid_pmid_2 = \"pmid:174777777777\"\n",
    "\n",
    "        test_dir = join(\"index\", \"python\", \"test\", \"data\")\n",
    "        with open(join(test_dir, \"glob.json\"), encoding=\"utf-8\") as fp:\n",
    "            self.data = json.load(fp)\n",
    "\n",
    "        self.valid_issn_1 = \"2376-5992\"\n",
    "        self.valid_issn_2 = \"1474-175X\"\n",
    "        self.invalid_issn_1 = \"2376-599C\"\n",
    "        self.invalid_issn_2 = \"2376-5995\"\n",
    "        self.invalid_issn_3 = \"2376-599\"\n",
    "\n",
    "        self.valid_orcid_1 = \"0000-0003-0530-4305\"\n",
    "        self.valid_orcid_2 = \"0000-0001-5506-523X\"\n",
    "        self.invalid_orcid_1 = \"0000-0003-0530-430C\"\n",
    "        self.invalid_orcid_2 = \"0000-0001-5506-5232\"\n",
    "        self.invalid_orcid_3 = \"0000-0001-5506-523\"\n",
    "        self.invalid_orcid_4 = \"1-5506-5232\"\n",
    "\n",
    "    def test_doi_normalise(self):\n",
    "        dm = DOIManager()\n",
    "        self.assertEqual(\n",
    "            self.valid_doi_1,\n",
    "            dm.normalise(self.valid_doi_1.upper().replace(\"10.\", \"doi: 10. \")),\n",
    "        )\n",
    "        self.assertEqual(\n",
    "            self.valid_doi_1,\n",
    "            dm.normalise(self.valid_doi_1.upper().replace(\"10.\", \"doi:10.\")),\n",
    "        )\n",
    "        self.assertEqual(\n",
    "            self.valid_doi_1,\n",
    "            dm.normalise(\n",
    "                self.valid_doi_1.upper().replace(\"10.\", \"https://doi.org/10.\")\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def test_doi_is_valid(self):\n",
    "        dm_nofile = DOIManager()\n",
    "        self.assertTrue(dm_nofile.is_valid(self.valid_doi_1))\n",
    "        self.assertTrue(dm_nofile.is_valid(self.valid_doi_2))\n",
    "        self.assertFalse(dm_nofile.is_valid(self.invalid_doi_1))\n",
    "        self.assertFalse(dm_nofile.is_valid(self.invalid_doi_2))\n",
    "\n",
    "        dm_file = DOIManager(self.data, use_api_service=False)\n",
    "        self.assertTrue(dm_file.is_valid(self.valid_doi_1))\n",
    "        self.assertFalse(dm_file.is_valid(self.invalid_doi_1))\n",
    "\n",
    "        dm_nofile_noapi = DOIManager(use_api_service=False)\n",
    "        self.assertFalse(dm_nofile_noapi.is_valid(self.valid_doi_1))\n",
    "        self.assertFalse(dm_nofile_noapi.is_valid(self.invalid_doi_1))\n",
    "\n",
    "\n",
    "    def test_pmid_normalise(self):\n",
    "        pm = PMIDManager()\n",
    "        self.assertEqual(self.valid_pmid_1, pm.normalise(self.valid_pmid_1.replace(\"\", \"pmid:\")))\n",
    "        self.assertEqual(self.valid_pmid_1, pm.normalise(self.valid_pmid_1.replace(\"\", \" \")))\n",
    "        self.assertEqual(self.valid_pmid_1, pm.normalise(\"https://pubmed.ncbi.nlm.nih.gov/\"+self.valid_pmid_1))\n",
    "        self.assertEqual(self.valid_pmid_2, pm.normalise(\"000\"+self.valid_pmid_2))\n",
    "\n",
    "\n",
    "    def test_pmid_is_valid(self):\n",
    "        pm_nofile = PMIDManager()\n",
    "        self.assertTrue(pm_nofile.is_valid(self.valid_pmid_1))\n",
    "        self.assertTrue(pm_nofile.is_valid(self.valid_pmid_2))\n",
    "        self.assertFalse(pm_nofile.is_valid(self.invalid_pmid_1))\n",
    "        self.assertFalse(pm_nofile.is_valid(self.invalid_pmid_2))\n",
    "\n",
    "        pm_file = PMIDManager(self.data, use_api_service=False)\n",
    "        self.assertTrue(pm_file.is_valid(self.valid_pmid_1))\n",
    "        self.assertFalse(pm_file.is_valid(self.invalid_pmid_1))\n",
    "\n",
    "        pm_nofile_noapi = PMIDManager(use_api_service=False)\n",
    "        self.assertFalse(pm_nofile_noapi.is_valid(self.valid_pmid_1))\n",
    "        self.assertFalse(pm_nofile_noapi.is_valid(self.invalid_pmid_1))\n",
    "\n",
    "\n",
    "    def test_issn_normalise(self):\n",
    "        im = ISSNManager()\n",
    "        self.assertEqual(\n",
    "            self.valid_issn_1, im.normalise(self.valid_issn_1.replace(\"-\", \"  \"))\n",
    "        )\n",
    "        self.assertEqual(\n",
    "            self.valid_issn_2, im.normalise(self.valid_issn_2.replace(\"-\", \"  \"))\n",
    "        )\n",
    "        self.assertEqual(\n",
    "            self.invalid_issn_3, im.normalise(self.invalid_issn_3.replace(\"-\", \"  \"))\n",
    "        )\n",
    "\n",
    "    def test_issn_is_valid(self):\n",
    "        im = ISSNManager()\n",
    "        self.assertTrue(im.is_valid(self.valid_issn_1))\n",
    "        self.assertTrue(im.is_valid(self.valid_issn_2))\n",
    "        self.assertFalse(im.is_valid(self.invalid_issn_1))\n",
    "        self.assertFalse(im.is_valid(self.invalid_issn_2))\n",
    "        self.assertFalse(im.is_valid(self.invalid_issn_3))\n",
    "\n",
    "    def test_orcid_normalise(self):\n",
    "        om = ORCIDManager()\n",
    "        self.assertEqual(\n",
    "            self.valid_orcid_1, om.normalise(self.valid_orcid_1.replace(\"-\", \"  \"))\n",
    "        )\n",
    "        self.assertEqual(\n",
    "            self.valid_orcid_1, om.normalise(\"https://orcid.org/\" + self.valid_orcid_1)\n",
    "        )\n",
    "        self.assertEqual(\n",
    "            self.valid_orcid_2, om.normalise(self.valid_orcid_2.replace(\"-\", \"  \"))\n",
    "        )\n",
    "        self.assertEqual(\n",
    "            self.invalid_orcid_3, om.normalise(self.invalid_orcid_3.replace(\"-\", \"  \"))\n",
    "        )\n",
    "\n",
    "    def test_orcid_is_valid(self):\n",
    "        om = ORCIDManager()\n",
    "        self.assertTrue(om.is_valid(self.valid_orcid_1))\n",
    "        self.assertTrue(om.is_valid(self.valid_orcid_2))\n",
    "        self.assertFalse(om.is_valid(self.invalid_orcid_1))\n",
    "        self.assertFalse(om.is_valid(self.invalid_orcid_2))\n",
    "        self.assertFalse(om.is_valid(self.invalid_orcid_3))\n",
    "        self.assertFalse(om.is_valid(self.invalid_orcid_4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GLOB.JSON INTEGRAZIONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"doi:10.1007/s11192-018-2988-z\": {\n",
    "        \"date\": \"2019-01-02\",\n",
    "        \"valid\": true,\n",
    "        \"issn\": [\"0138-9130\", \"1588-2861\"],\n",
    "        \"orcid\": [\"0000-0003-0530-4305\"]\n",
    "    },\n",
    "    \"doi:10.6092/issn.2532-8816/8555\": {\n",
    "        \"date\": \"2019-05-27\",\n",
    "        \"valid\": true,\n",
    "        \"issn\": [],\n",
    "        \"orcid\": []\n",
    "    },\n",
    "    \"doi:10.14763/2019.1.1389\": {\n",
    "        \"date\": null,\n",
    "        \"valid\": true,\n",
    "        \"issn\": [\"2197-6775\"],\n",
    "        \"orcid\": []\n",
    "    },\n",
    "    \"doi:10.1108/jd-12-2013-0166\": {\n",
    "        \"date\": null,\n",
    "        \"valid\": true,\n",
    "        \"issn\": [],\n",
    "        \"orcid\": [\"0000-0003-0530-4305\"]\n",
    "    },\n",
    "    \"doi:10.1108/12-2013-0166\": {\n",
    "        \"date\": null,\n",
    "        \"valid\": false,\n",
    "        \"issn\": [],\n",
    "        \"orcid\": []\n",
    "    },\n",
    "    \"doi:10.5065/d6b8565d\": {\n",
    "        \"date\": null,\n",
    "        \"valid\": true,\n",
    "        \"issn\": [],\n",
    "        \"orcid\": [\"0000-0001-7734-8388\"]\n",
    "    },\n",
    "        \"pmid:67308798798\": {\n",
    "        \"date\": null,\n",
    "        \"valid\": false,\n",
    "        \"issn\": [],\n",
    "        \"orcid\": []\n",
    "    },\n",
    "    \"pmid:174777777777\": {\n",
    "        \"date\": null,\n",
    "        \"valid\": false,\n",
    "        \"issn\": [],\n",
    "        \"orcid\": []\n",
    "    },\n",
    "    \"pmid:2942070\": {\n",
    "        \"date\": \"1986-08\",\n",
    "        \"valid\": true,\n",
    "        \"issn\": [\"0003-4819\"],\n",
    "        \"orcid\": []\n",
    "    },\n",
    "    \"pmid:1509982\": {\n",
    "        \"date\": \"1992-01\",\n",
    "        \"valid\": true,\n",
    "        \"issn\": [\"0065-4299\"],\n",
    "        \"orcid\": []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nih Parser\n",
    "<ul>\n",
    "    <li>Script del parser adattato dalla versione precedente di index (sul modello di croci perché usa csv e non json)</li>\n",
    "    <li>Testato</li>\n",
    "    <li>File Citations aggiunto a test data</li>\n",
    "    <li>File Dump aggiunto a test data</li>\n",
    "    <li><b>NOTE: sia in nih.py che in test_noci sostituisci</b> from index.python.src.identifier.pmid import PMIDManager #TO BE REFACTORED : from oc.index.identifier.pmid import PMIDManager e from index.python.src.parsing.nih import NIHParser # TO BE REFACTORED : from oc.index.parsing.nih import NIHParser</li>    \n",
    "    <li><b>NOTE:</b> Controllare se con il dump effettivo c'è bisogno di dividere in chunks (non credo si possa caricare per intero in memoria)</li>\n",
    "    <li><b>NOTE:</b> Chiedere perché i campi relativi alle selfcitations sono riempiti con \"no\" \"no\" nel per CROCI mentre in \"\" \"\" per COCI. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOCI PARSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "from csv import DictReader\n",
    "\n",
    "from index.python.src.identifier.pmid import PMIDManager #TO BE REFACTORED : from oc.index.identifier.pmid import PMIDManager\n",
    "from oc.index.parsing.base import CitationParser\n",
    "\n",
    "class NIHParser(CitationParser):\n",
    "    def __init__(self):\n",
    "        self._rows = []\n",
    "        self._pmid_manager = PMIDManager()\n",
    "\n",
    "    def is_valid(self, filename: str):\n",
    "        super().is_valid(filename)\n",
    "        return filename.endswith(\".csv\")\n",
    "\n",
    "    def parse(self, filename: str):\n",
    "        super().parse(filename)\n",
    "        with open( filename, encoding=\"utf8\" ) as fp: #chunks (?)\n",
    "            self._rows = list(DictReader(fp))\n",
    "        self._items = len(self._rows)\n",
    "\n",
    "    def get_next_citation_data(self):\n",
    "        if len(self._rows) == 0:\n",
    "            return None\n",
    "\n",
    "        row = self._rows.pop(0)\n",
    "        self._current_item += 1\n",
    "        citing = self._pmid_manager.normalise(row.get(\"citing\"))\n",
    "        cited = self._pmid_manager.normalise(row.get(\"referenced\"))\n",
    "\n",
    "        if citing is not None and cited is not None:\n",
    "            return citing, cited, None, None, None, None\n",
    "\n",
    "        return self.get_next_citation_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOCI PARSER TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "import unittest\n",
    "from os import makedirs\n",
    "from os.path import join, exists\n",
    "from os.path import join\n",
    "from csv import DictReader\n",
    "from index.python.src.parsing.nih import NIHParser # TO BE REFACTORED : from oc.index.parsing.nih import NIHParser\n",
    "\n",
    "class NOCITest(unittest.TestCase):\n",
    "    \"\"\"This class aims at testing the methods of the class NIHParser.\"\"\"\n",
    "    def setUp(self):\n",
    "        if not exists(\"tmp\"):\n",
    "            makedirs(\"tmp\")\n",
    "        test_dir = join(\"index\", \"python\", \"test\", \"data\")\n",
    "        self.input = join(test_dir, \"noci_dump.csv\")\n",
    "        self.citations = join(test_dir, \"noci_citations.csv\")\n",
    "\n",
    "\n",
    "    def test_citation_source(self):\n",
    "        parser = NIHParser()\n",
    "        parser.parse(self.input)\n",
    "        new = []\n",
    "        cit = parser.get_next_citation_data()\n",
    "        while cit is not None:\n",
    "            citing, cited, creation, timespan, journal_sc, author_sc = cit\n",
    "            new.append(\n",
    "                {\n",
    "                    \"citing\": citing,\n",
    "                    \"cited\": cited,\n",
    "                    \"creation\": \"\" if creation is None else creation,\n",
    "                    \"timespan\": \"\" if timespan is None else timespan,\n",
    "                    \"journal_sc\": \"\" if journal_sc is None else journal_sc,\n",
    "                    \"author_sc\": \"\" if author_sc is None else author_sc,\n",
    "                }\n",
    "            )\n",
    "            cit = parser.get_next_citation_data()\n",
    "\n",
    "        with open(self.citations, encoding=\"utf8\") as f:\n",
    "            old = list(DictReader(f))\n",
    "        self.assertEqual(new, old)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CITATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"citing\",\"cited\",\"creation\",\"timespan\",\"journal_sc\",\"author_sc\"\n",
    "\"2140506\",\"2942070\",\"\",\"\",\"\",\"\"\n",
    "\"1523579\",\"7097569\",\"\",\"\",\"\",\"\"\n",
    "\"1509982\",\"6501574\",\"\",\"\",\"\",\"\"\n",
    "\"1968312\",\"13673087\",\"\",\"\",\"\",\"\"\n",
    "\"2330868\",\"3958380\",\"\",\"\",\"\",\"\"\n",
    "\"1854174\",\"3037997\",\"\",\"\",\"\",\"\"\n",
    "\"2038824\",\"2494239\",\"\",\"\",\"\",\"\"\n",
    "\"2373284\",\"7189714\",\"\",\"\",\"\",\"\"\n",
    "\"3591292\",\"4092853\",\"\",\"\",\"\",\"\"\n",
    "\"2368927\",\"355650\",\"\",\"\",\"\",\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DUMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citing,referenced\n",
    "2140506,2942070\n",
    "1523579,7097569\n",
    "1509982,6501574\n",
    "1968312,13673087\n",
    "2330868,3958380\n",
    "1854174,3037997\n",
    "2038824,2494239\n",
    "2373284,7189714\n",
    "3591292,4092853\n",
    "2368927,355650\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. 26/05 - 07/06 (NIH preprocessing, NIH parser update, id_type in farm_revision, studio preliminare META, glob)\n",
    "<a id=\"entry_14\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 (da finire) - Correggere e Pubblicare Codice Visualizzazioni su GitHub OC\n",
    "crea repo su oc (statistics) + sistemaa ondone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 (✓) - Correggere Parser NOCI con Lettura in Chunks (Preprocessing e test preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NIH PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alive_progress import alive_it\n",
    "from os import sep, makedirs, walk\n",
    "import os.path\n",
    "from os.path import exists\n",
    "import csv\n",
    "\n",
    "class NIHPreProcessing():\n",
    "    \"\"\"This class aims at pre-processing iCite Database Snapshots (NIH Open\n",
    "    Citation Collection), available at: https://nih.figshare.com/search?q=iCite+Database+Snapshot.\n",
    "    In particular, NIHPreProcessing splits the original CSV file in many lighter CSV files,\n",
    "    each one containing the number of entities specified in input by the user\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._req_type = \".csv\"\n",
    "\n",
    "    def get_all_files(self, i_dir):\n",
    "        result = []\n",
    "        for cur_dir, cur_subdir, cur_files in walk(i_dir):\n",
    "            for file in alive_it(cur_files):\n",
    "                if file.lower().endswith(self._req_type):\n",
    "                    result.append(cur_dir + sep + file)\n",
    "        return result\n",
    "\n",
    "    def chunk_to_file(self, cur_n, target_n, out_dir, headers, lines):\n",
    "        if not exists(out_dir):\n",
    "            makedirs(out_dir)\n",
    "        if int(cur_n) != 0 and int(cur_n) % int(target_n) == 0:\n",
    "            print( \"Processed lines:\", cur_n, \". Reduced csv nr.\", cur_n //target_n)\n",
    "            filename = \"CSVFile_\" + str(cur_n//target_n) + self._req_type\n",
    "            with (open(os.path.join(out_dir, filename), 'w', encoding=\"utf8\", newline='')) as f_out:\n",
    "                writer = csv.writer(f_out)\n",
    "                writer.writerow(headers)\n",
    "                writer.writerows(lines)\n",
    "                lines = []\n",
    "            return lines\n",
    "        else:\n",
    "            print(\"Processed lines:\", cur_n)\n",
    "            filename = \"CSVFile_\" + \"Rem\" + self._req_type\n",
    "            with (open(os.path.join(out_dir, filename), 'w', encoding=\"utf8\", newline='')) as f_out:\n",
    "                writer = csv.writer(f_out)\n",
    "                writer.writerow(headers)\n",
    "                writer.writerows(lines)\n",
    "            return\n",
    "\n",
    "\n",
    "    def dump_split(self, input_dir, output_dir, num):\n",
    "        all_files = self.get_all_files(input_dir)\n",
    "        count = 0\n",
    "        lines = []\n",
    "        for file_idx, file in enumerate(all_files):\n",
    "            with open(file, 'r') as f:\n",
    "                f = csv.reader(f)\n",
    "                headers = next(f)\n",
    "                for line in f:\n",
    "                    count += 1\n",
    "                    lines.append(line)\n",
    "                    if int(count) != 0 and int(count) % int(num) == 0:\n",
    "                        lines = self.chunk_to_file(count, num, output_dir, headers, lines)\n",
    "\n",
    "        if len(lines) > 0:\n",
    "            self.chunk_to_file(count, num, output_dir, headers, lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NIH PREPROCESSING TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "import unittest\n",
    "from os.path import join, exists\n",
    "from index.python.src.preprocessing.nih_pp import NIHPreProcessing # TO DO: to be changed in : from oc.index.preprocessing.datacite_pp import DatacitePreProcessing\n",
    "import shutil\n",
    "import csv\n",
    "\n",
    "\n",
    "class NOCIPPTest(unittest.TestCase):\n",
    "    \"\"\"This class aims at testing the methods of the class DatacitePreProcessing.\"\"\"\n",
    "\n",
    "    def setUp(self):\n",
    "        test_dir = join(\"index\", \"python\", \"test\", \"data\")\n",
    "        self.input_dir = join(test_dir, \"noci_pp_dump_input\")\n",
    "        self.output_dir = join(test_dir, \"noci_pp_dump_output\")\n",
    "        self.num_0 = 356\n",
    "        self.num_1 = 8\n",
    "        self.num_2 = 5\n",
    "        self.num_3 = 300\n",
    "        self.num_4 = 4\n",
    "        self.NIHPP = NIHPreProcessing()\n",
    "        self.lines_sample = [[1, 14161139], [1, 14323813], [1, 4990046], [1, 4988806], [2, 4150960], [2, 4356257], [2, 4846745], [2, 4357832]]\n",
    "        self.headers = [\"citing\", \"referenced\"]\n",
    "\n",
    "\n",
    "    def test_dump_split(self):\n",
    "        if exists(self.output_dir):\n",
    "            shutil.rmtree(self.output_dir)\n",
    "        self.assertFalse(exists(self.output_dir))\n",
    "        self.NIHPP.dump_split(self.input_dir, self.output_dir, self.num_3)\n",
    "\n",
    "        #checks that the output directory is generated in the process.\n",
    "        self.assertTrue(exists(self.output_dir))\n",
    "\n",
    "        #checks that the input lines where stored in 2 files, one containing 300 items and the other the remaining 56\n",
    "        files = self.NIHPP.get_all_files( self.output_dir)\n",
    "        len_files = len(files)\n",
    "        self.assertEqual(len_files, 2)\n",
    "        for idx, file in enumerate(files):\n",
    "            with open(file, \"r\") as op_file:\n",
    "                reader = csv.reader(op_file, delimiter=\",\")\n",
    "                next(reader, None)\n",
    "                len_lines = len(list(reader))\n",
    "                self.assertTrue(len_lines == 300 or len_lines == 56)\n",
    "\n",
    "\n",
    "    def test_chunk_to_file(self):\n",
    "        if exists(self.output_dir):\n",
    "            shutil.rmtree(self.output_dir)\n",
    "        self.assertFalse(exists(self.output_dir))\n",
    "        self.NIHPP.chunk_to_file(self.num_1, self.num_4, self.output_dir, self.headers, self.lines_sample)\n",
    "\n",
    "        #checks that chunk_to_file recreates the output directory\n",
    "        self.assertTrue(exists(self.output_dir))\n",
    "\n",
    "        #checks that the input lines are correctly stored in a file\n",
    "        files = self.NIHPP.get_all_files(self.output_dir)\n",
    "        self.assertGreater(len(files), 0)\n",
    "\n",
    "        #CSVFile_2.csv : target number (num_4) is 4 and current number (num_1) is 8 --> 8%4 == 0,  8//4  == 2\n",
    "        self.assertTrue(exists(join(self.output_dir, \"CSVFile_2.csv\")))\n",
    "\n",
    "        #runs again the process using a current number which is not a multiple of the target number, i.e.: 5\n",
    "        shutil.rmtree(self.output_dir)\n",
    "        self.assertFalse(exists(self.output_dir))\n",
    "        self.NIHPP.chunk_to_file(self.num_2, self.num_4, self.output_dir, self.headers, self.lines_sample)\n",
    "\n",
    "        #checks that chunk_to_file recreates the output directory\n",
    "        self.assertTrue(exists(self.output_dir))\n",
    "\n",
    "        #checks that the input lines are correctly stored in a file\n",
    "        files = self.NIHPP.get_all_files(self.output_dir)\n",
    "        self.assertGreater(len(files), 0)\n",
    "\n",
    "        #CSVFile_Rem.csv : target number (num_4) is 4 and current number (num_1) is 8 --> 8%4 == 0,  8//4  == 2\n",
    "        self.assertTrue(exists(join(self.output_dir, \"CSVFile_Rem.csv\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOCI PARSER UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "from index.python.src.identifier.pmid import PMIDManager #TO BE REFACTORED : from oc.index.identifier.pmid import PMIDManager\n",
    "from oc.index.parsing.base import CitationParser\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class NIHParser(CitationParser):\n",
    "    def __init__(self):\n",
    "        self._rows = []\n",
    "        self._pmid_manager = PMIDManager()\n",
    "\n",
    "    def is_valid(self, filename: str):\n",
    "        super().is_valid(filename)\n",
    "        return filename.endswith(\".csv\")\n",
    "\n",
    "    def parse(self, filename: str):\n",
    "        super().parse(filename)\n",
    "        df = pd.DataFrame()\n",
    "        for chunk in pd.read_csv(filename, chunksize=1000):\n",
    "            f = pd.concat([df, chunk], ignore_index=True)\n",
    "            f.fillna(\"\", inplace=True)\n",
    "            self._rows = f.to_dict('records')\n",
    "            self._items = len(self._rows)\n",
    "\n",
    "    def get_next_citation_data(self):\n",
    "        if len(self._rows) == 0:\n",
    "            return None\n",
    "\n",
    "        row = self._rows.pop(0)\n",
    "        self._current_item += 1\n",
    "        citing = self._pmid_manager.normalise(row.get(\"citing\"))\n",
    "        cited = self._pmid_manager.normalise(row.get(\"referenced\"))\n",
    "\n",
    "        if citing is not None and cited is not None:\n",
    "            return citing, cited, None, None, None, None\n",
    "\n",
    "        return self.get_next_citation_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOCI PARSER TEST UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "import unittest\n",
    "from os import makedirs\n",
    "from os.path import join, exists\n",
    "from os.path import join\n",
    "from csv import DictReader\n",
    "from index.python.src.parsing.nih import NIHParser # TO BE REFACTORED : from oc.index.parsing.nih import NIHParser\n",
    "\n",
    "\n",
    "class NOCITest(unittest.TestCase):\n",
    "    \"\"\"This class aims at testing the methods of the class NIHParser.\"\"\"\n",
    "    def setUp(self):\n",
    "        if not exists(\"tmp\"):\n",
    "            makedirs(\"tmp\")\n",
    "        test_dir = join(\"index\", \"python\", \"test\", \"data\")\n",
    "        self.input = join(test_dir, \"noci_dump.csv\")\n",
    "        self.citations = join(test_dir, \"noci_citations.csv\")\n",
    "\n",
    "\n",
    "    def test_citation_source(self):\n",
    "        parser = NIHParser()\n",
    "        parser.parse(self.input)\n",
    "        new = []\n",
    "        counter = 0\n",
    "        cit = parser.get_next_citation_data()\n",
    "        while cit is not None:\n",
    "            print(\"PROCESSING CIT N.\", counter, \":\", cit)\n",
    "            citing, cited, creation, timespan, journal_sc, author_sc = cit\n",
    "            new.append(\n",
    "                {\n",
    "                    \"citing\": citing,\n",
    "                    \"cited\": cited,\n",
    "                    \"creation\": \"\" if creation is None else creation,\n",
    "                    \"timespan\": \"\" if timespan is None else timespan,\n",
    "                    \"journal_sc\": \"\" if journal_sc is None else journal_sc,\n",
    "                    \"author_sc\": \"\" if author_sc is None else author_sc,\n",
    "                }\n",
    "            )\n",
    "            cit = parser.get_next_citation_data()\n",
    "            counter += 1\n",
    "\n",
    "        with open(self.citations, encoding=\"utf8\") as f:\n",
    "            old = list(DictReader(f))\n",
    "\n",
    "        self.assertEqual(new, old)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 (✓) - Controllare che la struttura dei parser di NOCI e DOCI sia coerente con quella di COCI (non croci perché ha sorgente diversa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CROCI citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citing,cited,creation,timespan,journal_sc,author_sc\n",
    "10.1002/asi.20755,10.1109/wi.2006.164,2008-01-15,P0Y11M27D,no,no\n",
    "10.1002/asi.20755,10.5210/fm.v11i11.1413,2008-01-15,P1Y2M9D,no,no\n",
    "10.1002/asi.20755,10.5210/fm.v8i12.1108,2008-01-15,P4Y1M14D,no,no\n",
    "10.1002/asi.20755,10.5210/fm.v11i9.1400,2008-01-15,P1Y4M11D,no,no\n",
    "10.1002/asi.20755,10.1038/438900a,2008-01-15,P2Y1M0D,no,no\n",
    "10.1002/asi.20755,10.2307/2529310,2008-01-15,P30Y10M14D,no,no\n",
    "10.1002/asi.20755,10.2307/4486062,2008-01-15,P1Y7M14D,no,no\n",
    "10.1002/asi.20755,10.5210/fm.v12i4.1763,2008-01-15,P0Y9M13D,no,no\n",
    "10.1002/asi.20755,10.1145/503376.503456,2008-01-15,P5Y8M26D,no,no\n",
    "10.1002/asi.20755,10.1142/9789812701527_0009,2008-01-15,P2Y3M14D,no,no\n",
    "10.1002/asi.20755,10.1145/1501434.1501445,2008-01-15,P1Y2M16D,no,no\n",
    "10.1002/asi.20755,10.1007/11839569_35,2008-01-15,P1Y3M12D,no,no\n",
    "10.1002/asi.20755,10.2307/1562247,2008-01-15,P5Y1M14D,no,no\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COCI citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"citing\",\"cited\",\"creation\",\"timespan\",\"journal_sc\",\"author_sc\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1023/a:1021919228368\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1093/bioinformatics\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1042/bj20091474\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1016/j.websem.2013.05.001\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1523/jneurosci.0003-08.2008\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1371/journal.pcbi.0010034\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.5210/fm.v2i4.522\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.5539/ass.v9n5p18\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1108/eum0000000007123\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1136/bmj.a568\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1126/science.149.3683.510\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1007/s11192-009-0021-2\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1001/jama.295.1.90\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1073/pnas.0407743101\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1136/bmj.b2680\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1038/502298a\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1038/35079151\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1108/jd-07-2012-0082\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1002/(sici)1097-4571(198909)40:5<342::aid-asi7>3.0.co;2-u\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1145/1498765.1498780\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1177/030631277500500106\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1016/j.websem.2012.08.001\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1038/493159a\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.7717/peerj.175\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1371/journal.pone.0000308\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1038/495437a\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1007/s10579-012-9211-2\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1371/journal.pntd.0000228\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.5860/crln.73.10.8846\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1087/2009202\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1038/502295a\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1371/journal.pcbi.1000361\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1101/sqb.1972.036.01.015\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1002/asi.4630240406\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1177/030631277400400102\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.3115/1610075.1610091\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1007/bf02457980\",\"\",\"\",\"\",\"\"\n",
    "\"10.1108/jd-12-2013-0166\",\"10.1525/bio.2010.60.5.2\",\"\",\"\",\"\",\"\"\n",
    "\"10.7717/peerj.4375\",\"10.1016/j.joi.2016.08.002\",\"\",\"\",\"\",\"\"\n",
    "\"10.7717/peerj.4375\",\"10.1002/leap.1021\",\"\",\"\",\"\",\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOCI citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"citing\",\"cited\",\"creation\",\"timespan\",\"journal_sc\",\"author_sc\"\n",
    "\"2140506\",\"2942070\",\"\",\"\",\"\",\"\"\n",
    "\"1523579\",\"7097569\",\"\",\"\",\"\",\"\"\n",
    "\"1509982\",\"6501574\",\"\",\"\",\"\",\"\"\n",
    "\"1968312\",\"13673087\",\"\",\"\",\"\",\"\"\n",
    "\"2330868\",\"3958380\",\"\",\"\",\"\",\"\"\n",
    "\"1854174\",\"3037997\",\"\",\"\",\"\",\"\"\n",
    "\"2038824\",\"2494239\",\"\",\"\",\"\",\"\"\n",
    "\"2373284\",\"7189714\",\"\",\"\",\"\",\"\"\n",
    "\"3591292\",\"4092853\",\"\",\"\",\"\",\"\"\n",
    "\"2368927\",\"355650\",\"\",\"\",\"\",\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DOCI citations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"citing\",\"cited\",\"creation\",\"timespan\",\"journal_sc\",\"author_sc\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1521/suli.2007.37.4.467\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1111/j.1552-6356.2006.00034.x\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1001/archderm.144.7.879\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1215/9780822396147\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.2466/pr0.86.2.475-481\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1111/j.1943-278x.2012.00092.x\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1177/10547739922158368\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1037/0022-3514.60.6.895\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1186/1471-244x-13-278\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1016/j.soscij.2013.09.009\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.2466/pr0.97.7.887-890\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1016/j.soscij.2009.10.001\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1080/016396290950677\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1177/019027250406700304\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1080/10926771.2012.630340\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1016/j.soscij.2013.07.012\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1016/j.urology.2011.05.066\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.3928/02793695-20130731-03\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1177/014662167700100306\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1111/j.1467-9566.2007.00499.x\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1007/s007370050018\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1521/suli.2006.36.3.329\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1086/679190\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1016/j.paid.2008.04.011\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1016/j.bodyim.2011.03.007\",\"\",\"\",\"\",\"\"\n",
    "\"10.1016/j.soscij.2015.08.001\",\"10.1111/j.1745-7599.2009.00479.x\",\"\",\"\",\"\",\"\"\n",
    "\"10.1093/mnras/stv2808\",\"10.11570/13.0001\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1002/pol.1964.110021203\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1002/pol.1967.160050509\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1002/pol.1970.150080509\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1016/j.jconrel.2013.10.040\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1615/critrevtherdrugcarriersyst.2016015798\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1134/s1990793116070022\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1016/j.jconrel.2010.03.024\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1016/j.schres.2007.08.003\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1007/s11095-010-0152-4\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1080/00914037.2015.1099100\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1039/c5ra03535j\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1016/j.colsurfb.2011.03.043\",\"\",\"\",\"\",\"\"\n",
    "\"10.1007/s13346-017-0376-5\",\"10.1097/00007691-199808000-00004\",\"\",\"\",\"\",\"\"\n",
    "\"10.1038/sdata.2016.60\",\"10.11577/1236752\",\"\",\"\",\"\",\"\"\n",
    "\"10.11578/1480643\",\"10.15407/scin11.06.057\",\"\",\"\",\"\",\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 (✓) - META: studio preliminare, clonazione repo, spiegazione da Arcangelo\n",
    "- <b>step preliminare</b>: clonare meta \n",
    "- <b>obiettivo finale</b>: Aggiornare META con nuove sorgenti, quindi creare un software che legge i sorgenti usati da noci e doci per creare le tabelle di ingestione per meta. Ricorda che META non modifica il contenuto dei campi, ma aggiunge solo. \n",
    "- <b>obiettivi discussi con Arcangelo</b>: \n",
    "    - <b>coci_process:</b> provare a vedere se funziona con input dump di noci o doci\n",
    "    - <b>crossref_process:</b> c'è da creare un altro plugin su quel modello che crea le tabella di Meta a partire dai dati di Datacite e NIH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 (✓ + Da discutere) - Finder NIH \n",
    "- <b>ISSN</b>: finder doppio issn (✓) : in caso ci sia un doppio issn il finder di nih li aggiunge entrambi perché la regex usata cattura tutto quello che ha la forma di un issn e che segue la sequenza di caratteri \"IS - \" e lo aggiunge ad un set. \n",
    "- <b>DATE</b>: formati non presi in considerazione (da discutere per gestione finder). Formati inattesi (controllati manualmente su campione di 2000 pubblicazioni)\n",
    "    - DP - 1975 Jul-Aug (le date di pubblicazione possono essere intervalli di mesi)\n",
    "    - DP - 1975 Summer (le date di pubblicazione possono essere stagioni)\n",
    "    - DP - 1975 MAR-APR (le date di pubblicazione possono essere in caps lock)\n",
    "    - DP - 1975 Dec-1976 Jan (gli intervalli delle date di pubblicazione possono essere a cavallo di anni diversi)\n",
    "    - I nomi delle stagioni usati sono: Spring, Winter, Summer, Fall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NIH FINDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "from requests import get\n",
    "from datetime import datetime\n",
    "import re\n",
    "from urllib.parse import quote\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import oc.index.utils.dictionary as dict_utils\n",
    "from oc.index.finder.base import ApiDOIResourceFinder\n",
    "\n",
    "\n",
    "class NIHResourceFinder(ApiDOIResourceFinder):\n",
    "    \"\"\"This class implements an api doi resource finder for crossref\"\"\"\n",
    "\n",
    "    def __init__(self, data={}, use_api_service=True):\n",
    "        \"\"\"National Institute of Health resource finder constructor.\"\"\"\n",
    "        super().__init__(data, use_api_service=use_api_service, id_type=\"pmid\")\n",
    "        self._api = \"https://pubmed.ncbi.nlm.nih.gov/\"\n",
    "\n",
    "    def _get_issn(self, txt_obj):\n",
    "        result = set()\n",
    "        issns = re.findall(\"IS\\s+-\\s+\\d{4}-\\d{4}\", txt_obj)\n",
    "        for i in issns:\n",
    "            issn = re.search(\"\\d{4}-\\d{4}\", i).group(0)\n",
    "            norm_issn = self._im.normalise(issn)\n",
    "            if norm_issn is not None:\n",
    "                result.add(norm_issn)\n",
    "        return result\n",
    "\n",
    "    def _get_date(self, txt_obj):\n",
    "        date = re.search(\"DP\\s+-\\s+(\\d{4}(\\s?(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec))?(\\s?((3[0-1])|([1-2][0-9])|([0]?[1-9])))?)\", txt_obj).group(1)\n",
    "        re_search = re.search(\"(\\d{4})\\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s+((3[0-1])|([1-2][0-9])|([0]?[1-9]))\", date)\n",
    "        if re_search is not None:\n",
    "            result = re_search.group(0)\n",
    "            datetime_object = datetime.strptime(result, '%Y %b %d')\n",
    "            return datetime.strftime(datetime_object, '%Y-%m-%d')\n",
    "        else:\n",
    "            re_search = re.search(\"(\\d{4})\\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\", date)\n",
    "            if re_search is not None:\n",
    "                result = re_search.group(0)\n",
    "                datetime_object = datetime.strptime(result, '%Y %b')\n",
    "                return datetime.strftime(datetime_object, '%Y-%m')\n",
    "            else:\n",
    "                re_search = re.search(\"(\\d{4})\", date)\n",
    "                if re_search is not None:\n",
    "                    result = re.search(\"(\\d{4})\", date).group(0)\n",
    "                    datetime_object = datetime.strptime(result, '%Y')\n",
    "                    return datetime.strftime(datetime_object, '%Y')\n",
    "                else:\n",
    "                    return None\n",
    "\n",
    "    def _call_api(self, pmid_full):\n",
    "        if self._use_api_service:\n",
    "            pmid = self._dm.normalise(pmid_full)\n",
    "            r = get(self._api + quote(pmid) + \"/?format=pubmed\", headers=self._headers, timeout=30)\n",
    "            if r.status_code == 200:\n",
    "                r.encoding = \"utf-8\"\n",
    "                soup = BeautifulSoup(r.text, features=\"lxml\")\n",
    "                mdata = str(soup.find(id=\"article-details\"))\n",
    "                return mdata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FINDER TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "import unittest\n",
    "import json\n",
    "\n",
    "from os import makedirs\n",
    "from os.path import join, exists\n",
    "\n",
    "from oc.index.finder.crossref import CrossrefResourceFinder\n",
    "from oc.index.finder.datacite import DataCiteResourceFinder\n",
    "from oc.index.finder.nih import NIHResourceFinder\n",
    "from oc.index.finder.orcid import ORCIDResourceFinder\n",
    "from oc.index.finder.base import ResourceFinderHandler\n",
    "\n",
    "\n",
    "class ResourceFinderTest(unittest.TestCase):\n",
    "    \"\"\"This class aim at testing resource finders.\"\"\"\n",
    "\n",
    "    def setUp(self):\n",
    "        if not exists(\"tmp\"):\n",
    "            makedirs(\"tmp\")\n",
    "        test_dir = join(\"index\", \"python\", \"test\", \"data\")\n",
    "        with open(join(test_dir, \"glob.json\"), encoding=\"utf-8\") as fp:\n",
    "            self.data = json.load(fp)\n",
    "\n",
    "    def test_handler_get_date(self):\n",
    "        handler = ResourceFinderHandler(\n",
    "            [CrossrefResourceFinder(), DataCiteResourceFinder(), ORCIDResourceFinder()]\n",
    "        )\n",
    "        self.assertEqual(\"2019-05-27\", handler.get_date(\"10.6092/issn.2532-8816/8555\"))\n",
    "        self.assertNotEqual(\"2019-05-27\", handler.get_date(\"10.1108/jd-12-2013-0166\"))\n",
    "\n",
    "    def test_handler_share_issn(self):\n",
    "        handler = ResourceFinderHandler(\n",
    "            [CrossrefResourceFinder(), DataCiteResourceFinder(), ORCIDResourceFinder()]\n",
    "        )\n",
    "        share_issn, _, __ = handler.share_issn(\n",
    "            \"10.1007/s11192-018-2988-z\", \"10.1007/s11192-015-1565-y\"\n",
    "        )\n",
    "        self.assertTrue(share_issn)\n",
    "        share_issn, _, __ = handler.share_issn(\n",
    "            \"10.1007/s11192-018-2988-z\", \"10.6092/issn.2532-8816/8555\"\n",
    "        )\n",
    "        self.assertFalse(share_issn)\n",
    "\n",
    "    def test_handler_share_orcid(self):\n",
    "        handler = ResourceFinderHandler(\n",
    "            [CrossrefResourceFinder(), DataCiteResourceFinder(), ORCIDResourceFinder()]\n",
    "        )\n",
    "        share_orcid, _, __ = handler.share_orcid(\n",
    "            \"10.1007/s11192-018-2988-z\", \"10.5281/zenodo.3344898\"\n",
    "        )\n",
    "        self.assertTrue(share_orcid)\n",
    "        share_orcid, _, __ = handler.share_orcid(\n",
    "            \"10.1007/s11192-018-2988-z\", \"10.1007/s11192-015-1565-y5\"\n",
    "        )\n",
    "        self.assertFalse(share_orcid)\n",
    "\n",
    "    def test_orcid_get_orcid(self):\n",
    "        # Do not use support dict, only APIs\n",
    "        of_1 = ORCIDResourceFinder()\n",
    "        self.assertIn(\"0000-0003-0530-4305\", of_1.get_orcid(\"10.1108/jd-12-2013-0166\"))\n",
    "        self.assertNotIn(\n",
    "            \"0000-0001-5506-523X\", of_1.get_orcid(\"10.1108/jd-12-2013-0166\")\n",
    "        )\n",
    "\n",
    "        # Do use support dict, but avoid using APIs\n",
    "        of_2 = ORCIDResourceFinder(\n",
    "            self.data,\n",
    "            use_api_service=False,\n",
    "        )\n",
    "        self.assertIn(\"0000-0003-0530-4305\", of_2.get_orcid(\"10.1108/jd-12-2013-0166\"))\n",
    "        self.assertNotIn(\n",
    "            \"0000-0001-5506-523X\", of_2.get_orcid(\"10.1108/jd-12-2013-0166\")\n",
    "        )\n",
    "\n",
    "        # Do not use support files neither APIs\n",
    "        of_3 = ORCIDResourceFinder(use_api_service=False)\n",
    "        self.assertIsNone(of_3.get_orcid(\"10.1108/jd-12-2013-0166\"))\n",
    "\n",
    "    def test_datacite_get_orcid(self):\n",
    "        # Do not use support files, only APIs\n",
    "        df_1 = DataCiteResourceFinder()\n",
    "        self.assertIn(\"0000-0001-7734-8388\", df_1.get_orcid(\"10.5065/d6b8565d\"))\n",
    "        self.assertNotIn(\"0000-0001-5506-523X\", df_1.get_orcid(\"10.5065/d6b8565d\"))\n",
    "\n",
    "        # Do use support files, but avoid using APIs\n",
    "        df_2 = DataCiteResourceFinder(\n",
    "            self.data,\n",
    "            use_api_service=False,\n",
    "        )\n",
    "        self.assertIn(\"0000-0001-7734-8388\", df_2.get_orcid(\"10.5065/d6b8565d\"))\n",
    "        self.assertNotIn(\"0000-0001-5506-523X\", df_2.get_orcid(\"10.5065/d6b8565d\"))\n",
    "\n",
    "        # Do not use support files neither APIs\n",
    "        df_3 = DataCiteResourceFinder(use_api_service=False)\n",
    "        self.assertIsNone(df_3.get_orcid(\"10.5065/d6b8565d\"))\n",
    "\n",
    "    def test_datacite_get_issn(self):\n",
    "        # Do not use support files, only APIs\n",
    "        df_1 = DataCiteResourceFinder()\n",
    "        self.assertIn(\"1406-894X\", df_1.get_container_issn(\"10.15159/ar.21.030\"))\n",
    "        self.assertNotIn(\"1588-2861\", df_1.get_container_issn(\"10.15159/ar.21.030\"))\n",
    "\n",
    "        # Do use support files, but avoid using APIs\n",
    "        df_2 = DataCiteResourceFinder(\n",
    "            self.data,\n",
    "            use_api_service=False,\n",
    "        )\n",
    "        self.assertIn(\"2197-6775\", df_2.get_container_issn(\"10.14763/2019.1.1389\"))\n",
    "        self.assertNotIn(\"1588-2861\", df_2.get_container_issn(\"10.14763/2019.1.1389\"))\n",
    "\n",
    "        # Do not use support files neither APIs\n",
    "        df_3 = DataCiteResourceFinder(use_api_service=False)\n",
    "        self.assertIsNone(df_3.get_container_issn(\"10.14763/2019.1.1389\"))\n",
    "\n",
    "    def test_datacite_get_pub_date(self):\n",
    "        # Do not use support files, only APIs\n",
    "        df_1 = DataCiteResourceFinder()\n",
    "        self.assertIn(\"2019-05-27\", df_1.get_pub_date(\"10.6092/issn.2532-8816/8555\"))\n",
    "        self.assertNotEqual(\"2019\", df_1.get_pub_date(\"10.6092/issn.2532-8816/8555\"))\n",
    "\n",
    "        # Do use support files, but avoid using APIs\n",
    "        df_2 = DataCiteResourceFinder(\n",
    "            self.data,\n",
    "            use_api_service=False,\n",
    "        )\n",
    "        self.assertIn(\"2019-05-27\", df_2.get_pub_date(\"10.6092/issn.2532-8816/8555\"))\n",
    "        self.assertNotEqual(\n",
    "            \"2018-01-02\", df_2.get_pub_date(\"10.6092/issn.2532-8816/8555\")\n",
    "        )\n",
    "\n",
    "        # Do not use support files neither APIs\n",
    "        df_3 = DataCiteResourceFinder(use_api_service=False)\n",
    "        self.assertIsNone(df_3.get_pub_date(\"10.6092/issn.2532-8816/8555\"))\n",
    "\n",
    "    def test_crossref_get_orcid(self):\n",
    "        # Do not use support files, only APIs\n",
    "        cf_1 = CrossrefResourceFinder()\n",
    "        self.assertIn(\n",
    "            \"0000-0003-0530-4305\", cf_1.get_orcid(\"10.1007/s11192-018-2988-z\")\n",
    "        )\n",
    "        self.assertNotIn(\n",
    "            \"0000-0001-5506-523X\", cf_1.get_orcid(\"10.1007/s11192-018-2988-z\")\n",
    "        )\n",
    "\n",
    "        # Do use support files, but avoid using APIs\n",
    "        cf_2 = CrossrefResourceFinder(\n",
    "            self.data,\n",
    "            use_api_service=False,\n",
    "        )\n",
    "        self.assertIn(\n",
    "            \"0000-0003-0530-4305\", cf_2.get_orcid(\"10.1007/s11192-018-2988-z\")\n",
    "        )\n",
    "        self.assertNotIn(\n",
    "            \"0000-0001-5506-523X\", cf_2.get_orcid(\"10.1007/s11192-018-2988-z\")\n",
    "        )\n",
    "\n",
    "        # Do not use support files neither APIs\n",
    "        cf_3 = CrossrefResourceFinder(use_api_service=False)\n",
    "        self.assertIsNone(cf_3.get_orcid(\"10.1007/s11192-018-2988-z\"))\n",
    "\n",
    "    def test_crossref_get_issn(self):\n",
    "        # Do not use support files, only APIs\n",
    "        cf_1 = CrossrefResourceFinder()\n",
    "        self.assertIn(\"0138-9130\", cf_1.get_container_issn(\"10.1007/s11192-018-2988-z\"))\n",
    "        self.assertNotIn(\n",
    "            \"0138-9000\", cf_1.get_container_issn(\"10.1007/s11192-018-2988-z\")\n",
    "        )\n",
    "\n",
    "        # Do use support files, but avoid using APIs\n",
    "        cf_2 = CrossrefResourceFinder(\n",
    "            self.data,\n",
    "            use_api_service=False,\n",
    "        )\n",
    "        self.assertIn(\"1588-2861\", cf_2.get_container_issn(\"10.1007/s11192-018-2988-z\"))\n",
    "        self.assertNotIn(\n",
    "            \"0138-9000\", cf_2.get_container_issn(\"10.1007/s11192-018-2988-z\")\n",
    "        )\n",
    "\n",
    "        # Do not use support files neither APIs\n",
    "        cf_3 = CrossrefResourceFinder(use_api_service=False)\n",
    "        self.assertIsNone(cf_3.get_container_issn(\"10.1007/s11192-018-2988-z\"))\n",
    "\n",
    "    def test_crossref_get_pub_date(self):\n",
    "        # Do not use support files, only APIs\n",
    "        cf_1 = CrossrefResourceFinder()\n",
    "        self.assertIn(\"2019-01-02\", cf_1.get_pub_date(\"10.1007/s11192-018-2988-z\"))\n",
    "        self.assertNotEqual(\"2019\", cf_1.get_pub_date(\"10.1007/s11192-018-2988-z\"))\n",
    "\n",
    "        # Do use support files, but avoid using APIs\n",
    "        cf_2 = CrossrefResourceFinder(\n",
    "            self.data,\n",
    "            use_api_service=False,\n",
    "        )\n",
    "        self.assertIn(\"2019-01-02\", cf_2.get_pub_date(\"10.1007/s11192-018-2988-z\"))\n",
    "        self.assertNotEqual(\n",
    "            \"2018-01-02\", cf_2.get_pub_date(\"10.1007/s11192-018-2988-z\")\n",
    "        )\n",
    "\n",
    "        # Do not use support files neither APIs\n",
    "        cf_3 = CrossrefResourceFinder(use_api_service=False)\n",
    "        self.assertIsNone(cf_3.get_pub_date(\"10.1007/s11192-018-2988-z\"))\n",
    "\n",
    "    def test_nationalinstititeofhealth_get_orcid(self):\n",
    "        #Do not use support files, only APIs\n",
    "        nf_1 = NIHResourceFinder()\n",
    "        self.assertNotIn(\"0000-0002-1825-0097\", nf_1.get_orcid(\"29998776\"))\n",
    "        self.assertNotIn(\"0000-0002-1825-0097\", nf_1.get_orcid(\"7189714\"))\n",
    "        self.assertEqual([], nf_1.get_orcid(\"29998776\"))\n",
    "        self.assertEqual([], nf_1.get_orcid(\"1509982\"))\n",
    "\n",
    "        # Do use support files, but avoid using APIs\n",
    "        nf_2 = NIHResourceFinder(\n",
    "            self.data,\n",
    "            use_api_service=False,\n",
    "        )\n",
    "        self.assertIn(\"0000-0001-8403-9735\", nf_2.get_orcid(\"29998776\"))\n",
    "        self.assertNotIn(\"0000-0002-1825-0097\", nf_2.get_orcid(\"1509982\"))\n",
    "\n",
    "        # Do not use support files neither APIs\n",
    "        nf_3 = NIHResourceFinder(use_api_service=False)\n",
    "        self.assertIsNone(nf_3.get_orcid(\"7189714\"))\n",
    "\n",
    "    def test_nationalinstititeofhealth_get_issn(self):\n",
    "        # Do not use support files, only APIs\n",
    "        nf_1 = NIHResourceFinder()\n",
    "        self.assertIn(\"0003-4819\", nf_1.get_container_issn(\"2942070\"))\n",
    "        self.assertNotIn(\"0003-0000\", nf_1.get_container_issn(\"2942070\"))\n",
    "\n",
    "        # Do use support files, but avoid using APIs\n",
    "        nf_2 = NIHResourceFinder(\n",
    "            self.data,\n",
    "            use_api_service=False,\n",
    "        )\n",
    "        container_issn = nf_2.get_container_issn(\"1509982\")\n",
    "        self.assertIn(\"0065-4299\", container_issn)\n",
    "        self.assertNotIn(\"0065-4444\", container_issn)\n",
    "\n",
    "        # Do not use support files neither APIs\n",
    "        nf_3 = NIHResourceFinder(use_api_service=False)\n",
    "        self.assertIsNone(nf_3.get_container_issn(\"7189714\"))\n",
    "\n",
    "    def test_nationalinstititeofhealth_get_pub_date(self):\n",
    "        # Do not use support files, only APIs\n",
    "        nf_1 = NIHResourceFinder()\n",
    "        self.assertIn(\"1998-05-25\", nf_1.get_pub_date(\"9689714\"))\n",
    "        self.assertNotEqual(\"1998\", nf_1.get_pub_date(\"9689714\"))\n",
    "\n",
    "        # Do use support files, but avoid using APIs\n",
    "        nf_2 = NIHResourceFinder(\n",
    "            self.data,\n",
    "            use_api_service=False,\n",
    "        )\n",
    "        self.assertIn(\"1980-06\", nf_2.get_pub_date(\"7189714\"))\n",
    "        self.assertNotEqual(\"1980-06-22\", nf_2.get_pub_date(\"7189714\"))\n",
    "\n",
    "        # Do not use support files neither APIs\n",
    "        nf_3 = NIHResourceFinder(use_api_service=False)\n",
    "        self.assertIsNone(nf_3.get_pub_date(\"2942070\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 (✓) - Integrazione id_type in finder con Giuseppe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (✓) spiegazione (come testare le modifiche fatte al software) + modifica <b>setup.py</b>: se aggiungo files executable va notificato nel setup, se invece modifico files esistenti no. basta rifare pip install. <b>glob_crossref</b> anziché crossref_glob è la ridefinizione del nome da chiamare in console: è il comando specificato in setup che ridefinisce come viene chiamato l'executable: ricorda di aggiungere a setup gli eseguibili che crei e di fare pip install . tutte le volte che modifichi qualcosa. Altra cosa da tenere a mente è tenere aggiornato il setup e i requirements con le librerie utilizzate. Tutto questo vale per il locale, perché per aggiungere qualcosa di nuovo al pacchetto biusogna aggiornare la libreria su pypy.\n",
    "\n",
    "- (✓) discutere <b>aggiunta di name == main negli script dei glob</b>: può rimanere e può essere sfruttato per lanciare i test dei glob. Al massimo è superfluo, ma non crea problemi.\n",
    "\n",
    "- (✓) Controllo di <b>modifiche a CSVManager e GLOB Crossref</b> + aggiunta a farm_revision\n",
    "\n",
    "- (✓) Discussione sviluppo di <b>NIHResourceFinder</b>: specificare in super il parametro id type (in crossref e datacite non necessario perché doi di default)\n",
    "\n",
    "- (da fare) Sostituire le print con <b>GET_LOGGER</b> (vedi documentazione)\n",
    "\n",
    "- () Aggiunta di id_type a farm_revision, nel file di configurazione: aggiungiamo chiavi nel file di configurazione per specificare doi o pmid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[identifier]\n",
    "pmid=oc.index.identifier.pmid:PMIDManager\n",
    "doi=oc.index.identifier.doi:DOIManager\n",
    "\n",
    "[logging]\n",
    "# If set to 1 the logs will be printed in console, by default \n",
    "# they are only saved in ~/.opencitations/index/logs\n",
    "verbose=1\n",
    "\n",
    "# Legacy data source info (using csv)\n",
    "[csv]\n",
    "valid_doi=path/to/valid_doi\n",
    "id_date=path/to/id_date\n",
    "id_orcid=path/to/id_orcid\n",
    "id_issn=path/to/id_issn\n",
    "\n",
    "# Redis data source info\n",
    "[redis]\n",
    "host=127.0.0.1\n",
    "port=6379\n",
    "batch_size=10000\n",
    "db=0\n",
    "\n",
    "[cnc]\n",
    "# ORCID API key to be used to query the ORCID API\n",
    "orcid=\n",
    "# Lookup table for oci encoding\n",
    "lookup=~/.opencitations/index/lookup.csv\n",
    "# True whenever you want to use the api in the resource finder\n",
    "use_api=true\n",
    "# Comma seperated available services\n",
    "services=COCI\n",
    "\n",
    "[CNC_SERVICE_TEMPLATE]\n",
    "# Prefix to use for creating the OCIs\n",
    "prefix=\n",
    "# Parser to use for reading citation data. It should be a class extending \n",
    "# oc.index.parsing.base.CitationParser the format accepted is package:class\n",
    "parser=\n",
    "# The URL of the source from where the citation data have been extracted\n",
    "source=\n",
    "# The URL of the agent providing or processing the citation data\n",
    "agent=\n",
    "# The base URL of the dataset\n",
    "baseurl=\n",
    "# The base URL of the identifier of citing and cited entities, if any\n",
    "idbaseurl=\n",
    "# The name of the service that will made available the  citation data.\n",
    "service=\n",
    "# The database to use for support data\n",
    "db=0\n",
    "\n",
    "[COCI]\n",
    "prefix=020\n",
    "parser=oc.index.parsing.crossref:CrossrefParser\n",
    "source=https://api.crossref.org/works/[[citing]]\n",
    "agent=https://w3id.org/oc/index/prov/pa/1\n",
    "baseurl=https://w3id.org/oc/index/coci/\n",
    "idbaseurl=http://dx.doi.org/\n",
    "service=OpenCitations Index: COCI\n",
    "datasource=redis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 (da finire) - Inserire glob NOCI (dopo integrazione id_type in finder) in farm_revision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 (da finire) - Testare i glob\n",
    "- riprendere test coci già sviluppato\n",
    "- riprendere test noci già sviluppato \n",
    "- testare tutti i glob insieme\n",
    "- verificare che i files di supporto vengano generati, che se i files ci sono già il processo funzioni correttamente e non riaggiunga entità già inserite, che i quattro processi (data, issn, orcid e validazione) funzionino correttamente, che vengano validati anche i doi citati.\n",
    "- chiedere a riunione dubbi su questioni di uniformità\n",
    "- nel glob di doci non funziona il salvataggio nel cache file (problema risolto nella versione precedente: ricontrolla e correggi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 (✓) - Articolo \n",
    "Rilettura finale e commento alla versione ridotta di Enabling Portability and Reusability of Open Science Infrastructures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 (✓) - CSV MANAGER\n",
    "modifica di load_all_csv_files per fare in modo di creare il csv chiamato e aggiungere gli headers (\"id\", \"value\") nel caso in cui non fosse già presente. Modifica controllata con Giuseppe e aggiunta in farm_revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    @staticmethod\n",
    "    def __load_all_csv_files(list_of_csv_files, fun, line_threshold, **params):\n",
    "        result = []\n",
    "        header = None\n",
    "\n",
    "        for csv_path in list_of_csv_files:\n",
    "            #NOTA: manca nella libreria\n",
    "            if not exists(csv_path):\n",
    "                #open(csv_path, \"w\").close() sostituito con:\n",
    "                with open(csv_path, \"w\", encoding=\"utf8\") as f:\n",
    "                    f.write('\"id\",\"value\"\\n')\n",
    "                    f.close() #necessario? in add_value non c'è\n",
    "            with open(csv_path, encoding=\"utf-8\") as f:\n",
    "                csv_content = \"\"\n",
    "                for idx, line in enumerate(f.readlines()):\n",
    "                    if header is None:\n",
    "                        header = line\n",
    "                        csv_content = header\n",
    "                    else:\n",
    "                        if idx % line_threshold == 0:\n",
    "                            result.append(fun(csv_content, **params))\n",
    "                            csv_content = header\n",
    "                        csv_content += line\n",
    "\n",
    "            result.append(fun(csv_content, **params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11 (✓) Crossref GLOB\n",
    "- modifica a validazione di doi citanti e citati a seguito del refactoring della classe DOIManager. Modifica controllata e aggiunta a farm_revision con Giuseppe. \n",
    "- <b>modifica a processo di aggiunta date citati</b>: praticamente tutti i citati venivano aggiunti al file di supporto id_date associati a stringa vuota. è necessario? per ora ho fatto una modifica e i doi non associati a valori di date non vengono aggiunti direttamente al file. Però se era stato fatto così ci deve essere un motivo, quindi va discusso. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from os import sep, makedirs, walk\n",
    "from os.path import exists, basename, isdir\n",
    "from json import load, loads\n",
    "from collections import Counter\n",
    "from datetime import date\n",
    "from timeit import default_timer as timer\n",
    "from re import sub\n",
    "import tarfile\n",
    "\n",
    "\n",
    "from oc.index.oci.citation import Citation\n",
    "from oc.index.legacy.csv import CSVManager\n",
    "from oc.index.identifier.doi import DOIManager\n",
    "from oc.index.identifier.issn import ISSNManager\n",
    "from oc.index.identifier.orcid import ORCIDManager\n",
    "\n",
    "\n",
    "def build_pubdate(obj):\n",
    "    if \"issued\" in obj:  # Main citing object\n",
    "        if \"date-parts\" in obj[\"issued\"]:\n",
    "            # is an array of parts of dates\n",
    "            try:\n",
    "                obj_date = obj[\"issued\"][\"date-parts\"][0]\n",
    "\n",
    "                # lisdate[year,month,day]\n",
    "                listdate = [1, 1, 1]\n",
    "                dateparts = []\n",
    "                for i in range(0, len(obj_date)):\n",
    "                    try:\n",
    "                        dateparts.append(obj_date[i])\n",
    "                        intvalue = int(obj_date[i])\n",
    "                        listdate[i] = intvalue\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                # I have a date, so generate it\n",
    "                if (\n",
    "                    (1 < listdate[0] < 3000)\n",
    "                    and (0 < listdate[1] <= 12)\n",
    "                    and (0 < listdate[2] <= 31)\n",
    "                ):\n",
    "                    date_val = date(listdate[0], listdate[1], listdate[2])\n",
    "                    dformat = \"%Y\"\n",
    "\n",
    "                    # only month is specified\n",
    "                    if len(dateparts) == 2:\n",
    "                        dformat = \"%Y-%m\"\n",
    "                    elif len(dateparts) == 3 and (\n",
    "                        dateparts[1] != 1 or (dateparts[1] == 1 and dateparts[2] != 1)\n",
    "                    ):\n",
    "                        dformat = \"%Y-%m-%d\"\n",
    "\n",
    "                    date_in_str = date_val.strftime(dformat)\n",
    "                    return date_in_str\n",
    "            except:\n",
    "                pass\n",
    "    elif \"year\" in obj:  # Reference object\n",
    "        ref_year = sub(\"[^\\d]\", \"\", obj[\"year\"])[:4]\n",
    "        if ref_year:\n",
    "            return ref_year\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_all_files(i_dir_or_targz_file):\n",
    "    result = []\n",
    "    targz_fd = None\n",
    "\n",
    "    if isdir(i_dir_or_targz_file):\n",
    "        for cur_dir, cur_subdir, cur_files in walk(i_dir_or_targz_file):\n",
    "            for cur_file in cur_files:\n",
    "                if cur_file.endswith(\".json\") and not basename(cur_file).startswith(\n",
    "                    \".\"\n",
    "                ):\n",
    "                    result.append(cur_dir + sep + cur_file)\n",
    "    elif i_dir_or_targz_file.endswith(\"tar.gz\"):\n",
    "        targz_fd = tarfile.open(i_dir_or_targz_file, \"r:gz\", encoding=\"utf-8\")\n",
    "        for cur_file in targz_fd:\n",
    "            if cur_file.name.endswith(\".json\") and not basename(\n",
    "                cur_file.name\n",
    "            ).startswith(\".\"):\n",
    "                result.append(cur_file)\n",
    "    else:\n",
    "        print(\"It is not possible to process the input path.\")\n",
    "    return result, targz_fd\n",
    "\n",
    "\n",
    "def load_json(file, targz_fd, file_idx, len_all_files):\n",
    "    result = None\n",
    "\n",
    "    if targz_fd is None:\n",
    "        print(\"Open file %s of %s\" % (file_idx, len_all_files))\n",
    "        with open(file, encoding=\"utf8\") as f:\n",
    "            result = load(f)\n",
    "    else:\n",
    "        print(\"Open file %s of %s (in tar.gz archive)\" % (file_idx, len_all_files))\n",
    "        cur_tar_file = targz_fd.extractfile(file)\n",
    "        json_str = cur_tar_file.read()\n",
    "\n",
    "        # In Python 3.5 it seems that, for some reason, the extractfile method returns an\n",
    "        # object 'bytes' that cannot be managed by the function 'load' in the json package.\n",
    "        # Thus, to avoid issues, in case an object having type 'bytes' is return, it is\n",
    "        # transformed as a string before passing it to the function 'loads'. Please note\n",
    "        # that Python 3.9 does not show this behaviour, and it works correctly without\n",
    "        # any transformation.\n",
    "        if type(json_str) is bytes:\n",
    "            json_str = json_str.decode(\"utf-8\")\n",
    "\n",
    "        result = loads(json_str)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def process(input_dir, output_dir):\n",
    "    start = timer()\n",
    "    if not exists(output_dir):\n",
    "        makedirs(output_dir)\n",
    "\n",
    "    citing_doi_with_no_date = set()\n",
    "    valid_doi = CSVManager(output_dir + sep + \"valid_doi.csv\")\n",
    "    id_date = CSVManager(output_dir + sep + \"id_date.csv\")\n",
    "    id_issn = CSVManager(output_dir + sep + \"id_issn.csv\")\n",
    "    id_orcid = CSVManager(output_dir + sep + \"id_orcid.csv\")\n",
    "\n",
    "    doi_manager = DOIManager()\n",
    "    issn_manager = ISSNManager()\n",
    "    orcid_manager = ORCIDManager()\n",
    "\n",
    "    all_files, targz_fd = get_all_files(input_dir)\n",
    "    len_all_files = len(all_files)\n",
    "\n",
    "    # Read all the JSON file in the Crossref dump to create the main information of all the indexes\n",
    "    print(\"\\n\\n# Add valid DOIs from Crossref metadata\")\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        data = load_json(file, targz_fd, file_idx, len_all_files)\n",
    "\n",
    "        if \"items\" in data:\n",
    "            for obj in data[\"items\"]:\n",
    "                if \"DOI\" in obj:\n",
    "                    citing_doi = doi_manager.normalise(obj[\"DOI\"], True)\n",
    "                    #valid_doi.add_value(citing_doi, \"v\" if doi_manager.is_valid(citing_doi) else \"i\")\n",
    "                    valid_doi.add_value(citing_doi, \"v\") # NB:  add value aggiunge l'id se non c'era e aggiunge il valore al set di valori. Cosa succede se il valore c'è giù ed è invalid?\n",
    "\n",
    "                    if id_date.get_value(citing_doi) is None:\n",
    "                        citing_date = Citation.check_date(build_pubdate(obj))\n",
    "                        if citing_date is not None:\n",
    "                            id_date.add_value(citing_doi, citing_date)\n",
    "                            if citing_doi in citing_doi_with_no_date:\n",
    "                                citing_doi_with_no_date.remove(citing_doi)\n",
    "                        else:\n",
    "                            citing_doi_with_no_date.add(citing_doi)\n",
    "\n",
    "                    if id_issn.get_value(citing_doi) is None:\n",
    "                        if \"type\" in obj:\n",
    "                            cur_type = obj[\"type\"]\n",
    "                            if (\n",
    "                                cur_type is not None\n",
    "                                and \"journal\" in cur_type\n",
    "                                and \"ISSN\" in obj\n",
    "                            ):\n",
    "                                cur_issn = obj[\"ISSN\"]\n",
    "                                if cur_issn is not None:\n",
    "                                    for issn in [\n",
    "                                        issn_manager.normalise(issn)\n",
    "                                        for issn in cur_issn\n",
    "                                    ]:\n",
    "                                        if issn is not None:\n",
    "                                            id_issn.add_value(citing_doi, issn)\n",
    "\n",
    "                    if id_orcid.get_value(citing_doi) is None:\n",
    "                        if \"author\" in obj:\n",
    "                            cur_author = obj[\"author\"]\n",
    "                            if cur_author is not None:\n",
    "                                for author in cur_author:\n",
    "                                    if \"ORCID\" in author:\n",
    "                                        orcid = orcid_manager.normalise(author[\"ORCID\"])\n",
    "                                        if orcid is not None:\n",
    "                                            id_orcid.add_value(citing_doi, orcid)\n",
    "\n",
    "\n",
    "    middle =timer()\n",
    "    print(\"first process duration: :\", (middle - start))\n",
    "    # Do it again for updating the dates of the cited DOIs, if these are valid\n",
    "    print(\"\\n\\n# Check cited DOIs from Crossref reference field\")\n",
    "    doi_date = {}\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        data = load_json(file, targz_fd, file_idx, len_all_files)\n",
    "\n",
    "        if \"items\" in data:\n",
    "            for obj in data[\"items\"]:\n",
    "                if \"DOI\" in obj and \"reference\" in obj:\n",
    "                    for ref in obj[\"reference\"]:\n",
    "                        if \"DOI\" in ref:\n",
    "                            cited_doi = doi_manager.normalise(ref[\"DOI\"], True)\n",
    "                            if valid_doi.get_value(cited_doi) is None: #or valid_doi.get_value(cited_doi) == \"i\":\n",
    "                                # condizione aggiunta per evitare di validare di nuovo tramite API doi già validati\n",
    "                                # DA OTTIMIZZARE\n",
    "                                valid_doi.add_value(cited_doi, \"v\" if doi_manager.is_valid(cited_doi) else \"i\")\n",
    "                                if valid_doi.get_value(cited_doi) == \"v\" and id_date.get_value(cited_doi) is None:\n",
    "                                    if cited_doi not in doi_date:\n",
    "                                        doi_date[cited_doi] = []\n",
    "                                    cited_date = Citation.check_date(build_pubdate(ref))\n",
    "                                    if cited_date is not None:\n",
    "                                        doi_date[cited_doi].append(cited_date)\n",
    "                                        if cited_doi in citing_doi_with_no_date:\n",
    "                                            citing_doi_with_no_date.remove(cited_doi)\n",
    "\n",
    "    # Add the date to the DOI if such date is the most adopted one in the various references.\n",
    "    # In case two distinct dates are used the most, select the older one.\n",
    "    for doi in doi_date:\n",
    "        count = Counter(doi_date[doi])\n",
    "        if len(count):\n",
    "            top_value = count.most_common(1)[0][1]\n",
    "            selected_dates = []\n",
    "            for date in count:\n",
    "                if count[date] == top_value:\n",
    "                    selected_dates.append(date)\n",
    "            best_date = sorted(selected_dates)[0]\n",
    "            id_date.add_value(doi, best_date)\n",
    "        else:\n",
    "            # id_date.add_value(doi, \"\")\n",
    "            pass\n",
    "\n",
    "\n",
    "    # Add emtpy dates for the remaining DOIs\n",
    "    for doi in citing_doi_with_no_date:\n",
    "        id_date.add_value(doi, \"\")\n",
    "\n",
    "    # Close the file descriptor of the tar.gz archive if it was used\n",
    "    if targz_fd is not None:\n",
    "        targz_fd.close()\n",
    "\n",
    "    end = timer()\n",
    "    print(\"second process duration: \", end-middle)\n",
    "    print(\"full process duration: \", end-start)\n",
    "\n",
    "def main():\n",
    "    arg_parser = ArgumentParser(\n",
    "        \"Global files creator for COCI\",\n",
    "        description=\"Process Crossref JSON files and create global indexes to enable \"\n",
    "        \"the creation of COCI.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-i\",\n",
    "        \"--input_dir\",\n",
    "        dest=\"input_dir\",\n",
    "        required=True,\n",
    "        help=\"Either the directory or the zip file that contains the Crossref data dump \"\n",
    "        \"of JSON files.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-o\",\n",
    "        \"--output_dir\",\n",
    "        dest=\"output_dir\",\n",
    "        required=True,\n",
    "        help=\"The directory where the indexes are stored.\",\n",
    "    )\n",
    "\n",
    "    args = arg_parser.parse_args()\n",
    "    process(args.input_dir, args.output_dir)\n",
    "\n",
    "# Added for testing purposes, in the official version it should be removed\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "# GitHub\\index>python \"scripts/crossref_glob.py\" -i ./index/python/test/data/crossref_glob_dump_input -o ./index/python/test/data/crossref_glob_dump_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domande\n",
    "#### finder\n",
    "- questione date per NIH\n",
    "#### glob\n",
    "- richiedere spiegazione su doi senza data, chiedere se va fatta la stessa cosa anche con gli altri glob o se è una specifica di crossref\n",
    "- chiedere se cache file per ISSN va inserito anche negli altri glob (crossref)\n",
    "- chiedere perché per i doi senza data citati in crossref l'entità viene aggiunta a id_date con stringa vuota: è utile che un'entità di cui non abbiamo la data figuri nel file di supporto? il valore stringa vuota rimane nel set dei valori associati ad un id anche quando viene associata una data successivamente?\n",
    "- chiedere chiarimento sulla possibilità di rivalidare un doi invalido: è posssibile che un doi invalido in un momento sia valido successivamente? è un controllo che va rifatto o assumiamo che un doi invalido resterà sempre ivalido?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DA FARE\n",
    "- controlla i punti senza check alla luce delle risposte alle domande (uniformare glob, sistemare cache issn, risolvere get_date nel finder NIH, scrivere test dei glob): ho appuntato qui le cose da fare per proseguire il lavoro sui parser e sui finder (sono da finire per la prossima settimana - ho spostato la scadenza su trello)\n",
    "- Aggiungere DOCI e NOCI al file di configurazione (vedi COCI)\n",
    "- Rivedi punto su META: finiti glob e finder, creare software per creare tabelle per META\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (07/06 - 21/06) - iCiteMetadata preprocessing, NIH finder, NIH glob, test glob, tabelle csv per META NOCI + DOCI, DOCI + NOCI validate\n",
    "<a id=\"entry_15\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPEN SCIENCE GRAPHS INTEROPERABILITY \n",
    "- Authors: Open Science Graphs for FAIR Data Interest Group\n",
    "- Meeting agenda: https://www.rd-alliance.org/plenaries/rda-19th-plenary-meeting-part-international-data-week-20%E2%80%9323-june-2022-seoul-south-korea-7 \n",
    "- Presentazione : introduzione/ recap sul tema + 3 presentazioni sull'interoperabilità nell'Open Science\n",
    "\n",
    "<ol>\n",
    "    <li><b>Manocci, Open Science Graphs</b>: rappresentazioni delle entità di ricerca oltre il PDF, tenere traccia delle relazioni tra entità attraverso authoritative registries, connessioni tra elementi depositati. Vedi paper Manghi <b>Open Science Graphs Must Interoperate!</b>. Prima classificazione basata su sette dimensioni: Research entities modelled, Apploations served, Data sources integrated, Added value, Data export and provisioning, FAIRness, Openness. Tutto ciò sarebbe utile a ricercatori e metaricercatori (ricercatori in ambito science of science), ma anche ad aggregatori di dati (come imprese o infrastrutture di ricerca), che potrebbero contare su un framework comune per integrare informazioni provenienti da diversi grafi. Use cases: 1) Sincronizzazione di entità e relazioni, bulk dump (interrogabile in maniera modulare a seconda del tema di interesse). <b>Core information model:</b> Research artefacts (pubblicazioni, dataset, patenti, software), research concepts, organisations, persons, projects/funders, protocols, services (può essere estesa). <b>The Whys and Hows of Scholarly Repository Registries Interoperability.</b>: paper di Manghi, Manocci e altri appena consegnato. </li>\n",
    "    <li><b>Kristian Garza (DataCite): PID Graph - An Open Science Graph</b></li>\n",
    "    <li><b>Matthias Liffers (ARDC): Persistent identifiers and interoperability </b></li>\n",
    "    <li><b>Enrico Daga (Open University): Streamlining semantic data publishing with SPARQL Anything</b></li>\n",
    "    <li><b>Paolo Manghi: WG on OSG interoperability Roadmap: JUNE 20th - January 2023</b>. L'obiettivo è quello di produrre un breve documento che spieghi in maniera efficace (e non prolissa): core information model, common metadata format, protocolli di accesso, OSG profile, da pubblicare su Zenodo. Hanno insistito sul fatto di essere concisi ed efficaci. Apprezzano la partecipazione.</li>\n",
    "</ol>\n",
    "\n",
    "<b>TASK FORCES</b>\n",
    "<ol>\n",
    "    <li><b>TF 1: OSG CORE INFORMATION MODEL</b>: (da ora a fine settembre) cosa a cui daranno la precedenza, consiste nell'identificare le entità e use case scenarios, una survey sugli standard information models, PIDs, per le entità, e definizione incrementale del core model. Si tratta di identificare entità e proprietà da tracciare. L'obiettivo è avere qualcosa di fatto per fine settembre. Questa task si sovrapporrà in parte con:</li>\n",
    "    <li><b>TF 2: OSG DATA EXCHANGE COMMONS</b>: (da ora a novembre) In questa task rientra la survey sui metadata format per le entità (es. Dublin Core, DataCite...), e la scelta del Core Metadata Format. Anche questo deve svilupparsi in maniera incrementale, seguendo le evoluzioni del TF1.</li>\n",
    "    <li><b>TF 3: OSG ACCESS PROTOCOL COMMONS:</b> (da ottobre a gennaio). Si tratta dell'analisi degli standard protocols e approcci per scambiare dati tra grafi (RESTful API, SPARQL...), e della scelta di quelli adatti al caso in questione. Questa task verrà iniziata solo una volta definito un linguaggio comune ed aver scelto come scambiare i dati. La parte di backend non si basa necessariamente su rdf. </li>\n",
    "    <li><b>TF 4: OSG ACCESS PROTOCOL COMMONS: </b>(da ottobre a gennaio). Non si tratta di una priorità stringente ai fini dell'interoperabilità, tuttavia è un valore aggiunto molto interessante. Non è una task facile, e probabilmente sarà una delle più lunghe. In questo caso la deadline è pittosto flessibile. Consiste nel definire il profilo OSG, con attributi e vocabolario. Anche di questo ci sarà da pubblicare un breve documento su Zenodo.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICite Metadata Preprocessing \n",
    "il Glob di NOCI non utilizza lo stesso dump del parser, ma <b>iCiteMetadata</b>, un file csv di <b>21,53 GB</b> (versione non aggiornata, ora potrebbe essere di più). Oltre ad essere un altro file di grandi dimensioni, iCiteMetadata - a differenza di NIH-OCC usato dal parser - contiene anche diversi campi non utili per opencitations. Per questo motivo, <b>la classe per il preprocessing di NIH ed il test relativo sono stati estesi per preprocessare anche i dati di iCiteMetadata, dividendo il file iniziale in file minori e scartando i campi inutilizzati</b>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NIH PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "import unittest\n",
    "from os.path import join, exists\n",
    "from oc.index.preprocessing.nih_pp import NIHPreProcessing\n",
    "import shutil\n",
    "import csv\n",
    "\n",
    "\n",
    "class NOCIPPTest(unittest.TestCase):\n",
    "    \"\"\"This class aims at testing the methods of the classes NIHPreProcessing and ICiteMDPreProcessing.\"\"\"\n",
    "\n",
    "    def setUp(self):\n",
    "        self.test_dir = join(\"index\", \"python\", \"test\", \"data\")\n",
    "        self.NIHPP = NIHPreProcessing()\n",
    "        self.num_0 = 356\n",
    "        self.num_1 = 8\n",
    "        self.num_2 = 5\n",
    "        self.num_3 = 300\n",
    "        self.num_4 = 4\n",
    "\n",
    "        # NIH-OCC data, for NOCI parser\n",
    "        self.input_dir = join(self.test_dir, \"noci_pp_dump_input\")\n",
    "        self.output_dir = join(self.test_dir, \"noci_pp_dump_output\")\n",
    "        self.lines_sample = [\n",
    "            [1, 14161139],\n",
    "            [1, 14323813],\n",
    "            [1, 4990046],\n",
    "            [1, 4988806],\n",
    "            [2, 4150960],\n",
    "            [2, 4356257],\n",
    "            [2, 4846745],\n",
    "            [2, 4357832],\n",
    "        ]\n",
    "        self.headers = [\"citing\", \"referenced\"]\n",
    "\n",
    "        # iCite Metadata, for NOCI glob\n",
    "        self.input_md_dir = join(self.test_dir, \"noci_md_pp_dump_input\")\n",
    "        self.output_md_dir = join(self.test_dir, \"noci_md_pp_dump_output\")\n",
    "\n",
    "        self.headers_md = [\n",
    "            \"pmid\",\n",
    "            \"doi\",\n",
    "            \"title\",\n",
    "            \"authors\",\n",
    "            \"year\",\n",
    "            \"journal\",\n",
    "            \"cited_by\",\n",
    "            \"references\"\n",
    "        ]\n",
    "\n",
    "        self.lines_sample_md = [\n",
    "            [1,\"10.1016/0006-2944(75)90147-7\",\"Formate assay in body fluids: application in methanol poisoning.\",\"A B Makar, K E McMartin, M Palese, T R Tephly\",1975,\"Biochem Med\",\"27354968 6430597 27548239 7055965 30849241 21923939 6525992 7004236 33554654 34013366 34176544 34122605 6875695 109089 6615550 7396890 31264500 518695 33134728 27574557 30612633 28159467 33825562 2920026 24058668 2219121 2566887 6915 2733395 2334642 21569229 21912457 32727301 8461035 7265415 18553624 17016 20870 941156 6767446 28002644 32820233 19454010 3112558 33872434 24589977 6383751 7361809 7471469 9750739 34142875 28851427 29460824 31371922 33561370 30186270 3754027 7205659 99844 405471 24004664 31123410 115004 6815832 8040258 23350017 25489175 32660571 3537623 728186 20184691 7165305 32733622 7230276 214088 3789485 6968503 3426949 27555514 6549198 31544580 6634838 32765117\",\"4972128 4332837 13672941 14203183 14161139 14323813 4990046 4988806\"],\n",
    "            [2,\"10.1016/0006-291x(75)90482-9\",\"Delineation of the intimate details of the backbone conformation of pyridine nucleotide coenzymes in aqueous solution.\",\"K S Bose, R H Sarma\",1975,\"Biochem Biophys Res Commun\",\"6267127 26376 29458872 25548608 190032 22558138 26259654 31435170 28302598 21542697 26140007 890065 31544580 990401 39671\",\"4150960 4356257 4846745 4357832 4683494 4414857 4337195 4747846 4266012 4147828 1111570 4366080 1133382 4364802 4709237 4733399 4379057 17742850\"],\n",
    "            [3,\"10.1016/0006-291x(75)90498-2\",\"Metal substitutions incarbonic anhydrase: a halide ion probe study.\",\"R J Smith, R G Bryant\",1975,\"Biochem Biophys Res Commun\",\"25624746 33776281 32427033 28053241 22558138 24349293 7022113 24775716 27767123 29897055 13818 23643052 12463\",\"4632671 4977579 4992430 4958988 14417215 4992429 4621826 804171 4263471 4625501 4399045 4987292 4628675\"],\n",
    "            [4,\"10.1016/0006-291x(75)90506-9\",\"Effect of chloroquine on cultured fibroblasts: release of lysosomal hydrolases and inhibition of their uptake.\",\"U N Wiesmann, S DiDonato, N N Herschkowitz\",1975,\"Biochem Biophys Res Commun\",\"564972 8907731 7060838 6734624 31258218 7906514 27528195 19261 8216204 6221090 6365083 6870915 518687 2932104 7378072 28111290 7020765 6239657 1673037 895139 6817901 29684045 2937496 1660878 2961332 26308401 6284168 2543468 27136678 7138559 33597631 31536476 22305045 2452090 8295847 6793366 6615487 7151282 21816972 32663199 7342970 7057100 428466 7236683 2864350 6712986 6273196 31480869 27727286 21975914 476148 2933416 2530086 27146891 6228287 27328325 3827950 7190150 6279685 1015835 6276663 2730569 7314075 3877059 7165718 12763\",\"13663253 4271529 5021451 4607946 4374680 14907713 4275378 806251 4972437 4345092 4606365 4364008\"],\n",
    "            [5,\"10.1016/0006-291x(75)90508-2\",\"Atomic models for the polypeptide backbones of myohemerythrin and hemerythrin.\",\"W A Hendrickson, K B Ward\",1975,\"Biochem Biophys Res Commun\",\"7118409 6768892 2619971 2190210 3380793 20577584 8372226 7012375 856811 678527 33255345 33973855 402092 7012894 1257769 861288 1061139 3681996\",\"4882249 5059118 14834145 1056020 5509841\"],\n",
    "            [6,\"10.1016/0006-291x(75)90518-5\",\"Studies of oxygen binding energy to hemoglobin molecule.\",\"Y W Chow, R Pietranico, A Mukerji\",1975,\"Biochem Biophys Res Commun\",\"26668515 32953401 33134728 32470071 28601826 31567007 33094064\",\"4645548 14794725 16587956 14328650 1120094\"],\n",
    "            [7,\"10.1016/0006-2952(75)90020-9\",\"Maturation of the adrenal medulla--IV. Effects of morphine.\",\"T R Anderson, T A Slotkin\",1975,\"Biochem Pharmacol\",\"31215303 9414029 18246 41093 21355 6294570 942452 6870481 27705745 2858585 980225 24006099 5098 6259468 30612633 27030978 1271281 3003477 7001 7791109 6713511 999726 6280102 33872136 1774133 33872434\",\"17517355 15836459 15364646 18984078 20028328 5382448 18200670 4678819 17135164 15277068 12676044 15273078 20091597 5846992 11434754 17943819 17365137 18204101 18066129 17470951 1153082 15853441 16011454 22432689 14065927 15078424 16830309 21328257 18928139 15927926 1092305 11555193 19842218 15277090 22432635 21871125 17594991 5949627 22432564 14973986 11106086 14627335 12832592 21259185 4726566 15802416 21228727 4726565 15277076 19476742 21820672 15942912 22435354 16752934 16635970 15277109 22435615 16880367 18484782 6017359 19591529 19615308 11950176 18425916 22432518 15783241 19086008 12427501 16487688 16093238 22435415 18928148 4400965 4763252 12950418 17317655 18584321 18955223 4148818 10885091 4685445 16338199 16520304 1834807 15571467 18285310 4403908 4937070 12020172 21782365 19588398 15095142 17182489 15829470 22432729 235930 20370653\"],\n",
    "            [8,\"10.1016/0006-2952(75)90029-5\",\"Comparison between procaine and isocarboxazid metabolism in vitro by a liver microsomal amidase-esterase.\",\"K Moroi, T Sato\",1975,\"Biochem Pharmacol\",\"9224641 4004904 2756715 3245748 8743560 6745527 27034524 31695317 4059658 1876749 21846409 6712734 31632046 32005835 8218228 6875867 3706263 6612732 907716 7087253 3974403 463492 7181951 33977870 34121840 9586587 6770417 31664040 6123588 6239051 7295325 25584359 8654187 301955 537261 6126328 6772191 6494163 7203374\",\"19701189 9014768 21102463 18587394 13249955 15480983 18618634 16747230 16228179 19903424 4429589 17968351 17504508 4610350 19462429 4346266 15537905 19805227 8780562 4284968 14907713 16863561 15157825 19453248 5066156 4650633 18145350 19898471 2925048 20445446 20197757 6053218 18719139 20483763 16610046 19817673 4741776 13734134 20256398 11385576 15812518 18849966 20839313 17068223 8587604 12851870 14292314 19966812 4972656 20024904 5150150 3396969 14042697 4239096\"],\n",
    "        ]\n",
    "\n",
    "    def test_dump_split(self):\n",
    "        if exists(self.output_dir):\n",
    "            shutil.rmtree(self.output_dir)\n",
    "        self.assertFalse(exists(self.output_dir))\n",
    "        self.NIHPP.dump_split(self.input_dir, self.output_dir, self.num_3)\n",
    "\n",
    "        # checks that the output directory is generated in the process.\n",
    "        self.assertTrue(exists(self.output_dir))\n",
    "\n",
    "        # checks that the input lines where stored in 2 files, one containing 300 items and the other the remaining 56\n",
    "        files = self.NIHPP.get_all_files(self.output_dir)\n",
    "        len_files = len(files)\n",
    "        self.assertEqual(len_files, 2)\n",
    "        for idx, file in enumerate(files):\n",
    "            with open(file, \"r\") as op_file:\n",
    "                reader = csv.reader(op_file, delimiter=\",\")\n",
    "                next(reader, None)\n",
    "                len_lines = len(list(reader))\n",
    "                self.assertTrue(len_lines == 300 or len_lines == 56)\n",
    "\n",
    "\n",
    "    def test_icmd_split(self):\n",
    "        if exists(self.output_md_dir):\n",
    "            shutil.rmtree(self.output_md_dir)\n",
    "        self.assertFalse(exists(self.output_md_dir))\n",
    "        self.NIHPP.dump_split(self.input_md_dir, self.output_md_dir, self.num_3, filter_col=self.headers_md)\n",
    "\n",
    "        # checks that the output directory is generated in the process.\n",
    "        self.assertTrue(exists(self.output_md_dir))\n",
    "\n",
    "        # checks that the input lines where stored in 2 files, one containing 300 items and the other the remaining 56\n",
    "        files = self.NIHPP.get_all_files(self.output_md_dir)\n",
    "        len_files = len(files)\n",
    "        self.assertEqual(len_files, 2)\n",
    "        for idx, file in enumerate(files):\n",
    "            with open(file, \"r\") as op_file:\n",
    "                reader = csv.reader(op_file, delimiter=\",\")\n",
    "                next(reader, None)\n",
    "                len_lines = len(list(reader))\n",
    "                print(\"len_lines\", len_lines)\n",
    "                self.assertTrue(len_lines == 300 or len_lines == 56)\n",
    "\n",
    "    def test_icmd_chunk_to_file(self):\n",
    "        if exists(self.output_md_dir):\n",
    "            shutil.rmtree(self.output_md_dir)\n",
    "        self.assertFalse(exists(self.output_md_dir))\n",
    "        self.NIHPP.chunk_to_file(\n",
    "            self.num_1, self.num_4, self.output_md_dir, self.headers_md, self.lines_sample_md\n",
    "        )\n",
    "\n",
    "        # checks that chunk_to_file recreates the output directory\n",
    "        self.assertTrue(exists(self.output_md_dir))\n",
    "\n",
    "        # checks that the input lines are correctly stored in a file\n",
    "        files = self.NIHPP.get_all_files(self.output_md_dir)\n",
    "        self.assertGreater(len(files), 0)\n",
    "\n",
    "        # CSVFile_2.csv : target number (num_4) is 4 and current number (num_1) is 8 --> 8%4 == 0,  8//4  == 2\n",
    "        self.assertTrue(exists(join(self.output_md_dir, \"CSVFile_2.csv\")))\n",
    "\n",
    "        # runs again the process using a current number which is not a multiple of the target number, i.e.: 5\n",
    "        shutil.rmtree(self.output_md_dir)\n",
    "        self.assertFalse(exists(self.output_md_dir))\n",
    "        self.NIHPP.chunk_to_file(\n",
    "            self.num_2, self.num_4, self.output_md_dir, self.headers_md, self.lines_sample_md\n",
    "        )\n",
    "\n",
    "        # checks that chunk_to_file recreates the output directory\n",
    "        self.assertTrue(exists(self.output_md_dir))\n",
    "\n",
    "        # checks that the input lines are correctly stored in a file\n",
    "        files = self.NIHPP.get_all_files(self.output_md_dir)\n",
    "        self.assertGreater(len(files), 0)\n",
    "\n",
    "        # CSVFile_Rem.csv : target number (num_4) is 4 and current number (num_1) is 8 --> 8%4 == 0,  8//4  == 2\n",
    "        self.assertTrue(exists(join(self.output_md_dir, \"CSVFile_Rem.csv\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NIH PREPROCESSING TEST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "import unittest\n",
    "from os.path import join, exists\n",
    "from oc.index.preprocessing.nih_pp import NIHPreProcessing\n",
    "import shutil\n",
    "import csv\n",
    "\n",
    "\n",
    "class NOCIPPTest(unittest.TestCase):\n",
    "    \"\"\"This class aims at testing the methods of the classes NIHPreProcessing and ICiteMDPreProcessing.\"\"\"\n",
    "\n",
    "    def setUp(self):\n",
    "        self.test_dir = join(\"index\", \"python\", \"test\", \"data\")\n",
    "        self.NIHPP = NIHPreProcessing()\n",
    "        self.num_0 = 356\n",
    "        self.num_1 = 8\n",
    "        self.num_2 = 5\n",
    "        self.num_3 = 300\n",
    "        self.num_4 = 4\n",
    "\n",
    "        # NIH-OCC data, for NOCI parser\n",
    "        self.input_dir = join(self.test_dir, \"noci_pp_dump_input\")\n",
    "        self.output_dir = join(self.test_dir, \"noci_pp_dump_output\")\n",
    "        self.lines_sample = [\n",
    "            [1, 14161139],\n",
    "            [1, 14323813],\n",
    "            [1, 4990046],\n",
    "            [1, 4988806],\n",
    "            [2, 4150960],\n",
    "            [2, 4356257],\n",
    "            [2, 4846745],\n",
    "            [2, 4357832],\n",
    "        ]\n",
    "        self.headers = [\"citing\", \"referenced\"]\n",
    "\n",
    "        # iCite Metadata, for NOCI glob\n",
    "        self.input_md_dir = join(self.test_dir, \"noci_md_pp_dump_input\")\n",
    "        self.output_md_dir = join(self.test_dir, \"noci_md_pp_dump_output\")\n",
    "\n",
    "        self.headers_md = [\n",
    "            \"pmid\",\n",
    "            \"doi\",\n",
    "            \"title\",\n",
    "            \"authors\",\n",
    "            \"year\",\n",
    "            \"journal\",\n",
    "            \"cited_by\",\n",
    "            \"references\"\n",
    "        ]\n",
    "\n",
    "        self.lines_sample_md = [\n",
    "            [1,\"10.1016/0006-2944(75)90147-7\",\"Formate assay in body fluids: application in methanol poisoning.\",\"A B Makar, K E McMartin, M Palese, T R Tephly\",1975,\"Biochem Med\",\"27354968 6430597 27548239 7055965 30849241 21923939 6525992 7004236 33554654 34013366 34176544 34122605 6875695 109089 6615550 7396890 31264500 518695 33134728 27574557 30612633 28159467 33825562 2920026 24058668 2219121 2566887 6915 2733395 2334642 21569229 21912457 32727301 8461035 7265415 18553624 17016 20870 941156 6767446 28002644 32820233 19454010 3112558 33872434 24589977 6383751 7361809 7471469 9750739 34142875 28851427 29460824 31371922 33561370 30186270 3754027 7205659 99844 405471 24004664 31123410 115004 6815832 8040258 23350017 25489175 32660571 3537623 728186 20184691 7165305 32733622 7230276 214088 3789485 6968503 3426949 27555514 6549198 31544580 6634838 32765117\",\"4972128 4332837 13672941 14203183 14161139 14323813 4990046 4988806\"],\n",
    "            [2,\"10.1016/0006-291x(75)90482-9\",\"Delineation of the intimate details of the backbone conformation of pyridine nucleotide coenzymes in aqueous solution.\",\"K S Bose, R H Sarma\",1975,\"Biochem Biophys Res Commun\",\"6267127 26376 29458872 25548608 190032 22558138 26259654 31435170 28302598 21542697 26140007 890065 31544580 990401 39671\",\"4150960 4356257 4846745 4357832 4683494 4414857 4337195 4747846 4266012 4147828 1111570 4366080 1133382 4364802 4709237 4733399 4379057 17742850\"],\n",
    "            [3,\"10.1016/0006-291x(75)90498-2\",\"Metal substitutions incarbonic anhydrase: a halide ion probe study.\",\"R J Smith, R G Bryant\",1975,\"Biochem Biophys Res Commun\",\"25624746 33776281 32427033 28053241 22558138 24349293 7022113 24775716 27767123 29897055 13818 23643052 12463\",\"4632671 4977579 4992430 4958988 14417215 4992429 4621826 804171 4263471 4625501 4399045 4987292 4628675\"],\n",
    "            [4,\"10.1016/0006-291x(75)90506-9\",\"Effect of chloroquine on cultured fibroblasts: release of lysosomal hydrolases and inhibition of their uptake.\",\"U N Wiesmann, S DiDonato, N N Herschkowitz\",1975,\"Biochem Biophys Res Commun\",\"564972 8907731 7060838 6734624 31258218 7906514 27528195 19261 8216204 6221090 6365083 6870915 518687 2932104 7378072 28111290 7020765 6239657 1673037 895139 6817901 29684045 2937496 1660878 2961332 26308401 6284168 2543468 27136678 7138559 33597631 31536476 22305045 2452090 8295847 6793366 6615487 7151282 21816972 32663199 7342970 7057100 428466 7236683 2864350 6712986 6273196 31480869 27727286 21975914 476148 2933416 2530086 27146891 6228287 27328325 3827950 7190150 6279685 1015835 6276663 2730569 7314075 3877059 7165718 12763\",\"13663253 4271529 5021451 4607946 4374680 14907713 4275378 806251 4972437 4345092 4606365 4364008\"],\n",
    "            [5,\"10.1016/0006-291x(75)90508-2\",\"Atomic models for the polypeptide backbones of myohemerythrin and hemerythrin.\",\"W A Hendrickson, K B Ward\",1975,\"Biochem Biophys Res Commun\",\"7118409 6768892 2619971 2190210 3380793 20577584 8372226 7012375 856811 678527 33255345 33973855 402092 7012894 1257769 861288 1061139 3681996\",\"4882249 5059118 14834145 1056020 5509841\"],\n",
    "            [6,\"10.1016/0006-291x(75)90518-5\",\"Studies of oxygen binding energy to hemoglobin molecule.\",\"Y W Chow, R Pietranico, A Mukerji\",1975,\"Biochem Biophys Res Commun\",\"26668515 32953401 33134728 32470071 28601826 31567007 33094064\",\"4645548 14794725 16587956 14328650 1120094\"],\n",
    "            [7,\"10.1016/0006-2952(75)90020-9\",\"Maturation of the adrenal medulla--IV. Effects of morphine.\",\"T R Anderson, T A Slotkin\",1975,\"Biochem Pharmacol\",\"31215303 9414029 18246 41093 21355 6294570 942452 6870481 27705745 2858585 980225 24006099 5098 6259468 30612633 27030978 1271281 3003477 7001 7791109 6713511 999726 6280102 33872136 1774133 33872434\",\"17517355 15836459 15364646 18984078 20028328 5382448 18200670 4678819 17135164 15277068 12676044 15273078 20091597 5846992 11434754 17943819 17365137 18204101 18066129 17470951 1153082 15853441 16011454 22432689 14065927 15078424 16830309 21328257 18928139 15927926 1092305 11555193 19842218 15277090 22432635 21871125 17594991 5949627 22432564 14973986 11106086 14627335 12832592 21259185 4726566 15802416 21228727 4726565 15277076 19476742 21820672 15942912 22435354 16752934 16635970 15277109 22435615 16880367 18484782 6017359 19591529 19615308 11950176 18425916 22432518 15783241 19086008 12427501 16487688 16093238 22435415 18928148 4400965 4763252 12950418 17317655 18584321 18955223 4148818 10885091 4685445 16338199 16520304 1834807 15571467 18285310 4403908 4937070 12020172 21782365 19588398 15095142 17182489 15829470 22432729 235930 20370653\"],\n",
    "            [8,\"10.1016/0006-2952(75)90029-5\",\"Comparison between procaine and isocarboxazid metabolism in vitro by a liver microsomal amidase-esterase.\",\"K Moroi, T Sato\",1975,\"Biochem Pharmacol\",\"9224641 4004904 2756715 3245748 8743560 6745527 27034524 31695317 4059658 1876749 21846409 6712734 31632046 32005835 8218228 6875867 3706263 6612732 907716 7087253 3974403 463492 7181951 33977870 34121840 9586587 6770417 31664040 6123588 6239051 7295325 25584359 8654187 301955 537261 6126328 6772191 6494163 7203374\",\"19701189 9014768 21102463 18587394 13249955 15480983 18618634 16747230 16228179 19903424 4429589 17968351 17504508 4610350 19462429 4346266 15537905 19805227 8780562 4284968 14907713 16863561 15157825 19453248 5066156 4650633 18145350 19898471 2925048 20445446 20197757 6053218 18719139 20483763 16610046 19817673 4741776 13734134 20256398 11385576 15812518 18849966 20839313 17068223 8587604 12851870 14292314 19966812 4972656 20024904 5150150 3396969 14042697 4239096\"],\n",
    "        ]\n",
    "\n",
    "    def test_dump_split(self):\n",
    "        if exists(self.output_dir):\n",
    "            shutil.rmtree(self.output_dir)\n",
    "        self.assertFalse(exists(self.output_dir))\n",
    "        self.NIHPP.dump_split(self.input_dir, self.output_dir, self.num_3)\n",
    "\n",
    "        # checks that the output directory is generated in the process.\n",
    "        self.assertTrue(exists(self.output_dir))\n",
    "\n",
    "        # checks that the input lines where stored in 2 files, one containing 300 items and the other the remaining 56\n",
    "        files = self.NIHPP.get_all_files(self.output_dir)\n",
    "        len_files = len(files)\n",
    "        self.assertEqual(len_files, 2)\n",
    "        for idx, file in enumerate(files):\n",
    "            with open(file, \"r\") as op_file:\n",
    "                reader = csv.reader(op_file, delimiter=\",\")\n",
    "                next(reader, None)\n",
    "                len_lines = len(list(reader))\n",
    "                self.assertTrue(len_lines == 300 or len_lines == 56)\n",
    "\n",
    "\n",
    "    def test_icmd_split(self):\n",
    "        if exists(self.output_md_dir):\n",
    "            shutil.rmtree(self.output_md_dir)\n",
    "        self.assertFalse(exists(self.output_md_dir))\n",
    "        self.NIHPP.dump_split(self.input_md_dir, self.output_md_dir, self.num_3, filter_col=self.headers_md)\n",
    "\n",
    "        # checks that the output directory is generated in the process.\n",
    "        self.assertTrue(exists(self.output_md_dir))\n",
    "\n",
    "        # checks that the input lines where stored in 2 files, one containing 300 items and the other the remaining 56\n",
    "        files = self.NIHPP.get_all_files(self.output_md_dir)\n",
    "        len_files = len(files)\n",
    "        self.assertEqual(len_files, 2)\n",
    "        for idx, file in enumerate(files):\n",
    "            with open(file, \"r\") as op_file:\n",
    "                reader = csv.reader(op_file, delimiter=\",\")\n",
    "                next(reader, None)\n",
    "                len_lines = len(list(reader))\n",
    "                print(\"len_lines\", len_lines)\n",
    "                self.assertTrue(len_lines == 300 or len_lines == 56)\n",
    "\n",
    "    def test_icmd_chunk_to_file(self):\n",
    "        if exists(self.output_md_dir):\n",
    "            shutil.rmtree(self.output_md_dir)\n",
    "        self.assertFalse(exists(self.output_md_dir))\n",
    "        self.NIHPP.chunk_to_file(\n",
    "            self.num_1, self.num_4, self.output_md_dir, self.headers_md, self.lines_sample_md\n",
    "        )\n",
    "\n",
    "        # checks that chunk_to_file recreates the output directory\n",
    "        self.assertTrue(exists(self.output_md_dir))\n",
    "\n",
    "        # checks that the input lines are correctly stored in a file\n",
    "        files = self.NIHPP.get_all_files(self.output_md_dir)\n",
    "        self.assertGreater(len(files), 0)\n",
    "\n",
    "        # CSVFile_2.csv : target number (num_4) is 4 and current number (num_1) is 8 --> 8%4 == 0,  8//4  == 2\n",
    "        self.assertTrue(exists(join(self.output_md_dir, \"CSVFile_2.csv\")))\n",
    "\n",
    "        # runs again the process using a current number which is not a multiple of the target number, i.e.: 5\n",
    "        shutil.rmtree(self.output_md_dir)\n",
    "        self.assertFalse(exists(self.output_md_dir))\n",
    "        self.NIHPP.chunk_to_file(\n",
    "            self.num_2, self.num_4, self.output_md_dir, self.headers_md, self.lines_sample_md\n",
    "        )\n",
    "\n",
    "        # checks that chunk_to_file recreates the output directory\n",
    "        self.assertTrue(exists(self.output_md_dir))\n",
    "\n",
    "        # checks that the input lines are correctly stored in a file\n",
    "        files = self.NIHPP.get_all_files(self.output_md_dir)\n",
    "        self.assertGreater(len(files), 0)\n",
    "\n",
    "        # CSVFile_Rem.csv : target number (num_4) is 4 and current number (num_1) is 8 --> 8%4 == 0,  8//4  == 2\n",
    "        self.assertTrue(exists(join(self.output_md_dir, \"CSVFile_Rem.csv\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NIH Finder \n",
    "<b>get_date</b>\n",
    "<ul>\n",
    "    <li>ho controllato manualmente altri 8000 dati e <b>non sono emerse altre possibilità di formati alternativi</b> rispetto a quelli già analizzati.</li>\n",
    "    <li>ho reso le <b>regex case insensitive</b> per gestire la possibilità che i mesi siano scritti in upper case (anche se per ora non ho trovato nessun caso in cui il mese fosse scrtto per esteso)</li>\n",
    "    <li>ho provato a cambiare le espressioni per gestire la possibilità che il mese sia scritto per esteso e non abbreviato, ma poi ho visto che questo causa un problema con l'attuale struttura della data che viene passata come parametro di datetime.strptime, che si aspetta il mese in formato abbreviato (b%) e non esteso (%B). Visto che per gestire questa possibilità avrei dovuto complicare la funzione, ho deciso di <b>lasciare l'espressione regolare con solo le abbreviazioni dei mesi</b>: in questo modo cattura comunque solo i primi tre caratteri del mese, passando a datetime.strptime la data nel formato previsto.</li>\n",
    "    <li>ho fatto dei test con delle stringhe false (non realmente incontrate) per verificare che eventuali errori di inserimento delle date non causino comunque problemi al glob</li>\n",
    "</ul>\n",
    "\n",
    "<b>Esempi</b>\n",
    "    <ol>\n",
    "        <li><b>DP  - 1975 MAR</b> --> 1975-03</li>\n",
    "        <li><b>DP  - 1975 MARCH</b>--> 1975-03</li>\n",
    "        <li><b>DP  - 1975 MARCH-JULY</b>--> 1975-03</li>\n",
    "        <li><b>DP  - 1975 Mor-Jun</b>--> 1975</li>\n",
    "        <li><b>DP  - 1975 March</b>--> 1975-03</li>\n",
    "    </ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEST FINDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def test_nationalinstititeofhealth_get_pub_date(self):\n",
    "        # Do not use support files, only APIs\n",
    "        nf_1 = NIHResourceFinder()\n",
    "        self.assertIn(\"1998-05-25\", nf_1.get_pub_date(\"9689714\"))\n",
    "        self.assertIn(\"1975-03\", nf_1.get_pub_date(\"846\"))\n",
    "        # 846 --> DP  - 1975 MAR-APR, expected \"1975-03\"\n",
    "        self.assertIn(\"1975-12\", nf_1.get_pub_date(\"1296\"))\n",
    "        # 1296 --> DP  - 1975 Dec-1976 Jan, expected \"1975-12\"\n",
    "        self.assertIn(\"1975-07\", nf_1.get_pub_date(\"1552\"))\n",
    "        # 1552 --> DP  - 1975 Jul-Aug, expected \"1975-07\"\n",
    "        self.assertIn(\"1975\", nf_1.get_pub_date(\"1851\"))\n",
    "        # 1851 --> DP  - 1975 Summer, expected \"1975\"\n",
    "        self.assertIn(\"1976-07-03\", nf_1.get_pub_date(\"8768\"))\n",
    "        # 8768 --> DP  - 1976 Jul 3-10, expected \"1976-07-03\"\n",
    "        self.assertIn(\"1976-08-28\", nf_1.get_pub_date(\"8769\"))\n",
    "        # 8769 --> DP  - 1976 Aug 28-Sep 4, expected \"1976-08-28\"\n",
    "        self.assertIn(\"1976-07\", nf_1.get_pub_date(\"9428\"))\n",
    "        # 9428 --> DP  - 1976 Jul-AUG, expected \"1976-07\"\n",
    "        self.assertNotEqual(\"1998\", nf_1.get_pub_date(\"9689714\"))\n",
    "\n",
    "        # Do use support files, but avoid using APIs\n",
    "        nf_2 = NIHResourceFinder(\n",
    "            self.data,\n",
    "            use_api_service=False,\n",
    "        )\n",
    "        self.assertIn(\"1980-06\", nf_2.get_pub_date(\"7189714\"))\n",
    "        self.assertNotEqual(\"1980-06-22\", nf_2.get_pub_date(\"7189714\"))\n",
    "\n",
    "        # Do not use support files neither APIs\n",
    "        nf_3 = NIHResourceFinder(use_api_service=False)\n",
    "        self.assertIsNone(nf_3.get_pub_date(\"2942070\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NIH FINDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "from requests import get\n",
    "from datetime import datetime\n",
    "import re\n",
    "from urllib.parse import quote\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import oc.index.utils.dictionary as dict_utils\n",
    "from oc.index.finder.base import ApiDOIResourceFinder\n",
    "\n",
    "\n",
    "class NIHResourceFinder(ApiDOIResourceFinder):\n",
    "    \"\"\"This class implements an api doi resource finder for crossref\"\"\"\n",
    "\n",
    "    def __init__(self, data={}, use_api_service=True):\n",
    "        \"\"\"National Institute of Health resource finder constructor.\"\"\"\n",
    "        super().__init__(data, use_api_service=use_api_service, id_type=\"pmid\")\n",
    "        self._api = \"https://pubmed.ncbi.nlm.nih.gov/\"\n",
    "\n",
    "    def _get_issn(self, txt_obj):\n",
    "        result = set()\n",
    "        issns = re.findall(\"IS\\s+-\\s+\\d{4}-\\d{4}\", txt_obj)\n",
    "        for i in issns:\n",
    "            issn = re.search(\"\\d{4}-\\d{4}\", i).group(0)\n",
    "            norm_issn = self._im.normalise(issn)\n",
    "            if norm_issn is not None:\n",
    "                result.add(norm_issn)\n",
    "        return result\n",
    "\n",
    "    def _get_date(self, txt_obj):\n",
    "        date = re.search(\"DP\\s+-\\s+(\\d{4}(\\s?(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec))?(\\s?((3[0-1])|([1-2][0-9])|([0]?[1-9])))?)\", txt_obj, re.IGNORECASE).group(1)\n",
    "        re_search = re.search(\"(\\d{4})\\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s+((3[0-1])|([1-2][0-9])|([0]?[1-9]))\", date, re.IGNORECASE)\n",
    "        if re_search is not None:\n",
    "            result = re_search.group(0)\n",
    "            datetime_object = datetime.strptime(result, '%Y %b %d')\n",
    "            return datetime.strftime(datetime_object, '%Y-%m-%d')\n",
    "        else:\n",
    "            re_search = re.search(\"(\\d{4})\\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\", date, re.IGNORECASE)\n",
    "            if re_search is not None:\n",
    "                result = re_search.group(0)\n",
    "                datetime_object = datetime.strptime(result, '%Y %b')\n",
    "                return datetime.strftime(datetime_object, '%Y-%m')\n",
    "            else:\n",
    "                re_search = re.search(\"(\\d{4})\", date)\n",
    "                if re_search is not None:\n",
    "                    result = re.search(\"(\\d{4})\", date).group(0)\n",
    "                    datetime_object = datetime.strptime(result, '%Y')\n",
    "                    return datetime.strftime(datetime_object, '%Y')\n",
    "                else:\n",
    "                    return None\n",
    "\n",
    "    def _call_api(self, pmid_full):\n",
    "        if self._use_api_service:\n",
    "            pmid = self._dm.normalise(pmid_full)\n",
    "            r = get(self._api + quote(pmid) + \"/?format=pubmed\", headers=self._headers, timeout=30)\n",
    "            if r.status_code == 200:\n",
    "                r.encoding = \"utf-8\"\n",
    "                soup = BeautifulSoup(r.text, features=\"lxml\")\n",
    "                mdata = str(soup.find(id=\"article-details\"))\n",
    "                return mdata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID-ORCID ISSUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facendo un controllo tra i dati che mi ha passato Arcangelo (dump orcid di qualche mese fa) e i risultati attuali dell'API, ho notato che ci sono diverse aggiunte di dati falsificati e una rimozione (questo solo sulle prime 10 pubblicazioni). Alla luce di questo,  ho letto la documentazione delle procedure  per gestire i casi di profili ORCID sospetti, in cui si consiglia prima di contattare l'utente, e poi in caso di mancata collaborazione di avviare la procedura ufficiale per la verifica dell'accuratezza dei dati.<br>\n",
    "<b>Spunti</b>\n",
    "<ol>\n",
    "    <li><b>cercare strumenti per fare check su metadati (nomi autori pubblicazione - nome profilo ORCID)</b> e verificare se c'è un qualche tipo di corrispondenza con i dati del profilo ORCID che si dichiara autore della una pubbblicazione. <b>Software per check su corrispondenze tra nomi</b>: ci sono degli strumenti già sviluppati? Vale la pena di sviluppare uno strumento che confronti due stringhe che rappresentano nomi di persona e, tenendo conto di possibilità di variazioni relative a traslitterazioni e diversi standard di abbreviazione (stabiendo una soglia di accettabilità che tenga conto del compromesso tra permissività e accuratezza, per evitare che non venga riconosciuta la paternità di una pubblicazione al suo legittimo autore, così come anche che venga confermata la paternità di una pubblicazione ad un autore che ha falsificato i dati del proprio profilo ORCID) ?</li>\n",
    "    <li>è etico creare una <b>lista di profili ORCID \"non affidabili\"</b> in modo da contattarli per cercare di verificare i dati che hanno inserito? è già stata fatta?</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLOB COCI, DOCI, NOCI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I glob dei tre indici sono stati conclusi e testati + merge con Giuseppe in farm_revision di index "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### glob test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from os import sep, remove, makedirs\n",
    "import os\n",
    "from os.path import exists, join\n",
    "import shutil\n",
    "from shutil import rmtree\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from oc.index.legacy.csv import CSVManager\n",
    "from oc.index.identifier.issn import ISSNManager\n",
    "from oc.index.identifier.orcid import ORCIDManager\n",
    "from oc.index.identifier.doi import DOIManager\n",
    "from oc.index.identifier.pmid import PMIDManager\n",
    "from oc.index.scripts.doci_glob import issn_data_recover_doci, issn_data_to_cache_doci, get_all_files_doci, valid_date_doci, load_json_doci,process_doci\n",
    "from oc.index.scripts.noci_glob import issn_data_recover_noci, issn_data_to_cache_noci, build_pubdate_noci, get_all_files_noci, process_noci\n",
    "from oc.index.scripts.crossref_glob import build_pubdate_coci, get_all_files_coci, load_json_coci, process_coci\n",
    "\n",
    "\n",
    "class GlobTest(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.test_dir = join(\"index\", \"python\", \"test\", \"data\")\n",
    "        self.doi_manager = DOIManager()\n",
    "        self.pmid_manager = PMIDManager()\n",
    "        self.issn_manager = ISSNManager()\n",
    "        self.orcid_manager = ORCIDManager()\n",
    "\n",
    "        #COCI\n",
    "        self.inp_coci = join(self.test_dir, \"crossref_glob_dump_input\")\n",
    "        self.out_coci = join(self.test_dir, \"crossref_glob_dump_output\")\n",
    "        self.valid_doi_coci = CSVManager(join(self.out_coci, \"valid_doi.csv\"))\n",
    "        self.id_date_coci = CSVManager(join(self.out_coci, \"id_date.csv\"))\n",
    "        self.id_issn_coci = CSVManager(join(self.out_coci, \"id_issn.csv\"))\n",
    "        self.id_orcid_coci = CSVManager(join(self.out_coci, \"id_orcid.csv\"))\n",
    "        self.dir_get_all_files_coci = join(self.test_dir, \"crossref_glob_dump_input\")\n",
    "        self.sample_doi_coci = self.doi_manager.normalise(\"10.7717/peerj.4375\", True)\n",
    "        self.sample_reference_coci = self.doi_manager.normalise(\"10.1016/j.joi.2016.08.002\", True)\n",
    "        self.sample_doi_coci_2 = self.doi_manager.normalise(\"10.1016/j.websem.2017.06.001\", True)\n",
    "        self.obj_for_date = {\"issued\": {\"date-parts\": [[2017, 5]]}}\n",
    "        self.obj_for_date_2 = {\"issued\": {\"date-parts\": [[2018, 2, 13]]}}\n",
    "        self.obj_for_date_3 = {\"issued\": {\"date-parts\": [[2015, 3, 9]]}}\n",
    "        self.load_json_c_inp = join(self.inp_coci, \"crossref_dump.json\")\n",
    "\n",
    "        #DOCI\n",
    "        self.inp_doci = join(self.test_dir, \"doci_glob_dump_input\")\n",
    "        self.out_doci = join(self.test_dir, \"doci_glob_dump_output\")\n",
    "        self.valid_doi_doci = CSVManager(join(self.out_doci, \"valid_doi.csv\"))\n",
    "        self.id_date_doci = CSVManager(join(self.out_doci, \"id_date.csv\"))\n",
    "        self.id_issn_doci = CSVManager(join(self.out_doci, \"id_issn.csv\"))\n",
    "        self.id_orcid_doci = CSVManager(join(self.out_doci, \"id_orcid.csv\"))\n",
    "        self.issn_journal_doci = {\"european journal of organic chemistry\": [\"1434193X\"], \"drug delivery and translational research\": [\"2190-3948\"], \"the social science journal\": [\"1873-5355\"]}\n",
    "        self.n_doci = 3\n",
    "        self.dir_issn_map_doci = join(self.test_dir, \"recover_w_mapping_doci\")\n",
    "        self.dir_no_issn_map_doci = join(self.test_dir, \"recover_wo_mapping_doci\")\n",
    "        self.dir_data_to_cache_doci = join(self.test_dir, \"issn_data_to_cache_doci\")\n",
    "        self.dir_get_all_files_doci = join(self.test_dir, \"doci_pp_dump_output\")\n",
    "        self.sample_reference_doci = self.doi_manager.normalise(\"10.1002/anie.200504236\", True)\n",
    "        self.load_json_d_inp = join(self.inp_doci, \"doci_dump.json\")\n",
    "\n",
    "        #NOCI\n",
    "        self.inp_noci = join(self.test_dir, \"noci_glob_dump_input\")\n",
    "        self.out_noci = join(self.test_dir, \"noci_glob_dump_output\")\n",
    "        self.id_orcid_map = join(self.test_dir, \"noci_id_orcid_mapping\", \"doi_orcid_index.zip\")\n",
    "        self.n_noci = 3\n",
    "        self.valid_pmid = CSVManager(join(self.out_noci, \"valid_pmid.csv\"))\n",
    "        self.id_date_noci = CSVManager(join(self.out_noci, \"id_date.csv\"))\n",
    "        self.id_issn_noci = CSVManager(join(self.out_noci, \"id_issn.csv\"))\n",
    "        self.id_orcid_noci = CSVManager(join(self.out_noci, \"id_orcid.csv\"))\n",
    "        self.issn_journal_noci = {\"N Biotechnol\": [\"1871-6784\"], \"Biochem Med\": [\"0006-2944\"], \"Magn Reson Chem\": [\"0749-1581\"]}\n",
    "        self.dir_issn_map_noci = join(self.test_dir, \"recover_w_mapping_noci\")\n",
    "        self.dir_no_issn_map_noci = join(self.test_dir, \"recover_wo_mapping_noci\")\n",
    "        self.dir_data_to_cache_noci = join(self.test_dir, \"issn_data_to_cache_noci\")\n",
    "        self.dir_get_all_files_noci = join(self.test_dir, \"noci_md_pp_dump_output\")\n",
    "        self.csv_sample = join(self.inp_noci, \"CSVFile_1.csv\")\n",
    "        self.sample_reference_noci = self.pmid_manager.normalise(\"4150960\", True)\n",
    "\n",
    "    def test_build_pubdate_coci(self):\n",
    "        self.assertEqual(build_pubdate_coci(self.obj_for_date),\"2017-05\")\n",
    "        self.assertEqual(build_pubdate_coci(self.obj_for_date_2),\"2018-02-13\")\n",
    "        self.assertEqual(build_pubdate_coci(self.obj_for_date_3),\"2015-03-09\")\n",
    "\n",
    "    def test_get_all_files_coci(self):\n",
    "        all_files, opener = get_all_files_coci(self.dir_get_all_files_coci)\n",
    "        len_all_files = len(all_files)\n",
    "        self.assertEqual(len_all_files, 1)\n",
    "\n",
    "    def test_load_json_coci(self):\n",
    "        self.assertTrue(isinstance(load_json_coci(self.load_json_c_inp, None, 1, 1), dict))\n",
    "\n",
    "    def test_process_coci(self):\n",
    "        for files in os.listdir(self.out_coci):\n",
    "            path = os.path.join(self.out_coci, files)\n",
    "            try:\n",
    "                shutil.rmtree(path)\n",
    "            except OSError:\n",
    "                os.remove(path)\n",
    "        self.assertEqual(len(os.listdir(self.out_coci)), 0)\n",
    "        process_coci(self.inp_coci, self.out_coci)\n",
    "        self.assertEqual(len(os.listdir(self.out_coci)), 4)\n",
    "\n",
    "        citing_doi = self.doi_manager.normalise(self.sample_doi_coci, True)\n",
    "        citing_doi_2 = self.doi_manager.normalise(self.sample_doi_coci_2, True)\n",
    "        self.assertEqual(self.id_orcid_coci.get_value(citing_doi_2), {'0000-0003-0530-4305', '0000-0002-7562-5203'})\n",
    "        self.assertEqual(self.valid_doi_coci.get_value(citing_doi), {'v'})\n",
    "        self.assertEqual(self.valid_doi_coci.get_value(self.sample_reference_coci), {'v'})\n",
    "        self.assertEqual(self.id_date_coci.get_value(citing_doi), {'2018-02-13'})\n",
    "        self.assertEqual(self.id_issn_coci.get_value(citing_doi), {'2167-8359'})\n",
    "\n",
    "\n",
    "    #TEST DOCI GLOB\n",
    "    def test_issn_data_recover_doci(self):\n",
    "        self.assertTrue(True)\n",
    "        if exists(self.dir_no_issn_map_doci):\n",
    "            rmtree(self.dir_no_issn_map_doci)\n",
    "        makedirs(self.dir_no_issn_map_doci)\n",
    "        if exists(self.dir_issn_map_doci):\n",
    "            rmtree(self.dir_issn_map_doci)\n",
    "        makedirs(self.dir_issn_map_doci)\n",
    "        with open(join(self.dir_no_issn_map_doci, 'journal_issn.json'), 'w', encoding='utf-8') as g:\n",
    "            json.dump({}, g, ensure_ascii=False, indent=4)\n",
    "        with open(join(self.dir_issn_map_doci, 'journal_issn.json'), 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.issn_journal_doci, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        #Test the case in which there is no mapping file for journals - issn\n",
    "        self.assertEqual(issn_data_recover_doci(self.dir_no_issn_map_doci), {})\n",
    "        #Test the case in which there is a mapping file for journals - issn\n",
    "        self.assertNotEqual(issn_data_recover_doci(self.dir_issn_map_doci), {})\n",
    "\n",
    "        rmtree(self.dir_no_issn_map_doci)\n",
    "        rmtree(self.dir_issn_map_doci)\n",
    "\n",
    "    def test_issn_data_to_cache_doci(self):\n",
    "        filename = join(self.dir_data_to_cache_doci, 'journal_issn.json')\n",
    "        if not exists(self.dir_data_to_cache_doci):\n",
    "            makedirs(self.dir_data_to_cache_doci)\n",
    "        if exists(filename):\n",
    "            remove(filename)\n",
    "        self.assertFalse(exists(filename))\n",
    "        issn_data_to_cache_doci(self.issn_journal_doci, self.dir_data_to_cache_doci)\n",
    "        self.assertTrue(exists(filename))\n",
    "        rmtree(self.dir_data_to_cache_doci)\n",
    "\n",
    "    def test_get_all_files_doci(self):\n",
    "        all_files, opener = get_all_files_doci(self.dir_get_all_files_doci)\n",
    "        len_all_files = len(all_files)\n",
    "        self.assertEqual(len_all_files, 4)\n",
    "\n",
    "    def test_valid_date_doci(self):\n",
    "        self.assertTrue(isinstance(valid_date_doci(2018), str))\n",
    "        self.assertEqual(valid_date_doci(\"2018-11-25\"), \"2018-11-25\")\n",
    "        self.assertIsNone(valid_date_doci(\"11-25-2018\"))\n",
    "\n",
    "    def test_load_json_doci(self):\n",
    "        self.assertTrue(isinstance(load_json_doci(self.load_json_d_inp, None, 1, 1), dict))\n",
    "\n",
    "    def test_process_doci(self):\n",
    "        for files in os.listdir(self.out_doci):\n",
    "            path = os.path.join(self.out_doci, files)\n",
    "            try:\n",
    "                shutil.rmtree(path)\n",
    "            except OSError:\n",
    "                os.remove(path)\n",
    "        self.assertEqual(len(os.listdir(self.out_doci)), 0)\n",
    "        process_doci(self.inp_doci, self.out_doci, self.n_doci)\n",
    "        self.assertEqual(len(os.listdir(self.out_doci)), 5)\n",
    "\n",
    "        citing_doi = \"doi:10.1002/ejoc.201800947\"\n",
    "        self.assertEqual(self.id_orcid_doci.get_value(citing_doi), {'0000-0002-2397-9093'})\n",
    "        self.assertEqual(self.valid_doi_doci.get_value(citing_doi), {'v'})\n",
    "        self.assertEqual(self.valid_doi_doci.get_value(self.sample_reference_doci), {'v'})\n",
    "        self.assertEqual(self.id_date_doci.get_value(citing_doi), {'2018-11-25'})\n",
    "        self.assertEqual(self.id_issn_doci.get_value(citing_doi), {'1434-193X'})\n",
    "\n",
    "\n",
    "    #TEST NOCI GLOB\n",
    "    def test_issn_data_recover_noci(self):\n",
    "        if exists(self.dir_no_issn_map_noci):\n",
    "            rmtree(self.dir_no_issn_map_noci)\n",
    "        makedirs(self.dir_no_issn_map_noci)\n",
    "        if exists(self.dir_issn_map_noci):\n",
    "            rmtree(self.dir_issn_map_noci)\n",
    "        makedirs(self.dir_issn_map_noci)\n",
    "        with open(join(self.dir_no_issn_map_noci, 'journal_issn.json'), 'w', encoding='utf-8') as g:\n",
    "            json.dump({}, g, ensure_ascii=False, indent=4)\n",
    "        with open(join(self.dir_issn_map_noci, 'journal_issn.json'), 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.issn_journal_noci, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        #Test the case in which there is no mapping file for journals - issn\n",
    "        self.assertEqual(issn_data_recover_noci(self.dir_no_issn_map_noci), {})\n",
    "        #Test the case in which there is a mapping file for journals - issn\n",
    "        self.assertNotEqual(issn_data_recover_noci(self.dir_issn_map_noci), {})\n",
    "\n",
    "        rmtree(self.dir_no_issn_map_noci)\n",
    "        rmtree(self.dir_issn_map_noci)\n",
    "\n",
    "\n",
    "    def test_issn_data_to_cache_noci(self):\n",
    "        filename = join(self.dir_data_to_cache_noci, 'journal_issn.json')\n",
    "        if not exists(self.dir_data_to_cache_noci):\n",
    "            makedirs(self.dir_data_to_cache_noci)\n",
    "        if exists(filename):\n",
    "            remove(filename)\n",
    "        self.assertFalse(exists(filename))\n",
    "        issn_data_to_cache_noci(self.issn_journal_noci, self.dir_data_to_cache_noci)\n",
    "        self.assertTrue(exists(filename))\n",
    "        rmtree(self.dir_data_to_cache_noci)\n",
    "\n",
    "    def test_build_pubdate_noci(self):\n",
    "        df = pd.DataFrame()\n",
    "        for chunk in pd.read_csv(self.csv_sample, chunksize=1000):\n",
    "            f = pd.concat( [df, chunk], ignore_index=True )\n",
    "            f.fillna(\"\", inplace=True)\n",
    "            for index, row in f.iterrows():\n",
    "                pub_date = build_pubdate_noci(row)\n",
    "                self.assertTrue(isinstance(pub_date, str))\n",
    "                self.assertTrue(isinstance(int(pub_date), int))\n",
    "                self.assertEqual(len(pub_date), 4)\n",
    "\n",
    "    def test_get_all_files_noci(self):\n",
    "        self.assertTrue(True)\n",
    "        all_files, opener = get_all_files_noci(self.dir_get_all_files_noci)\n",
    "        len_all_files = len(all_files)\n",
    "        self.assertEqual(len_all_files, 2)\n",
    "\n",
    "    def test_process_noci(self):\n",
    "        for files in os.listdir(self.out_noci):\n",
    "            path = os.path.join(self.out_noci, files)\n",
    "            try:\n",
    "                shutil.rmtree(path)\n",
    "            except OSError:\n",
    "                os.remove(path)\n",
    "        self.assertEqual(len(os.listdir(self.out_noci)),0)\n",
    "        process_noci(self.inp_noci, self.out_noci, self.n_noci)\n",
    "        self.assertEqual(len(os.listdir(self.out_noci)), 5)\n",
    "\n",
    "        citing_pmid = \"pmid:2\"\n",
    "        self.assertEqual(self.id_orcid_noci.get_value(citing_pmid), {'0000-0003-0014-4963'})\n",
    "        self.assertEqual(self.valid_pmid.get_value(citing_pmid), {'v'})\n",
    "        self.assertEqual(self.valid_pmid.get_value(self.sample_reference_noci), {'v'})\n",
    "        self.assertEqual(self.id_date_noci.get_value(citing_pmid), {'1975'})\n",
    "        self.assertEqual(self.id_issn_noci.get_value(citing_pmid), {'0006-291X'})\n",
    "\n",
    "        #try again with doi_orcid mapping folder\n",
    "        # for files in os.listdir(self.out_noci):\n",
    "        #     path = os.path.join(self.out_noci, files)\n",
    "        #     try:\n",
    "        #         shutil.rmtree(path)\n",
    "        #     except OSError:\n",
    "        #         os.remove(path)\n",
    "        # self.assertEqual(len(os.listdir(self.out_noci)),0)\n",
    "        # process_noci(self.inp_noci, self.out_noci, self.n_noci, self.id_orcid_map)\n",
    "        # self.assertEqual(len(os.listdir(self.out_noci)), 5)\n",
    "        #\n",
    "        # df = pd.DataFrame()\n",
    "        # for chunk in pd.read_csv(self.csv_sample, chunksize=1000):\n",
    "        #     f = pd.concat([df, chunk], ignore_index=True)\n",
    "        #     f.fillna(\"\", inplace=True)\n",
    "        #     for index, row in f.iterrows():\n",
    "        #         pmid = row[\"pmid\"]\n",
    "        #         citing_pmid = self.pmid_manager.normalise(pmid, include_prefix=True)\n",
    "        #         if citing_pmid == \"pmid:2\":\n",
    "        #             self.assertEqual(self.id_orcid.get_value(citing_pmid), {'0000-0003-0014-4963'})\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### META"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### coci_process\n",
    "Ho testato coci_process con i dati prodotti dai parser di DOCI e NOCI \n",
    "<ul>\n",
    "    <li><b>Get dois from COCI</b>: input: path per cartella che contiene csv estratti o file zip. output: nome del file csv che verrà generato. Conterrà la lista di identificativi estratti. </li>\n",
    "    <li><b>NOTE:</b> Funziona tutt correttamente anche con i dati generati dai parser di DOCI e NOCI. Unica cosa da rivedere: nomenclatura da generalizzare da DOI a ID, sia nei messaggi che negli headers dell'output.</li>\n",
    "\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### crossref_process\n",
    "Per quanto riguarda le versioni nih e datacite di crossref_process, sto lavorando al codice ma mi prenderà ancora qualche giorno. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VALIDATE (INDEX) \n",
    "Sviluppato per evitare di aggiungere duplicati, non testato. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataCite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from oc.index.validate.base import CitationValidator\n",
    "from oc.index.identifier.doi import DOIManager\n",
    "from oc.index.utils.logging import get_logger\n",
    "\n",
    "\n",
    "class DataciteValidator(CitationValidator):\n",
    "    def __init__(self, service):\n",
    "        super().__init__(service)\n",
    "        self._doi_manager = DOIManager()\n",
    "        self._logger = get_logger()\n",
    "\n",
    "    def build_oci_query(self, input_file, result_map, disable_tqdm=False):\n",
    "        json_content = {\"data\": []}\n",
    "\n",
    "        # Build the OCI lookup query\n",
    "        self._logger.info(\"Reading citation data from \" + input_file)\n",
    "        query = []\n",
    "        needed_info = [\"relationType\", \"relatedIdentifierType\", \"relatedIdentifier\"]\n",
    "        with open(input_file, encoding=\"utf8\") as fp:\n",
    "            json_content = json.load(fp)\n",
    "        for row in tqdm(json_content[\"data\"], disable=disable_tqdm):\n",
    "            attr = row.get(\"attributes\")\n",
    "            citing = self._doi_manager.normalise(attr.get(\"doi\"))\n",
    "            if citing is not None and \"relatedIdentifiers\" in attr:\n",
    "                for ref in attr[\"relatedIdentifiers\"]:\n",
    "                    if [x for x in needed_info if x in ref]:\n",
    "                        relatedIdentifierType = (str(ref[\"relatedIdentifierType\"])).lower()\n",
    "                        rel_id = self._doi_manager.normalise(ref[\"relatedIdentifier\"])\n",
    "                        relationType = str(ref[\"relationType\"]).lower()\n",
    "                        if relatedIdentifierType == \"doi\":\n",
    "                            if relationType == \"references\" or relationType == \"cites\":\n",
    "                                cited = rel_id\n",
    "                                if cited is not None:\n",
    "                                    oci = self._oci_manager.get_oci(\n",
    "                                        citing, cited, prefix=self._prefix\n",
    "                                    ).replace(\"oci:\", \"\")\n",
    "                                    # Add oci only if has not been processed in the past\n",
    "                                    # in the case this is a duplicate.\n",
    "                                    if oci not in result_map:\n",
    "                                        query.append(oci)\n",
    "        return query\n",
    "\n",
    "    def validate_citations(self, input_files, result_map, output_directory):\n",
    "        needed_info = [\"relationType\", \"relatedIdentifierType\", \"relatedIdentifier\"]\n",
    "        for filename in os.listdir(input_files):\n",
    "            if filename.endswith(\".json\"):\n",
    "                json_content = {\"data\": []}\n",
    "\n",
    "                # Build the OCI lookup query\n",
    "                self._logger.info(\"Reading citation data from \" + filename)\n",
    "                query = []\n",
    "                with open(filename, encoding=\"utf8\") as fp:\n",
    "                    json_content = json.load(fp)\n",
    "                for row in tqdm(json_content[\"data\"]):\n",
    "                    attr = row.get(\"attributes\")\n",
    "                    citing = self._doi_manager.normalise(attr.get(\"doi\"))\n",
    "                    if citing is not None and \"relatedIdentifiers\" in attr:\n",
    "                        for ref in attr[\"relatedIdentifiers\"]:\n",
    "                            if [x for x in needed_info if x in ref]:\n",
    "                                relatedIdentifierType = (str(ref[\"relatedIdentifierType\"])).lower()\n",
    "                                rel_id = self._doi_manager.normalise(ref[\"relatedIdentifier\"])\n",
    "                                relationType = str(ref[\"relationType\"]).lower()\n",
    "                                if relatedIdentifierType == \"doi\":\n",
    "                                    if relationType == \"references\" or relationType == \"cites\":\n",
    "                                        cited = rel_id\n",
    "                                        if cited is not None:\n",
    "                                            oci = self._oci_manager.get_oci(\n",
    "                                                citing, cited, prefix=self._prefix\n",
    "                                            ).replace(\"oci:\", \"\")\n",
    "                                            # Add oci only if has not been processed in the past\n",
    "                                            # in the case this is a duplicate.\n",
    "                                            if oci not in result_map:\n",
    "                                                query.append(oci)\n",
    "\n",
    "                # Create input file\n",
    "                with open(\"input.csv\", \"w\") as f:\n",
    "                    for oci in query:\n",
    "                        f.write(oci + \"\\n\")\n",
    "\n",
    "                # Remove the processed citations\n",
    "                self._logger.info(\"Remove duplicates and existiting citations\")\n",
    "                duplicated = 0\n",
    "                items = []\n",
    "                for row in tqdm(json_content[\"data\"]):\n",
    "                    attr = row.get(\"attributes\")\n",
    "                    citing = self._doi_manager.normalise(attr.get(\"doi\"))\n",
    "                    if citing is not None and \"relatedIdentifiers\" in attr:\n",
    "                        reference = []\n",
    "                        for ref in attr[\"relatedIdentifiers\"]:\n",
    "                            if [x for x in needed_info if x in ref]:\n",
    "                                relatedIdentifierType = (str(ref[\"relatedIdentifierType\"])).lower()\n",
    "                                rel_id = self._doi_manager.normalise(ref[\"relatedIdentifier\"])\n",
    "                                relationType = str(ref[\"relationType\"]).lower()\n",
    "                                if relatedIdentifierType == \"doi\":\n",
    "                                    if relationType == \"references\" or relationType == \"cites\":\n",
    "                                        cited = rel_id\n",
    "                                        if cited is not None:\n",
    "                                            oci = self._oci_manager.get_oci(\n",
    "                                                citing, cited, prefix=self._prefix\n",
    "                                            ).replace(\"oci:\", \"\")\n",
    "                                            # Add oci only if has not been preprocessed and it is not a duplicate\n",
    "                                            if oci in result_map and not result_map[oci]:\n",
    "                                                # Set result map true for the oci to avoid duplicates\n",
    "                                                result_map[oci] = True\n",
    "                                                reference.append(ref)\n",
    "                                            else:\n",
    "                                                duplicated += 1\n",
    "                        row[\"attributes\"][\"relatedIdentifiers\"] = reference\n",
    "                        items.append(row)\n",
    "\n",
    "                # Save validated citations\n",
    "                self._logger.info(str(duplicated) + \" citations deleted\")\n",
    "                self._logger.info(\"Saving validated citations...\")\n",
    "                with open(os.path.join(output_directory, filename), \"w\") as fp:\n",
    "                    json.dump({\"data\": items}, fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NIH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "from oc.index.validate.base import CitationValidator\n",
    "from oc.index.identifier.pmid import PMIDManager\n",
    "from oc.index.utils.logging import get_logger\n",
    "\n",
    "\n",
    "\n",
    "class NIHValidator(CitationValidator):\n",
    "    def __init__(self, service):\n",
    "        super().__init__(service)\n",
    "        self._pmid_manager = PMIDManager()\n",
    "        self._logger = get_logger()\n",
    "\n",
    "    def build_oci_query(self, input_file, result_map, disable_tqdm=False):\n",
    "        csv_content = []\n",
    "\n",
    "        # Build the OCI lookup query\n",
    "        self._logger.info(\"Reading citation data from \" + input_file)\n",
    "        query = []\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        for chunk in pd.read_csv(input_file, chunksize=1000):\n",
    "            f = pd.concat([df, chunk], ignore_index=True)\n",
    "            f.fillna(\"\", inplace=True)\n",
    "            csv_content = f.to_dict(\"records\")\n",
    "            for row in tqdm(csv_content, disable=disable_tqdm):\n",
    "                citing = self._pmid_manager.normalise(row.get(\"citing\"))\n",
    "                cited = self._pmid_manager.normalise(row.get(\"referenced\"))\n",
    "                if cited is not None:\n",
    "                    oci = self._oci_manager.get_oci(\n",
    "                        citing, cited, prefix=self._prefix\n",
    "                    ).replace(\"oci:\", \"\")\n",
    "                    # Add oci only if has not been processed in the past\n",
    "                    # in the case this is a duplicate.\n",
    "                    if oci not in result_map:\n",
    "                        query.append(oci)\n",
    "        return query\n",
    "\n",
    "    def validate_citations(self, input_files, result_map, output_directory):\n",
    "        for filename in os.listdir(input_files):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                csv_content = []\n",
    "\n",
    "                # Build the OCI lookup query\n",
    "                self._logger.info(\"Reading citation data from \" + filename)\n",
    "                query = []\n",
    "                df = pd.DataFrame()\n",
    "                for chunk in pd.read_csv(input_file, chunksize=1000):\n",
    "                    f = pd.concat([df, chunk], ignore_index=True)\n",
    "                    f.fillna(\"\", inplace=True)\n",
    "                    csv_content = f.to_dict(\"records\")\n",
    "                    for row in tqdm(csv_content, disable=disable_tqdm):\n",
    "                        citing = self._pmid_manager.normalise(row.get(\"citing\"))\n",
    "                        cited = self._pmid_manager.normalise(row.get(\"referenced\"))\n",
    "                        if cited is not None:\n",
    "                            oci = self._oci_manager.get_oci(\n",
    "                                citing, cited, prefix=self._prefix\n",
    "                            ).replace(\"oci:\", \"\")\n",
    "                            # Add oci only if has not been processed in the past\n",
    "                            # in the case this is a duplicate.\n",
    "                            if oci not in result_map:\n",
    "                                query.append(oci)\n",
    "\n",
    "                                oci = self._oci_manager.get_oci(\n",
    "                                    citing, cited, prefix=self._prefix\n",
    "                                ).replace(\"oci:\", \"\")\n",
    "                                # Add oci only if has not been processed in the past\n",
    "                                # in the case this is a duplicate.\n",
    "                                if oci not in result_map:\n",
    "                                    query.append(oci)\n",
    "\n",
    "                # Create input file\n",
    "                with open(\"input.csv\", \"w\") as f:\n",
    "                    for oci in query:\n",
    "                        f.write(oci + \"\\n\")\n",
    "\n",
    "                # Remove the processed citations\n",
    "                self._logger.info(\"Remove duplicates and existiting citations\")\n",
    "                duplicated = 0\n",
    "                items = []\n",
    "                for row in tqdm(csv_content):\n",
    "                    citing = self._pmid_manager.normalise(row.get(\"citing\"))\n",
    "                    cited = self._pmid_manager.normalise(row.get(\"referenced\"))\n",
    "                    if cited is not None:\n",
    "                        oci = self._oci_manager.get_oci(\n",
    "                            citing, cited, prefix=self._prefix\n",
    "                        ).replace(\"oci:\", \"\")\n",
    "                        if oci in result_map and not result_map[oci]:\n",
    "                            # Set result map true for the oci to avoid duplicates\n",
    "                            result_map[oci] = True\n",
    "                            items.append(row)\n",
    "                        else:\n",
    "                            duplicated += 1\n",
    "\n",
    "                # Save validated citations\n",
    "                self._logger.info(str(duplicated) + \" citations deleted\")\n",
    "                self._logger.info(\"Saving validated citations...\")\n",
    "                keys = items[0].keys()\n",
    "                with open(os.path.join(output_directory, filename), \"w\", newline='') as output_file:\n",
    "                    dict_writer = csv.DictWriter(output_file, keys)\n",
    "                    dict_writer.writeheader()\n",
    "                    dict_writer.writerows(to_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## International Data Week and Glob update\n",
    "<a id=\"entry_16\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### International Data Week\n",
    "I video delle conferenze saranno ancora disponibili per 7 settimane. Se siete interessati a vederne alcuni potete accedere a https://idw2022.events.whova.com/sign_in con le credenziali <b>arianna.moretti4@unibo.it</b>, Password: <b>OpenCitations2022</b>, nella sezione https://idw2022.events.whova.com/VideoGallery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OSG WG on Interoperability \n",
    "Per ora ho aggiunto Ivan, Arcangelo, Giuseppe e me a https://docs.google.com/spreadsheets/d/17KyjjD425f1EC5J0hcxMVJZMhSzhjeynGDHQV3nBK6o/edit#gid=0. Ci siamo iscritti tutti al gruppo di interesse di RDA? (https://www.rd-alliance.org/groups/open-science-graphs-fair-data-ig). Dovremmo dividerci tra le due task. Le slides sono qui: https://drive.google.com/drive/folders/1nBvPF0j493WIzHhwXYuth8-9MW9UDrQP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li><b>TF 1: OSG CORE INFORMATION MODEL</b>: (da ora a fine settembre) cosa a cui daranno la precedenza, consiste nell'identificare le entità e use case scenarios, una survey sugli standard information models, PIDs, per le entità, e definizione incrementale del core model. Si tratta di identificare entità e proprietà da tracciare. L'obiettivo è avere qualcosa di fatto per fine settembre. Questa task si sovrapporrà in parte con:</li>\n",
    "    <li><b>TF 2: OSG DATA EXCHANGE COMMONS</b>: (da ora a novembre) In questa task rientra la survey sui metadata format per le entità (es. Dublin Core, DataCite...), e la scelta del Core Metadata Format. Anche questo deve svilupparsi in maniera incrementale, seguendo le evoluzioni del TF1.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FARM_REVISION\n",
    "Ho aggiunto i validate per nih e datacite, che devono però essere testati. Nel frattempo ho corretto tutti e tre i Glob in modo tale che gestissero la stringa vuota per i citati di cui non è ancora stata trovata la data. Ho testato i glob e ho fatto una pull request, in modo tale da chiudere la parte del lavoro con i glob gestita da CSV manager."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuova versione dei Glob con CSVDataSource\n",
    "Ho finito una prima bozza della versione del Glob di Noci. Sono sorti dei problemi e alcuni dubbi.\n",
    "<ol>\n",
    "    <li><b>Gestione dei files csv nel file di configurazione</b>: per ora c'è un solo file di configurazione che va aggiornato manualmente per verificare il corretto funzionamento dei vari glob, aggiungendo a mano i csv necessari. Con Giuseppe abbiamo parlato dell'ipotesi di usare gli stessi files per tutti gli indici. Tuttavia, in questo modo si creerebbero delle problematiche in termini di sovrascrizione e duplicati. A livello concettuale che linea seguiamo?</li>\n",
    "    <li>Ho fatto delle modifiche al metodo set di CSVDataSource perché mi dava dei problemi nel compilare i csv, dal momento che il metodo \"set\" ha come argomenti l'identificativo e il dizionario contenente i dati relativi a validità (che può essere True o False), data (che può essere None), orcid e issn (che possono essere liste vuote. In aggiunta utilizzava nei csv \"set\" che però non esiste in CSV manager.</li>\n",
    "    <li>NOTA: utilizzare set UNA SOLA VOLTA alla fine del processo di elaborazione del dizionario dell'entità. è più conveniente. Non chiamarlo alla fine di ogni controllo singolo (data/orcid/validità/issn).</li>\n",
    "    <li>Verificare che il processo di sovrascrizione venga gestito come prima. Penso di sì perché si basa su csv manager.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def set(self, resource_id, value):\n",
    "        self._valid_doi.set(resource_id, value[\"valid\"])\n",
    "        self._id_date.set(resource_id, value[\"date\"])\n",
    "        self._id_issn.set(resource_id, value[\"issn\"])\n",
    "        self._id_orcid.set(resource_id, value[\"orcid\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def set(self, resource_id, value):\n",
    "        if value[\"valid\"] is False:\n",
    "            self._valid_id.add_value(resource_id, \"i\")\n",
    "        elif value[\"valid\"] is True:\n",
    "            self._valid_id.add_value(resource_id, \"v\")\n",
    "        if value[\"date\"] is not None:\n",
    "            self._id_date.add_value(resource_id, value[\"date\"])\n",
    "        else:\n",
    "            self._id_date.add_value(resource_id, \"\")\n",
    "        if value[\"issn\"] is not None and value[\"issn\"] != []:\n",
    "            self._id_issn.add_value(resource_id, value[\"issn\"])\n",
    "        if value[\"orcid\"] is not None and value[\"orcid\"] != []:\n",
    "            self._id_orcid.add_value(resource_id, value[\"orcid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- unified (query unificata su tutte le collezioni che ci servono.)\n",
    "- serve federated API di OC. Ci servirà a gestire citazioni \n",
    "- elastic search per ricerca testuale e in generale: fare query su triplestores così grandi. Per il momento stiamo su blazegraph.\n",
    "- mantenere separati i support files.\n",
    "- Sistemare visualizzazioni con Ivan\n",
    "- aggiungere silvio alle task\n",
    "- 3 files configurazione diversi\n",
    "- al csv data source deve arrivare il valore fatto bene, quindi la modifica va fatta nei glob\n",
    "- scrivere a Paolo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "abbiamo bisogno di capire chi ci usa. Per fare ciò, bisogna analizzare i log, ma solo delle chiamate alle API lascia perdere il resto, degli ultimi mesi (li trovi qui https://www.dropbox.com/sh/o75xqpf84371bnu/AACkqZHE-5s8gsEE8xpmvBoXa?dl=1 ma a minuti li estenderò con anche maggio e giugno). I cambi da guardare sono HTTP_USER_AGENT (per vedere se ci sono menzioni specifiche a tool o siti web o aziende o quant'altro) e HTTP_REFERER che, quando è presente, indica il sito web da cui la richiesta è partita e, dal dominio, si capisce chi è. Anche qui, ti chiederei di classificarli per quanto possibile (tool, rivista, editore, etc.) mettendo il numerino di quante richieste sono ricevute. Per favore, tieni anche i numerini delle richieste per singolo \"utente\". Ci sarà da sviluppare qualche script, che poi verrà probabilmente raffinato mano a mano, perché sono tante richieste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from argparse import ArgumentParser\n",
    "from os import sep, makedirs, walk\n",
    "import os\n",
    "import os.path\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "from tarfile import TarFile\n",
    "import re\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from os.path import exists, basename, isdir, join\n",
    "from timeit import default_timer as timer\n",
    "from re import sub\n",
    "import pandas as pd\n",
    "import codecs\n",
    "\n",
    "def get_all_files(i_dir):\n",
    "    result = []\n",
    "    opener = None\n",
    "    if i_dir.endswith(\".zip\"):\n",
    "        zf = ZipFile(i_dir)\n",
    "        namelist = zf.namelist()\n",
    "        result = [x for x in namelist if x.lower().endswith(\".txt\")]\n",
    "        opener = zf.open\n",
    "    elif i_dir.endswith(\".tar.gz\"):\n",
    "        tf = TarFile.open(i_dir)\n",
    "        for name in tf.getnames():\n",
    "            if name.lower().endswith(\".txt\"):\n",
    "                result.append(name)\n",
    "        opener = tf.extractfile\n",
    "\n",
    "    else:\n",
    "        for cur_dir, cur_subdir, cur_files in walk(i_dir):\n",
    "            for file in cur_files:\n",
    "                if file.lower().endswith(\".txt\"):\n",
    "                    result.append(cur_dir + sep + file)\n",
    "        opener = open\n",
    "    return result, opener\n",
    "\n",
    "def process(input_dir):\n",
    "    if not os.path.exists(\"report\"):\n",
    "        makedirs(\"report\")\n",
    "    if not os.path.exists(\"report/viz\"):\n",
    "        makedirs(\"report/viz\")\n",
    "\n",
    "    month_report = dict()\n",
    "    all_files, opener = get_all_files(input_dir)\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        filename_month = re.search(\"(?<=oc-)(\\d{4}-\\d{1,2})(?=.txt)\", file).group(0)\n",
    "        if filename_month not in month_report.keys():\n",
    "            month_report[filename_month] = dict()\n",
    "            with open(file) as f:\n",
    "                txt_obj = \" \".join(f.readlines())\n",
    "                month_report[filename_month][\"user_agent\"] = get_user_agent(txt_obj)\n",
    "                month_report[filename_month][\"refer\"] = get_refer(txt_obj)\n",
    "    top_user_agent, top_refer = get_global_report(month_report)\n",
    "    viz_trend_monitor(top_user_agent, top_refer, month_report)\n",
    "\n",
    "def get_user_agent(txt_obj):\n",
    "    # per vedere se ci sono menzioni specifiche a tool o siti web o aziende o quant'altro\n",
    "    result = dict()\n",
    "    user_agents = re.findall(\"(?<=HTTP_USER_AGENT:\\s)([^#]+)\", txt_obj)\n",
    "    for i in user_agents:\n",
    "        agent = re.search(\".*\", i).group(0)\n",
    "        if agent is not None:\n",
    "            agent = agent.strip()\n",
    "            if agent in result.keys():\n",
    "                result[agent] += 1\n",
    "            else:\n",
    "                result[agent] = 1\n",
    "    return result\n",
    "\n",
    "def get_refer(txt_obj):\n",
    "    # indica il sito web da cui la richiesta è partita e, dal dominio, si capisce chi è\n",
    "    result = dict()\n",
    "    refers = re.findall(\"(?<=HTTP_REFERER:\\s)([^#]+)\", txt_obj)\n",
    "    for i in refers:\n",
    "        refer = re.search(\".*\", i).group(0)\n",
    "        if refer is not None:\n",
    "            refer = refer.strip()\n",
    "            if refer.endswith(\"/\"):\n",
    "                refer = refer[:-1]\n",
    "            if refer in result.keys():\n",
    "                result[refer] += 1\n",
    "            else:\n",
    "                result[refer] = 1\n",
    "    return result\n",
    "\n",
    "def get_global_report(report_dict):\n",
    "    top_user_agent = set()\n",
    "    top_refer = set()\n",
    "    list_of_dicts_to_csv_ua = list()\n",
    "    list_of_dicts_to_csv_r = list()\n",
    "    for k, v in report_dict.items():\n",
    "        ua_dict = dict()\n",
    "        ua_dict[\"month\"] = \"user agent \" + k\n",
    "        ua_median = statistics.median(v[\"user_agent\"].values())\n",
    "        ua_dict[\"median\"] = ua_median\n",
    "        ua_mean = statistics.mean(v[\"user_agent\"].values())\n",
    "        ua_dict[\"mean\"] = ua_mean\n",
    "        ua_dict[\"total_calls\"] = sum(v[\"user_agent\"].values())\n",
    "        ua_dict[\"from_total_origins\"] = len(v[\"user_agent\"])\n",
    "        #ua_dict[\"above_median\"] = [key for key, value in v[\"user_agent\"].values() if value > ua_median]\n",
    "        ua_above_median = {key: val for (key, val) in v[\"user_agent\"].items() if val > ua_median}\n",
    "        ua_dict[\"n_above_median\"] = len(sorted(ua_above_median, key=ua_above_median.get, reverse=True))\n",
    "        #ua_dict[\"above_mean\"] = [key for key, value in v[\"user_agent\"].values() if value > ua_mean]\n",
    "        ua_above_mean = {key: val for (key, val) in v[\"user_agent\"].items() if val > ua_mean}\n",
    "        ua_dict[\"n_above_mean\"] = len(sorted(ua_above_mean, key=ua_above_mean.get, reverse=True))\n",
    "        ua_dict[\"above_mean\"] = str(sorted(ua_above_mean.items(), key=lambda x:x[1], reverse=True)[:15])\n",
    "        sort_top_ua = sorted(ua_above_mean.items(), key=lambda x:x[1], reverse=True)[:15]\n",
    "        for ua in sort_top_ua:\n",
    "            top_user_agent.add(ua[0])\n",
    "\n",
    "        r_dict = dict()\n",
    "        r_dict[\"month\"] = \"refer \" + k\n",
    "        r_median = statistics.median(v[\"refer\"].values())\n",
    "        r_dict[\"median\"] = r_median\n",
    "        r_mean = statistics.mean(v[\"refer\"].values())\n",
    "        r_dict[\"mean\"] = r_mean\n",
    "        r_dict[\"total_calls\"] = sum(v[\"refer\"].values())\n",
    "        r_dict[\"from_total_origins\"] = len(v[\"refer\"])\n",
    "        #ua_dict[\"above_median\"] = [key for key, value in v[\"refer\"].values() if value > ua_median]\n",
    "        r_above_median = {key: val for (key, val) in v[\"refer\"].items() if val > r_median}\n",
    "        r_dict[\"n_above_median\"] = len(sorted(r_above_median, key=r_above_median.get, reverse=True))\n",
    "        #ua_dict[\"above_mean\"] = [key for key, value in v[\"refer\"].values() if value > ua_mean]\n",
    "        r_above_mean = {key: val for (key, val) in v[\"refer\"].items() if val > r_mean}\n",
    "        r_dict[\"n_above_mean\"] = len(sorted(r_above_mean, key=r_above_mean.get, reverse=True))\n",
    "        r_dict[\"above_mean\"] = str(sorted(r_above_mean.items(), key=lambda x:x[1], reverse=True)[:15])\n",
    "        sort_top_r = sorted(r_above_mean.items(), key=lambda x: x[1], reverse=True)[:15]\n",
    "        for r in sort_top_r:\n",
    "            top_refer.add(r[0])\n",
    "\n",
    "        list_of_dicts_to_csv_ua.append(ua_dict)\n",
    "        list_of_dicts_to_csv_r.append(r_dict)\n",
    "\n",
    "    with open('report/global_report_useragent.csv', 'w', encoding='utf8', newline='') as output_file:\n",
    "        fc = csv.DictWriter(output_file, fieldnames=list_of_dicts_to_csv_ua[0].keys())\n",
    "        fc.writeheader()\n",
    "        fc.writerows(list_of_dicts_to_csv_ua)\n",
    "    with open('report/global_report_refer.csv', 'w', encoding='utf8', newline='') as output_file:\n",
    "        fc = csv.DictWriter(output_file, fieldnames=list_of_dicts_to_csv_r[0].keys())\n",
    "        fc.writeheader()\n",
    "        fc.writerows(list_of_dicts_to_csv_r)\n",
    "\n",
    "    return top_user_agent, top_refer\n",
    "\n",
    "\n",
    "def viz_trend_monitor(agent_set, refer_set, report_dict):\n",
    "    months = sorted(report_dict.keys())\n",
    "    dict_to_dataframe_ua = dict()\n",
    "    dict_to_dataframe_ua[\"x_values\"] = tuple(months)\n",
    "    for agent in agent_set:\n",
    "        agent_list = []\n",
    "        for m in months:\n",
    "            if agent in report_dict[m][\"user_agent\"]:\n",
    "                agent_list.append(report_dict[m][\"user_agent\"][agent])\n",
    "            else:\n",
    "                agent_list.append(0)\n",
    "        dict_to_dataframe_ua[agent] = tuple(agent_list)\n",
    "\n",
    "\n",
    "    #df = pd.DataFrame(dict_to_dataframe)\n",
    "\n",
    "    # multiple line plots\n",
    "    print(\"WOOOOOW\", dict_to_dataframe_ua)\n",
    "    for k,v in dict_to_dataframe_ua.items():\n",
    "        if k != \"x_values\" and k != \"None\" and k is not None:\n",
    "            plt.plot(dict_to_dataframe_ua[\"x_values\"], dict_to_dataframe_ua[k], label=k)\n",
    "    # show legend\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # show graph\n",
    "    fig0 = plt.gcf()\n",
    "    fig0.tight_layout()\n",
    "    plt.show()\n",
    "    plt.draw()\n",
    "    fig0.savefig('report/viz/ua_report.png', dpi=100, bbox_inches='tight')\n",
    "\n",
    "\n",
    "    dict_to_dataframe_r = dict()\n",
    "    dict_to_dataframe_r[\"x_values\"] = tuple(months)\n",
    "    for refer in refer_set:\n",
    "        refer_list = []\n",
    "        for m in months:\n",
    "            if refer in report_dict[m][\"refer\"]:\n",
    "                refer_list.append(report_dict[m][\"refer\"][refer])\n",
    "            else:\n",
    "                refer_list.append(0)\n",
    "        dict_to_dataframe_r[refer] = tuple(refer_list)\n",
    "\n",
    "\n",
    "    #df = pd.DataFrame(dict_to_dataframe)\n",
    "\n",
    "    # multiple line plots\n",
    "    print(\"WIIIIIW\", dict_to_dataframe_r)\n",
    "    for k,v in dict_to_dataframe_r.items():\n",
    "        if k != \"x_values\" and k != \"None\" and k is not None:\n",
    "            plt.plot(dict_to_dataframe_r[\"x_values\"], dict_to_dataframe_r[k], label=k)\n",
    "    # show legend\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # show graph\n",
    "    fig1 = plt.gcf()\n",
    "    fig1.tight_layout()\n",
    "    plt.show()\n",
    "    plt.draw()\n",
    "    fig1.savefig('report/viz/r_report.png', dpi=100, bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    arg_parser = ArgumentParser(\n",
    "        \"script for analysing log data in OC\",\n",
    "        description=\"Process txt files containing log information\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-i\",\n",
    "        \"--input\",\n",
    "        dest=\"input\",\n",
    "        required=True,\n",
    "        help=\"Directory that contains OC txt log files\",\n",
    "    )\n",
    "\n",
    "    args = arg_parser.parse_args()\n",
    "    process(args.input)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# python \"main.py\" -i 2022\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IG OSG, TPDL, Log Data Analysis, Glob con CSV_Datasource\n",
    "<a id=\"entry_17\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper TPDL (scadenza 25 Luglio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Correzioni da fare</b>: <br>\n",
    "The paper discusses a four-step methodology for designing open science infrastructures that are reusable, replicable and portable in different environments. The proposed methodology adopts existing technologies to enable the isolation, federation and distribution of the infrastructure's services, relying on the 'infrastructure-as-code' practice. \n",
    "\n",
    "Although the overall topic is timely and interesting, <b>the novelty and unique contribution of the presented work is not clear</b>. The discussed methodology is more a set of guidelines on how to use existing technologies, suggesting the production of technical documents, the split of services, etc. \n",
    "<b>It is not clear what is the problem/limitation of the existing works (guidelines) that help in maintaining and monitoring open science infrastructures, and which also highlight the need of reusability and portability. </b>\n",
    "\n",
    "<b>I was expecting to see an application of the proposed methodology on at least one real infrastructure </b>(for showcasing its advantages), and not just a discussion on how this *could* be applied in the case of OpenCitations.\n",
    "<ol>\n",
    "    <li>chiarire la rilevanza e la particolarità del contributo</li>\n",
    "    <li>sottolineare quali sono i limiti delle linee guida seguite fino ad ora </li>\n",
    "    <li>spiegare perché non abbiamo portato un caso di applicazione già in atto anziché progettuale</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IG OSG \n",
    "#### Cosa è emerso dall'incontro di questa settimana:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13/07/2022 \n",
    "discussion about TF1-TF2\n",
    "There are lots of players in the scholarly domain modeling scholarly knowledge from different points of view, applications and angles. It would be interesting to make them communicate with each other. \n",
    "First 2 tasks:\n",
    "OSG core information Model : the purpose is that of defining a model that can equally express relevant info across all of the existing relevant models we start from, implementing interoperability layers and allowing many people to have the same representations of the same things.\n",
    "The second task concerns how we want this interoperability to happen from a technology point of view. \n",
    "\n",
    "As to start, we need a selection of OS graphs that we consider relevant for this work. We want to do something which is easily embraceable by a large number of users. For the moment, the more solutions we come up with the better it is. Task One is propaedeutic to task Two,  once we have one we can go on with two.\n",
    "So far, we don't intend a semantic web kind of graph: not necessarily semantic web tech for now, not necessarily modeled in one specific way. The starting point is that the graph components are to be combined by relations between entities identified by IDs. \n",
    "\n",
    "First action to be done: link OS graphs we already cover by design. OpenAire, OpenCitations, Research graph, semantic scholar, OpenAlex. Crossref itself could be identified as a graph, since we have a graph any time we have entities linked by relations. Orcid itself could be another organization to involve. In the beginning we have to understand which entities are in place and how we want to represent them. We have to understand how to represent the objects, which is the common semantic layer.\n",
    "\n",
    "Second part : dealing with interoperability. Since these actors or databases (some are graphs, not all of them, at least in the most common conception… however we consider graphs as collections implicitly representing relations between entities) do not share a common crosswalk, we have to create it. And this will come as a consequence of a common data model. Schema should be as light as possible. We have to decide on these aspects for now, protocols will come later. \n",
    "\n",
    "Are we able to add to the data extra information? We have to provide the user with the possibility to choose between the information that we have to be able to provide. \n",
    "\n",
    "Entity level analysis of these graphs/databases: task 1 is for obtaining a common ground semantic model. Is there any survey we want to do? Are we going to work from scratch? Very relevant question: Andrea has already done some work on this point and has arrived at the conclusion that no single existing model can be proposed as standard now. For example, CERIF (famous for link entities, https://www.researchgate.net/figure/Transforming-extended-relational-CERIF-into-Open-Graph-CERIF_tbl2_233906144 ) cannot be proposed as standard. There are solutions apparently geographically radicated to certain areas. Not adopted or accepted longitudinally. If we want to do some review on previous works he is totally up to. \n",
    "\n",
    "Paolo: A graph is more at a conceptual level. A graph is not necessarily something that should be stored “as a graph”, but is just something that can be accessed from the point of view of entities and their links.\n",
    " \n",
    "At this stage, it is very important to define which are the core entities we want to take into account. This first analysis will tell us what to focus on. For example, if bio entities are present in one over a hundred graphs, this is not what we should focus on. We have to focus on the core elements. However, there are already some entities identified for the data model (see slides): we are not going to reinvent the wheel. \n",
    "\n",
    "We have to consider including possible pointers: URL that takes you to the original record. It would also be quite relevant (not possible for all graphs). It has implications in provenance and trust. \n",
    "\n",
    "In conclusion, we have to define the schedule (August - September). We would like to define a table where we can write down and complete the points (we will be contacted via email for this). Once we have defined point two together, we will start with three. How to structure point three is to be defined. \n",
    "We will have another meeting in the second half of August. The idea is to continue the work with one meeting in August and one meeting in September. \n",
    "\n",
    "Can we use DCAT as a starting point? https://www.w3.org/TR/vocab-dcat-2/  ? Paolo Manghi does not agree. First of all, CERIF has a better representation for what we need. DCAT is important but is one of the tens out there. We don't want to push one model over the others now. We should deal with DCAT as with all the others. See also openAlex (https://openalex.org/ ) , which is more relevant in our domain. The matter is complex. Also schema.org is important. However, by definition, none of the existing materials solves the problem itself. So there is not a single starting point. \n",
    "\n",
    "In the next few days they’ll prepare the aforementioned table. For now the mailing list is enough, in future they may open a Slack group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gruppo RDA di OSG\n",
    "Andrea ha aggiunto chi ha dato disponibilità al RDA group di OSG. Siete tutti riusciti ad entrare nel gruppo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Week\n",
    "Nel caso in cui fossimo interessati ad alcune delle conferenze, i video saranno ancora visibili per tre o quattro settimane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ScanR\n",
    "Facendo l'analisi dei dati di Log ho trovato questo aggregatore sulla ricerca francese del Ministère de l'Enseignement supérieur et de la Recherche che potrebbe interessante anche per l'OSG IG. <br>\n",
    "<a href= \"https://scanr.enseignementsup-recherche.gouv.fr/\">scanR</a> allows you to search for companies active in research and innovation, public research laboratories, public funding, research work (publications, PhD dissertations). ScanR identifies the links between these different objects and allows to describe them in their context. For example, scanR can instantly provide a mapping of research collaborations of a laboratory or any other institution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSVDataSource\n",
    "Nonostante avessimo detto di fare in modo che i dati arrivassero più puliti possibile al CSVDataSource, ho fatto alcune modifiche per evitare problemi di sovrascrizione dei dati e gestione di più possibili dati per una chiave della mappa di una data entità.<br>\n",
    "Nello specifico, prima la parte del codice in questione era:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def set(self, resource_id, value):\n",
    "        self._valid_doi.set(resource_id, value[\"valid\"])\n",
    "        self._id_date.set(resource_id, value[\"date\"])\n",
    "        self._id_issn.set(resource_id, value[\"issn\"])\n",
    "        self._id_orcid.set(resource_id, value[\"orcid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ed ora è "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def set(self, resource_id, value):\n",
    "        if value[\"valid\"] is False:\n",
    "            self._valid_id.add_value(resource_id, \"i\")\n",
    "        elif value[\"valid\"] is True:\n",
    "            self._valid_id.add_value(resource_id, \"v\")\n",
    "        if value[\"date\"] is not None and value[\"date\"] != []:\n",
    "            #self._id_date.add_value(resource_id, value[\"date\"])\n",
    "            # per gestire inserimenti date multiple ed evitare errore  self.data[id_string].add(value) TypeError: unhashable type: 'set'\n",
    "            for date in value[\"date\"]:\n",
    "                self._id_date.add_value(resource_id, date)\n",
    "        else:\n",
    "            self._id_date.add_value(resource_id, \"\")\n",
    "        if value[\"issn\"] is not None and value[\"issn\"] != []:\n",
    "            # self._id_issn.add_value(resource_id, value[\"issn\"])\n",
    "            # per gestire inserimenti issn multipli ed evitare errore  self.data[id_string].add(value) TypeError: unhashable type: 'set'\n",
    "            for issn in value[\"issn\"]:\n",
    "                self._id_issn.add_value(resource_id, issn)\n",
    "        if value[\"orcid\"] is not None and value[\"orcid\"] != []:\n",
    "            # self._id_orcid.add_value(resource_id, value[\"orcid\"])\n",
    "            # per gestire inserimenti orcid multipli e evitare errore  self.data[id_string].add(value) TypeError: unhashable type: 'set'\n",
    "            for orcid in value[\"orcid\"]:\n",
    "                self._id_orcid.add_value(resource_id, orcid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "    <ol>\n",
    "    <li><b>Il valore della chiave \"valid\"</b>, per mantenere la vecchia struttura dei file (sia per come erano precedentemente strutturati i support file, ma anche per come funziona ad esempio il csv manager) va convertito in una stringa prima di essere trascritto nel csv. <b>Domanda:</b> è meglio modificare il csv manager per fare in modo che gestisca anche l'inserimento di booleani come valori (evitando l'errore % (id_string.replace('\"', '\"\"'), value.replace('\"', '\"\"')) AttributeError: 'bool' object has no attribute 'replace')) o tenere la struttura attuale con la conversione in stringhe \"v\" e \"i\"? Nota: csvdatasource.get(id)[\"valid\"], proprio come succedeva nell'analogo del csv manager, restituisce un set con -teoricamente- un solo valore. Tuttavia, in linea teorica, questo metodo rende possibile che csvdatasource.get(id)[\"valid\"] ritorni un set del tipo {\"v\", \"i\"}</li>\n",
    "    <li><b>Controllo dell'esistenza pregressa di un'entità</b>. Allo stato attuale csvdatasource.get(id) crea il dizionario-mappa dei valori raccolti per un dato identificativo in tutti e quattro i files di supporto. Tuttavia, csvdatasource.get(id) non può dare risposta negativa, perché genera il dizionario al momento della domanda. Quindi, allo stato attuale, un modo per capire se un'entità è già stata presa in considerazione o meno potrebbe essere:<b> if [k for k,v in dict.items() if v != None] </b>, ovvero controllare se almeno uno dei valori è divrso da None al momento del controllo, o anche solo <b>if csvdatasource.get(id)[\"valid\"]!= None</b>. C'è un altro modo per verificarlo?</li>\n",
    "        <li><b>\"issn\", \"orcid\" e \"dates\"</b>: essendo che in linea teorica possono contenere più di un valore, la struttura <b>self._id_issn.set(resource_id, value[\"issn\"])</b> può generare l'errore <b>self.data[id_string].add(value) TypeError: unhashable type: 'set'</b>, nel caso in cui si decida di strutturare il codice in modo tale da raccogliere prima tutti i dati (ad esempio tutti gli issn) e poi aggiornare la mappa dell'entità, utilizzando csv_datasource.set(id, dict) il minor numero di volte possibili. In caso contrario, l'operazione potrebbe essere ripetuta per ogni issn e per ogni orcid, ma la procedura rischia di diventare lenta. Per questo motivo ho sistemato questa parte di codice in modo tale da prevedere che (a prescindere che sia uno o che siano di più) i dati per i campi \"date\", \"issn\", \"orcid\" arrivino raggruppati in una lista, di cui ciascun elemento viene poi aggiunto ai csv dal csv manager, a meno che non sia già presente nel set di valori associati all'entità di riferimento.</li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzionamento dei nuovi glob - \n",
    "#### Inserimento di un nuovo documento o aggiornamento dei dati di uno già inserito\n",
    "-  <b>csv_datasource.get(citing_pmid)</b> restituisce un dizionario con 4 chiavi, tutte None se l'entità è nuova. ad esempio: csv_datasource.get(citing_pmid)  =  <b>{'date': None, 'valid': None, 'issn': None, 'orcid': None}</b>\n",
    "- la scrittura sui files (che corrisponde all'aggiornamento del dizionario dell'entità) avviente così: <b>csv_datasource.set(citing_pmid, entity)</b>, dove entity è il dizionario che corrisponde all'entità. Per questo motivo, ha senso farlo una volta sola, dopo aver aggiornato una copia del dizionario con tutte le informazioni a disposizione: validità, data, issn, orcid. \n",
    "- Ogni valore di ogni chiave è come sempre un set\n",
    "- ricapitolando, per ogni entità in questione, si ottengono eventuali dati già esistenti con csv_datasource.get(citing_pmid) . Se i dati non ci sono, si ottiene un dizionario vuoto generato sul momento. Si fa quindi una copia di questo dizionario salvandolo in una variabile, lo si aggiorna aggiungendo alla lista di ogni chiave i valori raccolti nel corso dell'analisi e infine si aggiornano tutti i glob files con csv_datasource.set(citing_pmid, entity).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Es. Noci Glob (versione CSV_Data_Source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "import csv\n",
    "from argparse import ArgumentParser\n",
    "from os import sep, makedirs, walk\n",
    "import os\n",
    "import os.path\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "from tarfile import TarFile\n",
    "import re\n",
    "from os.path import exists, basename, isdir, join\n",
    "from timeit import default_timer as timer\n",
    "from re import sub\n",
    "import pandas as pd\n",
    "import codecs\n",
    "\n",
    "from oc.index.oci.citation import Citation\n",
    "from oc.index.legacy.csv import CSVManager\n",
    "from oc.index.identifier.doi import DOIManager\n",
    "from oc.index.identifier.pmid import PMIDManager\n",
    "from oc.index.identifier.issn import ISSNManager\n",
    "from oc.index.identifier.orcid import ORCIDManager\n",
    "from oc.index.finder.orcid import ORCIDResourceFinder\n",
    "from oc.index.finder.crossref import CrossrefResourceFinder\n",
    "from oc.index.glob.csv import CSVDataSource\n",
    "\n",
    "#get = CSVDataSource.get(doi) #quando vuoi ottenere quello attuale get(doi) e ti restituisce la mappa se esiste\n",
    "#new = CSVDataSource.new()\n",
    "#set = CSVDataSource.set()\n",
    "\n",
    "# Questo datasource apre automaticamente i csv specificati nel config ( si trova nella\n",
    "# home come al solito poi .opencitations/index/config.ini)\n",
    "# controllo se prima esiste e se non esiste la creo\n",
    "# il file va riconfigurato a mano, quindi per ora sep\n",
    "# da ragionare gestione duplicati\n",
    "#\n",
    "#\n",
    "# Dopodiché qui si ragiona a documenti quindi,\n",
    "# un documento é una mappa contenente le chiavi valid, date, issn e orcid quando vuoi aggiungere un nuovo\n",
    "# entità fai set(doi, mappa) quando vuoi ottenere quello attuale get(doi) e ti restituisce la mappa\n",
    "# se esiste (chiavi: valid, date, issn e orcid ), per creare una nuova mappa documento chiami il metodo new sul datasource.\n",
    "# Per inizializzare il datasource semplicemente CSVDataSource(), il costruttore non ha parametri.\n",
    "\n",
    "\n",
    "def issn_data_recover_noci(directory):\n",
    "    journal_issn_dict = dict()\n",
    "    filename = join(directory, \"journal_issn.json\")\n",
    "    if not os.path.exists(filename):\n",
    "        return journal_issn_dict\n",
    "    else:\n",
    "        with open(filename, \"r\", encoding=\"utf8\") as fd:\n",
    "            journal_issn_dict = json.load(fd)\n",
    "            return journal_issn_dict\n",
    "\n",
    "\n",
    "def issn_data_to_cache_noci(name_issn_dict, directory):\n",
    "    filename = directory + sep + \"journal_issn.json\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as fd:\n",
    "        json.dump(name_issn_dict, fd, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "# takes in input a data structure representing a bibliographic entity\n",
    "def build_pubdate_noci(row):\n",
    "    year = str(row[\"year\"])\n",
    "    str_year = sub(\"[^\\d]\", \"\", year)[:4]\n",
    "    if str_year:\n",
    "        return str_year\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# get_all_files extracts all the needed files from the input directory\n",
    "def get_all_files_noci(i_dir):\n",
    "    result = []\n",
    "    opener = None\n",
    "    if i_dir.endswith(\".zip\"):\n",
    "        zf = ZipFile(i_dir)\n",
    "        namelist = zf.namelist()\n",
    "        result = [x for x in namelist if x.lower().endswith(\".csv\")]\n",
    "        opener = zf.open\n",
    "    elif i_dir.endswith(\".tar.gz\"):\n",
    "        tf = TarFile.open(i_dir)\n",
    "        for name in tf.getnames():\n",
    "            if name.lower().endswith(\".csv\"):\n",
    "                result.append(name)\n",
    "        opener = tf.extractfile\n",
    "\n",
    "    else:\n",
    "        for cur_dir, cur_subdir, cur_files in walk(i_dir):\n",
    "            for file in cur_files:\n",
    "                if file.lower().endswith(\".csv\"):\n",
    "                    result.append(cur_dir + sep + file)\n",
    "        opener = open\n",
    "    return result, opener\n",
    "\n",
    "\n",
    "def process_noci(input_dir, output_dir, n, id_orcid_dir=None):\n",
    "    print(\"prova\")\n",
    "    start = timer()\n",
    "    if not exists(output_dir):\n",
    "        makedirs(output_dir)\n",
    "\n",
    "    citing_pmid_with_no_date = set()\n",
    "    journal_issn_dict = issn_data_recover_noci(output_dir)\n",
    "    crossref_resource_finder = CrossrefResourceFinder()\n",
    "    orcid_resource_finder = ORCIDResourceFinder()\n",
    "\n",
    "    doi_manager = DOIManager()\n",
    "    issn_manager = ISSNManager()\n",
    "    orcid_manager = ORCIDManager()\n",
    "    pmid_manager = PMIDManager()\n",
    "    csv_datasource = CSVDataSource()\n",
    "    print(\"33255463\", csv_datasource.get(\"pmid:33255463\"),\"è valido??\",csv_datasource.get(\"pmid:33255463\")[\"valid\"])\n",
    "\n",
    "    all_files, opener = get_all_files_noci(input_dir)\n",
    "    len_all_files = len(all_files)\n",
    "    pmid_doi_map = dict()\n",
    "\n",
    "    # Read all the CSV file in the NIH dump to create the main information of all the indexes\n",
    "    # print(\"\\n\\n# Add valid PMIDs from NIH metadata\")\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        for chunk in pd.read_csv(file, chunksize=1000):\n",
    "            f = pd.concat([df, chunk], ignore_index=True)\n",
    "            f.fillna(\"\", inplace=True)\n",
    "\n",
    "            # print(\"Open file %s of %s\" % (file_idx, len_all_files))\n",
    "            for index, row in f.iterrows():\n",
    "                if int(index) != 0 and int(index) % int(n) == 0:\n",
    "                    # print( \"Group nr.\", int(index)//int(n), \"processed. Data from\", int(index), \"rows saved to journal_issn.json mapping file\")\n",
    "                    issn_data_to_cache_noci(journal_issn_dict, output_dir)\n",
    "\n",
    "                citing_pmid = pmid_manager.normalise(row[\"pmid\"], True)\n",
    "                if citing_pmid is not None:\n",
    "                    entity = csv_datasource.get(citing_pmid)\n",
    "                    entity[\"valid\"] = True\n",
    "\n",
    "                    citing_doi = doi_manager.normalise(row[\"doi\"], False)\n",
    "                    if citing_doi and csv_datasource.get(citing_pmid)[\"orcid\"] is None:\n",
    "                        #capire se li mette in una lista\n",
    "                        pmid_doi_map[citing_pmid] = {\"doi\": citing_doi, \"has_orcid\": False}\n",
    "\n",
    "                    if entity[\"date\"] is None:\n",
    "                        citing_date = Citation.check_date(build_pubdate_noci(row))\n",
    "                        if citing_date is not None:\n",
    "                            entity[\"date\"] = [citing_date]\n",
    "                            if citing_pmid in citing_pmid_with_no_date:\n",
    "                                citing_pmid_with_no_date.remove(citing_pmid)\n",
    "                        else:\n",
    "                            citing_pmid_with_no_date.add(citing_pmid)\n",
    "\n",
    "                    if entity[\"issn\"] is None:\n",
    "                        issn_list = []\n",
    "                        #capire se li mette in una lista\n",
    "                        journal_name = row[\"journal\"]\n",
    "                        if journal_name:\n",
    "                            if journal_name in journal_issn_dict.keys():\n",
    "                                for issn in journal_issn_dict[journal_name]:\n",
    "                                    issn_list.append(issn) #li aggiunge se sono più di uno?\n",
    "\n",
    "                            else:\n",
    "                                if citing_doi is not None:\n",
    "                                    json_res = crossref_resource_finder._call_api(citing_doi)\n",
    "                                    if json_res is not None:\n",
    "                                        issn_set = crossref_resource_finder._get_issn(json_res)\n",
    "                                        if len(issn_set) > 0:\n",
    "                                            journal_issn_dict[journal_name] = []\n",
    "                                        for issn in issn_set:\n",
    "                                            issn_norm = issn_manager.normalise(str(issn))\n",
    "                                            issn_list.append(issn_norm)\n",
    "                                            journal_issn_dict[journal_name].append(issn_norm)\n",
    "                        else:\n",
    "                            if citing_doi is not None:\n",
    "                                json_res = crossref_resource_finder._call_api(citing_doi)\n",
    "                                if json_res is not None:\n",
    "                                    issn_set = crossref_resource_finder._get_issn(json_res)\n",
    "                                    for issn in issn_set:\n",
    "                                        issn_norm = issn_manager.normalise(str(issn))\n",
    "                                        issn_list.append(issn_norm)\n",
    "                        if issn_list != []:\n",
    "                            entity[\"issn\"] = issn_list\n",
    "                    csv_datasource.set(citing_pmid, entity)\n",
    "\n",
    "            if len(pmid_doi_map) > 0:\n",
    "                if id_orcid_dir and exists(id_orcid_dir):\n",
    "                    orcid_id_files, op = get_all_files_noci(id_orcid_dir)\n",
    "                    len_orcid_id_files = len(orcid_id_files)\n",
    "                    if len_orcid_id_files > 0:\n",
    "                        for f_idx, f in enumerate(orcid_id_files, 1):\n",
    "                            unzip_file = op(f, mode=\"r\")\n",
    "                            unzip_file = csv.DictReader(\n",
    "                                codecs.iterdecode(unzip_file, \"utf-8\")\n",
    "                            )\n",
    "                            for row in unzip_file:\n",
    "                                if [\n",
    "                                    k\n",
    "                                    for k, v in pmid_doi_map.items()\n",
    "                                    if v[\"doi\"] == row[\"id\"]\n",
    "                                ]:\n",
    "                                    c_pmid = [\n",
    "                                        k\n",
    "                                        for k, v in pmid_doi_map.items()\n",
    "                                        if v[\"doi\"] == row[\"id\"]\n",
    "                                    ][\n",
    "                                        0\n",
    "                                    ]  # To do: exact match\n",
    "                                    c_doi = doi_manager.normalise(row[\"id\"], False)\n",
    "                                    orcid = re.search(\n",
    "                                        \"\\[(([X0-9]\\-?){4}){4}]\",\n",
    "                                        row[\"value\"],\n",
    "                                        re.IGNORECASE,\n",
    "                                    ).group(0)\n",
    "                                    if orcid:\n",
    "                                        nor_orcid = orcid_manager.normalise(orcid)\n",
    "                                        if nor_orcid:\n",
    "                                            c_pmid_entity = csv_datasource.get(c_pmid)\n",
    "                                            #id_orcid.add_value(c_pmid, nor_orcid)\n",
    "                                            if c_pmid_entity[\"orcid\"] is None:\n",
    "                                                c_pmid_entity[\"orcid\"] = []\n",
    "                                                c_pmid_entity[\"orcid\"].append(nor_orcid)\n",
    "                                            else:\n",
    "                                                c_pmid_entity[\"orcid\"] = list(c_pmid_entity[\"orcid\"])\n",
    "                                                c_pmid_entity[\"orcid\"].append(nor_orcid)\n",
    "\n",
    "                                            csv_datasource.set(c_pmid, c_pmid_entity)\n",
    "\n",
    "                                            if pmid_doi_map[c_pmid][\"has_orcid\"] == False:\n",
    "                                                pmid_doi_map[c_pmid][\"has_orcid\"] = True\n",
    "\n",
    "                for citing_pmid, d in pmid_doi_map.items():\n",
    "                    if d[\"has_orcid\"] == False:\n",
    "                        json_res = orcid_resource_finder._call_api(d[\"doi\"])\n",
    "                        if json_res is not None:\n",
    "\n",
    "                            orcid_list = []\n",
    "                            citing_pmid_dict = csv_datasource.get(citing_pmid)\n",
    "\n",
    "                            orcid_set = orcid_resource_finder._get_orcid(json_res)\n",
    "                            if len(orcid_set) > 0:\n",
    "                                d[\"has_orcid\"] = True\n",
    "                                for orcid in orcid_set:\n",
    "                                    orcid_norm = orcid_manager.normalise(orcid)\n",
    "                                    #id_orcid.add_value(citing_pmid, orcid_norm)\n",
    "                                    orcid_list.append(orcid_norm)\n",
    "                                if citing_pmid_dict[\"orcid\"] is None:\n",
    "                                    citing_pmid_dict[\"orcid\"] = orcid_list\n",
    "                                else:\n",
    "                                    citing_pmid_dict[\"orcid\"].extend(orcid_list)\n",
    "                                csv_datasource.set(citing_pmid,citing_pmid_dict)\n",
    "\n",
    "\n",
    "            pmid_doi_map = dict()\n",
    "            issn_data_to_cache_noci(journal_issn_dict, output_dir)\n",
    "\n",
    "    middle = timer()\n",
    "\n",
    "    # print(\"first process duration: :\", (middle - start))\n",
    "    # print(\"\\n\\n# Checking the referenced pmids validity\")\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        for chunk in pd.read_csv(file, chunksize=1000):\n",
    "            f = pd.concat([df, chunk], ignore_index=True)\n",
    "            f.fillna(\"\", inplace=True)\n",
    "            # print(\"Open file %s of %s\" % (file_idx, len_all_files))\n",
    "            for index, row in f.iterrows():\n",
    "                if row[\"references\"] != \"\":\n",
    "                    ref_string = row[\"references\"].strip()\n",
    "                    ref_string_norm = re.sub(\"\\s+\", \" \", ref_string)\n",
    "                    cited_pmids = set(ref_string_norm.split(\" \"))\n",
    "                    for cited_pmid in cited_pmids:\n",
    "                        cited_pmid = pmid_manager.normalise(cited_pmid, True)\n",
    "                        if cited_pmid is not None:\n",
    "                            cited_pmid_entity = csv_datasource.get(cited_pmid)\n",
    "                            if cited_pmid_entity[\"valid\"] is None:\n",
    "                                cited_pmid_entity[\"valid\"] = (True if pmid_manager.is_valid(cited_pmid) else False)\n",
    "                            #cited_pmid_entity[\"valid\"] viene salvato come v ma mappato come True, ritorna True\n",
    "                            if cited_pmid_entity[\"valid\"] == {\"v\"} and cited_pmid_entity[\"date\"] is None:\n",
    "                                #controlla che non restituisca v anziché True\n",
    "                                citing_pmid_with_no_date.add(cited_pmid)\n",
    "                            csv_datasource.set(cited_pmid, cited_pmid_entity)\n",
    "\n",
    "                if row[\"cited_by\"] != \"\":\n",
    "                    citing_string = row[\"cited_by\"].strip()\n",
    "                    citing_string_norm = re.sub(\"\\s+\", \" \", citing_string)\n",
    "                    citing_pmids = set(citing_string_norm.split(\" \"))\n",
    "                    for citing_p in citing_pmids:\n",
    "                        citing_p = pmid_manager.normalise(citing_p, True)\n",
    "                        if citing_p is not None:\n",
    "                            citing_p_entity = csv_datasource.get(citing_p)\n",
    "                            if citing_p_entity[\"valid\"] is None:\n",
    "                                citing_p_entity[\"valid\"] = (True if pmid_manager.is_valid(citing_p) else False)\n",
    "                            if citing_p_entity[\"valid\"] == {\"v\"} and citing_p_entity[\"date\"] is None:\n",
    "                            #if citing_p_entity[\"valid\"] is True and citing_p_entity[\"date\"] is None:\n",
    "                                citing_pmid_with_no_date.add(citing_p)\n",
    "                            csv_datasource.set(citing_p, citing_p_entity)\n",
    "\n",
    "    for pmid in citing_pmid_with_no_date:\n",
    "        pmid_entity = csv_datasource.get(pmid) #per accertarci che lo crei ( e lo crea date = None ovviamente)\n",
    "        #pmid_entity[\"date\"] = \"\" non c'è bisogno perché traduce None in stringa vuota\n",
    "        csv_datasource.set(pmid, pmid_entity)\n",
    "\n",
    "    end = timer()\n",
    "    # print(\"second process duration: \", end-middle)\n",
    "    # print(\"full process duration: \", end-start)\n",
    "\n",
    "\n",
    "def main():\n",
    "    arg_parser = ArgumentParser(\n",
    "        \"Global files creator for NOCI\",\n",
    "        description=\"Process iCiteMetadata CSV files and create global indexes to enable the creation of NOCI.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-i\",\n",
    "        \"--input\",\n",
    "        dest=\"input\",\n",
    "        required=True,\n",
    "        help=\"Either the directory or the zip file that contains the iCiteMetadata data dump of CSV files.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-o\",\n",
    "        \"--output\",\n",
    "        dest=\"output\",\n",
    "        required=True,\n",
    "        help=\"The directory where the indexes are stored.\",\n",
    "    )\n",
    "\n",
    "    arg_parser.add_argument(\n",
    "        \"-n\",\n",
    "        \"--entities\",\n",
    "        dest=\"entities\",\n",
    "        required=True,\n",
    "        help=\"Interval of processed entities after which the issn data are saved to the cache file.\",\n",
    "    )\n",
    "\n",
    "    arg_parser.add_argument(\n",
    "        \"-iod\",\n",
    "        \"--orcid\",\n",
    "        dest=\"orcid\",\n",
    "        required=False,\n",
    "        help=\"Either the directory or the zip file that contains the id-orcid mapping data.\",\n",
    "    )\n",
    "\n",
    "    args = arg_parser.parse_args()\n",
    "    process_noci(args.input, args.output, args.entities, args.orcid)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# python \"scripts/glob_noci_2.py\" -i ./index/python/test/data/noci_glob_dump_input -o ./index/python/test/data/noci_glob_dump_output -n 7 -iod ./index/python/test/data/noci_id_orcid_mapping/doi_orcid_index.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisi Dati di Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from argparse import ArgumentParser\n",
    "from os import sep, makedirs, walk\n",
    "import os\n",
    "import os.path\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "from tarfile import TarFile\n",
    "import re\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from user_agents import parse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from os.path import exists, basename, isdir, join\n",
    "from timeit import default_timer as timer\n",
    "from re import sub\n",
    "import pandas as pd\n",
    "import codecs\n",
    "\n",
    "def get_all_files(i_dir):\n",
    "    result = []\n",
    "    opener = None\n",
    "    if i_dir.endswith(\".zip\"):\n",
    "        zf = ZipFile(i_dir)\n",
    "        namelist = zf.namelist()\n",
    "        result = [x for x in namelist if x.lower().endswith(\".txt\")]\n",
    "        opener = zf.open\n",
    "    elif i_dir.endswith(\".tar.gz\"):\n",
    "        tf = TarFile.open(i_dir)\n",
    "        for name in tf.getnames():\n",
    "            if name.lower().endswith(\".txt\"):\n",
    "                result.append(name)\n",
    "        opener = tf.extractfile\n",
    "\n",
    "    else:\n",
    "        for cur_dir, cur_subdir, cur_files in walk(i_dir):\n",
    "            for file in cur_files:\n",
    "                if file.lower().endswith(\".txt\"):\n",
    "                    result.append(cur_dir + sep + file)\n",
    "        opener = open\n",
    "    return result, opener\n",
    "\n",
    "def process(input_dir):\n",
    "    if not os.path.exists(\"report\"):\n",
    "        makedirs(\"report\")\n",
    "    if not os.path.exists(\"report/viz\"):\n",
    "        makedirs(\"report/viz\")\n",
    "\n",
    "    month_report = dict()\n",
    "\n",
    "    all_files, opener = get_all_files(input_dir)\n",
    "\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        filename_month = re.search(\"(?<=oc-)(\\d{4}-\\d{1,2})(?=.txt)\", file).group(0)\n",
    "        if filename_month not in month_report.keys():\n",
    "            month_report[filename_month] = dict()\n",
    "            with open(file) as f:\n",
    "                txt_obj = \" \".join(f.readlines())\n",
    "                month_report[filename_month][\"user_agent\"] = get_user_agent(txt_obj)\n",
    "                month_report[filename_month][\"refer\"] = get_refer(txt_obj)\n",
    "\n",
    "    tot_major_ua_dict, tot_major_ref_dict = get_global_report(month_report)\n",
    "    analyse_everything(tot_major_ua_dict, tot_major_ref_dict)\n",
    "\n",
    "def get_user_agent(txt_obj):\n",
    "    # per vedere se ci sono menzioni specifiche a tool o siti web o aziende o quant'altro\n",
    "    result = dict()\n",
    "    user_agents = re.findall(\"(?<=HTTP_USER_AGENT:\\s)([^#]+)\", txt_obj)\n",
    "    for i in user_agents:\n",
    "        agent = re.search(\".*\", i).group(0)\n",
    "        if agent is not None:\n",
    "            agent = agent.strip()\n",
    "            if agent not in result.keys():\n",
    "                result[agent] = 1\n",
    "            else:\n",
    "                result[agent] += 1\n",
    "    return result\n",
    "\n",
    "def get_refer(txt_obj):\n",
    "    # indica il sito web da cui la richiesta è partita e, dal dominio, si capisce chi è\n",
    "    result = dict()\n",
    "    refers = re.findall(\"(?<=HTTP_REFERER:\\s)([^#]+)\", txt_obj)\n",
    "    for i in refers:\n",
    "        refer = re.search(\".*\", i).group(0)\n",
    "        if refer is not None:\n",
    "            refer = refer.strip()\n",
    "            if refer.endswith(\"/\"):\n",
    "                refer = refer[:-1]\n",
    "            if refer not in result.keys():\n",
    "                result[refer] = 1\n",
    "            else:\n",
    "                result[refer] += 1\n",
    "    return result\n",
    "\n",
    "def analyse_everything(dict_major_ua_on_total, dict_major_ref_on_total):\n",
    "    total_analysis_ua_dict = dict()\n",
    "    total_analysis_r_dict= dict()\n",
    "\n",
    "    #ritornare: un dizionario mappato stringa grezza stringa elaborata per l'altra visualizzazione + tutte altre info\n",
    "    #produrre il report su csv\n",
    "\n",
    "    #REFER\n",
    "    unordered_r_list = list()\n",
    "    for k, v in dict_major_ref_on_total.items():\n",
    "        total_analysis_r_dict[k] = dict()\n",
    "        total_analysis_r_dict[k][\"referer_url\"] = k\n",
    "        total_analysis_r_dict[k][\"total_usages\"] = v\n",
    "        total_analysis_r_dict[k][\"notes\"] = \"To be updated\" # to be manually updated\n",
    "        if k != \"None\":\n",
    "            unordered_r_list.append(total_analysis_r_dict[k])\n",
    "\n",
    "    ordered_r_list = sorted(unordered_r_list, key=lambda d: d['total_usages'], reverse=True)\n",
    "    with open('report/referer_analysis.csv', 'w', encoding='utf8', newline='') as output_file:\n",
    "        fc = csv.DictWriter(output_file, fieldnames=ordered_r_list[0].keys())\n",
    "        fc.writeheader()\n",
    "        fc.writerows(ordered_r_list)\n",
    "\n",
    "    #USER AGENT\n",
    "    for k,v in dict_major_ua_on_total.items():\n",
    "        total_analysis_ua_dict[k] = dict()\n",
    "        user_agent = parse(k)\n",
    "        pretty_string = str(user_agent)\n",
    "        total_analysis_ua_dict[k][\"ua_raw_string\"] = k\n",
    "        total_analysis_ua_dict[k][\"ua_pretty_string\"] = pretty_string\n",
    "        total_analysis_ua_dict[k][\"total_usages\"] = v\n",
    "        #total_analysis_ua_dict[k][\"browser\"] = str(user_agent.browser) #da qui si possono estrarre .version, .family, .version_string\n",
    "        #total_analysis_ua_dict[k][\"os\"] = str(user_agent.os) # da qui si possono estrarre .version, .family, .version_string\n",
    "        #total_analysis_ua_dict[k][\"device\"] = str(user_agent.device) # da qui si possono estrarre .family .brand .model\n",
    "        total_analysis_ua_dict[k][\"is_bot\"] = str(user_agent.is_bot)\n",
    "        #total_analysis_ua_dict[k][\"mobile\"] = str(user_agent.is_mobile)\n",
    "        #total_analysis_ua_dict[k][\"tablet\"] = str(user_agent.is_tablet)\n",
    "        #total_analysis_ua_dict[k][\"pc\"] = str(user_agent.is_pc)\n",
    "        #total_analysis_ua_dict[k][\"touch\"] = str(user_agent.is_touch_capable)\n",
    "        total_analysis_ua_dict[k][\"is_relevant\"] = \"NO\" # to be manually updated\n",
    "        total_analysis_ua_dict[k][\"notes\"] = \"To be updated\" # to be manually updated\n",
    "\n",
    "\n",
    "\n",
    "    unordered_ua_list = list()\n",
    "\n",
    "    #filters to mantain only the relevant ones\n",
    "    with open('combined_user_agents.txt', 'r') as f:\n",
    "        common_user_agents = [line.strip() for line in f if line.strip() !=\"\"]\n",
    "\n",
    "    not_relevant = [\"RStudio Desktop\", \"jsonlite / R version\", \"Apache-HttpClient/\", \"$%28PRODUCT_NAME%29/\", \"Go-http-client\", \"Java-http-client\", \"libcurl/\", \"Prometheus/\", \"Apache-Jena\", \"Apache-CXF\", \"HTTP.jl/\", \"Microsoft Office PowerPoint\"]\n",
    "    for key, user in total_analysis_ua_dict.items():\n",
    "        if user[\"ua_raw_string\"].strip() in common_user_agents:\n",
    "            print(key, \"discarded because in common_user_agents\")\n",
    "            pass\n",
    "        elif \"Mozilla/\" in user[\"ua_raw_string\"] or \"Opera/\" in user[\"ua_raw_string\"] or \"Open%20Access%20Helper%20Safari\" in user[\"ua_raw_string\"] or \"URL/Emacs\" in user[\"ua_raw_string\"]:\n",
    "            common_user_agents.append(user[\"ua_raw_string\"].strip())\n",
    "            print(key, \"added to the common user agent strings\")\n",
    "        elif user[\"ua_raw_string\"].strip() == \"None\":\n",
    "            print(key, \"discarded because is None\")\n",
    "            pass\n",
    "        elif any(s in user[\"ua_raw_string\"] for s in not_relevant):\n",
    "            print(key, \"discarded because not relevant\")\n",
    "            pass\n",
    "        elif user[\"ua_raw_string\"].strip() == \"None\":\n",
    "            print(key, \"discarded because is None\")\n",
    "            pass\n",
    "        elif \"Other / Other / Python\" in user[\"ua_pretty_string\"]:\n",
    "            print(key, \"discarded because python request\")\n",
    "            pass\n",
    "        elif user[\"is_bot\"] == \"True\":\n",
    "            print(key, \"discarded because it is a bot\")\n",
    "        else:\n",
    "            unordered_ua_list.append(user)\n",
    "\n",
    "    all_lines = set(common_user_agents)\n",
    "    with open('combined_user_agents.txt', 'w') as fo:\n",
    "        fo.write(\"\\n\".join(all_lines))\n",
    "\n",
    "    ordered_ua_list = sorted(unordered_ua_list, key=lambda d: d['total_usages'], reverse=True)\n",
    "\n",
    "\n",
    "\n",
    "    with open('report/user_agent_analysis.csv', 'w', encoding='utf8', newline='') as output_file:\n",
    "        fc = csv.DictWriter(output_file, fieldnames=ordered_ua_list[0].keys())\n",
    "        fc.writeheader()\n",
    "        fc.writerows(ordered_ua_list)\n",
    "\n",
    "    return total_analysis_ua_dict\n",
    "\n",
    "\n",
    "def get_global_report(report_dict):\n",
    "    detect_relevant_ua = dict()\n",
    "\n",
    "    top_user_agent = set()\n",
    "    top_refer = set()\n",
    "\n",
    "    top_ua_on_total = dict()\n",
    "    top_r_on_total = dict()\n",
    "\n",
    "    for k, v in report_dict.items():\n",
    "        ua_dict = dict()\n",
    "        ua_dict[\"month\"] = \"user agent \" + k\n",
    "        ua_median = statistics.median(v[\"user_agent\"].values())\n",
    "        ua_dict[\"median\"] = ua_median\n",
    "        ua_mean = statistics.mean(v[\"user_agent\"].values())\n",
    "        ua_dict[\"mean\"] = ua_mean\n",
    "        ua_dict[\"total_calls\"] = sum(v[\"user_agent\"].values())\n",
    "        ua_dict[\"from_total_origins\"] = len(v[\"user_agent\"])\n",
    "        #ua_dict[\"above_median\"] = [key for key, value in v[\"user_agent\"].values() if value > ua_median]\n",
    "        ua_above_median = {key: val for (key, val) in v[\"user_agent\"].items() if val > ua_median}\n",
    "        ua_dict[\"n_above_median\"] = len(sorted(ua_above_median, key=ua_above_median.get, reverse=True))\n",
    "        #ua_dict[\"above_mean\"] = [key for key, value in v[\"user_agent\"].values() if value > ua_mean]\n",
    "        ua_above_mean = {key: val for (key, val) in v[\"user_agent\"].items() if val > ua_mean}\n",
    "        ua_dict[\"n_above_mean\"] = len(sorted(ua_above_mean, key=ua_above_mean.get, reverse=True))\n",
    "        ua_dict[\"above_mean\"] = str(sorted(ua_above_mean.items(), key=lambda x:x[1], reverse=True)[:30])\n",
    "        sort_top_ua = sorted(ua_above_mean.items(), key=lambda x:x[1], reverse=True)[:30]\n",
    "\n",
    "        for ki,vi in ua_above_median.items():\n",
    "            top_user_agent.add(ki)\n",
    "\n",
    "        r_dict = dict()\n",
    "        r_dict[\"month\"] = \"refer \" + k\n",
    "        r_median = statistics.median(v[\"refer\"].values())\n",
    "        r_dict[\"median\"] = r_median\n",
    "        r_mean = statistics.mean(v[\"refer\"].values())\n",
    "        r_dict[\"mean\"] = r_mean\n",
    "        r_dict[\"total_calls\"] = sum(v[\"refer\"].values())\n",
    "        r_dict[\"from_total_origins\"] = len(v[\"refer\"])\n",
    "        #ua_dict[\"above_median\"] = [key for key, value in v[\"refer\"].values() if value > ua_median]\n",
    "        r_above_median = {key: val for (key, val) in v[\"refer\"].items() if val > r_median}\n",
    "        r_dict[\"n_above_median\"] = len(sorted(r_above_median, key=r_above_median.get, reverse=True))\n",
    "        #ua_dict[\"above_mean\"] = [key for key, value in v[\"refer\"].values() if value > ua_mean]\n",
    "        r_above_mean = {key: val for (key, val) in v[\"refer\"].items() if val > r_mean}\n",
    "        r_dict[\"n_above_mean\"] = len(sorted(r_above_mean, key=r_above_mean.get, reverse=True))\n",
    "        r_dict[\"above_mean\"] = str(sorted(r_above_mean.items(), key=lambda x:x[1], reverse=True)[:30])\n",
    "        sort_top_r = sorted(r_above_mean.items(), key=lambda x: x[1], reverse=True)[:30]\n",
    "\n",
    "        for kii,vii in r_above_median.items():\n",
    "            top_refer.add(kii)\n",
    "\n",
    "\n",
    "    #ripete il ciclo sommando solo i valori dei più rilevanti, che sono quelli che sono comparsi nella top 20 almeno in un mese\n",
    "    for k,v in report_dict.items():\n",
    "        for ua, usage in v[\"user_agent\"].items():\n",
    "            if ua in top_user_agent:\n",
    "                if ua not in top_ua_on_total.keys():\n",
    "                    top_ua_on_total[ua] = usage\n",
    "                else:\n",
    "                    top_ua_on_total[ua] += usage\n",
    "\n",
    "        for r, usage in v[\"refer\"].items():\n",
    "            if r in top_refer:\n",
    "                if r not in top_r_on_total.keys():\n",
    "                    top_r_on_total[r] = usage\n",
    "                else:\n",
    "                    top_r_on_total[r] += usage\n",
    "\n",
    "    return top_ua_on_total, top_r_on_total\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    arg_parser = ArgumentParser(\n",
    "        \"script for analysing log data in OC\",\n",
    "        description=\"Process txt files containing log information\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-i\",\n",
    "        \"--input\",\n",
    "        dest=\"input\",\n",
    "        required=True,\n",
    "        help=\"Directory that contains OC txt log files\",\n",
    "    )\n",
    "\n",
    "    args = arg_parser.parse_args()\n",
    "    process(args.input)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# python \"essential.py\" -i 2022\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prosecuzione lavoro:\n",
    "- Pubblicare la repository delle visualizzazioni (ci sentiamo oggi con Ivan)\n",
    "- Dividere i tre files di configurazione dei glob e controllare testi validate (con Giuseppe, da accordare)\n",
    "- Riprendere il lavoro con meta \n",
    "- Correzioni Articolo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Data Analysis, Glob con CSV_Datasource, Test Validate, Meta\n",
    "<a id=\"entry_18\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pubblicazione pagina visualizzazioni (repo GitHub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ivan ha creato la repository statistic-view su github per la pagina delle visualizzazioni e mi ha aggiunto come collaboratore. Ho sistemato le ultime cose nei miei files (come ad esempio le funzioni loading e done per il caricamento della pagina) e ho caricato tutto nella repository https://github.com/opencitations/statistics-view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prosecuzione monitoraggio attività di log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosa è emerso dal confronto con Chiara:\n",
    "<ol>\n",
    "    <li>Sarebbe meglio limitare il numero di entità rappresentate in ogni visualizzazione</li>\n",
    "    <li>Rifare le visualizzazioni in js in modo tale che siano interattive, permettano di visualizzare i dati relativi ad un solo agente alla volta...</li>\n",
    "    <li>Valutare la possibilità di farle in scala logaritmica se i dati variano molto tra gli agenti</li>\n",
    "    <li>Altre modifiche da studiare a seguito delle valutazioni di Chiara</li>\n",
    "</ol>\n",
    "\n",
    "Consigli di Silvio: \n",
    "<ol>\n",
    "    <li>raggruppare chiamate API e sparql</li>\n",
    "    <li>monitorare le new entries e rielaborare solo quelle di volta in volta</li>\n",
    "    <li>minimizzare il lavoro manuale da fare di volta in volta</li>\n",
    "    <li>visualizzazione mensile per capire se l'utilizzo è sistematico o una tantum</li>\n",
    "</ol>\n",
    "\n",
    "Altre note:\n",
    "<ol>\n",
    "    <li>Creare file json per costruire un albero di user noti che accedono ai nostri dati in più modi e fare una visualizzazione stacked bar (forse c'è un parametro stack di chart js che permette di fare questa cosa, va controllato)</li>\n",
    "    <li>lista bot-spider-crawler noti da tenere aggiornata</li>\n",
    "    <li>scartare le richieste che vengono da noi (opencitations)</li>\n",
    "    <li>fare una lista di librerie (così da tenere le visualizzazioni separate)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON per selezione analisi future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glob Files con CSVDataSource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COCI\n",
    "A differenza degli altri glob, quello di COCI gestisce la possibilità di dover selezionare, tra più date, quella più appropriata per un identificativo citato. Visto che nella versione dei glob con CSVDataSource aggiorno i dati in una copia del dizionario iniziale dell'entità (ottenuto con csv_datasource.get(id)) che poi trascrivo nei csv con csv_datasource.set(id, dizionario) una volta finiti di raccogliere i dati della pubblicazione in questione (validità, orcid, data, issn), <b>aggiornare solo la data in un secondo momento non era fattibile, visto che, in assenza di una data, la classe CSVDataSource aggiunge in automatico la stringa vuota per l'id in questione (quindi csv_datasource.get(id)[\"date\"] non sarebbe più None, e il valore andrebbe sostituito.</b> <br>\n",
    "Per questo motivo, ho creato un <b>dizionario provvisorio (entity_with_date_to_update)</b> in cui aggiungo le entità di cui va rivalutata la data da inserire a fine delle iterazioni, in modo tale da mantenere la struttura del precedente glob di crosseref. In pratica, se un identificativo viene aggiunto a <b>doi_date</b> con associata una lista di date tra cui scegliere, l'aggiunta dei dati relativi a quella pubblicazione viene rimandata alla fine del processo di valutazione di quale delle date sia la più appropriata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from os import sep, makedirs, walk\n",
    "from os.path import exists, basename, isdir\n",
    "from json import load, loads\n",
    "from collections import Counter\n",
    "from datetime import date\n",
    "from timeit import default_timer as timer\n",
    "from re import sub\n",
    "import tarfile\n",
    "\n",
    "\n",
    "from oc.index.oci.citation import Citation\n",
    "from oc.index.identifier.doi import DOIManager\n",
    "from oc.index.identifier.issn import ISSNManager\n",
    "from oc.index.identifier.orcid import ORCIDManager\n",
    "from oc.index.glob.csv import CSVDataSource\n",
    "\n",
    "\n",
    "\n",
    "def build_pubdate_coci(obj):\n",
    "    if \"issued\" in obj:  # Main citing object\n",
    "        if \"date-parts\" in obj[\"issued\"]:\n",
    "            # is an array of parts of dates\n",
    "            try:\n",
    "                obj_date = obj[\"issued\"][\"date-parts\"][0]\n",
    "\n",
    "                # lisdate[year,month,day]\n",
    "                listdate = [1, 1, 1]\n",
    "                dateparts = []\n",
    "                for i in range(0, len(obj_date)):\n",
    "                    try:\n",
    "                        dateparts.append(obj_date[i])\n",
    "                        intvalue = int(obj_date[i])\n",
    "                        listdate[i] = intvalue\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                # there is a date, so generate it\n",
    "                if (\n",
    "                    (1 < listdate[0] < 3000)\n",
    "                    and (0 < listdate[1] <= 12)\n",
    "                    and (0 < listdate[2] <= 31)\n",
    "                ):\n",
    "                    date_val = date(listdate[0], listdate[1], listdate[2])\n",
    "                    dformat = \"%Y\"\n",
    "\n",
    "                    # only month is specified\n",
    "                    if len(dateparts) == 2:\n",
    "                        dformat = \"%Y-%m\"\n",
    "                    elif len(dateparts) == 3 and (\n",
    "                        dateparts[1] != 1 or (dateparts[1] == 1 and dateparts[2] != 1)\n",
    "                    ):\n",
    "                        dformat = \"%Y-%m-%d\"\n",
    "\n",
    "                    date_in_str = date_val.strftime(dformat)\n",
    "                    return date_in_str\n",
    "            except:\n",
    "                pass\n",
    "    elif \"year\" in obj:  # Reference object\n",
    "        ref_year = sub(\"[^\\d]\", \"\", obj[\"year\"])[:4]\n",
    "        if ref_year:\n",
    "            return ref_year\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_all_files_coci(i_dir_or_targz_file):\n",
    "    result = []\n",
    "    targz_fd = None\n",
    "\n",
    "    if isdir(i_dir_or_targz_file):\n",
    "        for cur_dir, cur_subdir, cur_files in walk(i_dir_or_targz_file):\n",
    "            for cur_file in cur_files:\n",
    "                if cur_file.endswith(\".json\") and not basename(cur_file).startswith(\n",
    "                    \".\"\n",
    "                ):\n",
    "                    result.append(cur_dir + sep + cur_file)\n",
    "    elif i_dir_or_targz_file.endswith(\"tar.gz\"):\n",
    "        targz_fd = tarfile.open(i_dir_or_targz_file, \"r:gz\", encoding=\"utf-8\")\n",
    "        for cur_file in targz_fd:\n",
    "            if cur_file.name.endswith(\".json\") and not basename(\n",
    "                cur_file.name\n",
    "            ).startswith(\".\"):\n",
    "                result.append(cur_file)\n",
    "    else:\n",
    "        print(\"It is not possible to process the input path.\")\n",
    "    return result, targz_fd\n",
    "\n",
    "\n",
    "def load_json_coci(file, targz_fd, file_idx, len_all_files):\n",
    "    result = None\n",
    "\n",
    "    if targz_fd is None:\n",
    "        # print(\"Open file %s of %s\" % (file_idx, len_all_files))\n",
    "        with open(file, encoding=\"utf8\") as f:\n",
    "            result = load(f)\n",
    "    else:\n",
    "        # print(\"Open file %s of %s (in tar.gz archive)\" % (file_idx, len_all_files))\n",
    "        cur_tar_file = targz_fd.extractfile(file)\n",
    "        json_str = cur_tar_file.read()\n",
    "\n",
    "        # In Python 3.5 it seems that, for some reason, the extractfile method returns an\n",
    "        # object 'bytes' that cannot be managed by the function 'load' in the json package.\n",
    "        # Thus, to avoid issues, in case an object having type 'bytes' is return, it is\n",
    "        # transformed as a string before passing it to the function 'loads'. Please note\n",
    "        # that Python 3.9 does not show this behaviour, and it works correctly without\n",
    "        # any transformation.\n",
    "        if type(json_str) is bytes:\n",
    "            json_str = json_str.decode(\"utf-8\")\n",
    "\n",
    "        result = loads(json_str)\n",
    "    return result\n",
    "\n",
    "\n",
    "def process_coci(input_dir, output_dir):\n",
    "    start = timer()\n",
    "    if not exists(output_dir):\n",
    "        makedirs(output_dir)\n",
    "\n",
    "    doi_manager = DOIManager()\n",
    "    issn_manager = ISSNManager()\n",
    "    orcid_manager = ORCIDManager()\n",
    "    csv_datasource = CSVDataSource()\n",
    "\n",
    "    all_files, targz_fd = get_all_files_coci(input_dir)\n",
    "    len_all_files = len(all_files)\n",
    "\n",
    "    # Read all the JSON file in the Crossref dump to create the main information of all the indexes\n",
    "    # print(\"\\n\\n# Add valid DOIs from Crossref metadata\")\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        data = load_json_coci(file, targz_fd, file_idx, len_all_files)\n",
    "\n",
    "        if \"items\" in data:\n",
    "            for obj in data[\"items\"]:\n",
    "                if \"DOI\" in obj:\n",
    "                    citing_doi = doi_manager.normalise(obj[\"DOI\"], True)\n",
    "                    if citing_doi is not None:\n",
    "                        entity = csv_datasource.get(citing_doi)\n",
    "                        entity[\"valid\"] = True\n",
    "\n",
    "                        if entity[\"date\"] is None:\n",
    "                            citing_date = Citation.check_date(build_pubdate_coci(obj))\n",
    "                            if citing_date is not None:\n",
    "                                entity[\"date\"] = [citing_date]\n",
    "\n",
    "                        if entity[\"issn\"] is None:\n",
    "                            valid_issn_list = []\n",
    "                            if \"type\" in obj:\n",
    "                                cur_type = obj[\"type\"]\n",
    "                                if (\n",
    "                                    cur_type is not None\n",
    "                                    and \"journal\" in cur_type\n",
    "                                    and \"ISSN\" in obj\n",
    "                                ):\n",
    "                                    cur_issn = obj[\"ISSN\"]\n",
    "                                    if cur_issn is not None:\n",
    "                                        for issn in [\n",
    "                                            issn_manager.normalise(issn)\n",
    "                                            for issn in cur_issn\n",
    "                                        ]:\n",
    "                                            if issn is not None:\n",
    "                                                valid_issn_list.append(issn)\n",
    "\n",
    "                            entity[\"issn\"] = valid_issn_list\n",
    "\n",
    "                        if entity[\"orcid\"] is None:\n",
    "                            orcid_list = []\n",
    "                            if \"author\" in obj:\n",
    "                                cur_author = obj[\"author\"]\n",
    "                                if cur_author is not None:\n",
    "                                    for author in cur_author:\n",
    "                                        if \"ORCID\" in author:\n",
    "                                            orcid = orcid_manager.normalise(author[\"ORCID\"])\n",
    "                                            if orcid is not None:\n",
    "                                                orcid_list.append(orcid)\n",
    "                            entity[\"orcid\"] = orcid_list\n",
    "                        csv_datasource.set(citing_doi, entity)\n",
    "\n",
    "    middle = timer()\n",
    "    # print(\"first process duration: :\", (middle - start))\n",
    "    # Do it again for updating the dates of the cited DOIs, if these are valid\n",
    "    # print(\"\\n\\n# Check cited DOIs from Crossref reference field\")\n",
    "    doi_date = {}\n",
    "    entity_with_date_to_updete = {}\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        data = load_json_coci(file, targz_fd, file_idx, len_all_files)\n",
    "\n",
    "        if \"items\" in data:\n",
    "            for obj in data[\"items\"]:\n",
    "                if \"DOI\" in obj and \"reference\" in obj:\n",
    "                    for ref in obj[\"reference\"]:\n",
    "                        if \"DOI\" in ref:\n",
    "                            cited_doi = str(doi_manager.normalise(ref[\"DOI\"], True))\n",
    "                            if cited_doi is not None:\n",
    "                                cited_doi_entity = csv_datasource.get(cited_doi)\n",
    "                                if cited_doi_entity[\"valid\"] is None:\n",
    "                                    cited_doi_entity[\"valid\"] = (True if doi_manager.is_valid(cited_doi) else False)\n",
    "\n",
    "                                if cited_doi_entity[\"valid\"] is True and cited_doi_entity[\"date\"] is None:\n",
    "                                    if cited_doi not in doi_date:\n",
    "                                        doi_date[cited_doi] = []\n",
    "                                    cited_date = Citation.check_date(build_pubdate_coci(ref))\n",
    "                                    if cited_date is not None:\n",
    "                                        doi_date[cited_doi].append(cited_date)\n",
    "\n",
    "                                if cited_doi in doi_date:\n",
    "                                    if len(doi_date[cited_doi]) > 0:\n",
    "                                        entity_with_date_to_updete[cited_doi] = cited_doi_entity\n",
    "                                    else:\n",
    "                                        csv_datasource.set(cited_doi, cited_doi_entity)\n",
    "                                else:\n",
    "                                    csv_datasource.set(cited_doi, cited_doi_entity)\n",
    "\n",
    "    # Add the date to the DOI if such date is the most adopted one in the various references.\n",
    "    # In case two distinct dates are used the most, select the older one.\n",
    "    for doi in doi_date:\n",
    "        if doi in entity_with_date_to_updete.keys():\n",
    "            count = Counter(doi_date[doi])\n",
    "            if len(count):\n",
    "                top_value = count.most_common(1)[0][1]\n",
    "                selected_dates = []\n",
    "                for date in count:\n",
    "                    if count[date] == top_value:\n",
    "                        selected_dates.append(date)\n",
    "                best_date = sorted(selected_dates)[0]\n",
    "                doi_entity_for_date_update = entity_with_date_to_updete[doi]\n",
    "                doi_entity_for_date_update[\"date\"] = [best_date]\n",
    "                csv_datasource.set(doi, doi_entity_for_date_update)\n",
    "\n",
    "\n",
    "    # Close the file descriptor of the tar.gz archive if it was used\n",
    "    if targz_fd is not None:\n",
    "        targz_fd.close()\n",
    "\n",
    "    end = timer()\n",
    "    # print(\"second process duration: \", end-middle)\n",
    "    # print(\"full process duration: \", end-start)\n",
    "\n",
    "\n",
    "def main():\n",
    "    arg_parser = ArgumentParser(\n",
    "        \"Global files creator for COCI\",\n",
    "        description=\"Process Crossref JSON files and create global indexes to enable \"\n",
    "        \"the creation of COCI.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-i\",\n",
    "        \"--input\",\n",
    "        dest=\"input\",\n",
    "        required=True,\n",
    "        help=\"Either the directory or the zip file that contains the Crossref data dump \"\n",
    "        \"of JSON files.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-o\",\n",
    "        \"--output\",\n",
    "        dest=\"output\",\n",
    "        required=True,\n",
    "        help=\"The directory where the indexes are stored.\",\n",
    "    )\n",
    "\n",
    "    args = arg_parser.parse_args()\n",
    "    process_coci(args.input, args.output)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# python \"scripts/glob_crossref_2.py\" -i ./index/python/test/data/crossref_glob_dump_input -o ./index/python/test/data/crossref_glob_dump_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DOCI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "import os\n",
    "from os import sep, makedirs, walk\n",
    "from os.path import exists, basename, isdir\n",
    "from json import load, loads\n",
    "import datetime\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import tarfile\n",
    "\n",
    "#from oc.index.legacy.csv import CSVManager\n",
    "from oc.index.identifier.doi import DOIManager\n",
    "from oc.index.identifier.issn import ISSNManager\n",
    "from oc.index.identifier.orcid import ORCIDManager\n",
    "from oc.index.glob.csv import CSVDataSource\n",
    "\n",
    "\n",
    "def issn_data_recover_doci(directory):\n",
    "    journal_issn_dict = dict()\n",
    "    filename = directory + sep + \"journal_issn.json\"\n",
    "    if not os.path.exists(filename):\n",
    "        return journal_issn_dict\n",
    "    else:\n",
    "        with open(filename, \"r\", encoding=\"utf8\") as fd:\n",
    "            journal_issn_dict = json.load(fd)\n",
    "            types = type(journal_issn_dict)\n",
    "            return journal_issn_dict\n",
    "\n",
    "\n",
    "def issn_data_to_cache_doci(name_issn_dict, directory):\n",
    "    filename = directory + sep + \"journal_issn.json\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as fd:\n",
    "        json.dump(name_issn_dict, fd, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "def get_all_files_doci(i_dir_or_targz_file):\n",
    "    result = []\n",
    "    targz_fd = None\n",
    "\n",
    "    if isdir(i_dir_or_targz_file):\n",
    "        for cur_dir, cur_subdir, cur_files in walk(i_dir_or_targz_file):\n",
    "            for cur_file in cur_files:\n",
    "                if cur_file.endswith(\".json\") and not basename(cur_file).startswith(\n",
    "                    \".\"\n",
    "                ):\n",
    "                    result.append(cur_dir + sep + cur_file)\n",
    "    elif i_dir_or_targz_file.endswith(\"tar.gz\"):\n",
    "        targz_fd = tarfile.open(i_dir_or_targz_file, \"r:gz\", encoding=\"utf-8\")\n",
    "        for cur_file in targz_fd:\n",
    "            if cur_file.name.endswith(\".json\") and not basename(\n",
    "                cur_file.name\n",
    "            ).startswith(\".\"):\n",
    "                result.append(cur_file)\n",
    "    else:\n",
    "        print(\"It is not possible to process the input path.\")\n",
    "    return result, targz_fd\n",
    "\n",
    "\n",
    "def valid_date_doci(date_text):\n",
    "    date_text = str(date_text)\n",
    "    try:\n",
    "        return datetime.datetime.strptime(date_text, \"%Y-%m-%d\").strftime(\"%Y-%m-%d\")\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return datetime.datetime.strptime(date_text, \"%Y-%m\").strftime(\"%Y-%m\")\n",
    "        except ValueError:\n",
    "            try:\n",
    "                return datetime.datetime.strptime(date_text, \"%Y\").strftime(\"%Y\")\n",
    "            except ValueError:\n",
    "                if \"-\" in date_text:\n",
    "                    possibiliDate = date_text.split(\"-\")\n",
    "                    while possibiliDate:\n",
    "                        possibiliDate.pop()\n",
    "                        seperator = \"-\"\n",
    "                        data = seperator.join(possibiliDate)\n",
    "                        try:\n",
    "                            return datetime.datetime.strptime(\n",
    "                                data, \"%Y-%m-%d\"\n",
    "                            ).strftime(\"%Y-%m-%d\")\n",
    "                        except ValueError:\n",
    "                            try:\n",
    "                                return datetime.datetime.strptime(\n",
    "                                    data, \"%Y-%m\"\n",
    "                                ).strftime(\"%Y-%m\")\n",
    "                            except ValueError:\n",
    "                                try:\n",
    "                                    return datetime.datetime.strptime(\n",
    "                                        data, \"%Y\"\n",
    "                                    ).strftime(\"%Y\")\n",
    "                                except ValueError:\n",
    "                                    pass\n",
    "\n",
    "\n",
    "def load_json_doci(file, targz_fd, file_idx, len_all_files):\n",
    "    result = None\n",
    "\n",
    "    if targz_fd is None:\n",
    "        # print(\"Open file %s of %s\" % (file_idx, len_all_files))\n",
    "        with open(file, encoding=\"utf8\") as f:\n",
    "            result = load(f)\n",
    "    else:\n",
    "        # print(\"Open file %s of %s (in tar.gz archive)\" % (file_idx, len_all_files))\n",
    "        cur_tar_file = targz_fd.extractfile(file)\n",
    "        json_str = cur_tar_file.read()\n",
    "        # In Python 3.5 it seems that, for some reason, the extractfile method returns an\n",
    "        # object 'bytes' that cannot be managed by the function 'load' in the json package.\n",
    "        # Thus, to avoid issues, in case an object having type 'bytes' is return, it is\n",
    "        # transformed as a string before passing it to the function 'loads'. Please note\n",
    "        # that Python 3.9 does not show this behaviour, and it works correctly without\n",
    "        # any transformation.\n",
    "        if type(json_str) is bytes:\n",
    "            json_str = json_str.decode(\"utf-8\")\n",
    "\n",
    "        result = loads(json_str)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def process_doci(input_dir, output_dir, n):\n",
    "    start = timer()\n",
    "    if not exists(output_dir):\n",
    "        makedirs(output_dir)\n",
    "\n",
    "    # valid_doi = CSVManager(output_dir + sep + \"valid_doi.csv\")\n",
    "    # id_date = CSVManager(output_dir + sep + \"id_date.csv\")\n",
    "    # id_issn = CSVManager(output_dir + sep + \"id_issn.csv\")\n",
    "    # id_orcid = CSVManager(output_dir + sep + \"id_orcid.csv\")\n",
    "\n",
    "    journal_issn_dict = issn_data_recover_doci(output_dir)\n",
    "\n",
    "    doi_manager = DOIManager()\n",
    "    issn_manager = ISSNManager()\n",
    "    orcid_manager = ORCIDManager()\n",
    "    csv_datasource = CSVDataSource()\n",
    "\n",
    "    all_files, targz_fd = get_all_files_doci(input_dir)\n",
    "    len_all_files = len(all_files)\n",
    "    issnDict = {}\n",
    "    relevant_relations = [\"references\", \"isreferencedby\", \"cites\", \"iscitedby\"]\n",
    "\n",
    "    count = 0\n",
    "    # Read all the JSON files in the DataCite dump to create the main information of all the indexes\n",
    "    # print(\"\\n\\n# Add valid DOIs from DataCite metadata\")\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        data = load_json_doci(file, targz_fd, file_idx, len_all_files)\n",
    "        if \"data\" in data:\n",
    "            data_list = data[\"data\"]\n",
    "            for item in tqdm(data_list):\n",
    "                count += 1\n",
    "                attributes = item[\"attributes\"]\n",
    "                citing_doi = attributes[\"doi\"]\n",
    "                relatedIdentifiers = attributes[\"relatedIdentifiers\"]\n",
    "                citing_doi = doi_manager.normalise(citing_doi, True)\n",
    "                # valid_doi.add_value(citing_doi, \"v\" if doi_manager.is_valid(citing_doi) else \"i\")\n",
    "                if citing_doi is not None:\n",
    "                    entity = csv_datasource.get(citing_doi)\n",
    "                    entity[\"valid\"] = True\n",
    "\n",
    "                    # collect the date of issue if there is, otherwise the year of publcation\n",
    "                    if entity[\"date\"] is None:\n",
    "                        citing_date = []\n",
    "                        listDates = attributes[\"dates\"]\n",
    "                        publicationYear = attributes[\"publicationYear\"]\n",
    "\n",
    "                        if listDates != []:\n",
    "                            if [\n",
    "                                data\n",
    "                                for data in listDates\n",
    "                                if str(data[\"dateType\"]).lower() == \"issued\"\n",
    "                            ]:\n",
    "                                issue_dates = [\n",
    "                                    data\n",
    "                                    for data in listDates\n",
    "                                    if str(data[\"dateType\"]).lower() == \"issued\"\n",
    "                                ]\n",
    "                                if [\n",
    "                                    iss_date\n",
    "                                    for iss_date in issue_dates\n",
    "                                    if valid_date_doci(str(iss_date[\"date\"]))\n",
    "                                ]:\n",
    "                                    flt_issue_dates = [\n",
    "                                        iss_date\n",
    "                                        for iss_date in issue_dates\n",
    "                                        if valid_date_doci(str(iss_date[\"date\"]))\n",
    "                                    ]\n",
    "                                    for flt_iss_date in flt_issue_dates:\n",
    "                                        citing_date.append(\n",
    "                                            valid_date_doci(str(flt_iss_date[\"date\"])),\n",
    "                                        )\n",
    "                                        break\n",
    "\n",
    "                                # listDates exists and at least one of its element has \"issued\" in \"dateType\"\n",
    "                                # but none of the dates in listDates has a valid date in \"date\"\n",
    "                                elif publicationYear:\n",
    "                                    publicationYear = valid_date_doci(str(publicationYear))\n",
    "                                    if publicationYear:\n",
    "                                        citing_date.append(publicationYear)\n",
    "\n",
    "                            # listDates exists but none of its elements has \"issued\" in \"dateType\"\n",
    "                            elif publicationYear:\n",
    "                                publicationYear = valid_date_doci(str(publicationYear))\n",
    "                                if publicationYear:\n",
    "                                    citing_date.append(publicationYear)\n",
    "\n",
    "                        # listDates is an empty list: no dates in listDates\n",
    "                        elif publicationYear:\n",
    "                            publicationYear = valid_date_doci(str(publicationYear))\n",
    "                            if publicationYear:\n",
    "                                citing_date.append(publicationYear)\n",
    "\n",
    "                        entity[\"date\"] = citing_date\n",
    "\n",
    "                    # collect the orcid of the contributors\n",
    "                    if entity[\"orcid\"] is None:\n",
    "                        orcid_list = []\n",
    "                        contributorList = attributes[\"creators\"]\n",
    "                        if contributorList != []:\n",
    "                            for author in contributorList:\n",
    "                                if \"nameIdentifiers\" in author.keys():\n",
    "                                    infoAuthor = author[\"nameIdentifiers\"]\n",
    "                                    for element in infoAuthor:\n",
    "                                        if (\n",
    "                                            \"nameIdentifier\" in element.keys()\n",
    "                                            and \"nameIdentifierScheme\" in element.keys()\n",
    "                                        ):\n",
    "                                            if (\n",
    "                                                element[\"nameIdentifierScheme\"]\n",
    "                                            ).lower() == \"orcid\":\n",
    "                                                orcid = element[\"nameIdentifier\"]\n",
    "                                                if orcid is not None and orcid != \"\":\n",
    "                                                    orcid = orcid_manager.normalise(orcid)\n",
    "                                                    if orcid_manager.is_valid(orcid):\n",
    "                                                        orcid_list.append(orcid)\n",
    "                        entity[\"orcid\"] = orcid_list\n",
    "\n",
    "                    if entity[\"issn\"] is None:\n",
    "                        issn_set = set()\n",
    "                        valid_issn_list = []\n",
    "                        if relatedIdentifiers != []:\n",
    "                            for related in relatedIdentifiers:\n",
    "                                if \"relationType\" in related.keys():\n",
    "                                    relationType = related[\"relationType\"]\n",
    "                                    if relationType.lower() == \"ispartof\":\n",
    "                                        if \"relatedIdentifierType\" in related.keys():\n",
    "                                            relatedIdentifierType = (\n",
    "                                                str(related[\"relatedIdentifierType\"])\n",
    "                                            ).lower()\n",
    "                                            if relatedIdentifierType == \"issn\":\n",
    "                                                if \"relatedIdentifier\" in related.keys():\n",
    "                                                    relatedISSN = str(\n",
    "                                                        related[\"relatedIdentifier\"]\n",
    "                                                    )\n",
    "                                                    if relatedISSN:\n",
    "                                                        issn_set.add(relatedISSN)\n",
    "\n",
    "                        container = attributes[\"container\"]\n",
    "                        if (\n",
    "                            \"identifier\" in container.keys()\n",
    "                            and \"identifierType\" in container.keys()\n",
    "                        ):\n",
    "                            if (\n",
    "                                container[\"identifier\"] != \"\"\n",
    "                                and (container[\"identifierType\"]).lower() == \"issn\"\n",
    "                            ):\n",
    "                                cont_issn = container[\"identifier\"]\n",
    "                                issn_set.add(cont_issn)\n",
    "                                if \"title\" in container.keys():\n",
    "                                    journal_title = (container[\"title\"]).lower()\n",
    "                                    if journal_title in issnDict.keys():\n",
    "                                        issnList = issnDict[journal_title]\n",
    "                                        if issnList != []:\n",
    "                                            if [\n",
    "                                                el for el in issnList if el not in issn_set\n",
    "                                            ]:\n",
    "                                                issn_set.update(set(issnList))\n",
    "                                                issnDict[journal_title] = list(issn_set)\n",
    "                                        else:\n",
    "                                            issnDict[journal_title] = list(issn_set)\n",
    "                                    else:\n",
    "                                        issnDict[journal_title] = list(issn_set)\n",
    "\n",
    "                        normalised_issn_set = set()\n",
    "                        for issn in issn_set:\n",
    "                            norm_issn = issn_manager.normalise(issn)\n",
    "                            normalised_issn_set.add(norm_issn)\n",
    "                        for issn in normalised_issn_set:\n",
    "                            if issn_manager.is_valid(issn):\n",
    "                                valid_issn_list.append(issn)\n",
    "\n",
    "                        entity[\"issn\"] = valid_issn_list\n",
    "\n",
    "                    csv_datasource.set(citing_doi, entity)\n",
    "\n",
    "                    if int(count) != 0 and int(count) % int(n) == 0:\n",
    "                        issn_data_to_cache_doci(issnDict, output_dir)\n",
    "\n",
    "    issn_data_to_cache_doci(issnDict, output_dir)\n",
    "    middle = timer()\n",
    "    # print(\"first process duration: :\", (middle - start))\n",
    "\n",
    "    cited_dois = 0\n",
    "    count = 0\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        data = load_json_doci(file, targz_fd, file_idx, len_all_files)\n",
    "        if \"data\" in data:\n",
    "            data_list = data[\"data\"]\n",
    "            for item in tqdm(data_list):\n",
    "                count += 1\n",
    "                # print(\"processing entity n.\", count, \"for cited dois\")\n",
    "                attributes = item[\"attributes\"]\n",
    "                relatedIdentifiers = attributes[\"relatedIdentifiers\"]\n",
    "                if relatedIdentifiers != []:\n",
    "                    for related in relatedIdentifiers:\n",
    "                        relationType = related[\"relationType\"]\n",
    "                        if relationType:\n",
    "                            if relationType.lower() in relevant_relations:\n",
    "                                if \"relatedIdentifierType\" in related.keys():\n",
    "                                    relatedIdentifierType = (\n",
    "                                        str(related[\"relatedIdentifierType\"])\n",
    "                                    ).lower()\n",
    "                                    if relatedIdentifierType == \"doi\":\n",
    "                                        if \"relatedIdentifier\" in related.keys():\n",
    "                                            relatedDOI = doi_manager.normalise(\n",
    "                                                related[\"relatedIdentifier\"], True\n",
    "                                            )\n",
    "                                            if relatedDOI is not None:\n",
    "                                                relatedDOI_entity = csv_datasource.get(relatedDOI)\n",
    "                                                if relatedDOI_entity[\"valid\"] is None:\n",
    "                                                    relatedDOI_entity[\"valid\"] = (True if doi_manager.is_valid(relatedDOI) else False)\n",
    "                                                    cited_dois += 1\n",
    "                                                csv_datasource.set(relatedDOI, relatedDOI_entity)\n",
    "\n",
    "\n",
    "    end = timer()\n",
    "    # print(\"second process duration: \", end-middle)\n",
    "    # print(\"full process duration: \", end-start)\n",
    "\n",
    "\n",
    "def main():\n",
    "    arg_parser = ArgumentParser(\n",
    "        \"Global files creator for DOCI\",\n",
    "        description=\"Process DataCite JSON files and create global indexes to enable \"\n",
    "        \"the creation of DOCI.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-i\",\n",
    "        \"--input\",\n",
    "        dest=\"input\",\n",
    "        required=True,\n",
    "        help=\"Either the directory or the zip file that contains the DataCite data dump \"\n",
    "        \"of JSON files.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-o\",\n",
    "        \"--output\",\n",
    "        dest=\"output\",\n",
    "        required=True,\n",
    "        help=\"The directory where the indexes are stored.\",\n",
    "    )\n",
    "\n",
    "    arg_parser.add_argument(\n",
    "        \"-n\",\n",
    "        \"--num_entities\",\n",
    "        dest=\"num_entities\",\n",
    "        required=True,\n",
    "        help=\"Interval of processed entities after which the issn data are saved to cache files.\",\n",
    "    )\n",
    "\n",
    "    args = arg_parser.parse_args()\n",
    "    process_doci(args.input, args.output, args.num_entities)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# python \"scripts/glob_doci_2.py\" -i ./index/python/test/data/doci_glob_dump_input -o ./index/python/test/data/doci_glob_dump_output -n 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "import csv\n",
    "from argparse import ArgumentParser\n",
    "from os import sep, makedirs, walk\n",
    "import os\n",
    "import os.path\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "from tarfile import TarFile\n",
    "import re\n",
    "from os.path import exists, basename, isdir, join\n",
    "from timeit import default_timer as timer\n",
    "from re import sub\n",
    "import pandas as pd\n",
    "import codecs\n",
    "\n",
    "from oc.index.oci.citation import Citation\n",
    "from oc.index.identifier.doi import DOIManager\n",
    "from oc.index.identifier.pmid import PMIDManager\n",
    "from oc.index.identifier.issn import ISSNManager\n",
    "from oc.index.identifier.orcid import ORCIDManager\n",
    "from oc.index.finder.orcid import ORCIDResourceFinder\n",
    "from oc.index.finder.crossref import CrossrefResourceFinder\n",
    "from oc.index.glob.csv import CSVDataSource\n",
    "\n",
    "\n",
    "def issn_data_recover_noci(directory):\n",
    "    journal_issn_dict = dict()\n",
    "    filename = join(directory, \"journal_issn.json\")\n",
    "    if not os.path.exists(filename):\n",
    "        return journal_issn_dict\n",
    "    else:\n",
    "        with open(filename, \"r\", encoding=\"utf8\") as fd:\n",
    "            journal_issn_dict = json.load(fd)\n",
    "            return journal_issn_dict\n",
    "\n",
    "\n",
    "def issn_data_to_cache_noci(name_issn_dict, directory):\n",
    "    filename = directory + sep + \"journal_issn.json\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as fd:\n",
    "        json.dump(name_issn_dict, fd, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "# takes in input a data structure representing a bibliographic entity\n",
    "def build_pubdate_noci(row):\n",
    "    year = str(row[\"year\"])\n",
    "    str_year = sub(\"[^\\d]\", \"\", year)[:4]\n",
    "    if str_year:\n",
    "        return str_year\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# get_all_files extracts all the needed files from the input directory\n",
    "def get_all_files_noci(i_dir):\n",
    "    result = []\n",
    "    opener = None\n",
    "    if i_dir.endswith(\".zip\"):\n",
    "        zf = ZipFile(i_dir)\n",
    "        namelist = zf.namelist()\n",
    "        result = [x for x in namelist if x.lower().endswith(\".csv\")]\n",
    "        opener = zf.open\n",
    "    elif i_dir.endswith(\".tar.gz\"):\n",
    "        tf = TarFile.open(i_dir)\n",
    "        for name in tf.getnames():\n",
    "            if name.lower().endswith(\".csv\"):\n",
    "                result.append(name)\n",
    "        opener = tf.extractfile\n",
    "\n",
    "    else:\n",
    "        for cur_dir, cur_subdir, cur_files in walk(i_dir):\n",
    "            for file in cur_files:\n",
    "                if file.lower().endswith(\".csv\"):\n",
    "                    result.append(cur_dir + sep + file)\n",
    "        opener = open\n",
    "    return result, opener\n",
    "\n",
    "\n",
    "def process_noci(input_dir, output_dir, n, id_orcid_dir=None):\n",
    "    start = timer()\n",
    "    if not exists(output_dir):\n",
    "        makedirs(output_dir)\n",
    "\n",
    "    journal_issn_dict = issn_data_recover_noci(output_dir)\n",
    "    crossref_resource_finder = CrossrefResourceFinder()\n",
    "    orcid_resource_finder = ORCIDResourceFinder()\n",
    "\n",
    "    doi_manager = DOIManager()\n",
    "    issn_manager = ISSNManager()\n",
    "    orcid_manager = ORCIDManager()\n",
    "    pmid_manager = PMIDManager()\n",
    "    csv_datasource = CSVDataSource()\n",
    "\n",
    "    all_files, opener = get_all_files_noci(input_dir)\n",
    "    len_all_files = len(all_files)\n",
    "    pmid_doi_map = dict()\n",
    "\n",
    "    # Read all the CSV file in the NIH dump to create the main information of all the indexes\n",
    "    # print(\"\\n\\n# Add valid PMIDs from NIH metadata\")\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        for chunk in pd.read_csv(file, chunksize=1000):\n",
    "            f = pd.concat([df, chunk], ignore_index=True)\n",
    "            f.fillna(\"\", inplace=True)\n",
    "\n",
    "            # print(\"Open file %s of %s\" % (file_idx, len_all_files))\n",
    "            for index, row in f.iterrows():\n",
    "                if int(index) != 0 and int(index) % int(n) == 0:\n",
    "                    # print( \"Group nr.\", int(index)//int(n), \"processed. Data from\", int(index), \"rows saved to journal_issn.json mapping file\")\n",
    "                    issn_data_to_cache_noci(journal_issn_dict, output_dir)\n",
    "\n",
    "                citing_pmid = pmid_manager.normalise(row[\"pmid\"], True)\n",
    "                if citing_pmid is not None:\n",
    "                    entity = csv_datasource.get(citing_pmid)\n",
    "                    entity[\"valid\"] = True\n",
    "\n",
    "                    citing_doi = doi_manager.normalise(row[\"doi\"], False)\n",
    "                    if citing_doi and csv_datasource.get(citing_pmid)[\"orcid\"] is None:\n",
    "                        pmid_doi_map[citing_pmid] = {\"doi\": citing_doi, \"has_orcid\": False}\n",
    "\n",
    "                    if entity[\"date\"] is None:\n",
    "                        citing_date = Citation.check_date(build_pubdate_noci(row))\n",
    "                        if citing_date is not None:\n",
    "                            entity[\"date\"] = [citing_date]\n",
    "\n",
    "                    if entity[\"issn\"] is None:\n",
    "                        issn_list = []\n",
    "                        journal_name = row[\"journal\"]\n",
    "                        if journal_name:\n",
    "                            if journal_name in journal_issn_dict.keys():\n",
    "                                for issn in journal_issn_dict[journal_name]:\n",
    "                                    issn_list.append(issn)\n",
    "\n",
    "                            else:\n",
    "                                if citing_doi is not None:\n",
    "                                    json_res = crossref_resource_finder._call_api(citing_doi)\n",
    "                                    if json_res is not None:\n",
    "                                        issn_set = crossref_resource_finder._get_issn(json_res)\n",
    "                                        if len(issn_set) > 0:\n",
    "                                            journal_issn_dict[journal_name] = []\n",
    "                                        for issn in issn_set:\n",
    "                                            issn_norm = issn_manager.normalise(str(issn))\n",
    "                                            issn_list.append(issn_norm)\n",
    "                                            journal_issn_dict[journal_name].append(issn_norm)\n",
    "                        else:\n",
    "                            if citing_doi is not None:\n",
    "                                json_res = crossref_resource_finder._call_api(citing_doi)\n",
    "                                if json_res is not None:\n",
    "                                    issn_set = crossref_resource_finder._get_issn(json_res)\n",
    "                                    for issn in issn_set:\n",
    "                                        issn_norm = issn_manager.normalise(str(issn))\n",
    "                                        issn_list.append(issn_norm)\n",
    "                        if issn_list != []:\n",
    "                            entity[\"issn\"] = issn_list\n",
    "                    csv_datasource.set(citing_pmid, entity)\n",
    "\n",
    "            if len(pmid_doi_map) > 0:\n",
    "                if id_orcid_dir and exists(id_orcid_dir):\n",
    "                    orcid_id_files, op = get_all_files_noci(id_orcid_dir)\n",
    "                    len_orcid_id_files = len(orcid_id_files)\n",
    "                    if len_orcid_id_files > 0:\n",
    "                        for f_idx, f in enumerate(orcid_id_files, 1):\n",
    "                            unzip_file = op(f, mode=\"r\")\n",
    "                            unzip_file = csv.DictReader(\n",
    "                                codecs.iterdecode(unzip_file, \"utf-8\")\n",
    "                            )\n",
    "                            for row in unzip_file:\n",
    "                                if [\n",
    "                                    k\n",
    "                                    for k, v in pmid_doi_map.items()\n",
    "                                    if v[\"doi\"] == row[\"id\"]\n",
    "                                ]:\n",
    "                                    c_pmid = [\n",
    "                                        k\n",
    "                                        for k, v in pmid_doi_map.items()\n",
    "                                        if v[\"doi\"] == row[\"id\"]\n",
    "                                    ][\n",
    "                                        0\n",
    "                                    ]\n",
    "                                    c_doi = doi_manager.normalise(row[\"id\"], False)\n",
    "                                    orcid = re.search(\n",
    "                                        \"\\[(([X0-9]\\-?){4}){4}]\",\n",
    "                                        row[\"value\"],\n",
    "                                        re.IGNORECASE,\n",
    "                                    ).group(0)\n",
    "                                    if orcid:\n",
    "                                        nor_orcid = orcid_manager.normalise(orcid)\n",
    "                                        if nor_orcid:\n",
    "                                            c_pmid_entity = csv_datasource.get(c_pmid)\n",
    "                                            if c_pmid_entity[\"orcid\"] is None:\n",
    "                                                c_pmid_entity[\"orcid\"] = []\n",
    "                                                c_pmid_entity[\"orcid\"].append(nor_orcid)\n",
    "                                            else:\n",
    "                                                c_pmid_entity[\"orcid\"] = list(c_pmid_entity[\"orcid\"])\n",
    "                                                c_pmid_entity[\"orcid\"].append(nor_orcid)\n",
    "\n",
    "                                            csv_datasource.set(c_pmid, c_pmid_entity)\n",
    "\n",
    "                                            if pmid_doi_map[c_pmid][\"has_orcid\"] == False:\n",
    "                                                pmid_doi_map[c_pmid][\"has_orcid\"] = True\n",
    "\n",
    "                for citing_pmid, d in pmid_doi_map.items():\n",
    "                    if d[\"has_orcid\"] == False:\n",
    "                        json_res = orcid_resource_finder._call_api(d[\"doi\"])\n",
    "                        if json_res is not None:\n",
    "\n",
    "                            orcid_list = []\n",
    "                            citing_pmid_dict = csv_datasource.get(citing_pmid)\n",
    "\n",
    "                            orcid_set = orcid_resource_finder._get_orcid(json_res)\n",
    "                            if len(orcid_set) > 0:\n",
    "                                d[\"has_orcid\"] = True\n",
    "                                for orcid in orcid_set:\n",
    "                                    orcid_norm = orcid_manager.normalise(orcid)\n",
    "                                    orcid_list.append(orcid_norm)\n",
    "                                if citing_pmid_dict[\"orcid\"] is None:\n",
    "                                    citing_pmid_dict[\"orcid\"] = orcid_list\n",
    "                                else:\n",
    "                                    citing_pmid_dict[\"orcid\"].extend(orcid_list)\n",
    "                                csv_datasource.set(citing_pmid,citing_pmid_dict)\n",
    "\n",
    "\n",
    "            pmid_doi_map = dict()\n",
    "            issn_data_to_cache_noci(journal_issn_dict, output_dir)\n",
    "\n",
    "    middle = timer()\n",
    "\n",
    "    # print(\"first process duration: :\", (middle - start))\n",
    "    # print(\"\\n\\n# Checking the referenced pmids validity\")\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        for chunk in pd.read_csv(file, chunksize=1000):\n",
    "            f = pd.concat([df, chunk], ignore_index=True)\n",
    "            f.fillna(\"\", inplace=True)\n",
    "            # print(\"Open file %s of %s\" % (file_idx, len_all_files))\n",
    "            for index, row in f.iterrows():\n",
    "                if row[\"references\"] != \"\":\n",
    "                    ref_string = row[\"references\"].strip()\n",
    "                    ref_string_norm = re.sub(\"\\s+\", \" \", ref_string)\n",
    "                    cited_pmids = set(ref_string_norm.split(\" \"))\n",
    "                    for cited_pmid in cited_pmids:\n",
    "                        cited_pmid = pmid_manager.normalise(cited_pmid, True)\n",
    "\n",
    "                        if cited_pmid is not None:\n",
    "                            cited_pmid_entity = csv_datasource.get(cited_pmid)\n",
    "                            if cited_pmid_entity[\"valid\"] is None:\n",
    "                                cited_pmid_entity[\"valid\"] = (True if pmid_manager.is_valid(cited_pmid) else False)\n",
    "                            csv_datasource.set(cited_pmid, cited_pmid_entity)\n",
    "\n",
    "                if row[\"cited_by\"] != \"\":\n",
    "                    citing_string = row[\"cited_by\"].strip()\n",
    "                    citing_string_norm = re.sub(\"\\s+\", \" \", citing_string)\n",
    "                    citing_pmids = set(citing_string_norm.split(\" \"))\n",
    "                    for citing_p in citing_pmids:\n",
    "                        citing_p = pmid_manager.normalise(citing_p, True)\n",
    "                        if citing_p is not None:\n",
    "                            citing_p_entity = csv_datasource.get(citing_p)\n",
    "                            if citing_p_entity[\"valid\"] is None:\n",
    "                                citing_p_entity[\"valid\"] = (True if pmid_manager.is_valid(citing_p) else False)\n",
    "                            csv_datasource.set(citing_p, citing_p_entity)\n",
    "\n",
    "    end = timer()\n",
    "    # print(\"second process duration: \", end-middle)\n",
    "    # print(\"full process duration: \", end-start)\n",
    "\n",
    "\n",
    "def main():\n",
    "    arg_parser = ArgumentParser(\n",
    "        \"Global files creator for NOCI\",\n",
    "        description=\"Process iCiteMetadata CSV files and create global indexes to enable the creation of NOCI.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-i\",\n",
    "        \"--input\",\n",
    "        dest=\"input\",\n",
    "        required=True,\n",
    "        help=\"Either the directory or the zip file that contains the iCiteMetadata data dump of CSV files.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-o\",\n",
    "        \"--output\",\n",
    "        dest=\"output\",\n",
    "        required=True,\n",
    "        help=\"The directory where the indexes are stored.\",\n",
    "    )\n",
    "\n",
    "    arg_parser.add_argument(\n",
    "        \"-n\",\n",
    "        \"--entities\",\n",
    "        dest=\"entities\",\n",
    "        required=True,\n",
    "        help=\"Interval of processed entities after which the issn data are saved to the cache file.\",\n",
    "    )\n",
    "\n",
    "    arg_parser.add_argument(\n",
    "        \"-iod\",\n",
    "        \"--orcid\",\n",
    "        dest=\"orcid\",\n",
    "        required=False,\n",
    "        help=\"Either the directory or the zip file that contains the id-orcid mapping data.\",\n",
    "    )\n",
    "\n",
    "    args = arg_parser.parse_args()\n",
    "    process_noci(args.input, args.output, args.entities, args.orcid)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# python \"scripts/glob_noci_2.py\" -i ./index/python/test/data/noci_glob_dump_input -o ./index/python/test/data/noci_glob_dump_output -n 7 -iod ./index/python/test/data/noci_id_orcid_mapping/doi_orcid_index.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gestione Nome Autore ORCID in NOCI \n",
    "Allo stato attuale, la gestione dell'ORCID in NOCI crea dei problemi per la questione dell'autoattribuzione di articoli non propri. Ho aggiunto un passaggio (che non risolve davvero il problema ma screma una buona parte delle false attribuzioni. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Estrazione di una lista di cognomi dalla stringa del campo \"author\" del dump NIH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_authors_surnames = re.findall(\n",
    "    \"[a-zA-Z\\'\\-áéíóúäëïöüÄłŁőŐűŰZàáâäãåąčćęèéêëėįìíîïłńòóôöõøùúûüųūÿýżźñçčšžÀÁÂÄÃÅĄĆČĖĘÈÉÊËÌÍÎÏĮŁŃÒÓÔÖÕØÙÚÛÜŲŪŸÝŻŹÑßÇŒÆČŠŽñÑâê]{2,}\",\n",
    "    row[\"authors\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Il risultato è l'estrazione di una lista contenente tutti i cognomi degli Autori, che viene salvata come valore della chiave \"all_authors_surnames\" del dizionario relativo al pmid in pmid_doi_map (pmid_doi_map[c_pmid][\"all_authors_surnames\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) La stessa regex viene riapplicata al campo \"value\" dei csv di mappatura doi-ORCID, per estrarre nomi e cognomi dell'autore associato all'Orcid. Perché l'autore venga considerato valido, deve esserci almeno un match tra la lista dei nomi estratti dal dump e la lista di nomi estratti dal file di mappatura. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orcid = re.search(\n",
    "    \"\\[(([X0-9]\\-?){4}){4}]\",\n",
    "    row[\"value\"],\n",
    "    re.IGNORECASE,\n",
    ").group(0)\n",
    "author_name_parts = re.findall(\"[a-zA-Z\\'\\-áéíóúäëïöüÄłŁőŐűŰZàáâäãåąčćęèéêëėįìíîïłńòóôöõøùúûüųūÿýżźñçčšžÀÁÂÄÃÅĄĆČĖĘÈÉÊËÌÍÎÏĮŁŃÒÓÔÖÕØÙÚÛÜŲŪŸÝŻŹÑßÇŒÆČŠŽñÑâê]{2,}\", row[\"value\"])\n",
    "all_authors_surnames = pmid_doi_map[c_pmid][\"all_authors_surnames\"]\n",
    "matches = [i for i in author_name_parts if i in all_authors_surnames]\n",
    "if len(matches) > 0:\n",
    "    if orcid:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Attualmente il glob di NOCI gestisce la possibilità di essere lanciato senza la cartella di files csv di mappatura facendo riferimento alle API(più che altro per fini di test, che altrimenti impiegano molto tempo per l'apertura dei file di mappatura in proporzione al numero di identificativi testati). Ho provato a mantenere lo stesso tipo di approccio, cercando la stringa del nome dell'autore con BS, ma per accedere all'elemento che contiene la stringa del nome dell'autore devo usare selenium (The selenium package is used to automate web browser interaction from Python). A questo punto, volevo chiedere se non è forse meglio togliere direttamente questa possibilità e basare la ricerca solo sul file di mappatura già sviluppato da Arcangelo (i dati sono gli stessi, magari non aggiornati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<body>\n",
    "<app-root> </app-root>\n",
    "<noscript>Please enable JavaScript to continue using this application.</noscript>\n",
    "<script crossorigin=\"use-credentials\" src=\"runtime.07f916153122b14a-en.js\" type=\"module\"></script><script crossorigin=\"use-credentials\" src=\"polyfills.ca301adc42fc1eaa-en.js\" type=\"module\"></script><script crossorigin=\"use-credentials\" src=\"main.c0e20dee10eb52f4-en.js\" type=\"module\"></script>\n",
    "</body>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSVDataSource\n",
    "Testando il glob di Crossref mi sono resa conto che aveva senso fare in modo che tutte le altre operazioni e trascrizioni relative ad un identificativo invalido fossero saltate, una volta constatata la sua invalidità (anche perché questo portava all'aggiunta di una stringa vuota per gli id invalidi in id_date). Ora il codice del metodo set della classe CSVDataSource è il seguente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def set(self, resource_id, value):\n",
    "        if value[\"valid\"] is False:\n",
    "            self._valid_id.add_value(resource_id, \"i\")\n",
    "        elif value[\"valid\"] is True:\n",
    "            self._valid_id.add_value(resource_id, \"v\")\n",
    "            #Indented so that all the operations and transcriptions are performed only for valid ids\n",
    "            if value[\"date\"] is not None and value[\"date\"] != []:\n",
    "                # for multiple values and to avoid self.data[id_string].add(value) TypeError: unhashable type: 'set'\n",
    "                for date in value[\"date\"]:\n",
    "                    self._id_date.add_value(resource_id, date)\n",
    "            else:\n",
    "                self._id_date.add_value(resource_id, \"\")\n",
    "            if value[\"issn\"] is not None and value[\"issn\"] != []:\n",
    "                # for multiple values and to avoid self.data[id_string].add(value) TypeError: unhashable type: 'set'\n",
    "                for issn in value[\"issn\"]:\n",
    "                    self._id_issn.add_value(resource_id, issn)\n",
    "            if value[\"orcid\"] is not None and value[\"orcid\"] != []:\n",
    "                # for multiple values and to avoid self.data[id_string].add(value) TypeError: unhashable type: 'set'\n",
    "                for orcid in value[\"orcid\"]:\n",
    "                    self._id_orcid.add_value(resource_id, orcid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Do:\n",
    "- raggruppa API e SPARQL ()\n",
    "- raggruppa richieste da stessa fonte (crea json di utenti noti) ()\n",
    "- fai elenco manuale di librerie note ()\n",
    "- fai anche file di bot crawler spider ()\n",
    "- manda dati a chiara + chiamata con chiara (√)\n",
    "- fai visualizzazioni mensili ()\n",
    "- vedi con giiuseppe questione di files di configurazione e test validate ()\n",
    "- finisci i glob (√)\n",
    "- sviluppa test validate ()\n",
    "- finisci con ivan visualizzazioni (√)\n",
    "- meta ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: da time agnostic library vedi come spacchettare la cartella da zenodo \n",
    "api orcid CONTROLLA ORCID RESOURCE FINDER\n",
    "CONTROLLA GRAPH ENRICHER --> C'è modo di risalire dal doi all'orcid, non so se c'è da fare un'altra chiamata per ottenere il nome. \n",
    "GUARDA ANCHE OPENCITATION CORPUS. \n",
    "cancella diario e ricrea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index final commit (CSVDatasource, ORCIDResourceFinderPMID, CSVDataSource GLOB, Validate NOCI and DOCI + tests), Log data visualizations (26/07 -30/08)\n",
    "<a class=\"anchor\" id=\"entry_19\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Index  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrazione nomi autori (per verifica identità autori NIH dump - ORCID, in NOCI glob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) con Orcid Resource Finder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'orcid-identifier': {'uri': 'https://orcid.org/0000-0002-7445-7279',\n",
       "   'path': '0000-0002-7445-7279',\n",
       "   'host': 'orcid.org'}}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[{'orcid-identifier': {'uri': 'https://orcid.org/0000-0002-7445-7279', 'path': '0000-0002-7445-7279', 'host': 'orcid.org'}}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non è possibile perché il **json_object che arriva a _get_orcid da _call_api non contiene informazioni sul nome dell'autore**. <br>\n",
    "La risposta all'API completa è:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': [{'orcid-identifier': {'uri': 'https://orcid.org/0000-0002-7445-7279',\n",
       "    'path': '0000-0002-7445-7279',\n",
       "    'host': 'orcid.org'}}],\n",
       " 'num-found': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " {'result': [{'orcid-identifier': {'uri': 'https://orcid.org/0000-0002-7445-7279', 'path': '0000-0002-7445-7279', 'host': 'orcid.org'}}], 'num-found': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selenium** (libreria python per il web scraping) sembrava interessante ma è una strada che eviterei perché **richiede il download di executable drivers**. (*Message: 'geckodriver' executable needs to be in PATH*). Inoltre ho trovato questo commento : *While Selenium might seem tempting and useful, it has one main problem that can't be fixed: **performance**. By calculating every single thing a browser does, **you will need a lot more power**. Even PhantomJS does not compete with a simple request. I recommend that you will only use Selenium when you really need to click buttons.* (https://stackoverflow.com/a/45864089) , che mi fa pensare che a prescindere non fosse una buona idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) HTML Session (versione web crawling di requests: requests-HTML) + Bs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "\n",
    "session = HTMLSession()\n",
    "r = session.get(a_page_url)\n",
    "r.html.render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sfrutta una **libreria per il parsing HTML**. Questa opzione però **non risolve il problema dell'autenticazione, nemmeno inserendo le credenziali da utente** (pare che **per accedere al nome degli autori** sia **necessario il token che si ottiene solo dopo la la registrazione dell'applicazione**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Graph Enricher\n",
    "Ci siamo sentiti con Davide per capire se fosse possibile estrarre il nome di un autore partendo dall'ORCID sfruttando GraphEnricher.\n",
    "- Creazione di istanza ORCID importando l'interfaccia API di GE. (from graphenricher.API import * , orcid_api = ORCID())\n",
    "- Input della query : **self.orcid_api.query(author_list, [(GraphEntity.iri_doi, id)])**, dove GraphEntity arriva dalla libreria ocdm, mentre author list è una lista che contiene una tupla di formato [(family name, given name, None, None)].\n",
    "\n",
    "**Problema**: la **nostra necessità era passare un ORCID e ricevere il nome dell'autore. Questa funzione svolge il procedimento inverso**. Abbiamo **provato** quindi dando in **input solo la tupla con orcid e None come family name e given name, ma dà un errore 500** (quindi probabilmente è un problema lato orcid, o un problema relativo al fatto che GE opera sulla versione dell'api 2.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Seguendo il tutorial di ORCID \"API Orcid to get record data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leggendo la documentazione ho avuto l'impressione che l'unico modo per ottenere l'informazione del nome dell'autore sia accedere con le proprie credenziali utente alla piattaforma ORCID, registrare la propria applicazione dichiarandone la finalità, e ottenere il token e le credenziali client di accesso all'API pubblica (che è sufficiente, non serve quella ad accesso limitato)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il tutorial è basato sulla versione 3.0 dello schema ORCID e ha lo scopo di spiegare come accedere alle informazioni **pubbliche o ad accesso limitato** (a seconda che si scelga di usare l'API pubblica o member). Io ho seguito la procedura per l'accesso pubblico. \n",
    "<ol>\n",
    "    <li><b>Ottenere Credenziali Client</b>: Per ottenere le credenziali (username e password) bisogna registrare l'applicazione che utilizzerà il servizio. Viene precisato che <b>chiunque può registrarsi per richiedere le \"read-only\"</b>. Mi è stato richiesto di accedere con le mie credenziali ORCID, selezionare \"developer tools\" e proseguire con <b>Register for the free ORCID public API</b>. I termini di servizio: <b>L'API pubblica permette di leggere le informazioni pubbliche di un ORCID record e cercare dati pubblici dal registro ORCID, in accordo con i Public Client Terms of Service.</b></li>\n",
    "    <li><b>Ottenere Access Token</b> con richiesta POST con credenziali</li>\n",
    "    <li><b>Usare Token per accedere a API</b>. <i> La richiesta usa l'ORCID e non il DOI come in ORCID resource finder. La risposta è un JSON molto complesso, che contiene una chiave con informazioni relative al nome dell'autore (nomi, cognomi e altri nomi)</i> </li>\n",
    "</ol>\n",
    "<b>DOMANDE E PUNTI DA DISCUTERE</b> <br>\n",
    "Estendere ORCID RESOURCE FINDER anche per PMID? c'è la possibilità, discutere con Silvio e Giuseppe. (√) \n",
    "Possibile double check sull'identità degli autori conservando informazioni su iniziali dei nomi (questo implica prima dividere la stringa alla virgola, poi la regex, una seconda regex per le lettere maiuscole, poi confrontare che almeno una delle iniziali corrisponda all'iniziale di uno dei nomi riportati in orcid).(√) \n",
    "<b>Discutere i punti in grassetto e capire se l'utilizzo dell'API che facciamo è conforme con lo scopo della versione pubblica dell'API( )</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PUBLIC CLIENT TERMS OF SERVICE (come gestire le credenziali?)\n",
    "<ol>\n",
    "    <li>You may not use the Public Client to perpetually poll the ORCID Websites. </li>\n",
    "    <li><b>An individual may only have one Public Client</b>.   You may not obtain more than one ORCID iD for the purpose of obtaining multiple Public Clients. </li>\n",
    "    <li><b>You may not share your Public Client or transfer your Public Client credentials to another individual. (If an individual leaves an organization, a new individual at the organization must register for a new Public Client for the organization to continue to access the Public Client benefits). </b> </li>\n",
    "    <li>You may not use any data obtained from the Registry in a manner that is false or misleading.</li>\n",
    "    <li>You may not use email or physical addresses obtained from ORCID records to send junk mail, spam, chain letters, pyramid schemes or similar communications, and you may not send marketing or other commercial communications, unless you give the person the right to opt-out of such communications.</li>\n",
    "    <li>You may not use the Public Client for any unlawful, illegal (in the United States and any jurisdiction in which you are located), or injurious purpose.</li>\n",
    "    <li>You may not use the Public Client in any way that damages, disables, overburdens or impairs the operation of the Websites or Registry.  Such prohibited actions include, but are not limited to: violating or attempting to violate security measures; denial of service attacks, accessing services or data that are not intended for your use; logging into a server or account which you are not authorized to access; attempting to probe, scan or test the vulnerability of a system or network; <b>attempting to interfere with the service of any users, host or network</b>; forging any TCP/IP packet header or any part of a header information in any email or posting; and infecting the Websites or Registry with software viruses or any other computer code, files or programs designed to interrupt, destroy or limit the functionality of any software, hardware, or telecommunications equipment.</li>\n",
    "    <li><b>If you are prohibited from receiving U.S. origin services or software you may not use the Public Client. You may not export the Public Client to any countries that are subject to the export control restrictions of the United States.</b></li>\n",
    "    <li>You may not use the ORCID name in any way to suggest ORCID’s affiliation or endorsement of any individual, organization, product, or service without the prior written consent of ORCID.</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Registrazione dell'API pubblica di ORCID come richiesto nel tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"orcid_api_app.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note chiamata con Giuseppe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- csv datasource get(id) ora restituisce **None** se tutti i campi per un'entità sono vuoti (anziché **{\"valid\": None, \"orcid\": None, \"date\": None, \"issn\": None}**)\n",
    "- **Modifiche a config**: decommentare i file e modificare i path ai vari files csv. \n",
    "- **Specificare servizio al datasource**: Bisogna passare come argomento la stringa del sevrizio che si sta usando (DOCI, NOCI, COCI, CROCI), che sono le stringhe che si trovano in services.\n",
    "- **validate**: è stato fatto il test per crossref, per gli altri è da implementare ma sarà simile). I test da fare sono due: uno per controllare che estragga tutti gli OCI dalle citazioni e l'altro per controllare che - qualora un OCI sia già stato incontrato - nel nuovo file generato (senza duplicati) vengano inclusi tutti gli OCI tranne quello della citazione già gestita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cose da fare in Index\n",
    "- Estendere ORCID resource finder per PMID (5(√))\n",
    "- validazione con le iniziali dei nomi degli autori, oltre che con i cognomi (per questo andrebbe fatta tipo una tupla o un dizionario) (1(√))\n",
    "- test validate (estendere)(2(√))\n",
    "- fare le modifiche relative a cambiamenti in csvdatasource e config (3(√))\n",
    "- sistemare test glob (4(√))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "import unittest\n",
    "import os\n",
    "from os.path import join\n",
    "from csv import DictReader\n",
    "\n",
    "from oc.index.validate.crossref import CrossrefValidator\n",
    "from oc.index.validate.datacite import DataciteValidator\n",
    "from oc.index.validate.nih import NIHValidator\n",
    "from oc.index.oci.citation import OCIManager\n",
    "from oc.index.utils.config import get_config\n",
    "\n",
    "\n",
    "class ValidateTest(unittest.TestCase):\n",
    "    \"\"\"This class aim at testing the methods of the class\n",
    "    belongs to package oc.index.validate\"\"\"\n",
    "\n",
    "    def setUp(self):\n",
    "        test_dir = join(\"index\", \"python\", \"test\", \"data\")\n",
    "\n",
    "        self.coci_input = join(test_dir, \"coci_validate\")\n",
    "        self.coci_validate = CrossrefValidator()\n",
    "\n",
    "        self.doci_input = join(test_dir, \"doci_validate\")\n",
    "        self.doci_validate = DataciteValidator()\n",
    "\n",
    "        self.noci_input = join(test_dir, \"noci_validate\")\n",
    "        self.noci_validate = NIHValidator()\n",
    "\n",
    "        oci_manager = OCIManager(\n",
    "            lookup_file=os.path.expanduser(get_config().get(\"cnc\", \"lookup\"))\n",
    "        )\n",
    "\n",
    "        with open(join(test_dir, \"crossref_citations.csv\"), encoding=\"utf8\") as f:\n",
    "            self.coci_truth = []\n",
    "            for citation in list(DictReader(f)):\n",
    "                self.coci_truth.append(\n",
    "                    oci_manager.get_oci(\n",
    "                        citation[\"citing\"], citation[\"cited\"], prefix=\"020\"\n",
    "                    ).replace(\"oci:\", \"\")\n",
    "                )\n",
    "\n",
    "        with open(join(test_dir, \"doci_citations.csv\"), encoding=\"utf8\") as f0:\n",
    "            self.doci_truth = []\n",
    "            for citation in list(DictReader(f0)):\n",
    "                self.doci_truth.append(\n",
    "                    oci_manager.get_oci(\n",
    "                        citation[\"citing\"], citation[\"cited\"], prefix=\"080\"\n",
    "                    ).replace(\"oci:\", \"\")\n",
    "                )\n",
    "\n",
    "        with open(join(test_dir, \"noci_citations.csv\"), encoding=\"utf8\") as f1:\n",
    "            self.noci_truth = []\n",
    "            for citation in list(DictReader(f1)):\n",
    "                self.noci_truth.append(\n",
    "                    oci_manager.get_oci(\n",
    "                        citation[\"citing\"], citation[\"cited\"], prefix=\"0160\"\n",
    "                    ).replace(\"oci:\", \"\")\n",
    "                )\n",
    "\n",
    "    def test_crossref_query_build(self):\n",
    "        query = self.coci_validate.build_oci_query(\n",
    "            join(self.coci_input, \"0.json\"), {}, disable_tqdm=True\n",
    "        )\n",
    "        self.assertEqual(set(query), set(self.coci_truth))\n",
    "\n",
    "    def test_crossref_validate(self):\n",
    "        query_old = self.coci_validate.build_oci_query(\n",
    "            join(self.coci_input, \"0.json\"), {}, disable_tqdm=True\n",
    "        )\n",
    "        result_map = {key: False for key in query_old}\n",
    "        result_map[\n",
    "            \"020070701073625141427193704030705-0200100000236211410253701000201\"\n",
    "        ] = True\n",
    "\n",
    "        self.coci_validate.validate_citations(\n",
    "            self.coci_input, result_map, join(\"tmp\", \"coci_validate\")\n",
    "        )\n",
    "        query_new = self.coci_validate.build_oci_query(\n",
    "            join(join(\"tmp\", \"coci_validate\"), \"0.json\"), {}, disable_tqdm=True\n",
    "        )\n",
    "        self.assertEqual(len(query_old) - 1, len(query_new))\n",
    "        pass\n",
    "\n",
    "    def test_datacite_query_build(self):\n",
    "        query = self.doci_validate.build_oci_query(\n",
    "            join(self.doci_input, \"0.json\"), {}, disable_tqdm=True\n",
    "        )\n",
    "        self.assertEqual(set(query), set(self.doci_truth))\n",
    "\n",
    "\n",
    "    def test_datacite_validate(self):\n",
    "        query_old = self.doci_validate.build_oci_query(\n",
    "            join(self.doci_input, \"0.json\"), {}, disable_tqdm=True\n",
    "        )\n",
    "        result_map = {key: False for key in query_old}\n",
    "        result_map[\"08001000007362801030304066300010763000307066305-0800100010636193719122423271421370200000337000204\"] = True\n",
    "        self.doci_validate.validate_citations(\n",
    "            self.doci_input, result_map, join(\"tmp\", \"doci_validate\")\n",
    "        )\n",
    "        query_new = self.doci_validate.build_oci_query(\n",
    "            join(join(\"tmp\", \"doci_validate\"), \"0.json\"), {}, disable_tqdm=True\n",
    "        )\n",
    "        self.assertEqual(len(query_old) - 1, len(query_new))\n",
    "        pass\n",
    "\n",
    "    def test_nih_query_build(self):\n",
    "        query = self.noci_validate.build_oci_query(\n",
    "            join(self.noci_input, \"0.csv\"), {}, disable_tqdm=True\n",
    "        )\n",
    "        self.assertEqual(set(query), set(self.noci_truth))\n",
    "\n",
    "    def test_nih_validate(self):\n",
    "        query_old = self.noci_validate.build_oci_query(\n",
    "            join(self.noci_input, \"0.csv\"), {}, disable_tqdm=True\n",
    "        )\n",
    "        result_map = {key: False for key in query_old}\n",
    "        result_map[\n",
    "            \"016001050203050709-016007000907050609\"\n",
    "        ] = True\n",
    "\n",
    "        self.noci_validate.validate_citations(\n",
    "            self.noci_input, result_map, join(\"tmp\", \"noci_validate\")\n",
    "        )\n",
    "        query_new = self.noci_validate.build_oci_query(\n",
    "            join(join(\"tmp\", \"noci_validate\"), \"0.csv\"), {}, disable_tqdm=True\n",
    "        )\n",
    "        self.assertEqual(len(query_old) - 1, len(query_new))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versioni aggiornate e testate degli script di validate di NOCI e DOCI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validate/nih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "from oc.index.validate.base import CitationValidator\n",
    "from oc.index.identifier.pmid import PMIDManager\n",
    "from oc.index.utils.logging import get_logger\n",
    "\n",
    "\n",
    "\n",
    "class NIHValidator(CitationValidator):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"NOCI\")\n",
    "        self._pmid_manager = PMIDManager()\n",
    "        self._logger = get_logger()\n",
    "\n",
    "    def build_oci_query(self, input_file, result_map, disable_tqdm=False):\n",
    "        csv_content = []\n",
    "\n",
    "        # Build the OCI lookup query\n",
    "        self._logger.info(\"Reading citation data from \" + input_file)\n",
    "        query = []\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        for chunk in pd.read_csv(input_file, chunksize=1000):\n",
    "            f = pd.concat([df, chunk], ignore_index=True)\n",
    "            f.fillna(\"\", inplace=True)\n",
    "            csv_content = f.to_dict(\"records\")\n",
    "            for row in tqdm(csv_content, disable=disable_tqdm):\n",
    "                citing = self._pmid_manager.normalise(row.get(\"citing\"))\n",
    "                cited = self._pmid_manager.normalise(row.get(\"referenced\"))\n",
    "\n",
    "                if cited is not None:\n",
    "                    oci = self._oci_manager.get_oci(\n",
    "                        citing, cited, prefix=self._prefix\n",
    "                    ).replace(\"oci:\", \"\")\n",
    "                    # Add oci only if has not been processed in the past\n",
    "                    # in the case this is a duplicate.\n",
    "                    if oci not in result_map:\n",
    "                        query.append(oci)\n",
    "        return query\n",
    "\n",
    "    def validate_citations(self, input_directory, result_map, output_directory):\n",
    "        if not os.path.exists(output_directory):\n",
    "            os.makedirs(output_directory)\n",
    "        for filename in os.listdir(input_directory):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                csv_content = []\n",
    "\n",
    "                # Build the OCI lookup query\n",
    "                self._logger.info(\"Reading citation data from \" + filename)\n",
    "                query = []\n",
    "                df = pd.DataFrame()\n",
    "                for chunk in pd.read_csv(os.path.join(input_directory, filename), chunksize=1000):\n",
    "                    f = pd.concat([df, chunk], ignore_index=True)\n",
    "                    f.fillna(\"\", inplace=True)\n",
    "                    csv_content = f.to_dict(\"records\")\n",
    "                    for row in tqdm(csv_content):\n",
    "                        citing = self._pmid_manager.normalise(row.get(\"citing\"))\n",
    "                        cited = self._pmid_manager.normalise(row.get(\"referenced\"))\n",
    "                        if citing is not None and cited is not None:\n",
    "                            oci = self._oci_manager.get_oci(\n",
    "                                citing, cited, prefix=self._prefix\n",
    "                            ).replace(\"oci:\", \"\")\n",
    "                            # Add oci only if has not been processed in the past\n",
    "                            # in the case this is a duplicate.\n",
    "                            if oci not in result_map:\n",
    "                                query.append(oci)\n",
    "\n",
    "                # Create input file\n",
    "                with open(\"input.csv\", \"w\") as f:\n",
    "                    for oci in query:\n",
    "                        f.write(oci + \"\\n\")\n",
    "\n",
    "                # Remove the processed citations\n",
    "                self._logger.info(\"Remove duplicates and existiting citations\")\n",
    "                duplicated = 0\n",
    "                items = []\n",
    "                for row in tqdm(csv_content):\n",
    "                    citing = self._pmid_manager.normalise(row.get(\"citing\"))\n",
    "                    cited = self._pmid_manager.normalise(row.get(\"referenced\"))\n",
    "                    if citing is not None and cited is not None:\n",
    "                        oci = self._oci_manager.get_oci(\n",
    "                            citing, cited, prefix=self._prefix\n",
    "                        ).replace(\"oci:\", \"\")\n",
    "                        if oci in result_map and not result_map[oci]:\n",
    "                            # Set result map true for the oci to avoid duplicates\n",
    "                            result_map[oci] = True\n",
    "                            items.append(row)\n",
    "                        else:\n",
    "                            duplicated += 1\n",
    "\n",
    "                # Save validated citations\n",
    "                self._logger.info(str(duplicated) + \" citations deleted\")\n",
    "                self._logger.info(\"Saving validated citations...\")\n",
    "                keys = items[0].keys()\n",
    "                with open(os.path.join(output_directory, filename), \"w\", newline='') as output_file:\n",
    "                    dict_writer = csv.DictWriter(output_file, keys)\n",
    "                    dict_writer.writeheader()\n",
    "                    dict_writer.writerows(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validate/datacite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from oc.index.validate.base import CitationValidator\n",
    "from oc.index.identifier.doi import DOIManager\n",
    "from oc.index.utils.logging import get_logger\n",
    "\n",
    "\n",
    "class DataciteValidator(CitationValidator):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"DOCI\")\n",
    "        self._doi_manager = DOIManager()\n",
    "        self._logger = get_logger()\n",
    "\n",
    "    def build_oci_query(self, input_file, result_map, disable_tqdm=False):\n",
    "        json_content = {\"data\": []}\n",
    "\n",
    "        # Build the OCI lookup query\n",
    "        self._logger.info(\"Reading citation data from \" + input_file)\n",
    "        query = []\n",
    "        needed_info = [\"relationType\", \"relatedIdentifierType\", \"relatedIdentifier\"]\n",
    "        with open(input_file, encoding=\"utf8\") as fp:\n",
    "            json_content = json.load(fp)\n",
    "        for row in tqdm(json_content[\"data\"], disable=disable_tqdm):\n",
    "            attr = row.get(\"attributes\")\n",
    "            citing = self._doi_manager.normalise(attr.get(\"doi\"))\n",
    "            if citing is not None and \"relatedIdentifiers\" in attr:\n",
    "                for ref in attr[\"relatedIdentifiers\"]:\n",
    "                    if [x for x in needed_info if x in ref]:\n",
    "                        relatedIdentifierType = (str(ref[\"relatedIdentifierType\"])).lower()\n",
    "                        rel_id = self._doi_manager.normalise(ref[\"relatedIdentifier\"])\n",
    "                        relationType = str(ref[\"relationType\"]).lower()\n",
    "                        if relatedIdentifierType == \"doi\":\n",
    "                            if relationType == \"references\" or relationType == \"cites\":\n",
    "                                cited = rel_id\n",
    "                                if cited is not None:\n",
    "                                    oci = self._oci_manager.get_oci(\n",
    "                                        citing, cited, prefix=self._prefix\n",
    "                                    ).replace(\"oci:\", \"\")\n",
    "                                    # Add oci only if has not been processed in the past\n",
    "                                    # in the case this is a duplicate.\n",
    "                                    if oci not in result_map:\n",
    "                                        query.append(oci)\n",
    "                            elif relationType == \"isreferencedby\" or relationType == \"iscitedby\":\n",
    "                                cited = citing\n",
    "                                if rel_id is not None:\n",
    "                                    oci = self._oci_manager.get_oci(\n",
    "                                        rel_id, cited, prefix=self._prefix\n",
    "                                    ).replace(\"oci:\", \"\")\n",
    "                                    # Add oci only if has not been processed in the past\n",
    "                                    # in the case this is a duplicate.\n",
    "                                    if oci not in result_map:\n",
    "                                        query.append(oci)\n",
    "\n",
    "        return query\n",
    "\n",
    "    def validate_citations(self, input_directory, result_map, output_directory):\n",
    "        if not os.path.exists(output_directory):\n",
    "            os.makedirs(output_directory)\n",
    "        needed_info = [\"relationType\", \"relatedIdentifierType\", \"relatedIdentifier\"]\n",
    "        for filename in os.listdir(input_directory):\n",
    "            if filename.endswith(\".json\"):\n",
    "                json_content = {\"data\": []}\n",
    "\n",
    "                # Build the OCI lookup query\n",
    "                self._logger.info(\"Reading citation data from \" + filename)\n",
    "                query = []\n",
    "                with open(os.path.join(input_directory, filename), encoding=\"utf8\") as fp:\n",
    "                    json_content = json.load(fp)\n",
    "                for row in tqdm(json_content[\"data\"]):\n",
    "                    attr = row.get(\"attributes\")\n",
    "                    citing = self._doi_manager.normalise(attr.get(\"doi\"))\n",
    "                    if citing is not None and \"relatedIdentifiers\" in attr:\n",
    "                        for ref in attr[\"relatedIdentifiers\"]:\n",
    "                            if [x for x in needed_info if x in ref]:\n",
    "                                relatedIdentifierType = (str(ref[\"relatedIdentifierType\"])).lower()\n",
    "                                rel_id = self._doi_manager.normalise(ref[\"relatedIdentifier\"])\n",
    "                                relationType = str(ref[\"relationType\"]).lower()\n",
    "                                if relatedIdentifierType == \"doi\":\n",
    "                                    if relationType == \"references\" or relationType == \"cites\":\n",
    "                                        cited = rel_id\n",
    "                                        if cited is not None:\n",
    "                                            oci = self._oci_manager.get_oci(\n",
    "                                                citing, cited, prefix=self._prefix\n",
    "                                            ).replace(\"oci:\", \"\")\n",
    "                                            # Add oci only if has not been processed in the past\n",
    "                                            # in the case this is a duplicate.\n",
    "                                            if oci not in result_map:\n",
    "                                                query.append(oci)\n",
    "                                    elif relationType == \"isreferencedby\" or relationType == \"iscitedby\":\n",
    "                                        cited = citing\n",
    "                                        if rel_id is not None:\n",
    "                                            oci = self._oci_manager.get_oci(\n",
    "                                                rel_id, cited, prefix=self._prefix\n",
    "                                            ).replace(\"oci:\", \"\")\n",
    "                                            # Add oci only if has not been processed in the past\n",
    "                                            # in the case this is a duplicate.\n",
    "                                            if oci not in result_map:\n",
    "                                                query.append(oci)\n",
    "\n",
    "                # Create input file\n",
    "                with open(\"input.csv\", \"w\") as f:\n",
    "                    for oci in query:\n",
    "                        f.write(oci + \"\\n\")\n",
    "\n",
    "                # Remove the processed citations\n",
    "                self._logger.info(\"Remove duplicates and existiting citations\")\n",
    "                duplicated = 0\n",
    "                items = []\n",
    "                for row in tqdm(json_content[\"data\"]):\n",
    "                    attr = row.get(\"attributes\")\n",
    "                    citing = self._doi_manager.normalise(attr.get(\"doi\"))\n",
    "                    if citing is not None and \"relatedIdentifiers\" in attr:\n",
    "                        reference = []\n",
    "                        for ref in attr[\"relatedIdentifiers\"]:\n",
    "                            if [x for x in needed_info if x in ref]:\n",
    "                                relatedIdentifierType = (str(ref[\"relatedIdentifierType\"])).lower()\n",
    "                                rel_id = self._doi_manager.normalise(ref[\"relatedIdentifier\"])\n",
    "                                relationType = str(ref[\"relationType\"]).lower()\n",
    "                                if relatedIdentifierType == \"doi\":\n",
    "                                    if relationType == \"references\" or relationType == \"cites\":\n",
    "                                        cited = rel_id\n",
    "                                        if cited is not None:\n",
    "                                            oci = self._oci_manager.get_oci(\n",
    "                                                citing, cited, prefix=self._prefix\n",
    "                                            ).replace(\"oci:\", \"\")\n",
    "                                            # Add oci only if has not been preprocessed and it is not a duplicate\n",
    "                                            if oci in result_map and not result_map[oci]:\n",
    "                                                # Set result map true for the oci to avoid duplicates\n",
    "                                                result_map[oci] = True\n",
    "                                                reference.append(ref)\n",
    "                                            else:\n",
    "                                                duplicated += 1\n",
    "                                    elif relationType == \"isreferencedby\" or relationType == \"iscitedby\":\n",
    "                                        cited = citing\n",
    "                                        if rel_id is not None:\n",
    "                                            oci = self._oci_manager.get_oci(\n",
    "                                                rel_id, cited, prefix=self._prefix\n",
    "                                            ).replace(\"oci:\", \"\")\n",
    "                                            # Add oci only if has not been preprocessed and it is not a duplicate\n",
    "                                            if oci in result_map and not result_map[oci]:\n",
    "                                                # Set result map true for the oci to avoid duplicates\n",
    "                                                result_map[oci] = True\n",
    "                                                reference.append(ref)\n",
    "                                            else:\n",
    "                                                duplicated += 1\n",
    "                        row[\"attributes\"][\"relatedIdentifiers\"] = reference\n",
    "                        items.append(row)\n",
    "\n",
    "                # Save validated citations\n",
    "                self._logger.info(str(duplicated) + \" citations deleted\")\n",
    "                self._logger.info(\"Saving validated citations...\")\n",
    "                with open(os.path.join(output_directory, filename), \"w\") as fp:\n",
    "                    json.dump({\"data\": items}, fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orcid Resource Finder per PMID \n",
    "**DOMANDA**: Ho fatto una seconda classe specifica perché l'id type era passato come argomento (**super().__init__(data, use_api_service=use_api_service, id_type=\"pmid\")**) e in default id_type = \"doi\". Quindi per ora c'è una classe che gestisce il recupero ORCID da ID per i PMID. Da discutere se si può mantenere così"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ORCIDResourceFinderPMID(ApiDOIResourceFinder):\n",
    "    \"\"\"This class implements an identifier manager for orcid identifier\"\"\"\n",
    "\n",
    "    def __init__(self, data={}, use_api_service=True, api_key=None):\n",
    "        \"\"\"ORCID resource finder constructor.\n",
    "\n",
    "        Args:\n",
    "            date (str, optional): path to date file. Defaults to None.\n",
    "            orcid (str, optional): path to orcid file. Defaults to None.\n",
    "            issn (str, optional): path to issn file. Defaults to None.\n",
    "            doi (str, optional): path to doi file. Defaults to None.\n",
    "            use_api_service (bool, optional): true if you want to use api service. Defaults to True.\n",
    "            key (str, optional): api key. Defaults to None.\n",
    "        \"\"\"\n",
    "        super().__init__(data, use_api_service=use_api_service, id_type=\"pmid\")\n",
    "        self._api = \"https://pub.orcid.org/v2.1/search?q=\"\n",
    "        self._api_key = api_key\n",
    "\n",
    "    def _get_orcid(self, json_obj):\n",
    "        result = set()\n",
    "\n",
    "        if json_obj is not None:\n",
    "            for item in json_obj:\n",
    "                orcid = item.get(\"orcid-identifier\")\n",
    "                if orcid is not None:\n",
    "                    orcid_norm = self._om.normalise(orcid[\"path\"])\n",
    "                    if orcid_norm is not None:\n",
    "                        result.add(orcid_norm)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _call_api(self, pmid_full):\n",
    "        if self._use_api_service:\n",
    "            if self._api_key is not None:\n",
    "                self._headers[\"Authorization\"] = \"Bearer %s\" % self._api_key\n",
    "            self._headers[\"Content-Type\"] = \"application/json\"\n",
    "\n",
    "            pmid = self._dm.normalise(pmid_full)\n",
    "            r = get(\n",
    "                self._api\n",
    "                + quote('pmid-self:\"%s\"' % (pmid)),\n",
    "                headers=self._headers,\n",
    "                timeout=30,\n",
    "            )\n",
    "            if r.status_code == 200:\n",
    "                r.encoding = \"utf-8\"\n",
    "                json_res = loads(r.text)\n",
    "                return json_res.get(\"result\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resource Finder Test (modifica per ORCID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def test_orcid_get_orcid(self):\n",
    "        # Do not use support dict, only APIs\n",
    "        of_1 = ORCIDResourceFinder()\n",
    "        self.assertIn(\"0000-0003-0530-4305\", of_1.get_orcid(\"10.1108/jd-12-2013-0166\"))\n",
    "        #self.assertIn(\"0000-0002-4762-5345\", of_1.get_orcid(\"5\"))\n",
    "        self.assertNotIn(\n",
    "            \"0000-0001-5506-523X\", of_1.get_orcid(\"10.1108/jd-12-2013-0166\")\n",
    "        )\n",
    "        of_1pmid = ORCIDResourceFinderPMID()\n",
    "        self.assertIn(\"0000-0002-4762-5345\", of_1pmid.get_orcid(\"5\"))\n",
    "        self.assertNotIn(\n",
    "            \"0000-0001-5506-523X\", of_1pmid.get_orcid(\"5\")\n",
    "        )\n",
    "\n",
    "        # Do use support dict, but avoid using APIs\n",
    "        of_2 = ORCIDResourceFinder(\n",
    "            self.data,\n",
    "            use_api_service=False,\n",
    "        )\n",
    "        self.assertIn(\"0000-0003-0530-4305\", of_2.get_orcid(\"10.1108/jd-12-2013-0166\"))\n",
    "        self.assertNotIn(\n",
    "            \"0000-0001-5506-523X\", of_2.get_orcid(\"10.1108/jd-12-2013-0166\")\n",
    "        )\n",
    "\n",
    "        of_2pmid = ORCIDResourceFinderPMID()\n",
    "        self.assertIn(\"0000-0002-4762-5345\", of_2pmid.get_orcid(\"5\"))\n",
    "        self.assertNotIn(\n",
    "            \"0000-0001-5506-523X\", of_2pmid.get_orcid(\"5\")\n",
    "        )\n",
    "\n",
    "        # Do not use support files neither APIs\n",
    "        of_3 = ORCIDResourceFinder(use_api_service=False)\n",
    "        self.assertIsNone(of_3.get_orcid(\"10.1108/jd-12-2013-0166\"))\n",
    "\n",
    "        of_3pmid = ORCIDResourceFinderPMID(use_api_service=False)\n",
    "        self.assertIsNone(of_3pmid.get_orcid(\"5\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versione aggiornata di GLOB e test (a seguito delle modifiche di Giuseppe su csv datasource e file di configurazione) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NIH \n",
    "#### Verifica Identità Autore (ORCID - NIH,  con validazione nome + cognome autore - da testare con zip in input) - adattato a modifiche di giuseppe su config e csv data source)\n",
    "In particolare, ho gestito il **controllo della corrispondenza tra cognomi dichiarati nel dump e cognomi recuperati tramite ORCID (passando per il DOI)**. In un secondo momento ho aggiunto anche un controllo sulla **corrispondenza delle iniziali del nome fornite nel dump NIH e i nomi ottenuti dalle API di ORCID** (almeno uno dei riportati in ORCID deve iniziare con una delle lettere riportate nel dump NIH). Il **controllo** avviene dopo aver trasformato tutto **in lowercase** (dal momento che in ORCID non c'è un controllo sulla forma).\n",
    "**Ho sistemato un passaggio del csv datasource (sempre metodo set) per fare in modo che i dizionari di entità parzialmente compilati potessero essere aggiornati in un secondo momento (non per le date, per il motivo di cui abbiamo già discusso)**. Per la **gestione della validazione dell'identità degli autori**, ho aggiunto **due argomenti facoltativi (client id e client secret)**, senza i quali viene saltata la parte di verifica orcid tramite api (visto che senza le credenziali e senza token il servizio non funziona) e di conseguenza nessun dato relativo ad associazioni id-orcid viene salvato (questo sempre qualora non sia stata specificata nemmeno la cartella zippata con dati di mappatura doi-orcid, che rispetto all'uso di API è la modalità preferita). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "import csv\n",
    "from argparse import ArgumentParser\n",
    "from os import sep, makedirs, walk\n",
    "import os\n",
    "import os.path\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "from tarfile import TarFile\n",
    "import re\n",
    "from os.path import exists, basename, isdir, join\n",
    "from timeit import default_timer as timer\n",
    "from re import sub\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import requests\n",
    "\n",
    "from oc.index.oci.citation import Citation\n",
    "from oc.index.identifier.doi import DOIManager\n",
    "from oc.index.identifier.pmid import PMIDManager\n",
    "from oc.index.identifier.issn import ISSNManager\n",
    "from oc.index.identifier.orcid import ORCIDManager\n",
    "from oc.index.finder.orcid import ORCIDResourceFinder\n",
    "from oc.index.finder.crossref import CrossrefResourceFinder\n",
    "from oc.index.glob.csv import CSVDataSource\n",
    "\n",
    "\n",
    "def check_author_identity_api(uri, authors_dicts_list, orcid_client_id, orcid_client_secret):\n",
    "    data = {\"client_id\": orcid_client_id, \"client_secret\": orcid_client_secret,\"grant_type\": \"client_credentials\", \"scope\": \"/read-public\" }\n",
    "    response = requests.post(uri, headers = {\"Accept\": \"application/json\"}, data = data)\n",
    "    identity_verified = False\n",
    "    if response.status_code == 200:\n",
    "        json_response = response.json()\n",
    "        person = json_response[\"person\"]\n",
    "        g_names = person[\"name\"][\"given-names\"][\"value\"]\n",
    "        f_name = person[\"name\"][\"family-name\"][\"value\"]\n",
    "        orcid_author_surnames_list = re.findall(\n",
    "                        \"[a-zA-Z\\'\\-áéíóúäëïöüÄłŁőŐűŰZàáâäãåąčćęèéêëėįìíîïłńòóôöõøùúûüųūÿýżźñçčšžÀÁÂÄÃÅĄĆČĖĘÈÉÊËÌÍÎÏĮŁŃÒÓÔÖÕØÙÚÛÜŲŪŸÝŻŹÑßÇŒÆČŠŽñÑâê]{2,}\",\n",
    "                        f_name)\n",
    "        orcid_author_surnames_list_l = [x.lower() for x in orcid_author_surnames_list]\n",
    "        orcid_author_names_list = re.findall(\n",
    "                        \"[a-zA-Z\\'\\-áéíóúäëïöüÄłŁőŐűŰZàáâäãåąčćęèéêëėįìíîïłńòóôöõøùúûüųūÿýżźñçčšžÀÁÂÄÃÅĄĆČĖĘÈÉÊËÌÍÎÏĮŁŃÒÓÔÖÕØÙÚÛÜŲŪŸÝŻŹÑßÇŒÆČŠŽñÑâê]{2,}\",\n",
    "                        g_names)\n",
    "        orcid_author_names_list_l = [x.lower() for x in orcid_author_names_list]\n",
    "\n",
    "        matches = [dict for dict in authors_dicts_list if\n",
    "                   [sn for sn in dict[\"surnames\"] if sn in orcid_author_surnames_list_l] and [l for l in dict[\"names\"] if any(\n",
    "                       element.startswith(l) and element not in dict[\"surnames\"] for element in orcid_author_names_list_l)]]\n",
    "\n",
    "        if matches:\n",
    "            identity_verified = True\n",
    "    return identity_verified\n",
    "\n",
    "\n",
    "def issn_data_recover_noci(directory):\n",
    "    journal_issn_dict = dict()\n",
    "    filename = join(directory, \"journal_issn.json\")\n",
    "    if not os.path.exists(filename):\n",
    "        return journal_issn_dict\n",
    "    else:\n",
    "        with open(filename, \"r\", encoding=\"utf8\") as fd:\n",
    "            journal_issn_dict = json.load(fd)\n",
    "            return journal_issn_dict\n",
    "\n",
    "\n",
    "def issn_data_to_cache_noci(name_issn_dict, directory):\n",
    "    filename = directory + sep + \"journal_issn.json\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as fd:\n",
    "        json.dump(name_issn_dict, fd, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "# takes in input a data structure representing a bibliographic entity\n",
    "def build_pubdate_noci(row):\n",
    "    year = str(row[\"year\"])\n",
    "    str_year = sub(\"[^\\d]\", \"\", year)[:4]\n",
    "    if str_year:\n",
    "        return str_year\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# get_all_files extracts all the needed files from the input directory\n",
    "def get_all_files_noci(i_dir):\n",
    "    result = []\n",
    "    opener = None\n",
    "    if i_dir.endswith(\".zip\"):\n",
    "        zf = ZipFile(i_dir)\n",
    "        namelist = zf.namelist()\n",
    "        result = [x for x in namelist if x.lower().endswith(\".csv\")]\n",
    "        opener = zf.open\n",
    "    elif i_dir.endswith(\".tar.gz\"):\n",
    "        tf = TarFile.open(i_dir)\n",
    "        for name in tf.getnames():\n",
    "            if name.lower().endswith(\".csv\"):\n",
    "                result.append(name)\n",
    "        opener = tf.extractfile\n",
    "\n",
    "    else:\n",
    "        for cur_dir, cur_subdir, cur_files in walk(i_dir):\n",
    "            for file in cur_files:\n",
    "                if file.lower().endswith(\".csv\"):\n",
    "                    result.append(cur_dir + sep + file)\n",
    "        opener = open\n",
    "    return result, opener\n",
    "\n",
    "\n",
    "def process_noci(input_dir, output_dir, n, id_orcid_dir=None, orcid_client_id=None, orcid_client_secret=None):\n",
    "\n",
    "    start = timer()\n",
    "    if not exists(output_dir):\n",
    "        makedirs(output_dir)\n",
    "\n",
    "    journal_issn_dict = issn_data_recover_noci(output_dir)\n",
    "    crossref_resource_finder = CrossrefResourceFinder()\n",
    "    orcid_resource_finder = ORCIDResourceFinder()\n",
    "\n",
    "    doi_manager = DOIManager()\n",
    "    issn_manager = ISSNManager()\n",
    "    orcid_manager = ORCIDManager()\n",
    "    pmid_manager = PMIDManager()\n",
    "    csv_datasource = CSVDataSource(\"NOCI\")\n",
    "\n",
    "    all_files, opener = get_all_files_noci(input_dir)\n",
    "    len_all_files = len(all_files)\n",
    "    pmid_doi_map = dict()\n",
    "\n",
    "    # Read all the CSV file in the NIH dump to create the main information of all the indexes\n",
    "    # print(\"\\n\\n# Add valid PMIDs from NIH metadata\")\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        for chunk in pd.read_csv(file, chunksize=1000):\n",
    "            f = pd.concat([df, chunk], ignore_index=True)\n",
    "            f.fillna(\"\", inplace=True)\n",
    "\n",
    "            # print(\"Open file %s of %s\" % (file_idx, len_all_files))\n",
    "            for index, row in f.iterrows():\n",
    "                if int(index) != 0 and int(index) % int(n) == 0:\n",
    "                    # print( \"Group nr.\", int(index)//int(n), \"processed. Data from\", int(index), \"rows saved to journal_issn.json mapping file\")\n",
    "                    issn_data_to_cache_noci(journal_issn_dict, output_dir)\n",
    "\n",
    "                citing_pmid = pmid_manager.normalise(row[\"pmid\"], True)\n",
    "                if citing_pmid is not None:\n",
    "                    authors_dicts_list = []\n",
    "                    authors_split_list = row[\"authors\"].split(\",\")\n",
    "                    for author in authors_split_list:\n",
    "                        names = re.findall(\"([A-Z]|[ÄŐŰÀÁÂÄÃÅĄĆČĖĘÈÉÊËÌÍÎÏĮŁŃÒÓÔÖÕØÙÚÛÜŲŪŸÝŻŹÑßÇŒÆČŠŽÑ]){1}\\s\", author)\n",
    "                        strp_names = [(x.strip()).lower() for x in names]\n",
    "                        surnames = re.findall(\n",
    "                        \"[a-zA-Z\\'\\-áéíóúäëïöüÄłŁőŐűŰZàáâäãåąčćęèéêëėįìíîïłńòóôöõøùúûüųūÿýżźñçčšžÀÁÂÄÃÅĄĆČĖĘÈÉÊËÌÍÎÏĮŁŃÒÓÔÖÕØÙÚÛÜŲŪŸÝŻŹÑßÇŒÆČŠŽñÑâê]{2,}\",\n",
    "                        author)\n",
    "                        surnames_l = [s.lower() for s in surnames]\n",
    "                        author_dict = {\"names\":strp_names, \"surnames\":surnames_l}\n",
    "                        authors_dicts_list.append(author_dict)\n",
    "\n",
    "                    if csv_datasource.get(citing_pmid) is None:\n",
    "                        entity = dict()\n",
    "\n",
    "                        entity[\"valid\"] = True\n",
    "\n",
    "                        citing_doi = doi_manager.normalise(row[\"doi\"], False)\n",
    "                        if citing_doi:\n",
    "                            pmid_doi_map[citing_pmid] = {\"doi\": citing_doi, \"has_orcid\": False, \"all_authors_names\": authors_dicts_list}\n",
    "\n",
    "                        citing_date = Citation.check_date(build_pubdate_noci(row))\n",
    "                        if citing_date is not None:\n",
    "                            entity[\"date\"] = [citing_date]\n",
    "\n",
    "                        issn_list = []\n",
    "                        journal_name = row[\"journal\"]\n",
    "                        if journal_name:\n",
    "                            if journal_name in journal_issn_dict.keys():\n",
    "                                for issn in journal_issn_dict[journal_name]:\n",
    "                                    issn_list.append(issn)\n",
    "\n",
    "                            else:\n",
    "                                if citing_doi is not None:\n",
    "                                    json_res = crossref_resource_finder._call_api(citing_doi)\n",
    "                                    if json_res is not None:\n",
    "                                        issn_set = crossref_resource_finder._get_issn(json_res)\n",
    "                                        if len(issn_set) > 0:\n",
    "                                            journal_issn_dict[journal_name] = []\n",
    "                                        for issn in issn_set:\n",
    "                                            issn_norm = issn_manager.normalise(str(issn))\n",
    "                                            issn_list.append(issn_norm)\n",
    "                                            journal_issn_dict[journal_name].append(issn_norm)\n",
    "                        else:\n",
    "                            if citing_doi is not None:\n",
    "                                json_res = crossref_resource_finder._call_api(citing_doi)\n",
    "                                if json_res is not None:\n",
    "                                    issn_set = crossref_resource_finder._get_issn(json_res)\n",
    "                                    for issn in issn_set:\n",
    "                                        issn_norm = issn_manager.normalise(str(issn))\n",
    "                                        issn_list.append(issn_norm)\n",
    "                        if issn_list != []:\n",
    "                            entity[\"issn\"] = issn_list\n",
    "\n",
    "                        csv_datasource.set(citing_pmid, entity)\n",
    "\n",
    "            if len(pmid_doi_map) > 0:\n",
    "                if id_orcid_dir and exists(id_orcid_dir):\n",
    "                    orcid_id_files, op = get_all_files_noci(id_orcid_dir)\n",
    "                    len_orcid_id_files = len(orcid_id_files)\n",
    "                    if len_orcid_id_files > 0:\n",
    "                        for f_idx, f in enumerate(orcid_id_files, 1):\n",
    "                            unzip_file = op(f, mode=\"r\")\n",
    "                            unzip_file = csv.DictReader(\n",
    "                                codecs.iterdecode(unzip_file, \"utf-8\")\n",
    "                            )\n",
    "                            for row in unzip_file:\n",
    "                                if [\n",
    "                                    k\n",
    "                                    for k, v in pmid_doi_map.items()\n",
    "                                    if v[\"doi\"] == row[\"id\"]\n",
    "                                ]:\n",
    "                                    c_pmid = [\n",
    "                                        k\n",
    "                                        for k, v in pmid_doi_map.items()\n",
    "                                        if v[\"doi\"] == row[\"id\"]\n",
    "                                    ][\n",
    "                                        0\n",
    "                                    ]\n",
    "                                    c_doi = doi_manager.normalise(row[\"id\"], False)\n",
    "                                    #DA TESTARE\n",
    "                                    orcid = re.search(\n",
    "                                        \"\\[(([X0-9]\\-?){4}){4}]\",\n",
    "                                        row[\"value\"],\n",
    "                                        re.IGNORECASE,\n",
    "                                    ).group(0)\n",
    "                                    author_name_parts = re.findall(\"[a-zA-Z\\'\\-áéíóúäëïöüÄłŁőŐűŰZàáâäãåąčćęèéêëėįìíîïłńòóôöõøùúûüųūÿýżźñçčšžÀÁÂÄÃÅĄĆČĖĘÈÉÊËÌÍÎÏĮŁŃÒÓÔÖÕØÙÚÛÜŲŪŸÝŻŹÑßÇŒÆČŠŽñÑâê]{2,}\", row[\"value\"])\n",
    "                                    author_name_parts_l = [np.lower() for np in author_name_parts]\n",
    "                                    authors_dicts_list = pmid_doi_map[c_pmid][\"all_authors_names\"]\n",
    "                                    matches = [dict for dict in authors_dicts_list if [sn for sn in dict[\"surnames\"] if sn in author_name_parts_l] and [l for l in dict[\"names\"] if any(element.startswith(l) and element not in dict[\"surnames\"] for element in author_name_parts_l)]]\n",
    "                                    if matches and orcid:\n",
    "                                        nor_orcid = orcid_manager.normalise(orcid)\n",
    "                                        if nor_orcid:\n",
    "                                            c_pmid_entity = csv_datasource.get(c_pmid)\n",
    "                                            if c_pmid_entity[\"orcid\"] is None:\n",
    "                                                c_pmid_entity[\"orcid\"] = []\n",
    "                                                c_pmid_entity[\"orcid\"].append(nor_orcid)\n",
    "                                            else:\n",
    "                                                c_pmid_entity[\"orcid\"] = list(c_pmid_entity[\"orcid\"])\n",
    "                                                c_pmid_entity[\"orcid\"].append(nor_orcid)\n",
    "\n",
    "                                            csv_datasource.set(c_pmid, c_pmid_entity)\n",
    "                                            if pmid_doi_map[c_pmid][\"has_orcid\"] == False:\n",
    "                                                pmid_doi_map[c_pmid][\"has_orcid\"] = True\n",
    "\n",
    "                if orcid_client_id and orcid_client_secret:\n",
    "                    for citing_pmid, d in pmid_doi_map.items():\n",
    "                        if d[\"has_orcid\"] == False:\n",
    "                            json_res = orcid_resource_finder._call_api(d[\"doi\"])\n",
    "                            if json_res is not None and len(json_res)> 0:\n",
    "                                # To do: check if absence of result with orcid resource finder\n",
    "                                # implies absence of result also with access token\n",
    "                                certified_orcid = []\n",
    "                                for orcid_dict in json_res:\n",
    "                                    json_uri = orcid_dict[\"orcid-identifier\"][\"uri\"]\n",
    "                                    chek_passed = check_author_identity_api(json_uri, d[\"all_authors_names\"], orcid_client_id, orcid_client_secret)\n",
    "                                    norm_orc = orcid_manager.normalise(json_uri)\n",
    "                                    if chek_passed and norm_orc:\n",
    "                                        certified_orcid.append(norm_orc)\n",
    "\n",
    "                                citing_pmid_dict = csv_datasource.get(citing_pmid)\n",
    "\n",
    "                                if len(certified_orcid) > 0:\n",
    "                                    d[\"has_orcid\"] = True\n",
    "                                    if citing_pmid_dict[\"orcid\"] is None:\n",
    "                                        citing_pmid_dict[\"orcid\"] = certified_orcid\n",
    "                                    else:\n",
    "                                        citing_pmid_dict[\"orcid\"].extend(certified_orcid)\n",
    "                                    csv_datasource.set(citing_pmid,citing_pmid_dict)\n",
    "\n",
    "\n",
    "            pmid_doi_map = dict()\n",
    "            issn_data_to_cache_noci(journal_issn_dict, output_dir)\n",
    "\n",
    "    middle = timer()\n",
    "\n",
    "    # print(\"first process duration: :\", (middle - start))\n",
    "    # print(\"\\n\\n# Checking the referenced pmids validity\")\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        for chunk in pd.read_csv(file, chunksize=1000):\n",
    "            f = pd.concat([df, chunk], ignore_index=True)\n",
    "            f.fillna(\"\", inplace=True)\n",
    "            # print(\"Open file %s of %s\" % (file_idx, len_all_files))\n",
    "            for index, row in f.iterrows():\n",
    "                if row[\"references\"] != \"\":\n",
    "                    ref_string = row[\"references\"].strip()\n",
    "                    ref_string_norm = re.sub(\"\\s+\", \" \", ref_string)\n",
    "                    cited_pmids = set(ref_string_norm.split(\" \"))\n",
    "                    for cited_pmid in cited_pmids:\n",
    "                        cited_pmid = pmid_manager.normalise(cited_pmid, True)\n",
    "\n",
    "                        if cited_pmid is not None:\n",
    "                            cited_pmid_entity = csv_datasource.get(cited_pmid)\n",
    "                            if cited_pmid_entity is None:\n",
    "                                cited_pmid_entity = dict()\n",
    "                                cited_pmid_entity[\"valid\"] = (True if pmid_manager.is_valid(cited_pmid) else False)\n",
    "                                csv_datasource.set(cited_pmid, cited_pmid_entity)\n",
    "\n",
    "                if row[\"cited_by\"] != \"\":\n",
    "                    citing_string = row[\"cited_by\"].strip()\n",
    "                    citing_string_norm = re.sub(\"\\s+\", \" \", citing_string)\n",
    "                    citing_pmids = set(citing_string_norm.split(\" \"))\n",
    "                    for citing_p in citing_pmids:\n",
    "                        citing_p = pmid_manager.normalise(citing_p, True)\n",
    "                        if citing_p is not None:\n",
    "                            citing_p_entity = csv_datasource.get(citing_p)\n",
    "                            if citing_p_entity is None:\n",
    "                                citing_p_entity = dict()\n",
    "                                citing_p_entity[\"valid\"] = (True if pmid_manager.is_valid(citing_p) else False)\n",
    "                                csv_datasource.set(citing_p, citing_p_entity)\n",
    "\n",
    "    end = timer()\n",
    "    # print(\"second process duration: \", end-middle)\n",
    "    # print(\"full process duration: \", end-start)\n",
    "\n",
    "\n",
    "def main():\n",
    "    arg_parser = ArgumentParser(\n",
    "        \"Global files creator for NOCI\",\n",
    "        description=\"Process iCiteMetadata CSV files and create global indexes to enable the creation of NOCI.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-i\",\n",
    "        \"--input\",\n",
    "        dest=\"input\",\n",
    "        required=True,\n",
    "        help=\"Either the directory or the zip file that contains the iCiteMetadata data dump of CSV files.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-o\",\n",
    "        \"--output\",\n",
    "        dest=\"output\",\n",
    "        required=True,\n",
    "        help=\"The directory where the indexes are stored.\",\n",
    "    )\n",
    "\n",
    "    arg_parser.add_argument(\n",
    "        \"-n\",\n",
    "        \"--entities\",\n",
    "        dest=\"entities\",\n",
    "        required=True,\n",
    "        help=\"Interval of processed entities after which the issn data are saved to the cache file.\",\n",
    "    )\n",
    "\n",
    "    arg_parser.add_argument(\n",
    "        \"-iod\",\n",
    "        \"--orcid\",\n",
    "        dest=\"orcid\",\n",
    "        required=False,\n",
    "        help=\"Either the directory or the zip file that contains the id-orcid mapping data.\",\n",
    "    )\n",
    "\n",
    "    arg_parser.add_argument(\n",
    "        \"-oci\",\n",
    "        \"--orcid_client_id\",\n",
    "        dest=\"orcid_client_id\",\n",
    "        required=False,\n",
    "        help=\"ORCID credentials: orcid client ID, to double check that the identity of the authors declared in NIH \"\n",
    "             \"dump corresponds to the ORCID registry data. The credentials are required to obtain the token, which is\"\n",
    "             \"required in order to access ORCID public API. Client ID and Client secret can be required in the \"\n",
    "             \"Developer tools section of the ORCID platform.\",\n",
    "    )\n",
    "\n",
    "    arg_parser.add_argument(\n",
    "        \"-ocs\",\n",
    "        \"--orcid_client_secret\",\n",
    "        dest=\"orcid_client_secret\",\n",
    "        required=False,\n",
    "        help=\"ORCID credentials: orcid password, to double check that the identity of the authors declared in NIH \"\n",
    "             \"dump corresponds to the ORCID registry data. The credentials are required to obtain the token, which is\"\n",
    "             \"required in order to access ORCID public API. Client ID and Client secret can be required in the \"\n",
    "             \"Developer tools section of the ORCID platform.\",\n",
    "    )\n",
    "\n",
    "    args = arg_parser.parse_args()\n",
    "    process_noci(args.input, args.output, args.entities, args.orcid, args.orcid_client_id, args.orcid_client_secret)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# python \"scripts/glob_noci.py\" -i ./index/python/test/data/noci_glob_dump_input -o ./index/python/test/data/noci_glob_dump_output -n 7 -iod ./index/python/test/data/noci_id_orcid_mapping/doi_orcid_index.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CROSSREF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from os import sep, makedirs, walk\n",
    "from os.path import exists, basename, isdir\n",
    "from json import load, loads\n",
    "from collections import Counter\n",
    "from datetime import date\n",
    "from timeit import default_timer as timer\n",
    "from re import sub\n",
    "import tarfile\n",
    "\n",
    "\n",
    "from oc.index.oci.citation import Citation\n",
    "from oc.index.identifier.doi import DOIManager\n",
    "from oc.index.identifier.issn import ISSNManager\n",
    "from oc.index.identifier.orcid import ORCIDManager\n",
    "from oc.index.glob.csv import CSVDataSource\n",
    "\n",
    "\n",
    "\n",
    "def build_pubdate_coci(obj):\n",
    "    if \"issued\" in obj:  # Main citing object\n",
    "        if \"date-parts\" in obj[\"issued\"]:\n",
    "            # is an array of parts of dates\n",
    "            try:\n",
    "                obj_date = obj[\"issued\"][\"date-parts\"][0]\n",
    "\n",
    "                # lisdate[year,month,day]\n",
    "                listdate = [1, 1, 1]\n",
    "                dateparts = []\n",
    "                for i in range(0, len(obj_date)):\n",
    "                    try:\n",
    "                        dateparts.append(obj_date[i])\n",
    "                        intvalue = int(obj_date[i])\n",
    "                        listdate[i] = intvalue\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                # there is a date, so generate it\n",
    "                if (\n",
    "                    (1 < listdate[0] < 3000)\n",
    "                    and (0 < listdate[1] <= 12)\n",
    "                    and (0 < listdate[2] <= 31)\n",
    "                ):\n",
    "                    date_val = date(listdate[0], listdate[1], listdate[2])\n",
    "                    dformat = \"%Y\"\n",
    "\n",
    "                    # only month is specified\n",
    "                    if len(dateparts) == 2:\n",
    "                        dformat = \"%Y-%m\"\n",
    "                    elif len(dateparts) == 3 and (\n",
    "                        dateparts[1] != 1 or (dateparts[1] == 1 and dateparts[2] != 1)\n",
    "                    ):\n",
    "                        dformat = \"%Y-%m-%d\"\n",
    "\n",
    "                    date_in_str = date_val.strftime(dformat)\n",
    "                    return date_in_str\n",
    "            except:\n",
    "                pass\n",
    "    elif \"year\" in obj:  # Reference object\n",
    "        ref_year = sub(\"[^\\d]\", \"\", obj[\"year\"])[:4]\n",
    "        if ref_year:\n",
    "            return ref_year\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_all_files_coci(i_dir_or_targz_file):\n",
    "    result = []\n",
    "    targz_fd = None\n",
    "\n",
    "    if isdir(i_dir_or_targz_file):\n",
    "        for cur_dir, cur_subdir, cur_files in walk(i_dir_or_targz_file):\n",
    "            for cur_file in cur_files:\n",
    "                if cur_file.endswith(\".json\") and not basename(cur_file).startswith(\n",
    "                    \".\"\n",
    "                ):\n",
    "                    result.append(cur_dir + sep + cur_file)\n",
    "    elif i_dir_or_targz_file.endswith(\"tar.gz\"):\n",
    "        targz_fd = tarfile.open(i_dir_or_targz_file, \"r:gz\", encoding=\"utf-8\")\n",
    "        for cur_file in targz_fd:\n",
    "            if cur_file.name.endswith(\".json\") and not basename(\n",
    "                cur_file.name\n",
    "            ).startswith(\".\"):\n",
    "                result.append(cur_file)\n",
    "    else:\n",
    "        print(\"It is not possible to process the input path.\")\n",
    "    return result, targz_fd\n",
    "\n",
    "\n",
    "def load_json_coci(file, targz_fd, file_idx, len_all_files):\n",
    "    result = None\n",
    "\n",
    "    if targz_fd is None:\n",
    "        # print(\"Open file %s of %s\" % (file_idx, len_all_files))\n",
    "        with open(file, encoding=\"utf8\") as f:\n",
    "            result = load(f)\n",
    "    else:\n",
    "        # print(\"Open file %s of %s (in tar.gz archive)\" % (file_idx, len_all_files))\n",
    "        cur_tar_file = targz_fd.extractfile(file)\n",
    "        json_str = cur_tar_file.read()\n",
    "\n",
    "        # In Python 3.5 it seems that, for some reason, the extractfile method returns an\n",
    "        # object 'bytes' that cannot be managed by the function 'load' in the json package.\n",
    "        # Thus, to avoid issues, in case an object having type 'bytes' is return, it is\n",
    "        # transformed as a string before passing it to the function 'loads'. Please note\n",
    "        # that Python 3.9 does not show this behaviour, and it works correctly without\n",
    "        # any transformation.\n",
    "        if type(json_str) is bytes:\n",
    "            json_str = json_str.decode(\"utf-8\")\n",
    "\n",
    "        result = loads(json_str)\n",
    "    return result\n",
    "\n",
    "\n",
    "def process_coci(input_dir, output_dir):\n",
    "    start = timer()\n",
    "    if not exists(output_dir):\n",
    "        makedirs(output_dir)\n",
    "\n",
    "    doi_manager = DOIManager()\n",
    "    issn_manager = ISSNManager()\n",
    "    orcid_manager = ORCIDManager()\n",
    "    csv_datasource = CSVDataSource(\"COCI\")\n",
    "\n",
    "    all_files, targz_fd = get_all_files_coci(input_dir)\n",
    "    len_all_files = len(all_files)\n",
    "\n",
    "    # Read all the JSON file in the Crossref dump to create the main information of all the indexes\n",
    "    # print(\"\\n\\n# Add valid DOIs from Crossref metadata\")\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        data = load_json_coci(file, targz_fd, file_idx, len_all_files)\n",
    "\n",
    "        if \"items\" in data:\n",
    "            for obj in data[\"items\"]:\n",
    "                if \"DOI\" in obj:\n",
    "                    citing_doi = doi_manager.normalise(obj[\"DOI\"], True)\n",
    "                    if citing_doi is not None:\n",
    "                        entity = csv_datasource.get(citing_doi)\n",
    "                        if entity is None:\n",
    "                            entity = dict()\n",
    "                            entity[\"valid\"] = True\n",
    "\n",
    "                            citing_date = Citation.check_date(build_pubdate_coci(obj))\n",
    "                            if citing_date is not None:\n",
    "                                entity[\"date\"] = [citing_date]\n",
    "\n",
    "                            valid_issn_list = []\n",
    "                            if \"type\" in obj:\n",
    "                                cur_type = obj[\"type\"]\n",
    "                                if (\n",
    "                                    cur_type is not None\n",
    "                                    and \"journal\" in cur_type\n",
    "                                    and \"ISSN\" in obj\n",
    "                                ):\n",
    "                                    cur_issn = obj[\"ISSN\"]\n",
    "                                    if cur_issn is not None:\n",
    "                                        for issn in [\n",
    "                                            issn_manager.normalise(issn)\n",
    "                                            for issn in cur_issn\n",
    "                                        ]:\n",
    "                                            if issn is not None:\n",
    "                                                valid_issn_list.append(issn)\n",
    "\n",
    "                            if len(valid_issn_list) > 0:\n",
    "                                entity[\"issn\"] = valid_issn_list\n",
    "\n",
    "                            orcid_list = []\n",
    "                            if \"author\" in obj:\n",
    "                                cur_author = obj[\"author\"]\n",
    "                                if cur_author is not None:\n",
    "                                    for author in cur_author:\n",
    "                                        if \"ORCID\" in author:\n",
    "                                            orcid = orcid_manager.normalise(author[\"ORCID\"])\n",
    "                                            if orcid is not None:\n",
    "                                                orcid_list.append(orcid)\n",
    "                            if len(orcid_list) > 0 :\n",
    "                                entity[\"orcid\"] = orcid_list\n",
    "                            csv_datasource.set(citing_doi, entity)\n",
    "\n",
    "    middle = timer()\n",
    "    # print(\"first process duration: :\", (middle - start))\n",
    "    # Do it again for updating the dates of the cited DOIs, if these are valid\n",
    "    # print(\"\\n\\n# Check cited DOIs from Crossref reference field\")\n",
    "    doi_date = {}\n",
    "    entity_with_date_to_updete = {}\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        data = load_json_coci(file, targz_fd, file_idx, len_all_files)\n",
    "\n",
    "        if \"items\" in data:\n",
    "            for obj in data[\"items\"]:\n",
    "                if \"DOI\" in obj and \"reference\" in obj:\n",
    "                    for ref in obj[\"reference\"]:\n",
    "                        if \"DOI\" in ref:\n",
    "                            cited_doi = str(doi_manager.normalise(ref[\"DOI\"], True))\n",
    "                            if cited_doi is not None:\n",
    "                                cited_doi_entity = csv_datasource.get(cited_doi)\n",
    "                                if cited_doi_entity is None:\n",
    "                                    cited_doi_entity = dict()\n",
    "                                    cited_doi_entity[\"valid\"] = (True if doi_manager.is_valid(cited_doi) else False)\n",
    "\n",
    "                                if cited_doi_entity[\"valid\"] is True and \"date\" not in cited_doi_entity.keys():\n",
    "                                    if cited_doi not in doi_date:\n",
    "                                        doi_date[cited_doi] = []\n",
    "                                    cited_date = Citation.check_date(build_pubdate_coci(ref))\n",
    "                                    if cited_date is not None:\n",
    "                                        doi_date[cited_doi].append(cited_date)\n",
    "\n",
    "                                if cited_doi in doi_date:\n",
    "                                    if len(doi_date[cited_doi]) > 0:\n",
    "                                        entity_with_date_to_updete[cited_doi] = cited_doi_entity\n",
    "                                    else:\n",
    "                                        csv_datasource.set(cited_doi, cited_doi_entity)\n",
    "                                else:\n",
    "                                    csv_datasource.set(cited_doi, cited_doi_entity)\n",
    "\n",
    "    # Add the date to the DOI if such date is the most adopted one in the various references.\n",
    "    # In case two distinct dates are used the most, select the older one.\n",
    "    for doi in doi_date:\n",
    "        if doi in entity_with_date_to_updete.keys():\n",
    "            count = Counter(doi_date[doi])\n",
    "            if len(count):\n",
    "                top_value = count.most_common(1)[0][1]\n",
    "                selected_dates = []\n",
    "                for date in count:\n",
    "                    if count[date] == top_value:\n",
    "                        selected_dates.append(date)\n",
    "                best_date = sorted(selected_dates)[0]\n",
    "                doi_entity_for_date_update = entity_with_date_to_updete[doi]\n",
    "                doi_entity_for_date_update[\"date\"] = [best_date]\n",
    "                csv_datasource.set(doi, doi_entity_for_date_update)\n",
    "            else:\n",
    "                doi_entity_for_date_update = entity_with_date_to_updete[doi]\n",
    "                csv_datasource.set(doi, doi_entity_for_date_update)\n",
    "\n",
    "\n",
    "\n",
    "    # Close the file descriptor of the tar.gz archive if it was used\n",
    "    if targz_fd is not None:\n",
    "        targz_fd.close()\n",
    "\n",
    "    end = timer()\n",
    "    # print(\"second process duration: \", end-middle)\n",
    "    # print(\"full process duration: \", end-start)\n",
    "\n",
    "\n",
    "def main():\n",
    "    arg_parser = ArgumentParser(\n",
    "        \"Global files creator for COCI\",\n",
    "        description=\"Process Crossref JSON files and create global indexes to enable \"\n",
    "        \"the creation of COCI.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-i\",\n",
    "        \"--input\",\n",
    "        dest=\"input\",\n",
    "        required=True,\n",
    "        help=\"Either the directory or the zip file that contains the Crossref data dump \"\n",
    "        \"of JSON files.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-o\",\n",
    "        \"--output\",\n",
    "        dest=\"output\",\n",
    "        required=True,\n",
    "        help=\"The directory where the indexes are stored.\",\n",
    "    )\n",
    "\n",
    "    args = arg_parser.parse_args()\n",
    "    process_coci(args.input, args.output)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# python \"scripts/glob_crossref.py\" -i ./index/python/test/data/crossref_glob_dump_input -o ./index/python/test/data/crossref_glob_dump_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATACITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "import os\n",
    "from os import sep, makedirs, walk\n",
    "from os.path import exists, basename, isdir\n",
    "from json import load, loads\n",
    "import datetime\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import tarfile\n",
    "\n",
    "#from oc.index.legacy.csv import CSVManager\n",
    "from oc.index.identifier.doi import DOIManager\n",
    "from oc.index.identifier.issn import ISSNManager\n",
    "from oc.index.identifier.orcid import ORCIDManager\n",
    "from oc.index.glob.csv import CSVDataSource\n",
    "\n",
    "\n",
    "def issn_data_recover_doci(directory):\n",
    "    journal_issn_dict = dict()\n",
    "    filename = directory + sep + \"journal_issn.json\"\n",
    "    if not os.path.exists(filename):\n",
    "        return journal_issn_dict\n",
    "    else:\n",
    "        with open(filename, \"r\", encoding=\"utf8\") as fd:\n",
    "            journal_issn_dict = json.load(fd)\n",
    "            types = type(journal_issn_dict)\n",
    "            return journal_issn_dict\n",
    "\n",
    "\n",
    "def issn_data_to_cache_doci(name_issn_dict, directory):\n",
    "    filename = directory + sep + \"journal_issn.json\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as fd:\n",
    "        json.dump(name_issn_dict, fd, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "def get_all_files_doci(i_dir_or_targz_file):\n",
    "    result = []\n",
    "    targz_fd = None\n",
    "\n",
    "    if isdir(i_dir_or_targz_file):\n",
    "        for cur_dir, cur_subdir, cur_files in walk(i_dir_or_targz_file):\n",
    "            for cur_file in cur_files:\n",
    "                if cur_file.endswith(\".json\") and not basename(cur_file).startswith(\n",
    "                    \".\"\n",
    "                ):\n",
    "                    result.append(cur_dir + sep + cur_file)\n",
    "    elif i_dir_or_targz_file.endswith(\"tar.gz\"):\n",
    "        targz_fd = tarfile.open(i_dir_or_targz_file, \"r:gz\", encoding=\"utf-8\")\n",
    "        for cur_file in targz_fd:\n",
    "            if cur_file.name.endswith(\".json\") and not basename(\n",
    "                cur_file.name\n",
    "            ).startswith(\".\"):\n",
    "                result.append(cur_file)\n",
    "    else:\n",
    "        print(\"It is not possible to process the input path.\")\n",
    "    return result, targz_fd\n",
    "\n",
    "\n",
    "def valid_date_doci(date_text):\n",
    "    date_text = str(date_text)\n",
    "    try:\n",
    "        return datetime.datetime.strptime(date_text, \"%Y-%m-%d\").strftime(\"%Y-%m-%d\")\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return datetime.datetime.strptime(date_text, \"%Y-%m\").strftime(\"%Y-%m\")\n",
    "        except ValueError:\n",
    "            try:\n",
    "                return datetime.datetime.strptime(date_text, \"%Y\").strftime(\"%Y\")\n",
    "            except ValueError:\n",
    "                if \"-\" in date_text:\n",
    "                    possibiliDate = date_text.split(\"-\")\n",
    "                    while possibiliDate:\n",
    "                        possibiliDate.pop()\n",
    "                        seperator = \"-\"\n",
    "                        data = seperator.join(possibiliDate)\n",
    "                        try:\n",
    "                            return datetime.datetime.strptime(\n",
    "                                data, \"%Y-%m-%d\"\n",
    "                            ).strftime(\"%Y-%m-%d\")\n",
    "                        except ValueError:\n",
    "                            try:\n",
    "                                return datetime.datetime.strptime(\n",
    "                                    data, \"%Y-%m\"\n",
    "                                ).strftime(\"%Y-%m\")\n",
    "                            except ValueError:\n",
    "                                try:\n",
    "                                    return datetime.datetime.strptime(\n",
    "                                        data, \"%Y\"\n",
    "                                    ).strftime(\"%Y\")\n",
    "                                except ValueError:\n",
    "                                    pass\n",
    "\n",
    "\n",
    "def load_json_doci(file, targz_fd, file_idx, len_all_files):\n",
    "    result = None\n",
    "\n",
    "    if targz_fd is None:\n",
    "        # print(\"Open file %s of %s\" % (file_idx, len_all_files))\n",
    "        with open(file, encoding=\"utf8\") as f:\n",
    "            result = load(f)\n",
    "    else:\n",
    "        # print(\"Open file %s of %s (in tar.gz archive)\" % (file_idx, len_all_files))\n",
    "        cur_tar_file = targz_fd.extractfile(file)\n",
    "        json_str = cur_tar_file.read()\n",
    "        # In Python 3.5 it seems that, for some reason, the extractfile method returns an\n",
    "        # object 'bytes' that cannot be managed by the function 'load' in the json package.\n",
    "        # Thus, to avoid issues, in case an object having type 'bytes' is return, it is\n",
    "        # transformed as a string before passing it to the function 'loads'. Please note\n",
    "        # that Python 3.9 does not show this behaviour, and it works correctly without\n",
    "        # any transformation.\n",
    "        if type(json_str) is bytes:\n",
    "            json_str = json_str.decode(\"utf-8\")\n",
    "\n",
    "        result = loads(json_str)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def process_doci(input_dir, output_dir, n):\n",
    "    start = timer()\n",
    "    if not exists(output_dir):\n",
    "        makedirs(output_dir)\n",
    "\n",
    "    # valid_doi = CSVManager(output_dir + sep + \"valid_doi.csv\")\n",
    "    # id_date = CSVManager(output_dir + sep + \"id_date.csv\")\n",
    "    # id_issn = CSVManager(output_dir + sep + \"id_issn.csv\")\n",
    "    # id_orcid = CSVManager(output_dir + sep + \"id_orcid.csv\")\n",
    "\n",
    "    journal_issn_dict = issn_data_recover_doci(output_dir)\n",
    "\n",
    "    doi_manager = DOIManager()\n",
    "    issn_manager = ISSNManager()\n",
    "    orcid_manager = ORCIDManager()\n",
    "    csv_datasource = CSVDataSource(\"DOCI\")\n",
    "\n",
    "    all_files, targz_fd = get_all_files_doci(input_dir)\n",
    "    len_all_files = len(all_files)\n",
    "    issnDict = {}\n",
    "    relevant_relations = [\"references\", \"isreferencedby\", \"cites\", \"iscitedby\"]\n",
    "\n",
    "    count = 0\n",
    "    # Read all the JSON files in the DataCite dump to create the main information of all the indexes\n",
    "    # print(\"\\n\\n# Add valid DOIs from DataCite metadata\")\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        data = load_json_doci(file, targz_fd, file_idx, len_all_files)\n",
    "        if \"data\" in data:\n",
    "            data_list = data[\"data\"]\n",
    "            for item in tqdm(data_list):\n",
    "                count += 1\n",
    "                attributes = item[\"attributes\"]\n",
    "                citing_doi = attributes[\"doi\"]\n",
    "                relatedIdentifiers = attributes[\"relatedIdentifiers\"]\n",
    "                citing_doi = doi_manager.normalise(citing_doi, True)\n",
    "                # valid_doi.add_value(citing_doi, \"v\" if doi_manager.is_valid(citing_doi) else \"i\")\n",
    "                if citing_doi is not None:\n",
    "                    entity = csv_datasource.get(citing_doi)\n",
    "                    if entity is None:\n",
    "                        entity = dict()\n",
    "                        entity[\"valid\"] = True\n",
    "\n",
    "                    # collect the date of issue if there is, otherwise the year of publcation\n",
    "                    citing_date = []\n",
    "                    listDates = attributes[\"dates\"]\n",
    "                    publicationYear = attributes[\"publicationYear\"]\n",
    "\n",
    "                    if listDates != []:\n",
    "                        if [\n",
    "                            data\n",
    "                            for data in listDates\n",
    "                            if str(data[\"dateType\"]).lower() == \"issued\"\n",
    "                        ]:\n",
    "                            issue_dates = [\n",
    "                                data\n",
    "                                for data in listDates\n",
    "                                if str(data[\"dateType\"]).lower() == \"issued\"\n",
    "                            ]\n",
    "                            if [\n",
    "                                iss_date\n",
    "                                for iss_date in issue_dates\n",
    "                                if valid_date_doci(str(iss_date[\"date\"]))\n",
    "                            ]:\n",
    "                                flt_issue_dates = [\n",
    "                                    iss_date\n",
    "                                    for iss_date in issue_dates\n",
    "                                    if valid_date_doci(str(iss_date[\"date\"]))\n",
    "                                ]\n",
    "                                for flt_iss_date in flt_issue_dates:\n",
    "                                    citing_date.append(\n",
    "                                        valid_date_doci(str(flt_iss_date[\"date\"])),\n",
    "                                    )\n",
    "                                    break\n",
    "\n",
    "                            # listDates exists and at least one of its element has \"issued\" in \"dateType\"\n",
    "                            # but none of the dates in listDates has a valid date in \"date\"\n",
    "                            elif publicationYear:\n",
    "                                publicationYear = valid_date_doci(str(publicationYear))\n",
    "                                if publicationYear:\n",
    "                                    citing_date.append(publicationYear)\n",
    "\n",
    "                        # listDates exists but none of its elements has \"issued\" in \"dateType\"\n",
    "                        elif publicationYear:\n",
    "                            publicationYear = valid_date_doci(str(publicationYear))\n",
    "                            if publicationYear:\n",
    "                                citing_date.append(publicationYear)\n",
    "\n",
    "                    # listDates is an empty list: no dates in listDates\n",
    "                    elif publicationYear:\n",
    "                        publicationYear = valid_date_doci(str(publicationYear))\n",
    "                        if publicationYear:\n",
    "                            citing_date.append(publicationYear)\n",
    "\n",
    "                    if len(citing_date) > 0:\n",
    "                        entity[\"date\"] = citing_date\n",
    "\n",
    "                    # collect the orcid of the contributors\n",
    "                    orcid_list = []\n",
    "                    contributorList = attributes[\"creators\"]\n",
    "                    if contributorList != []:\n",
    "                        for author in contributorList:\n",
    "                            if \"nameIdentifiers\" in author.keys():\n",
    "                                infoAuthor = author[\"nameIdentifiers\"]\n",
    "                                for element in infoAuthor:\n",
    "                                    if (\n",
    "                                        \"nameIdentifier\" in element.keys()\n",
    "                                        and \"nameIdentifierScheme\" in element.keys()\n",
    "                                    ):\n",
    "                                        if (\n",
    "                                            element[\"nameIdentifierScheme\"]\n",
    "                                        ).lower() == \"orcid\":\n",
    "                                            orcid = element[\"nameIdentifier\"]\n",
    "                                            if orcid is not None and orcid != \"\":\n",
    "                                                orcid = orcid_manager.normalise(orcid)\n",
    "                                                if orcid_manager.is_valid(orcid):\n",
    "                                                    orcid_list.append(orcid)\n",
    "                    if len(orcid_list)>0:\n",
    "                        entity[\"orcid\"] = orcid_list\n",
    "\n",
    "                    issn_set = set()\n",
    "                    valid_issn_list = []\n",
    "                    if relatedIdentifiers != []:\n",
    "                        for related in relatedIdentifiers:\n",
    "                            if \"relationType\" in related.keys():\n",
    "                                relationType = related[\"relationType\"]\n",
    "                                if relationType.lower() == \"ispartof\":\n",
    "                                    if \"relatedIdentifierType\" in related.keys():\n",
    "                                        relatedIdentifierType = (\n",
    "                                            str(related[\"relatedIdentifierType\"])\n",
    "                                        ).lower()\n",
    "                                        if relatedIdentifierType == \"issn\":\n",
    "                                            if \"relatedIdentifier\" in related.keys():\n",
    "                                                relatedISSN = str(\n",
    "                                                    related[\"relatedIdentifier\"]\n",
    "                                                )\n",
    "                                                if relatedISSN:\n",
    "                                                    issn_set.add(relatedISSN)\n",
    "\n",
    "                    container = attributes[\"container\"]\n",
    "                    if (\n",
    "                        \"identifier\" in container.keys()\n",
    "                        and \"identifierType\" in container.keys()\n",
    "                    ):\n",
    "                        if (\n",
    "                            container[\"identifier\"] != \"\"\n",
    "                            and (container[\"identifierType\"]).lower() == \"issn\"\n",
    "                        ):\n",
    "                            cont_issn = container[\"identifier\"]\n",
    "                            issn_set.add(cont_issn)\n",
    "                            if \"title\" in container.keys():\n",
    "                                journal_title = (container[\"title\"]).lower()\n",
    "                                if journal_title in issnDict.keys():\n",
    "                                    issnList = issnDict[journal_title]\n",
    "                                    if issnList != []:\n",
    "                                        if [\n",
    "                                            el for el in issnList if el not in issn_set\n",
    "                                        ]:\n",
    "                                            issn_set.update(set(issnList))\n",
    "                                            issnDict[journal_title] = list(issn_set)\n",
    "                                    else:\n",
    "                                        issnDict[journal_title] = list(issn_set)\n",
    "                                else:\n",
    "                                    issnDict[journal_title] = list(issn_set)\n",
    "\n",
    "                    normalised_issn_set = set()\n",
    "                    for issn in issn_set:\n",
    "                        norm_issn = issn_manager.normalise(issn)\n",
    "                        normalised_issn_set.add(norm_issn)\n",
    "                    for issn in normalised_issn_set:\n",
    "                        if issn_manager.is_valid(issn):\n",
    "                            valid_issn_list.append(issn)\n",
    "\n",
    "                    if len(valid_issn_list) >0:\n",
    "                        entity[\"issn\"] = valid_issn_list\n",
    "\n",
    "                    csv_datasource.set(citing_doi, entity)\n",
    "\n",
    "                    if int(count) != 0 and int(count) % int(n) == 0:\n",
    "                        issn_data_to_cache_doci(issnDict, output_dir)\n",
    "\n",
    "    issn_data_to_cache_doci(issnDict, output_dir)\n",
    "    middle = timer()\n",
    "    # print(\"first process duration: :\", (middle - start))\n",
    "\n",
    "    cited_dois = 0\n",
    "    count = 0\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        data = load_json_doci(file, targz_fd, file_idx, len_all_files)\n",
    "        if \"data\" in data:\n",
    "            data_list = data[\"data\"]\n",
    "            for item in tqdm(data_list):\n",
    "                count += 1\n",
    "                # print(\"processing entity n.\", count, \"for cited dois\")\n",
    "                attributes = item[\"attributes\"]\n",
    "                relatedIdentifiers = attributes[\"relatedIdentifiers\"]\n",
    "                if relatedIdentifiers != []:\n",
    "                    for related in relatedIdentifiers:\n",
    "                        relationType = related[\"relationType\"]\n",
    "                        if relationType:\n",
    "                            if relationType.lower() in relevant_relations:\n",
    "                                if \"relatedIdentifierType\" in related.keys():\n",
    "                                    relatedIdentifierType = (\n",
    "                                        str(related[\"relatedIdentifierType\"])\n",
    "                                    ).lower()\n",
    "                                    if relatedIdentifierType == \"doi\":\n",
    "                                        if \"relatedIdentifier\" in related.keys():\n",
    "                                            relatedDOI = doi_manager.normalise(\n",
    "                                                related[\"relatedIdentifier\"], True\n",
    "                                            )\n",
    "                                            if relatedDOI is not None:\n",
    "                                                relatedDOI_entity = csv_datasource.get(relatedDOI)\n",
    "                                                if relatedDOI_entity is None:\n",
    "                                                    relatedDOI_entity = dict()\n",
    "                                                    relatedDOI_entity[\"valid\"] = (True if doi_manager.is_valid(relatedDOI) else False)\n",
    "                                                    cited_dois += 1\n",
    "                                                    csv_datasource.set(relatedDOI, relatedDOI_entity)\n",
    "\n",
    "\n",
    "    end = timer()\n",
    "    # print(\"second process duration: \", end-middle)\n",
    "    # print(\"full process duration: \", end-start)\n",
    "\n",
    "\n",
    "def main():\n",
    "    arg_parser = ArgumentParser(\n",
    "        \"Global files creator for DOCI\",\n",
    "        description=\"Process DataCite JSON files and create global indexes to enable \"\n",
    "        \"the creation of DOCI.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-i\",\n",
    "        \"--input\",\n",
    "        dest=\"input\",\n",
    "        required=True,\n",
    "        help=\"Either the directory or the zip file that contains the DataCite data dump \"\n",
    "        \"of JSON files.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-o\",\n",
    "        \"--output\",\n",
    "        dest=\"output\",\n",
    "        required=True,\n",
    "        help=\"The directory where the indexes are stored.\",\n",
    "    )\n",
    "\n",
    "    arg_parser.add_argument(\n",
    "        \"-n\",\n",
    "        \"--num_entities\",\n",
    "        dest=\"num_entities\",\n",
    "        required=True,\n",
    "        help=\"Interval of processed entities after which the issn data are saved to cache files.\",\n",
    "    )\n",
    "\n",
    "    args = arg_parser.parse_args()\n",
    "    process_doci(args.input, args.output, args.num_entities)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# python \"scripts/glob_doci.py\" -i ./index/python/test/data/doci_glob_dump_input -o ./index/python/test/data/doci_glob_dump_output -n 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### config.ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[identifier]\n",
    "pmid=oc.index.identifier.pmid:PMIDManager\n",
    "doi=oc.index.identifier.doi:DOIManager\n",
    "\n",
    "[logging]\n",
    "# If set to 1 the logs will be printed in console, by default \n",
    "# they are only saved in ~/.opencitations/index/logs\n",
    "verbose=1\n",
    "\n",
    "# Redis data source info\n",
    "[redis]\n",
    "host=127.0.0.1\n",
    "port=6379\n",
    "batch_size=10000\n",
    "db=0\n",
    "\n",
    "[cnc]\n",
    "# ORCID API key to be used to query the ORCID API\n",
    "orcid=\n",
    "# Lookup table for oci encoding\n",
    "lookup=~/.opencitations/index/lookup.csv\n",
    "# True whenever you want to use the api in the resource finder\n",
    "use_api=true\n",
    "# Comma seperated available services\n",
    "services=COCI,NOCI,CROCI,DOCI\n",
    "# Available identifiers type\n",
    "identifiers=doi,pmid\n",
    "\n",
    "[CNC_SERVICE_TEMPLATE]\n",
    "# Prefix to use for creating the OCIs\n",
    "prefix=\n",
    "# Parser to use for reading citation data. It should be a class extending \n",
    "# oc.index.parsing.base.CitationParser the format accepted is package:class\n",
    "parser=\n",
    "# The URL of the source from where the citation data have been extracted\n",
    "source=\n",
    "# The URL of the agent providing or processing the citation data\n",
    "agent=\n",
    "# The base URL of the dataset\n",
    "baseurl=\n",
    "# The base URL of the identifier of citing and cited entities, if any\n",
    "idbaseurl=\n",
    "# The name of the service that will made available the  citation data.\n",
    "service=\n",
    "# The type of datasource to use. The available datasources are csv and redis\n",
    "datasource=\n",
    "# The identifier used for cited and citing\n",
    "identifier=\n",
    "\n",
    "[COCI]\n",
    "prefix=020\n",
    "parser=oc.index.parsing.crossref:CrossrefParser\n",
    "validator=oc.index.validate.crossref:CrossrefValidator\n",
    "source=https://api.crossref.org/works/[[citing]]\n",
    "agent=https://w3id.org/oc/index/prov/pa/1\n",
    "baseurl=https://w3id.org/oc/index/coci/\n",
    "idbaseurl=http://dx.doi.org/\n",
    "service=OpenCitations Index: COCI\n",
    "datasource=redis\n",
    "identifier=doi\n",
    "# Legacy CSV Usage\n",
    "valid_id=/Users/ariannamorettj/Documents/GitHub/index/index/python/test/data/crossref_glob_dump_output/valid_id.csv\n",
    "id_date=/Users/ariannamorettj/Documents/GitHub/index/index/python/test/data/crossref_glob_dump_output/id_date.csv\n",
    "id_orcid=/Users/ariannamorettj/Documents/GitHub/index/index/python/test/data/crossref_glob_dump_output/id_orcid.csv\n",
    "id_issn=/Users/ariannamorettj/Documents/GitHub/index/index/python/test/data/crossref_glob_dump_output/id_issn.csv\n",
    "\n",
    "[NOCI]\n",
    "prefix=0160\n",
    "parser=oc.index.parsing.nih:NIHParser\n",
    "source=https://doi.org/10.35092/yhjc.c.4586573\n",
    "agent=https://w3id.org/oc/index/prov/ra/1\n",
    "baseurl=https://w3id.org/oc/index/noci/\n",
    "idbaseurl=https://pubmed.ncbi.nlm.nih.gov/\n",
    "service=OpenCitations Index: NOCI\n",
    "datasource=redis\n",
    "identifier=pmid\n",
    "# Legacy CSV Usage\n",
    "valid_id=/Users/ariannamorettj/Documents/GitHub/index/index/python/test/data/noci_glob_dump_output/valid_id.csv\n",
    "id_date=/Users/ariannamorettj/Documents/GitHub/index/index/python/test/data/noci_glob_dump_output/id_date.csv\n",
    "id_orcid=/Users/ariannamorettj/Documents/GitHub/index/index/python/test/data/noci_glob_dump_output/id_orcid.csv\n",
    "id_issn=/Users/ariannamorettj/Documents/GitHub/index/index/python/test/data/noci_glob_dump_output/id_issn.csv\n",
    "\n",
    "[CROCI]\n",
    "prefix=050\n",
    "parser=oc.index.parsing.crowdsourced:CrowdsourcedParser\n",
    "source=https://doi.org/10.5281/zenodo.3832935\n",
    "agent=https://orcid.org/0000-0003-0530-4305\n",
    "baseurl=https://w3id.org/oc/index/croci/\n",
    "idbaseurl=http://dx.doi.org/\n",
    "service=OpenCitations Index: CROCI\n",
    "datasource=redis\n",
    "identifier=doi\n",
    "# Legacy CSV Usage\n",
    "# valid_id=path/to/valid_id\n",
    "# id_date=path/to/id_date\n",
    "# id_orcid=path/to/id_orcid\n",
    "# id_issn=path/to/id_issn\n",
    "\n",
    "[DOCI]\n",
    "prefix=080\n",
    "parser=oc.index.parsing.datacite:DataciteParser\n",
    "source=api datacite guardare crossref [[citing]]\n",
    "agent=\n",
    "baseurl=\n",
    "idbaseurl=\n",
    "service=OpenCitations Index: DOCI\n",
    "datasource=redis\n",
    "identifier=doi\n",
    "# Legacy CSV Usage\n",
    "valid_id=/Users/ariannamorettj/Documents/GitHub/index/index/python/test/data/doci_glob_dump_output/valid_id.csv\n",
    "id_date=/Users/ariannamorettj/Documents/GitHub/index/index/python/test/data/doci_glob_dump_output/id_date.csv\n",
    "id_orcid=/Users/ariannamorettj/Documents/GitHub/index/index/python/test/data/doci_glob_dump_output/id_orcid.csv\n",
    "id_issn=/Users/ariannamorettj/Documents/GitHub/index/index/python/test/data/doci_glob_dump_output/id_issn.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEST Glob\n",
    "Note: Per quanto riguarda ORCID, ho provato sia il glob di noci lanciato con cartella zippata (DOI-ORCID) sia con le credenziali per l'utilizzo di API. Non ho aggiunto ai test nessuna delle due casistiche perché in un caso rallenta di molto il test e richiede il download della cartella zippata, mentre nell'altro richiede la pubblicazione di credenziali personali. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from os import sep, remove, makedirs\n",
    "import os\n",
    "from os.path import exists, join\n",
    "import shutil\n",
    "from shutil import rmtree\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from oc.index.glob.csv import CSVDataSource\n",
    "from oc.index.identifier.issn import ISSNManager\n",
    "from oc.index.identifier.orcid import ORCIDManager\n",
    "from oc.index.identifier.doi import DOIManager\n",
    "from oc.index.identifier.pmid import PMIDManager\n",
    "\n",
    "from oc.index.scripts.glob_doci import (\n",
    "    issn_data_recover_doci,\n",
    "    issn_data_to_cache_doci,\n",
    "    get_all_files_doci,\n",
    "    valid_date_doci,\n",
    "    load_json_doci,\n",
    "    process_doci,\n",
    ")\n",
    "\n",
    "\n",
    "from oc.index.scripts.glob_noci import (\n",
    "    issn_data_recover_noci,\n",
    "    issn_data_to_cache_noci,\n",
    "    build_pubdate_noci,\n",
    "    get_all_files_noci,\n",
    "    process_noci,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "from oc.index.scripts.glob_crossref import (\n",
    "    build_pubdate_coci,\n",
    "    get_all_files_coci,\n",
    "    load_json_coci,\n",
    "    process_coci,\n",
    ")\n",
    "\n",
    "\n",
    "class GlobTest(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.test_dir = join(\"index\", \"python\", \"test\", \"data\")\n",
    "        self.doi_manager = DOIManager()\n",
    "        self.pmid_manager = PMIDManager()\n",
    "        self.issn_manager = ISSNManager()\n",
    "        self.orcid_manager = ORCIDManager()\n",
    "\n",
    "        # COCI\n",
    "        self.inp_coci = join(self.test_dir, \"crossref_glob_dump_input\")\n",
    "        self.out_coci = join(self.test_dir, \"crossref_glob_dump_output\")\n",
    "        self.coci_datasource = CSVDataSource(\"COCI\")\n",
    "        self.dir_get_all_files_coci = join(self.test_dir, \"crossref_glob_dump_input\")\n",
    "        self.sample_doi_coci = self.doi_manager.normalise(\"10.7717/peerj.4375\", True)\n",
    "        self.sample_reference_coci = self.doi_manager.normalise(\n",
    "            \"10.1016/j.joi.2016.08.002\", True\n",
    "        )\n",
    "        self.sample_doi_coci_2 = self.doi_manager.normalise(\n",
    "            \"10.1016/j.websem.2017.06.001\", True\n",
    "        )\n",
    "        self.obj_for_date = {\"issued\": {\"date-parts\": [[2017, 5]]}}\n",
    "        self.obj_for_date_2 = {\"issued\": {\"date-parts\": [[2018, 2, 13]]}}\n",
    "        self.obj_for_date_3 = {\"issued\": {\"date-parts\": [[2015, 3, 9]]}}\n",
    "        self.load_json_c_inp = join(self.inp_coci, \"crossref_dump.json\")\n",
    "\n",
    "        # DOCI\n",
    "        self.inp_doci = join(self.test_dir, \"doci_glob_dump_input\")\n",
    "        self.out_doci = join(self.test_dir, \"doci_glob_dump_output\")\n",
    "        self.doci_datasource = CSVDataSource(\"DOCI\")\n",
    "        self.issn_journal_doci = {\n",
    "            \"european journal of organic chemistry\": [\"1434193X\"],\n",
    "            \"drug delivery and translational research\": [\"2190-3948\"],\n",
    "            \"the social science journal\": [\"1873-5355\"],\n",
    "        }\n",
    "        self.n_doci = 3\n",
    "        self.dir_issn_map_doci = join(self.test_dir, \"recover_w_mapping_doci\")\n",
    "        self.dir_no_issn_map_doci = join(self.test_dir, \"recover_wo_mapping_doci\")\n",
    "        self.dir_data_to_cache_doci = join(self.test_dir, \"issn_data_to_cache_doci\")\n",
    "        self.dir_get_all_files_doci = join(self.test_dir, \"doci_pp_dump_output\")\n",
    "        self.sample_reference_doci = self.doi_manager.normalise(\n",
    "            \"10.1002/anie.200504236\", True\n",
    "        )\n",
    "        self.load_json_d_inp = join(self.inp_doci, \"doci_dump.json\")\n",
    "\n",
    "        # NOCI\n",
    "        self.inp_noci = join(self.test_dir, \"noci_glob_dump_input\")\n",
    "        self.out_noci = join(self.test_dir, \"noci_glob_dump_output\")\n",
    "        self.id_orcid_map = join(\n",
    "            self.test_dir, \"noci_id_orcid_mapping\", \"doi_orcid_index.zip\"\n",
    "        )\n",
    "        self.n_noci = 3\n",
    "        self.noci_datasource = CSVDataSource(\"NOCI\")\n",
    "        self.issn_journal_noci = {\n",
    "            \"N Biotechnol\": [\"1871-6784\"],\n",
    "            \"Biochem Med\": [\"0006-2944\"],\n",
    "            \"Magn Reson Chem\": [\"0749-1581\"],\n",
    "        }\n",
    "        self.dir_issn_map_noci = join(self.test_dir, \"recover_w_mapping_noci\")\n",
    "        self.dir_no_issn_map_noci = join(self.test_dir, \"recover_wo_mapping_noci\")\n",
    "        self.dir_data_to_cache_noci = join(self.test_dir, \"issn_data_to_cache_noci\")\n",
    "        self.dir_get_all_files_noci = join(self.test_dir, \"noci_md_pp_dump_output\")\n",
    "        self.csv_sample = join(self.inp_noci, \"CSVFile_1.csv\")\n",
    "        self.sample_reference_noci = self.pmid_manager.normalise(\"4150960\", True)\n",
    "\n",
    "    def test_build_pubdate_coci(self):\n",
    "        self.assertEqual(build_pubdate_coci(self.obj_for_date), \"2017-05\")\n",
    "        self.assertEqual(build_pubdate_coci(self.obj_for_date_2), \"2018-02-13\")\n",
    "        self.assertEqual(build_pubdate_coci(self.obj_for_date_3), \"2015-03-09\")\n",
    "\n",
    "    def test_get_all_files_coci(self):\n",
    "        all_files, opener = get_all_files_coci(self.dir_get_all_files_coci)\n",
    "        len_all_files = len(all_files)\n",
    "        self.assertEqual(len_all_files, 1)\n",
    "\n",
    "    def test_load_json_coci(self):\n",
    "        self.assertTrue(\n",
    "            isinstance(load_json_coci(self.load_json_c_inp, None, 1, 1), dict)\n",
    "        )\n",
    "\n",
    "    def test_process_coci(self):\n",
    "        for files in os.listdir(self.out_coci):\n",
    "            path = os.path.join(self.out_coci, files)\n",
    "            try:\n",
    "                shutil.rmtree(path)\n",
    "            except OSError:\n",
    "                os.remove(path)\n",
    "        self.assertEqual(len(os.listdir(self.out_coci)), 0)\n",
    "        process_coci(self.inp_coci, self.out_coci)\n",
    "        self.assertEqual(len(os.listdir(self.out_coci)), 4)\n",
    "\n",
    "        citing_doi = self.doi_manager.normalise(self.sample_doi_coci, True)\n",
    "        citing_doi_2 = self.doi_manager.normalise(self.sample_doi_coci_2, True)\n",
    "        self.assertEqual(\n",
    "            self.coci_datasource.get(citing_doi_2)[\"orcid\"],\n",
    "            {\"0000-0003-0530-4305\", \"0000-0002-7562-5203\"},\n",
    "        )\n",
    "        self.assertEqual(self.coci_datasource.get(citing_doi)[\"valid\"], {\"v\"})\n",
    "        self.assertEqual(self.coci_datasource.get(self.sample_reference_coci)[\"valid\"], {\"v\"})\n",
    "        self.assertEqual(self.coci_datasource.get(citing_doi)[\"date\"], {\"2018-02-13\"})\n",
    "        self.assertEqual(self.coci_datasource.get(citing_doi)[\"issn\"], {\"2167-8359\"})\n",
    "\n",
    "    # TEST DOCI GLOB\n",
    "    def test_issn_data_recover_doci(self):\n",
    "        self.assertTrue(True)\n",
    "        if exists(self.dir_no_issn_map_doci):\n",
    "            rmtree(self.dir_no_issn_map_doci)\n",
    "        makedirs(self.dir_no_issn_map_doci)\n",
    "        if exists(self.dir_issn_map_doci):\n",
    "            rmtree(self.dir_issn_map_doci)\n",
    "        makedirs(self.dir_issn_map_doci)\n",
    "        with open(\n",
    "            join(self.dir_no_issn_map_doci, \"journal_issn.json\"), \"w\", encoding=\"utf-8\"\n",
    "        ) as g:\n",
    "            json.dump({}, g, ensure_ascii=False, indent=4)\n",
    "        with open(\n",
    "            join(self.dir_issn_map_doci, \"journal_issn.json\"), \"w\", encoding=\"utf-8\"\n",
    "        ) as f:\n",
    "            json.dump(self.issn_journal_doci, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        # Test the case in which there is no mapping file for journals - issn\n",
    "        self.assertEqual(issn_data_recover_doci(self.dir_no_issn_map_doci), {})\n",
    "        # Test the case in which there is a mapping file for journals - issn\n",
    "        self.assertNotEqual(issn_data_recover_doci(self.dir_issn_map_doci), {})\n",
    "\n",
    "        rmtree(self.dir_no_issn_map_doci)\n",
    "        rmtree(self.dir_issn_map_doci)\n",
    "\n",
    "    def test_issn_data_to_cache_doci(self):\n",
    "        filename = join(self.dir_data_to_cache_doci, \"journal_issn.json\")\n",
    "        if not exists(self.dir_data_to_cache_doci):\n",
    "            makedirs(self.dir_data_to_cache_doci)\n",
    "        if exists(filename):\n",
    "            remove(filename)\n",
    "        self.assertFalse(exists(filename))\n",
    "        issn_data_to_cache_doci(self.issn_journal_doci, self.dir_data_to_cache_doci)\n",
    "        self.assertTrue(exists(filename))\n",
    "        rmtree(self.dir_data_to_cache_doci)\n",
    "\n",
    "    def test_get_all_files_doci(self):\n",
    "        all_files, opener = get_all_files_doci(self.dir_get_all_files_doci)\n",
    "        len_all_files = len(all_files)\n",
    "        self.assertEqual(len_all_files, 4)\n",
    "\n",
    "    def test_valid_date_doci(self):\n",
    "        self.assertTrue(isinstance(valid_date_doci(2018), str))\n",
    "        self.assertEqual(valid_date_doci(\"2018-11-25\"), \"2018-11-25\")\n",
    "        self.assertIsNone(valid_date_doci(\"11-25-2018\"))\n",
    "\n",
    "    def test_load_json_doci(self):\n",
    "        self.assertTrue(\n",
    "            isinstance(load_json_doci(self.load_json_d_inp, None, 1, 1), dict)\n",
    "        )\n",
    "\n",
    "    def test_process_doci(self):\n",
    "        for files in os.listdir(self.out_doci):\n",
    "            path = os.path.join(self.out_doci, files)\n",
    "            try:\n",
    "                shutil.rmtree(path)\n",
    "            except OSError:\n",
    "                os.remove(path)\n",
    "        self.assertEqual(len(os.listdir(self.out_doci)), 0)\n",
    "        process_doci(self.inp_doci, self.out_doci, self.n_doci)\n",
    "        self.assertEqual(len(os.listdir(self.out_doci)), 5)\n",
    "\n",
    "        citing_doi = \"doi:10.1002/ejoc.201800947\"\n",
    "        self.assertEqual(self.doci_datasource.get(citing_doi)[\"orcid\"], {\"0000-0002-2397-9093\"})\n",
    "        self.assertEqual(self.doci_datasource.get(citing_doi)[\"valid\"], {\"v\"})\n",
    "        self.assertEqual(self.doci_datasource.get(self.sample_reference_doci)[\"valid\"], {\"v\"})\n",
    "        self.assertEqual(self.doci_datasource.get(citing_doi)[\"date\"], {\"2018-11-25\"})\n",
    "        self.assertEqual(self.doci_datasource.get(citing_doi)[\"issn\"], {\"1434-193X\"})\n",
    "\n",
    "    # TEST NOCI GLOB\n",
    "    def test_issn_data_recover_noci(self):\n",
    "        if exists(self.dir_no_issn_map_noci):\n",
    "            rmtree(self.dir_no_issn_map_noci)\n",
    "        makedirs(self.dir_no_issn_map_noci)\n",
    "        if exists(self.dir_issn_map_noci):\n",
    "            rmtree(self.dir_issn_map_noci)\n",
    "        makedirs(self.dir_issn_map_noci)\n",
    "        with open(\n",
    "            join(self.dir_no_issn_map_noci, \"journal_issn.json\"), \"w\", encoding=\"utf-8\"\n",
    "        ) as g:\n",
    "            json.dump({}, g, ensure_ascii=False, indent=4)\n",
    "        with open(\n",
    "            join(self.dir_issn_map_noci, \"journal_issn.json\"), \"w\", encoding=\"utf-8\"\n",
    "        ) as f:\n",
    "            json.dump(self.issn_journal_noci, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        # Test the case in which there is no mapping file for journals - issn\n",
    "        self.assertEqual(issn_data_recover_noci(self.dir_no_issn_map_noci), {})\n",
    "        # Test the case in which there is a mapping file for journals - issn\n",
    "        self.assertNotEqual(issn_data_recover_noci(self.dir_issn_map_noci), {})\n",
    "\n",
    "        rmtree(self.dir_no_issn_map_noci)\n",
    "        rmtree(self.dir_issn_map_noci)\n",
    "\n",
    "    def test_issn_data_to_cache_noci(self):\n",
    "        filename = join(self.dir_data_to_cache_noci, \"journal_issn.json\")\n",
    "        if not exists(self.dir_data_to_cache_noci):\n",
    "            makedirs(self.dir_data_to_cache_noci)\n",
    "        if exists(filename):\n",
    "            remove(filename)\n",
    "        self.assertFalse(exists(filename))\n",
    "        issn_data_to_cache_noci(self.issn_journal_noci, self.dir_data_to_cache_noci)\n",
    "        self.assertTrue(exists(filename))\n",
    "        rmtree(self.dir_data_to_cache_noci)\n",
    "\n",
    "    def test_build_pubdate_noci(self):\n",
    "        df = pd.DataFrame()\n",
    "        for chunk in pd.read_csv(self.csv_sample, chunksize=1000):\n",
    "            f = pd.concat([df, chunk], ignore_index=True)\n",
    "            f.fillna(\"\", inplace=True)\n",
    "            for index, row in f.iterrows():\n",
    "                pub_date = build_pubdate_noci(row)\n",
    "                self.assertTrue(isinstance(pub_date, str))\n",
    "                self.assertTrue(isinstance(int(pub_date), int))\n",
    "                self.assertEqual(len(pub_date), 4)\n",
    "\n",
    "    def test_get_all_files_noci(self):\n",
    "        self.assertTrue(True)\n",
    "        all_files, opener = get_all_files_noci(self.dir_get_all_files_noci)\n",
    "        len_all_files = len(all_files)\n",
    "        self.assertEqual(len_all_files, 2)\n",
    "\n",
    "    def test_process_noci(self):\n",
    "        for files in os.listdir(self.out_noci):\n",
    "            path = os.path.join(self.out_noci, files)\n",
    "            try:\n",
    "                shutil.rmtree(path)\n",
    "            except OSError:\n",
    "                os.remove(path)\n",
    "        self.assertEqual(len(os.listdir(self.out_noci)), 0)\n",
    "        process_noci(self.inp_noci, self.out_noci, self.n_noci)\n",
    "        self.assertEqual(len(os.listdir(self.out_noci)), 5)\n",
    "\n",
    "        citing_pmid = \"pmid:2\"\n",
    "        citing_pmid5 = \"pmid:5\"\n",
    "        self.assertEqual(self.noci_datasource.get(citing_pmid)[\"orcid\"], None)\n",
    "        # self.assertEqual(self.noci_datasource.get(citing_pmid5)[\"orcid\"], {\"0000-0002-4762-5345\"})\n",
    "        # run the glob process with credetials to make this test assertion pass\n",
    "        self.assertEqual(self.noci_datasource.get(citing_pmid)[\"valid\"], {\"v\"})\n",
    "        self.assertEqual(self.noci_datasource.get(self.sample_reference_noci)[\"valid\"], {\"v\"})\n",
    "        self.assertEqual(self.noci_datasource.get(citing_pmid)[\"date\"], {\"1975\"})\n",
    "        self.assertEqual(self.noci_datasource.get(citing_pmid)[\"issn\"], {\"0006-291X\"})\n",
    "\n",
    "        # try again with doi_orcid mapping folder\n",
    "        # for files in os.listdir(self.out_noci):\n",
    "        #     path = os.path.join(self.out_noci, files)\n",
    "        #     try:\n",
    "        #         shutil.rmtree(path)\n",
    "        #     except OSError:\n",
    "        #         os.remove(path)\n",
    "        # self.assertEqual(len(os.listdir(self.out_noci)),0)\n",
    "        # process_noci(self.inp_noci, self.out_noci, self.n_noci, self.id_orcid_map)\n",
    "        # self.assertEqual(len(os.listdir(self.out_noci)), 5)\n",
    "        #\n",
    "        # df = pd.DataFrame()\n",
    "        # for chunk in pd.read_csv(self.csv_sample, chunksize=1000):\n",
    "        #     f = pd.concat([df, chunk], ignore_index=True)\n",
    "        #     f.fillna(\"\", inplace=True)\n",
    "        #     for index, row in f.iterrows():\n",
    "        #         pmid = row[\"pmid\"]\n",
    "        #         citing_pmid = self.pmid_manager.normalise(pmid, include_prefix=True)\n",
    "        #         if citing_pmid == \"pmid:2\":\n",
    "        #             self.assertEqual(self.id_orcid.get_value(citing_pmid), {'0000-0003-0014-4963'})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Data Source (Modifica su CSV DataSource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "\n",
    "import json\n",
    "from os.path import exists, basename, isdir, join, isfile\n",
    "from oc.index.utils.config import get_config\n",
    "from oc.index.glob.datasource import DataSource\n",
    "from oc.index.legacy.csv import CSVManager\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "class CSVDataSource(DataSource):\n",
    "    def __init__(self, service):\n",
    "        super(CSVDataSource, self).__init__()\n",
    "\n",
    "        self._valid_id = CSVManager(csv_path=get_config().get(service, \"valid_id\"))\n",
    "        self._id_date = CSVManager(csv_path=get_config().get(service, \"id_date\"))\n",
    "        self._id_orcid = CSVManager(csv_path=get_config().get(service, \"id_orcid\"))\n",
    "        self._id_issn = CSVManager(csv_path=get_config().get(service, \"id_issn\"))\n",
    "\n",
    "    def get(self, resource_id):\n",
    "        entry = self.new()\n",
    "        entry[\"valid\"] = self._valid_id.get_value(resource_id)\n",
    "        entry[\"date\"] = self._id_date.get_value(resource_id)\n",
    "        entry[\"issn\"] = self._id_issn.get_value(resource_id)\n",
    "        entry[\"orcid\"] = self._id_orcid.get_value(resource_id)\n",
    "        if (\n",
    "            entry[\"valid\"] == None\n",
    "            and entry[\"date\"] == None\n",
    "            and entry[\"issn\"] == None\n",
    "            and entry[\"orcid\"] == None\n",
    "        ):\n",
    "            return None\n",
    "        return entry\n",
    "\n",
    "    def mget(self, resources_id):\n",
    "        return {key: self.get(key) for key in resources_id}\n",
    "\n",
    "    def set(self, resource_id, value):\n",
    "        # if the value dict was compiled for the first time, the value will be True/False\n",
    "        # while if the value dict is being updated and the validity information was retrieved\n",
    "        # from csv files, the value retrieved for the validity will be a set with a unique\n",
    "        # value, either \"i\" or \"v\"\n",
    "        if \"valid\" in value.keys():\n",
    "            if value[\"valid\"] is False or value[\"valid\"] == {\"i\"}:\n",
    "                self._valid_id.add_value(resource_id, \"i\")\n",
    "            elif value[\"valid\"] is True or value[\"valid\"] == {\"v\"}:\n",
    "                self._valid_id.add_value(resource_id, \"v\")\n",
    "                # so that all the operations and transcriptions are performed only for valid ids\n",
    "\n",
    "                if \"date\" in value.keys():\n",
    "                    if value[\"date\"] is not None and len(value[\"date\"])>0:\n",
    "                        # for multiple values and to avoid self.data[id_string].add(value) TypeError: unhashable type: 'set'\n",
    "                        for date in value[\"date\"]:\n",
    "                            self._id_date.add_value(resource_id, date)\n",
    "                    else:\n",
    "                        self._id_date.add_value(resource_id, \"\")\n",
    "                else:\n",
    "                    self._id_date.add_value(resource_id, \"\")\n",
    "\n",
    "                if \"issn\" in value.keys():\n",
    "                    if value[\"issn\"] is not None and len(value[\"issn\"])>0:\n",
    "                        # for multiple values and to avoid self.data[id_string].add(value) TypeError: unhashable type: 'set'\n",
    "                        for issn in value[\"issn\"]:\n",
    "                            self._id_issn.add_value(resource_id, issn)\n",
    "\n",
    "                if \"orcid\" in value.keys():\n",
    "                    if value[\"orcid\"] is not None and len(value[\"orcid\"])>0:\n",
    "                        # for multiple values and to avoid self.data[id_string].add(value) TypeError: unhashable type: 'set'\n",
    "                        for orcid in value[\"orcid\"]:\n",
    "                            self._id_orcid.add_value(resource_id, orcid)\n",
    "\n",
    "    def mset(self, resources):\n",
    "        for key in resources.keys():\n",
    "            self.set(key, resources[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commit (index farm_revision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CSVDataSource glob (DOCI, NOCI,COCI), validate (DOCI, NOCI), ORCID Resource Finder for PMID**\n",
    "\n",
    "- New version of CSVDataSource glob for DOCI, NOCI, COCI\n",
    "- Update of the glob tests script\n",
    "- csv.py update (CSVDataSource, methods get and set)\n",
    "- Update of the validate scripts for NOCI and DOCI\n",
    "- validate test script update (for NOCI and DOCI) + upload of the sample files for the test\n",
    "- ORCID resource finder PMID class creation, for extracting the authors' ORCIDs from the PMID of a publication\n",
    "- finder test extension (for ORCIDResourceFinderPMID)\n",
    "- config.ini update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Visualizzazioni dati di log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON user agent e referer noti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classificazione è frutto del confronto tra me e Chiara. Silvio dovrebbe dare un'occhiata alle voci in \"in_evaluation\" ed eventualmente darci un feedback. Per ora, il dizionario contiene tutti i referer e gli ua incontrati, (**mancano ua esclusi prima di passare il file a chiara? Controlla mail**) con lo scopo di gestire in maniera più veloce le analisi future, rivalutando solo le new entries. Il dizionario ha questa struttura principale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"user_agent\":{\n",
    "        \"relevant\":{},\n",
    "        \"not_relevant\":{},\n",
    "        \"in_evaluation\":{}\n",
    "    },\n",
    "    \"referer\":{\n",
    "        \"relevant\":{},\n",
    "        \"not_relevant\":{},\n",
    "        \"in_evaluation\":{}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fake entry \n",
    "\"not_relevant\":{\n",
    "    \"OpenCitations\":{\n",
    "        \"contains\": [\n",
    "            \"opencitations.net\",\n",
    "            \"opencitations.net/about\"\n",
    "        ],\n",
    "        \"type\": \"already in our contact network\",\n",
    "        \"related_to\": [\"Silvio Peroni\"]\n",
    "    }\n",
    "},"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ognuna delle chiavi contiene un dizionario, le cui chiavi sono i nomi dei referer e user agent, e i valori sono a loro volta dizionari. Il dizionario di un'entità è rappresentato come segue: la voce contiene una **chiave obbligatoria** (**\"contains\"**), che contiene una lista con l'elenco delle stringhe con cui l'entità è comparsa, e due **chiavi facoltative** (**\"type\" e \"related_to\"**); la prima contiene una stringa che classifica l'entità in base alla ragione per cui è stata definita relevant, not relevant o in evaluation, mentre la seconda contiene una lista di stringhe dei nomi delle chiavi di altre entità, a cui l'entità in questione è eventualmente collegata. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da fare:\n",
    "- **Creare NUOVI CAMPI NEL JSON (nel nested dict \"not_relevant\") per gli user agent che sono stati scartati prima dell'analisi e per quelli attualmente gestiti dai txt contenenti user agent comuni e bot noti**, affinché contribuiscano alla scrematura per i mesi successivi. \n",
    "- Integrare **nel ranking annuale** la **distribuzione percentuale per servizio utilizzato** (per individuare utilizzi attivi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come ho strutturato il lavoro:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"loganalysis.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Statistics-view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ho parlato con Ivan che ha modificato le visualizzazioni nel server di test. I punti principali sono: \n",
    "<ol>\n",
    "    <li><b>Spostamento dalla barra di navigazione principale</b>: ora ci si arriva tramite <a href=https://test.opencitations.net/datasets>https://test.opencitations.net/datasets</a> e da <a href=https://test.opencitations.net/querying>https://test.opencitations.net/querying</a> (dovrebbe andare bene ma è da discutere a riunione con il resto del gruppo).</li>\n",
    "    <li><b>Generazione automatica delle visualizzazioni al cambio di parametri nei select e nei calendari</b> anziché cliccando il bottone di invio dopo aver modificato i parametri. Inoltre, <b>lo spostamento dei select e dei calendari interattivi sopra alle visualizzazioni</b>, secondo me, rende più immediata per l'utente la comprensione della possibilità di modificare i parametri delle visualizzazioni stesse, dal momento che sono anche molto grandi e di conseguenza non viene spontaneo pensare che si debba scorrere in basso per aggiornarle.</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) OSG-IG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dopo l'ultima riunione ho aggiornato il file google doc in cui avevo preso appunti sulla riunione precedente. Se può essere utile, il link per accedere al documento è <a href=\"https://docs.google.com/document/d/1yk9UUP0aMxBlY9xGABxQMYmADeuda0WuS0Sl-gDNn-A/edit?usp=sharing\">https://docs.google.com/document/d/1yk9UUP0aMxBlY9xGABxQMYmADeuda0WuS0Sl-gDNn-A/edit?usp=sharing</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do:\n",
    "<ol>\n",
    "    <li><b>statistics-view</b>: cambiare lug (jul) e togliere il trattino sotto alle etichette</li>\n",
    "    <li>caricare figshgare cartella mappata zippata (e notifica in README(?) la possibilità di utilizzare quella tabella per mappatura doi-orcid in utilizzo autonomo di NOCI glob)</li>\n",
    "    <li>nota: accesso limitato è per la scrittura. Fai doppio passaggio orcid resource pmid in GLOB NOCI</li>\n",
    "    <li><b>user agent analysis</b>: per il futuro Chiara deve poterlo usare da sola. Quando le esigenze cresceranno dovrà diventare automatico (Chiara deve poter modificare l'ultimo json valido dall'interfaccia).</li>\n",
    "    <li><b>Prossimi indici</b>: OA non ha identificativi propri (non ha id locali univoci). Ce lo dobbiamo creare noi con META. Cosa possiamo usare? CROCI, è fatto apposta, generai i METAid partendo da dati citazionali. Però Silvio non vorrebbe passare per CROCI. Silvio è anche per evitare arxiv id, a meno che non siano quelli generici. Perché Arxiv dà un unico id per tutto il work, non uno per espressioni. Noi gestiamo espressioni. Silvio vorrebbe un contenitore specifico per Open</li>\n",
    "    <li>Controllare corrispondenza con Paolo sui dati che hanno pubblicato</li>\n",
    "    <li><b>Problema duplicati</b>: capire da dove vengono e come rimuoverli: toglierli dallo zip e ricaricare lo zip senza. Nel dump non possono esserci doppioni. </li>\n",
    "    <li><b>OSG-IG</b>: guarda tabella da aggiornare.</li>\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Agent and Referer code refinement + first part of Javascript visualization (30/08 - 06/09) <a class=\"anchor\" id=\"entry_20\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code New structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"analisi_ua_ref.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Agent and Referer string management steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>per ogni file che arriva in input come lista di stringhe (righe rappresentanti ciascuna una richiesta), si crea un dizionario, che sarà il valore della chiave \"user_agent\" o \"referer\" per il mese a cui fa riferimento il file in questione</li>\n",
    "    <li>da ogni stringa nella lista viene estratto user agent / referer e request uri (ovvero il servizio che è stato richiesto). </li>\n",
    "    <li>A questo punto, le stringhe dell'entità e del servizio vengono pulite (messe in lowercase, eliminati eventuali spazi a inizio o fine stringa...). In aggiunta, si prova ad estrarre un nome di dominio senza sottodomini, per controllare se eventualmente, anche nel caso in cui l'url in questione non sia ancora stato incontrato, venga associato ad altri url simili con cui condivide il nome di dominio (nel caso del referer molto utile, nel caso di user agent a volte utile e a volte fuorviante, ho dovuto fare della pulizia e gestire diverse eccezioni)</li>\n",
    "    <li>Controllo se la stringa in questione o il dominio estratto (ammesso che non rientri tra quelli non utili) sia già presente all'interno di una delle liste di stringhe con cui una data entità si è già presentata </li>\n",
    "    <li>Gestione della possibilità che - per qualche motivo - la stringa sia stata integrata automaticamente in più di un dizionario tra i tre principali (rilevati, non rilevanti, in valutazione). Questa casistica richiede la necessità di gerarchizzare le successive possibilità di conteggio. Il criterio che ho scelto è dare priorità a \"relevant\" su \"non relevant\" e \"not relevant\" su evaluation, visto che teoricamente il gruppo di user strings in valutazione è quello più ampio, nonché quello in cui vengono automaticamente riversate le stringhe che non è stato possibile gestire diversamente. Ognuna di queste possibilità si conclude con un break del for loop di iterazione tra i dizionari tra i cui valori compare la stringa o una parte di essa, perché rischieremmo di gonfiare i risultati altrimenti</li>.\n",
    "    <li>Se invece la stringa è comparsa nei valori di uno solo dei tre dizionari, viene gestita di conseguenza e il dato viene registrato in maniera lineare. Nota: in questo processo viene sia aggiornato il dizionario di rilevanza, sia le note di commento (anche queste dizionario), che il dizionario month report (in cui registro solo i rilevanti e quelli in valutazione, aggiornando un dizionario collegato alla stringa della chiave (stessa che rappresenta l'entità nel dizionario di rilevanza), che contiene le categorie dei servizi richiesti e un contatore del numero di richieste raggruppabili sotto la categoria). </li>\n",
    "    <li>Nel caso in cui invece non ci sia stato nessun match tra la stringa e in questione e quelle note, nel caso in cui dalla strinag sia stato estratto un dominio che fa riferimento ad un user agent noto, la stringa viene classificata come non rilevante.</li>\n",
    "    <li>Alternativamente, si fa un tentativo per vedere se la stringa fa riferimento ad un bot. In questo caso, se la stringa fa già parte della lista di stringhe da scartare, allora viene classificata come bot </li>\n",
    "    <li>Tutto quello che non ha fatto match precedentemente viene salvato come da valutare</li>\n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"composizionedatiutilizzo.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"reportcomplessivo.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06/09 - 13/09 (NOCI glob update, User agent code fix, ID Manager repo, Tables for meta <a class=\"anchor\" id=\"entry_21\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOCI glob code update \n",
    "- integrazione primo controllo preliminare con ORCID Resource Finder per PMID. Il controllo avviene solo se sono state specificate le credenziali per l'utilizzo delle API pubbliche. Se il controllo avviene con successo, viene aggiornato il valore \"has_orcid\" nel dizionario di mapping pmid-doi (per la dizionario relativo alla chiave del pmid in questione). In questo modo, i pmid mappati con doi che sarebbero poi stati usati per recuperare l'orcid dal doi vengono direttamente scartati, qualora gli orcid siano già stati trovati. \n",
    "- Modifiche a check_author_identity_api (perché la struttura della risposta dell'API è più variabile di quanto avessi considerato nella versione precedente: diverse chiavi interne vengono direttamente eliminate (anziché essere mantenute con campo vuoto associato) qualora l'utente compili male i campi relativi ai propri dati personali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python\n",
    "# Copyright (c) 2022 The OpenCitations Index Authors.\n",
    "#\n",
    "# Permission to use, copy, modify, and/or distribute this software for any purpose\n",
    "# with or without fee is hereby granted, provided that the above copyright notice\n",
    "# and this permission notice appear in all copies.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n",
    "# REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n",
    "# FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\n",
    "# OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,\n",
    "# DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS\n",
    "# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS\n",
    "# SOFTWARE.\n",
    "import csv\n",
    "from argparse import ArgumentParser\n",
    "from os import sep, makedirs, walk\n",
    "import os\n",
    "import os.path\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "from tarfile import TarFile\n",
    "import re\n",
    "from os.path import exists, basename, isdir, join\n",
    "from timeit import default_timer as timer\n",
    "from re import sub\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import requests\n",
    "\n",
    "from oc.index.oci.citation import Citation\n",
    "from oc.index.identifier.doi import DOIManager\n",
    "from oc.index.identifier.pmid import PMIDManager\n",
    "from oc.index.identifier.issn import ISSNManager\n",
    "from oc.index.identifier.orcid import ORCIDManager\n",
    "from oc.index.finder.orcid import ORCIDResourceFinder, ORCIDResourceFinderPMID\n",
    "from oc.index.finder.crossref import CrossrefResourceFinder\n",
    "from oc.index.glob.csv import CSVDataSource\n",
    "\n",
    "def check_author_identity_api(uri, authors_dicts_list, orcid_client_id, orcid_client_secret):\n",
    "    data = {\"client_id\": orcid_client_id, \"client_secret\": orcid_client_secret,\"grant_type\": \"client_credentials\", \"scope\": \"/read-public\" }\n",
    "    response = requests.post(uri, headers = {\"Accept\": \"application/json\"}, data = data)\n",
    "    identity_verified = False\n",
    "    if response.status_code == 200:\n",
    "        json_response = response.json()\n",
    "        if json_response is not None and json_response != {}:\n",
    "            person = json_response[\"person\"]\n",
    "            if person != None and person != {}:\n",
    "                if \"name\" in person.keys():\n",
    "                    given_names = [v for k,v in person[\"name\"].items() if k ==\"given-names\" and v is not None]\n",
    "                    if given_names:\n",
    "                        if \"value\" in person[\"name\"][\"given-names\"]:\n",
    "                            g_names = person[\"name\"][\"given-names\"][\"value\"]\n",
    "                            family_name = [v for k,v in person[\"name\"].items() if k ==\"family-name\" and v is not None]\n",
    "                            if family_name:\n",
    "                                if \"value\" in person[\"name\"][\"family-name\"]:\n",
    "                                    f_name = person[\"name\"][\"family-name\"][\"value\"]\n",
    "                                    orcid_author_surnames_list = re.findall(\n",
    "                                                    \"[a-zA-Z\\'\\-áéíóúäëïöüÄłŁőŐűŰZàáâäãåąčćęèéêëėįìíîïłńòóôöõøùúûüųūÿýżźñçčšžÀÁÂÄÃÅĄĆČĖĘÈÉÊËÌÍÎÏĮŁŃÒÓÔÖÕØÙÚÛÜŲŪŸÝŻŹÑßÇŒÆČŠŽñÑâê]{2,}\",\n",
    "                                                    f_name)\n",
    "                                    orcid_author_surnames_list_l = [x.lower() for x in orcid_author_surnames_list]\n",
    "                                    orcid_author_names_list = re.findall(\n",
    "                                    \"[a-zA-Z\\'\\-áéíóúäëïöüÄłŁőŐűŰZàáâäãåąčćęèéêëėįìíîïłńòóôöõøùúûüųūÿýżźñçčšžÀÁÂÄÃÅĄĆČĖĘÈÉÊËÌÍÎÏĮŁŃÒÓÔÖÕØÙÚÛÜŲŪŸÝŻŹÑßÇŒÆČŠŽñÑâê]{2,}\",\n",
    "                                    g_names)\n",
    "                                    orcid_author_names_list_l = [x.lower() for x in orcid_author_names_list]\n",
    "                                    matches = [dict for dict in authors_dicts_list if\n",
    "                               [sn for sn in dict[\"surnames\"] if sn in orcid_author_surnames_list_l] and [l for l in dict[\"names\"] if any(\n",
    "                                   element.startswith(l) and element not in dict[\"surnames\"] for element in orcid_author_names_list_l)]]\n",
    "                                    if matches:\n",
    "                                        identity_verified = True\n",
    "    return identity_verified\n",
    "\n",
    "\n",
    "def issn_data_recover_noci(directory):\n",
    "    journal_issn_dict = dict()\n",
    "    filename = join(directory, \"journal_issn.json\")\n",
    "    if not os.path.exists(filename):\n",
    "        return journal_issn_dict\n",
    "    else:\n",
    "        with open(filename, \"r\", encoding=\"utf8\") as fd:\n",
    "            journal_issn_dict = json.load(fd)\n",
    "            return journal_issn_dict\n",
    "\n",
    "\n",
    "def issn_data_to_cache_noci(name_issn_dict, directory):\n",
    "    filename = directory + sep + \"journal_issn.json\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as fd:\n",
    "        json.dump(name_issn_dict, fd, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "# takes in input a data structure representing a bibliographic entity\n",
    "def build_pubdate_noci(row):\n",
    "    year = str(row[\"year\"])\n",
    "    str_year = sub(\"[^\\d]\", \"\", year)[:4]\n",
    "    if str_year:\n",
    "        return str_year\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# get_all_files extracts all the needed files from the input directory\n",
    "def get_all_files_noci(i_dir):\n",
    "    result = []\n",
    "    opener = None\n",
    "    if i_dir.endswith(\".zip\"):\n",
    "        zf = ZipFile(i_dir)\n",
    "        namelist = zf.namelist()\n",
    "        result = [x for x in namelist if x.lower().endswith(\".csv\")]\n",
    "        opener = zf.open\n",
    "    elif i_dir.endswith(\".tar.gz\"):\n",
    "        tf = TarFile.open(i_dir)\n",
    "        for name in tf.getnames():\n",
    "            if name.lower().endswith(\".csv\"):\n",
    "                result.append(name)\n",
    "        opener = tf.extractfile\n",
    "\n",
    "    else:\n",
    "        for cur_dir, cur_subdir, cur_files in walk(i_dir):\n",
    "            for file in cur_files:\n",
    "                if file.lower().endswith(\".csv\"):\n",
    "                    result.append(cur_dir + sep + file)\n",
    "        opener = open\n",
    "    return result, opener\n",
    "\n",
    "\n",
    "def process_noci(input_dir, output_dir, n, id_orcid_dir=None, orcid_client_id=None, orcid_client_secret=None):\n",
    "\n",
    "    start = timer()\n",
    "    if not exists(output_dir):\n",
    "        makedirs(output_dir)\n",
    "\n",
    "    journal_issn_dict = issn_data_recover_noci(output_dir)\n",
    "    crossref_resource_finder = CrossrefResourceFinder()\n",
    "    orcid_resource_finder = ORCIDResourceFinder()\n",
    "    pmid_orcid_resource_finder = ORCIDResourceFinderPMID()\n",
    "\n",
    "\n",
    "    doi_manager = DOIManager()\n",
    "    issn_manager = ISSNManager()\n",
    "    orcid_manager = ORCIDManager()\n",
    "    pmid_manager = PMIDManager()\n",
    "    csv_datasource = CSVDataSource(\"NOCI\")\n",
    "\n",
    "    all_files, opener = get_all_files_noci(input_dir)\n",
    "    len_all_files = len(all_files)\n",
    "    pmid_doi_map = dict()\n",
    "\n",
    "    # Read all the CSV file in the NIH dump to create the main information of all the indexes\n",
    "    # print(\"\\n\\n# Add valid PMIDs from NIH metadata\")\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        for chunk in pd.read_csv(file, chunksize=1000):\n",
    "            f = pd.concat([df, chunk], ignore_index=True)\n",
    "            f.fillna(\"\", inplace=True)\n",
    "\n",
    "            # print(\"Open file %s of %s\" % (file_idx, len_all_files))\n",
    "            for index, row in f.iterrows():\n",
    "                if int(index) != 0 and int(index) % int(n) == 0:\n",
    "                    # print( \"Group nr.\", int(index)//int(n), \"processed. Data from\", int(index), \"rows saved to journal_issn.json mapping file\")\n",
    "                    issn_data_to_cache_noci(journal_issn_dict, output_dir)\n",
    "\n",
    "                citing_pmid = pmid_manager.normalise(row[\"pmid\"], True)\n",
    "                if citing_pmid is not None:\n",
    "                    authors_dicts_list = []\n",
    "                    authors_split_list = row[\"authors\"].split(\",\")\n",
    "                    for author in authors_split_list:\n",
    "                        names = re.findall(\"([A-Z]|[ÄŐŰÀÁÂÄÃÅĄĆČĖĘÈÉÊËÌÍÎÏĮŁŃÒÓÔÖÕØÙÚÛÜŲŪŸÝŻŹÑßÇŒÆČŠŽÑ]){1}\\s\", author)\n",
    "                        strp_names = [(x.strip()).lower() for x in names]\n",
    "                        surnames = re.findall(\n",
    "                        \"[a-zA-Z\\'\\-áéíóúäëïöüÄłŁőŐűŰZàáâäãåąčćęèéêëėįìíîïłńòóôöõøùúûüųūÿýżźñçčšžÀÁÂÄÃÅĄĆČĖĘÈÉÊËÌÍÎÏĮŁŃÒÓÔÖÕØÙÚÛÜŲŪŸÝŻŹÑßÇŒÆČŠŽñÑâê]{2,}\",\n",
    "                        author)\n",
    "                        surnames_l = [s.lower() for s in surnames]\n",
    "                        author_dict = {\"names\":strp_names, \"surnames\":surnames_l}\n",
    "                        authors_dicts_list.append(author_dict)\n",
    "\n",
    "                    if csv_datasource.get(citing_pmid) is None:\n",
    "                        entity = dict()\n",
    "\n",
    "                        entity[\"valid\"] = True\n",
    "\n",
    "                        citing_doi = doi_manager.normalise(row[\"doi\"], False)\n",
    "                        if citing_doi:\n",
    "                            pmid_doi_map[citing_pmid] = {\"doi\": citing_doi, \"has_orcid\": False, \"all_authors_names\": authors_dicts_list}\n",
    "\n",
    "                        citing_date = Citation.check_date(build_pubdate_noci(row))\n",
    "                        if citing_date is not None:\n",
    "                            entity[\"date\"] = [citing_date]\n",
    "\n",
    "                        if orcid_client_id and orcid_client_secret:\n",
    "                            json_res_pmid = pmid_orcid_resource_finder._call_api(citing_pmid)\n",
    "                            if json_res_pmid is not None and len(json_res_pmid) > 0:\n",
    "                                pmid_certified_orcid = []\n",
    "                                for orcid_dict_pmid in json_res_pmid:\n",
    "                                    pmid_json_uri = orcid_dict_pmid[\"orcid-identifier\"][\"uri\"]\n",
    "                                    pmid_chek_passed = check_author_identity_api(pmid_json_uri, authors_dicts_list,\n",
    "                                                                                    orcid_client_id,\n",
    "                                                                                    orcid_client_secret)\n",
    "                                    pmid_norm_orc = orcid_manager.normalise(pmid_json_uri)\n",
    "                                    if pmid_chek_passed and pmid_norm_orc:\n",
    "                                        pmid_certified_orcid.append(pmid_norm_orc)\n",
    "\n",
    "                                if len(pmid_certified_orcid) > 0:\n",
    "                                    entity[\"orcid\"] = pmid_certified_orcid\n",
    "                                    if citing_pmid in pmid_doi_map.keys():\n",
    "                                        pmid_doi_map[citing_pmid][\"has_orcid\"] = True\n",
    "\n",
    "\n",
    "                        issn_list = []\n",
    "                        journal_name = row[\"journal\"]\n",
    "                        if journal_name:\n",
    "                            if journal_name in journal_issn_dict.keys():\n",
    "                                for issn in journal_issn_dict[journal_name]:\n",
    "                                    issn_list.append(issn)\n",
    "\n",
    "                            else:\n",
    "                                if citing_doi is not None:\n",
    "                                    json_res = crossref_resource_finder._call_api(citing_doi)\n",
    "                                    if json_res is not None:\n",
    "                                        issn_set = crossref_resource_finder._get_issn(json_res)\n",
    "                                        if len(issn_set) > 0:\n",
    "                                            journal_issn_dict[journal_name] = []\n",
    "                                        for issn in issn_set:\n",
    "                                            issn_norm = issn_manager.normalise(str(issn))\n",
    "                                            issn_list.append(issn_norm)\n",
    "                                            journal_issn_dict[journal_name].append(issn_norm)\n",
    "                        else:\n",
    "                            if citing_doi is not None:\n",
    "                                json_res = crossref_resource_finder._call_api(citing_doi)\n",
    "                                if json_res is not None:\n",
    "                                    issn_set = crossref_resource_finder._get_issn(json_res)\n",
    "                                    for issn in issn_set:\n",
    "                                        issn_norm = issn_manager.normalise(str(issn))\n",
    "                                        issn_list.append(issn_norm)\n",
    "                        if issn_list != []:\n",
    "                            entity[\"issn\"] = issn_list\n",
    "\n",
    "                        csv_datasource.set(citing_pmid, entity)\n",
    "\n",
    "            pmid_doi_map = {k:v for k,v in pmid_doi_map.items() if v[\"has_orcid\"] is False}\n",
    "\n",
    "            if len(pmid_doi_map) > 0:\n",
    "                if id_orcid_dir and exists(id_orcid_dir):\n",
    "                    orcid_id_files, op = get_all_files_noci(id_orcid_dir)\n",
    "                    len_orcid_id_files = len(orcid_id_files)\n",
    "                    if len_orcid_id_files > 0:\n",
    "                        for f_idx, f in enumerate(orcid_id_files, 1):\n",
    "                            unzip_file = op(f, mode=\"r\")\n",
    "                            unzip_file = csv.DictReader(\n",
    "                                codecs.iterdecode(unzip_file, \"utf-8\")\n",
    "                            )\n",
    "                            for row in unzip_file:\n",
    "                                if [\n",
    "                                    k\n",
    "                                    for k, v in pmid_doi_map.items()\n",
    "                                    if v[\"doi\"] == row[\"id\"]\n",
    "                                ]:\n",
    "                                    c_pmid = [\n",
    "                                        k\n",
    "                                        for k, v in pmid_doi_map.items()\n",
    "                                        if v[\"doi\"] == row[\"id\"]\n",
    "                                    ][\n",
    "                                        0\n",
    "                                    ]\n",
    "                                    c_doi = doi_manager.normalise(row[\"id\"], False)\n",
    "                                    #DA TESTARE\n",
    "                                    orcid = re.search(\n",
    "                                        \"\\[(([X0-9]\\-?){4}){4}]\",\n",
    "                                        row[\"value\"],\n",
    "                                        re.IGNORECASE,\n",
    "                                    ).group(0)\n",
    "                                    author_name_parts = re.findall(\"[a-zA-Z\\'\\-áéíóúäëïöüÄłŁőŐűŰZàáâäãåąčćęèéêëėįìíîïłńòóôöõøùúûüųūÿýżźñçčšžÀÁÂÄÃÅĄĆČĖĘÈÉÊËÌÍÎÏĮŁŃÒÓÔÖÕØÙÚÛÜŲŪŸÝŻŹÑßÇŒÆČŠŽñÑâê]{2,}\", row[\"value\"])\n",
    "                                    author_name_parts_l = [np.lower() for np in author_name_parts]\n",
    "                                    authors_dicts_list = pmid_doi_map[c_pmid][\"all_authors_names\"]\n",
    "                                    matches = [dict for dict in authors_dicts_list if [sn for sn in dict[\"surnames\"] if sn in author_name_parts_l] and [l for l in dict[\"names\"] if any(element.startswith(l) and element not in dict[\"surnames\"] for element in author_name_parts_l)]]\n",
    "                                    if matches and orcid:\n",
    "                                        nor_orcid = orcid_manager.normalise(orcid)\n",
    "                                        if nor_orcid:\n",
    "                                            c_pmid_entity = csv_datasource.get(c_pmid)\n",
    "                                            if c_pmid_entity[\"orcid\"] is None:\n",
    "                                                c_pmid_entity[\"orcid\"] = []\n",
    "                                                c_pmid_entity[\"orcid\"].append(nor_orcid)\n",
    "                                            else:\n",
    "                                                c_pmid_entity[\"orcid\"] = list(c_pmid_entity[\"orcid\"])\n",
    "                                                c_pmid_entity[\"orcid\"].append(nor_orcid)\n",
    "\n",
    "                                            csv_datasource.set(c_pmid, c_pmid_entity)\n",
    "                                            if pmid_doi_map[c_pmid][\"has_orcid\"] == False:\n",
    "                                                pmid_doi_map[c_pmid][\"has_orcid\"] = True\n",
    "\n",
    "                if orcid_client_id and orcid_client_secret:\n",
    "                    for citing_pmid, d in pmid_doi_map.items():\n",
    "                        if d[\"has_orcid\"] == False:\n",
    "                            json_res = orcid_resource_finder._call_api(d[\"doi\"])\n",
    "                            if json_res is not None and len(json_res)> 0:\n",
    "                                # To do: check if absence of result with orcid resource finder\n",
    "                                # implies absence of result also with access token\n",
    "                                certified_orcid = []\n",
    "                                for orcid_dict in json_res:\n",
    "                                    json_uri = orcid_dict[\"orcid-identifier\"][\"uri\"]\n",
    "                                    chek_passed = check_author_identity_api(json_uri, d[\"all_authors_names\"], orcid_client_id, orcid_client_secret)\n",
    "                                    norm_orc = orcid_manager.normalise(json_uri)\n",
    "                                    if chek_passed and norm_orc:\n",
    "                                        certified_orcid.append(norm_orc)\n",
    "\n",
    "                                citing_pmid_dict = csv_datasource.get(citing_pmid)\n",
    "\n",
    "                                if len(certified_orcid) > 0:\n",
    "                                    d[\"has_orcid\"] = True\n",
    "                                    if citing_pmid_dict[\"orcid\"] is None:\n",
    "                                        citing_pmid_dict[\"orcid\"] = certified_orcid\n",
    "                                    else:\n",
    "                                        citing_pmid_dict[\"orcid\"].extend(certified_orcid)\n",
    "                                    csv_datasource.set(citing_pmid,citing_pmid_dict)\n",
    "\n",
    "\n",
    "            pmid_doi_map = dict()\n",
    "            issn_data_to_cache_noci(journal_issn_dict, output_dir)\n",
    "\n",
    "    middle = timer()\n",
    "\n",
    "    # print(\"first process duration: :\", (middle - start))\n",
    "    # print(\"\\n\\n# Checking the referenced pmids validity\")\n",
    "    for file_idx, file in enumerate(all_files, 1):\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        for chunk in pd.read_csv(file, chunksize=1000):\n",
    "            f = pd.concat([df, chunk], ignore_index=True)\n",
    "            f.fillna(\"\", inplace=True)\n",
    "            # print(\"Open file %s of %s\" % (file_idx, len_all_files))\n",
    "            for index, row in f.iterrows():\n",
    "                if row[\"references\"] != \"\":\n",
    "                    ref_string = row[\"references\"].strip()\n",
    "                    ref_string_norm = re.sub(\"\\s+\", \" \", ref_string)\n",
    "                    cited_pmids = set(ref_string_norm.split(\" \"))\n",
    "                    for cited_pmid in cited_pmids:\n",
    "                        cited_pmid = pmid_manager.normalise(cited_pmid, True)\n",
    "\n",
    "                        if cited_pmid is not None:\n",
    "                            cited_pmid_entity = csv_datasource.get(cited_pmid)\n",
    "                            if cited_pmid_entity is None:\n",
    "                                cited_pmid_entity = dict()\n",
    "                                cited_pmid_entity[\"valid\"] = (True if pmid_manager.is_valid(cited_pmid) else False)\n",
    "                                csv_datasource.set(cited_pmid, cited_pmid_entity)\n",
    "\n",
    "                if row[\"cited_by\"] != \"\":\n",
    "                    citing_string = row[\"cited_by\"].strip()\n",
    "                    citing_string_norm = re.sub(\"\\s+\", \" \", citing_string)\n",
    "                    citing_pmids = set(citing_string_norm.split(\" \"))\n",
    "                    for citing_p in citing_pmids:\n",
    "                        citing_p = pmid_manager.normalise(citing_p, True)\n",
    "                        if citing_p is not None:\n",
    "                            citing_p_entity = csv_datasource.get(citing_p)\n",
    "                            if citing_p_entity is None:\n",
    "                                citing_p_entity = dict()\n",
    "                                citing_p_entity[\"valid\"] = (True if pmid_manager.is_valid(citing_p) else False)\n",
    "                                csv_datasource.set(citing_p, citing_p_entity)\n",
    "\n",
    "    end = timer()\n",
    "    # print(\"second process duration: \", end-middle)\n",
    "    # print(\"full process duration: \", end-start)\n",
    "\n",
    "\n",
    "def main():\n",
    "    arg_parser = ArgumentParser(\n",
    "        \"Global files creator for NOCI\",\n",
    "        description=\"Process iCiteMetadata CSV files and create global indexes to enable the creation of NOCI.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-i\",\n",
    "        \"--input\",\n",
    "        dest=\"input\",\n",
    "        required=True,\n",
    "        help=\"Either the directory or the zip file that contains the iCiteMetadata data dump of CSV files.\",\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"-o\",\n",
    "        \"--output\",\n",
    "        dest=\"output\",\n",
    "        required=True,\n",
    "        help=\"The directory where the indexes are stored.\",\n",
    "    )\n",
    "\n",
    "    arg_parser.add_argument(\n",
    "        \"-n\",\n",
    "        \"--entities\",\n",
    "        dest=\"entities\",\n",
    "        required=True,\n",
    "        help=\"Interval of processed entities after which the issn data are saved to the cache file.\",\n",
    "    )\n",
    "\n",
    "    arg_parser.add_argument(\n",
    "        \"-iod\",\n",
    "        \"--orcid\",\n",
    "        dest=\"orcid\",\n",
    "        required=False,\n",
    "        help=\"Either the directory or the zip file that contains the id-orcid mapping data.\",\n",
    "    )\n",
    "\n",
    "    arg_parser.add_argument(\n",
    "        \"-oci\",\n",
    "        \"--orcid_client_id\",\n",
    "        dest=\"orcid_client_id\",\n",
    "        required=False,\n",
    "        help=\"ORCID credentials: orcid client ID, to double check that the identity of the authors declared in NIH \"\n",
    "             \"dump corresponds to the ORCID registry data. The credentials are required to obtain the token, which is\"\n",
    "             \"required in order to access ORCID public API. Client ID and Client secret can be required in the \"\n",
    "             \"Developer tools section of the ORCID platform.\",\n",
    "    )\n",
    "\n",
    "    arg_parser.add_argument(\n",
    "        \"-ocs\",\n",
    "        \"--orcid_client_secret\",\n",
    "        dest=\"orcid_client_secret\",\n",
    "        required=False,\n",
    "        help=\"ORCID credentials: orcid password, to double check that the identity of the authors declared in NIH \"\n",
    "             \"dump corresponds to the ORCID registry data. The credentials are required to obtain the token, which is\"\n",
    "             \"required in order to access ORCID public API. Client ID and Client secret can be required in the \"\n",
    "             \"Developer tools section of the ORCID platform.\",\n",
    "    )\n",
    "\n",
    "    args = arg_parser.parse_args()\n",
    "    process_noci(args.input, args.output, args.entities, args.orcid, args.orcid_client_id, args.orcid_client_secret)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# python \"scripts/glob_noci.py\" -i ./index/python/test/data/noci_glob_dump_input -o ./index/python/test/data/noci_glob_dump_output -n 7 -iod ./index/python/test/data/noci_id_orcid_mapping/doi_orcid_index.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call con Giuseppe:\n",
    "- abbiamo lanciato i test e corretto gli errori che sono emersi\n",
    "- merge delle due versioni di farm_revision\n",
    "- accesso a repository index: per limitare le possibilità di dover fare un altro merge manualmente, potrei essere inclusa come collaboratrice a index su github? così evitiamo di lavorare su delle versioni che diventano troppo diverse tra loro e sveltiamo i processi di modifica futuri."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Agent Code Fix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- su suggerimento di Arcangelo, ho sviluppato una versione del codice che porta avanti due processi in parallelo, guadagnando diverse ore. \n",
    "- purtroppo, per la versione che aggiorna automaticamente il json di riferimento, il report finale e le note ci vuole ancora quasi una giornata. Sto continuando a lavorarci collateralmente, ma per tirare fuori i dati per inviare le e-mail entro metà mese ho sviluppato ieri un'altra versione che tiene conto solo degli agent e dei referer di interesse, che impiega poche ore. Oggi pomeriggio avrò i primi risultati, che nella migliore delle ipotesi saranno già corretti. Nel peggiore dei casi potrebbero volerci massimo un altro paio di giorni, ma siamo a buon punto \n",
    "- per la gestione di user agent e referer simili tra loro ho utilizzato una funzione con SequenceMatcher(None, a, b).ratio() e sembra che i risultati abbiano più senso (permette di scartare le stringhe che sono simili perché magari hanno in comune solo il nome di una libreria utilizzata per la chiamata).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID Manager Repository "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- chiamata con Arcangelo ed Elia per creare la repository da cui sviluppare il pacchetto. \n",
    "- abbiamo deciso di attenerci prevalentemente alla versione degli id manager di Farm Revision. Isbn non c'era quindi ho fatto delle modifiche alla versione di arcangelo per integrarla. \n",
    "- ho fatto delle modifiche agli id manager per dividere quanto più possibile i metodi e mantenerli coerenti tra le varie sottoclassi. Non ho potuto sviluppare exists per isbn e issn (per orcid sì) perché le api sono a pagamento, quindi is valid è verificato solo tramite check digit \n",
    "- test con Elia di exists + modifica gestione risposta api per evitar errori "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13/09 - 20/09 (ID Manager update - User Agent and Referer Results - Meta Tables)<a class=\"anchor\" id=\"entry_22\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Agent and Referer Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ho continuato a modificare il codice e ho deciso di dividerlo in due parti per permettere una parallelizzazione maggiore. <b>Parte Uno</b>: Raccolta istanze User Agent e Referer e classificazione. Questa parte produce un repor sotto forma di json, dove le chiavi restano i referer /UA noti, e i valori sono liste contenenti le istanze raccolte. i (n) processi paralleli producono n json, che vengono uniti in un unico dizionario finale, da cui vengono eliminati i duplicati. Alla fine di questo processo c'è un controllo umano, per correggere eventuali classificazioni errate.<b>Parte Due</b>: Inizia un nuovo processo, sempre in parallelo, che però prende solo in considerazione i dati già classificati come rilevanti , e conteggia gli utilizzi, classificandoli per tipologia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fine processo ci siamo confrontate con Chiara e abbiamo finito il lavoro per l'anno 2022, mesi gennaio - giugno "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID Manager update\n",
    "#### DOI Regex\n",
    "Versione precedente:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "^doi:10\\\\..+/.+$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da <a href=\"https://www.doi.org/doi_handbook/2_Numbering.html#2.2\">Doi Handbook</a>. La sintassi del DOI prevede:\n",
    "<ol>\n",
    "    <li>Suffisso (assegnato al registrant) + prefisso(scelto dal registrant) separati da forward slash (pr / suf)</li>\n",
    "    <li>Nessun limite di lunghezza per prefisso, suffisso o doi in generale.</li>\n",
    "    <li>Case insensitive + può contenere ogni carattere unicode</li>\n",
    "    <li>Il DOI è una \"stringa opaca\", che significa che nessuna informazione definitiva può essere inferita dalla stringa stessa: le informazioni a cui fare fede sono quelle fornite nei metadati</li>\n",
    "    <li>Il prefisso si compone del Directory indicator (10.) seguito dal registrant code.</li>\n",
    "    <li>Attualmente vengono utilizzate quattro cifre ma non c'è nessuna regola che impone che il registrant code non possa essere altro (<a href=\"https://www.doi.org/overview/DOI_article_ELIS3.pdf\">Digital Object Identifier (DOI®\n",
    ") System - Norman Paskin</a>). Attualmente dovrebbero essere arrivati fino a nove cifre (come avevamo considerato nel progetto di <a href=\"https://github.com/open-sci/2020-2021-the-leftovers-20-code/blob/main/publishers.py\">Open Science</a>)</li>\n",
    "</ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "^doi:10\\.(\\d{4,9}|[^\\s/]+(\\.[^\\s/]+)*)/[^\\s]+$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In linea teorica, il formato prevede un <b>\"10.\" seguito da un prefisso (generalmente da 4 a 9 cifre, ma non è detto)</b> , separato <b>eventualmente</b> da <b>un punto a cui segue una seconda parte opzionale del prefisso</b>. un <b>forward slash</b> separa il tutto dal <b>suffisso</b>. Posto che il forward slash è utilizzato come separatore tra prefisso e suffisso, <b>ho assunto che il prefisso non potesse contenere un altro forward slash</b> (rendendo incomprensibile la separazione) <b>e che né prefisso né suffisso potessero contenere space characters</b>. Tutto il resto è accettato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refactoring id_manager class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li> <b>I metodi della classe base ora hanno un comportamento di default positivo, a parte normalise, che è rimasto abstract</b> e viene implemementato in ogni sottoclasse.</li>\n",
    "    <li> <b>Ora tutte le classi hanno la possibilità di prendere in input anche un dizionario con dati su validazioni pregresse</b>, onde evitare di utilizzare inutilmente le API</li>\n",
    "    <li> <b>A ISBN è stato aggiunto un metodo syntax_ok oltre al check digit</b>, che era già presente</li>\n",
    "    <li> <b>Il check digit è stato diviso dal syntax_ok</b>, in modo tale che venisse implementato <b>solo nelle classi  degli identificativi che permettono il check digit effettivo</b> (inteso in senso proprio e non esteso come prima), mentre il <b>syntax_ok è stato sviluppato come metodo in tutte le classi figlie</b>.</li>\n",
    "    <li><b>Test e update file glob.json</b>, da cui viene caricato il dizionario dei dati già noti</li>\n",
    "    <li>Confronto <b>con Elia: Proposta di aggiungere un parametro tipo get_extra_info=False a is_valid</b>, che viene <b>poi passato a exist</b>. Il vantaggio di mettere questo parametro inizializzato a False già in is_valid (e non solo in exist) permette, su richiesta, di ottenere informazioni aggiuntive (es. publisher, tipo di pubblicazione, ecc.). senza dover fare una seconda chiamata alle API, e di ottenere, insieme al booleano relativo alla validazione, anche un dizionario con i dati aggiuntivi recuperati. In alternativa, il parametro get_extra_info=False si potrebbe aggiungere solo ad exists, ma il vantaggio sarebbe limitato alle occasioni in cui si può chiamare exists da solo: nella maggior parte dei casi resterebbe la doppia chiamata alle API, dal momento che non si potrebbero recuperare le informazioni già nel corso della prima validazione.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparazione Tabelle Meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>Sono partita dal preprocessing e lo sto gestendo con la stessa impostazione usata per index. Dovendolo però reinserire in un altro progetto l'ho ristrutturato in classi, con una classe base da cui le istanze specifiche sono figlie</li>\n",
    "    <li>Tra i parametri ho inserito una lista di campi rilevanti che servono da filtro nel passaggio dal dump iniziale ai files ridotti (che poi diventano input del processo della sorgente specifica). Non ho controllato approfonditamente, ma dove posso trovare un elenco di campi rilevanti per meta? come gestisco la mancanza di informazioni? passo anche per le API? </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domande\n",
    "<ol>\n",
    "    <li>Chiedere ad Arcangelo come preferisce che io gestisca il lavoro su meta (faccio un fork?)</li>\n",
    "    <li>Per la gestione dei PMID in meta utilizzo direttamente oc_idmanager? o estendo il codice in meta?</li>\n",
    "    <li>Inseriamo in oc_idmanager i metaid? (mi pare che Davide parlasse di un idmanager</li>\n",
    "    <li>Chiedere a Giuseppe la gestione del lavoro che faceca storer/update.py</li>\n",
    "    <li>Chiedere per l'inserimento di get_extrainfi in validate</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- specifica nella documentazione del software la sintassi doi \n",
    "- fai fork repo di arca\n",
    "- parla con arca dei tipi accettati  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20/09 - 28/09 (OC_IDManager updates, OC_Meta Tables Update: preprocessing NIH + DC, processing DC, documentation study DC)<a class=\"anchor\" id=\"entry_23\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing (per Tabelle META): Conclusione NIH + Sviluppo DC + test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per quanto riguarda il preprocessing, ho finito di sviluppare la classe <a href=\"https://github.com/ariannamorettj/oc_meta/blob/master/oc_meta/preprocessing/base.py\">base</a> e le due <a href=\"https://github.com/ariannamorettj/oc_meta/tree/master/oc_meta/preprocessing\">classi per il preprocessing (NIH e DataCite)</a> in modo tale che nel processo effettivo si possano utilizzare dei dump già preprocessati. Ho aggiunto un test ai <a href=\"https://github.com/ariannamorettj/oc_meta/blob/master/test/preprocessing_test.py\">test</a> di meta per verificare che le classi funzionassero correttamente. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studio documentazione Meta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confronto con Arcangelo, discussione su tabelle meta, types di pubblicazioni e mappatura tra linguaggi controllati (ancora in corso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://github.com/opencitations/crowdsourcing/blob/main/docs/csv_documentation.pdf\">https://github.com/opencitations/crowdsourcing/blob/main/docs/csv_documentation.pdf</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sviluppo Processing DataCite e Studio preliminare Documentazione DataCite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documento di riferimento : <a href=\"https://schema.datacite.org/meta/kernel-4.4/doc/DataCite-MetadataKernel_v4.4.pdf\">DataCite Schema Documentation 4.4 (2021)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Informazioni Generali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In DataCite, le proprietà per convenzione vengono scritte con l'iniziale maiuscola, mentre le sottproprietà hanno l'iniziale minuscola. Le lettere iniziali di eventuali successive parole in una priprietà composta da più parole sono maiuscole. <br>\n",
    "Esiste una <b> lista degli elementi obbligatori</b>, che, qualora non fossero presenti tra i dati forniti dall'utente di DataCite, vanno sostituiti con dei riempitivi conformi ad uno degli standard accettati (machine-readable).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vincoli di Cardinalità/quantità"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<b>Domanda:</b> <i>Come è possibile che il vincolo di  cardinalità/quantità entri in contrasto con la divisione mandatory/optional? Sono vincolati tra loro? Ad esempio, per quanto riguarda i campi con vincolo di cardinalità \"richiesto\" tra le proprietà opzionali, ponendo che un campo opzionale sia quello delle pubblicazioni collegate, una volta che ho inserito una pubblicazione collegata a quel punto devo obbligatoriamente specificarne un identificativo? Oppure, nel caso di un campo con vincolo di cardinalità \"opzionale\" all'interno delle proprietà obbligatorie devo supporre che non sia necessario che io abbia a disposizione quel dato, ma che comparirà comunque tra i metadati della pubblicazione inserita, solo che il valore del campo sarà uno dei valori sostitutivi conformi a specifici schemi machine readable di cui si parlava sopra?</i><b>Oppure</b>, è possibile che ad essere obbligatori o opzionali siano soltanto le proprietà di primo livello, quelle principali, e che poi a loro volta le sottoproprietà possano essere obbligatorie o meno in maniera non correlata.<br>\n",
    "<b>\"Occurrence\"indicates cardinality/quantity constraints for the properties as follows</b>:\n",
    "<ol>\n",
    "    <li>0-n = optional and repeatable</li>\n",
    "    <li>0-1 = optional, but not repeatable</li>\n",
    "    <li>1-n = required and repeatable</li>\n",
    "    <li>1 = required, but not repeatable</li>\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Mandatory properties</b>\n",
    "<ol>\n",
    "    <li><b>[1] Identifier (1)</b></li>\n",
    "    <li><b>[1.a] identifierType (1)</b>. Controlled List Value: DOI</li>\n",
    "    <li><b>[2] Creator (1-n)</b>. May be a corporate/institutional or personal name. Note: DataCite infrastructure supports up to 10,000 names. For name lists above that size, consider attribution via linking to the related metadata</li>\n",
    "    <li><b>[2.1] creatorName(1)</b>. Note that the personal name, format should be: family, given. Names in non-roman scripts may be transliterated according to the ALA-LC tables</li>\n",
    "    <li><b>[2.1.a] nameType (0-1)</b>Controlled List Values: <ol><li>Organizational</li><li>Personal (default)</li></ol></li>\n",
    "    <li><b>[2.2] givenName (0-1)</b></li>\n",
    "    <li><b>[2.3] familyName (0-1)</b></li>\n",
    "    <li><b>[2.4] nameIdentifier (0-n)</b>. Uniquely identifies an individual or legal entity, according to various schemes. The format is dependent upon scheme.</li>\n",
    "    <li><b>[2.4.a] nameIdentifierScheme (1)</b>: The name of the name identifier scheme. <b>If nameIdentifier is used, nameIdentifierScheme is mandatory.\n",
    "</b>Examples: ORCID, ISNI, ROR,GRID</li>\n",
    "    <li><b>[2.4.b] schemeURI (0-1)</b></li>\n",
    "    <li><b>[2.5] affiliation (0-n)</b>. Affiliation of the creator, free text</li>\n",
    "    <li><b>[2.5.a] affiliationIdentifier (0-n)</b>. Uniquely identifies the organizational affiliation of the creator, the format depends upon the scheme, e.g. ror format</li>\n",
    "    <li><b>[2.5.b] affiliationIdentifierScheme (1)</b>. Name of the affiliation identifier scheme, e.g. ROR</li>\n",
    "    <li><b>[2.5.c] SchemeURI (0-1)</b></li>\n",
    "    <li><b>[3] Title (1-n)</b>. Free text</li>\n",
    "    <li><b>[3.a] titleType (0-1)</b> Controlled List of Values <ol><li>AlternativeTitle</li><li>Subtitle</li><li>TranslatedTitle</li><li>Other</li></ol></li>\n",
    "    <li><b>[4] Publisher (1)</b>. The name of the entity that holds, archives, publishes prints, distributes, releases, issues, or produces the resource. This property will be used to formulate the citation, so consider the prominence of the role. For software, use Publisher for the code repository. If there is an entity other than a code repository, that \"holds, archives, publishes, prints, distributes, releases, issues, or produces\" the code, use the property Contributor/contributorType/ hostingInstitution for the code repository.</li>\n",
    "    <li><b>[5] PublicationYear (1)</b>. The year when the data was or will be made publicly available. In the case of resources such as software or dynamic data where there may be multiple releases in one year, include the Date/dateType/ dateInformation property and sub-properties to provide more information about the publication or release date details.</li>\n",
    "    <li><b>[10] ResourceType (1)</b>. A description of the resource in free format text</li>\n",
    "    <li><b>[10.a] resourceTypeGeneral (1)</b>. General type of a resource, described with a controlled list of values <ol><li>Audiovisual</li>\n",
    "        <li>Book</li>\n",
    "        <li>BookChapter</li>\n",
    "        <li>Collection</li>\n",
    "        <li>ComputationalNotebook</li>\n",
    "        <li>ConferencePaper</li>\n",
    "        <li>ConferenceProceeding</li>\n",
    "        <li>DataPaper</li>\n",
    "        <li>Dataset</li>\n",
    "        <li>Dissertation</li>\n",
    "        <li>Event</li>\n",
    "        <li>Image</li>\n",
    "        <li>InteractiveResource</li>\n",
    "        <li>Journal</li>\n",
    "        <li>JournalArticle</li>\n",
    "        <li>Model</li>\n",
    "        <li>OutputManagementPlan</li>\n",
    "        <li>PeerReview</li>\n",
    "        <li>PhysicalObject</li>\n",
    "        <li>Preprint</li>\n",
    "        <li>Report</li>\n",
    "        <li>Service</li>\n",
    "        <li>Software</li>\n",
    "        <li>Sound</li>\n",
    "        <li>Standard</li>\n",
    "        <li>Text</li>\n",
    "        <li>Workflow</li>\n",
    "        <li>Other</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "</ol>\n",
    "C'è un'appendice che definisce più dettagliatamente i valori controllati elencati sopra. (<a href=\"https://schema.datacite.org/meta/kernel-4.4/doc/DataCite-MetadataKernel_v4.4.pdf\">Appendice, pag 47, resourceTypeGeneral</a>)<br>\n",
    "<b>NOTA/DOMANDA:</b> Ho notato che nel mio dump molte entry sono classificate come \"text\" perché diverse delle voci sopraelencate sono state inserite solo nell'ultima versione dello schema di datacite (2021). Questo implica che tutti i dati in DataCite precedenti il 2021 hanno i journal Article classificati come \"Text\", almeno nel campo resourceTypeGeneral. <b>Ci sono altri sottocampi opzionali del campo \"types\" che possono fornire un'informazione più precisa, ma questo implicherebbe fare un ulteriore controllo che comporterebbe una mappatura più ampia, tra almeno tre o quattro liste di valori controllati (schemi)</b>. Come la gestisco?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources type mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empiricamente, ho notato che i sei sottocampi di \"types\" nel dump di datacite sono i seguenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'types': {'ris': 'JOUR',\n",
       "  'bibtex': 'article',\n",
       "  'citeproc': 'article-journal',\n",
       "  'schemaOrg': 'ScholarlyArticle',\n",
       "  'resourceType': 'JournalArticle',\n",
       "  'resourceTypeGeneral': 'Text'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"types\": \n",
    " {\"ris\": \"JOUR\", \n",
    "  \"bibtex\": \"article\", \n",
    "  \"citeproc\": \"article-journal\", \n",
    "  \"schemaOrg\": \"ScholarlyArticle\", \n",
    "  \"resourceType\": \"JournalArticle\", \n",
    "  \"resourceTypeGeneral\": \"Text\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'types': {'ris': 'CHAP',\n",
       "  'bibtex': 'inbook',\n",
       "  'citeproc': 'chapter',\n",
       "  'schemaOrg': 'Chapter',\n",
       "  'resourceType': 'BookChapter',\n",
       "  'resourceTypeGeneral': 'Text'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " {\"types\":\n",
    "   {\"ris\": \"CHAP\", \n",
    "  \"bibtex\": \"inbook\", \n",
    "  \"citeproc\": \"chapter\", \n",
    "  \"schemaOrg\": \"Chapter\", \n",
    "  \"resourceType\": \"BookChapter\", \n",
    "  \"resourceTypeGeneral\": \"Text\"}   \n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Osservazioni / Domande</b>\n",
    "<ul>\n",
    "    <li>Gli unici due campi menzionati chiaramente in documentazione sono <b>resourceType</b> e <b>resourceTypeGeneral</b></li>\n",
    "    <li>Il motivo per cui non userei <b>resourceType</b> è che secondo documentazione il valore di questo campo dovrebbe essere \"free text\". Empiricamente non sembrerebbe (pare che segua in qualche modo un vocabolario controllato), tuttavia non credo sia affidabile per questo motivo </li>\n",
    "    <li><b>resourceTypeGeneral</b> ad oggi sembrerebbe l'opzione migliore perché è un campo obbligatorio e segue un vocabolario controllato. Tuttavia in questo caso il problema principale sta nel fatto che la maggior parte dei termini (tra cui anche alcuni molto comuni, come l'equivalente di JournalArticle, sono stati introdotti solo nella versione 4.4 rilasciata l'anno scorso. Per questo motivo nelle risorse caricate prima di quest'anno nella stragrande maggioranza dei casi il valore utilizzato è sempre \"Text\", che è poco preciso e poco informativo.</li>\n",
    "    <li>Per quanto riguarda i restanti 4 (bibtex, citeproc, schemaOrg, ris), non trovo in nessun punto della documentazione un riferimento alla possibilità di utilizzarli in alternativa a resourceType o resourceTypeGeneral. Vengono menzionati come \"supported formats\" nella pagina delle guides <a href=\"https://support.datacite.org/docs/how-can-i-map-different-metadata-formats-to-the-datacite-xml\">How can I map different metadata formats to the DataCite schema?</a>, dove comunque non ci sono riferimenti relativi ai datatypes. Nella pagina esplicitamente dedicata ai <a href=\"https://support.datacite.org/docs/what-are-the-resource-types-for-datacite-dois\">datatypes</a> non si parla invece di mappatura.</li>\n",
    "    <li>Di conseguenza, mi verrebbe da pensare che la mappatura sia a discrezione del singolo (?) e che questo renda inefficace ogni tentativo di mappatura a posteriori che permetta di ricondurre in maniera affidabile i datatypes di DataCite a quelli di Meta.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Domanda:</b> Sto lavorando ad un mapping tra resourceTypeGeneral e Meta (Fabio) e sono indecisa se estenderlo anche agli altri vocabolari controllati. L'idea sarebbe quella di avere a disposizione un metodo all'interno del processing di DataCite che riconduce il resource type trovato all'equivalente in Meta. Arcangelo suggerisce di fare controlli a cascata. Cosa ne pensate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Recommended and Optional Properties (selezione di dati utili per index o meta)</b>\n",
    "    <ol>\n",
    "        <li><b>[7] Contributor (0-n)</b>. The institution or person, responsible for collecting, managing, distributing, or otherwise contributing to the development of the resource. To supply multiple contributors,\\n\",\n",
    "    \"repeat this property.\\n\",\n",
    "    \"For software, if there is an\\n\",\n",
    "    \"alternate entity that \\\"holds,\\n\",\n",
    "    \"archives, publishes, prints,\\n\",\n",
    "    \"distributes, releases, issues, or produces\\\" the code, use the\\n\",\n",
    "    \"contributorType\\n\",\n",
    "    \"\\\"hostingInstitution\\\" for the code\\n\",\n",
    "    \"repository.</li>\\n\",\n",
    "    \"    <li><b>[7.a] contributorType(1)</b>. The type of contributor of the\\n\",\n",
    "    \"resource. If Contributor is used, then\\n\",\n",
    "    \"        contributorType is mandatory. <ol>\\n\",\n",
    "    \"        <li>ContactPerson</li>\\n\",\n",
    "    \"        <li>DataCollector</li>\\n\",\n",
    "    \"        <li>DataCurator</li>\\n\",\n",
    "    \"        <li>DataManager</li>\\n\",\n",
    "    \"        <li>Distributor: Institution tasked with\\n\",\n",
    "    \"responsibility to\\n\",\n",
    "    \"generate/disseminate copies of\\n\",\n",
    "    \"the resource in either electronic or\\n\",\n",
    "    \"print form. Works stored in more than one\\n\",\n",
    "    \"archive/repository may credit each\\n\",\n",
    "    \"as a distributor.</li>\\n\",\n",
    "    \"        <li><b>Editor</b>: A person who oversees the details\\n\",\n",
    "    \"related to the publication format\\n\",\n",
    "    \"of the resource\\n\",\n",
    "    \"Note: if the Editor is to be credited\\n\",\n",
    "    \"in place of multiple creators, the\\n\",\n",
    "    \"Editor’s name may be supplied as\\n\",\n",
    "    \"Creator, with “(Ed.)” appended to\\n\",\n",
    "    \"the name.</li>\\n\",\n",
    "    \"        <li>HostingInstitution</li>\\n\",\n",
    "    \"        <li>Producer</li>\\n\",\n",
    "    \"        <li>ProjectLeader</li>\\n\",\n",
    "    \"        <li>ProjectManager</li>\\n\",\n",
    "    \"        <li>ProjectMember</li>\\n\",\n",
    "    \"        <li>RegistrationAgency: Institution/organisation officially\\n\",\n",
    "    \"appointed by a Registration\\n\",\n",
    "    \"Authority to handle specific tasks\\n\",\n",
    "    \"within a defined area of\\n\",\n",
    "    \"responsibility\\n\",\n",
    "    \"DataCite is a Registration Agency\\n\",\n",
    "    \"for the International DOI\\n\",\n",
    "    \"Foundation (IDF). One of\\n\",\n",
    "    \"DataCite’s tasks is to assign DOI\\n\",\n",
    "    \"prefixes to the allocating agents\\n\",\n",
    "    \"who then assign the full, specific\\n\",\n",
    "    \"character string to data clients,\\n\",\n",
    "    \"provide metadata back to the\\n\",\n",
    "    \"DataCite registry, etc.</li>\\n\",\n",
    "    \"        <li>RegistrationAuthority: A standards-setting body from\\n\",\n",
    "    \"which Registration Agencies obtain\\n\",\n",
    "    \"official recognition and guidance\\n\",\n",
    "    \"The IDF serves as the Registration\\n\",\n",
    "    \"Authority for the International\\n\",\n",
    "    \"Standards Organisation (ISO) in the\\n\",\n",
    "    \"area/domain of Digital Object\\n\",\n",
    "    \"Identifiers.</li>        \\n\",\n",
    "    \"        <li>RelatedPerson</li>\\n\",\n",
    "    \"        <li>Researcher</li>        \\n\",\n",
    "    \"        <li>ResearchGroup</li>\\n\",\n",
    "    \"        <li>RightsHolder</li>        \\n\",\n",
    "    \"        <li>Sponsor</li>\\n\",\n",
    "    \"        <li>Supervisor</li>        \\n\",\n",
    "    \"        <li>WorkPackageLeader</li>\\n\",\n",
    "    \"        <li>Other</li>        \\n\",\n",
    "    \"        </ol>\\n\",\n",
    "    \"    </li>\\n\",\n",
    "    \"    <li><b>[7.1] contributorName (1)</b>. The full name of the contributor If Contributor is used, then\\n\",\n",
    "    \"contributorName is\\n\",\n",
    "    \"mandatory.\\n\",\n",
    "    \"Examples: Patel, Emily; ABC\\n\",\n",
    "    \"Foundation\\n\",\n",
    "    \"The personal name format\\n\",\n",
    "    \"should be: family, given. Nonroman names should be transliterated according to the\\n\",\n",
    "    \"ALA-LC schemas</li>\\n\",\n",
    "    \"    <li><b>[7.4] nameIdentifier ()0-n</b>. Uniquely identifies an individual\\n\",\n",
    "    \"or legal entity, according to\\n\",\n",
    "    \"various schemes\\n\",\n",
    "    \"The format is dependent upon\\n\",\n",
    "    \"scheme.</li>\\n\",\n",
    "    \"    <li><b>[7.4.a] nameIdentifierScheme (1) </b>. The name of the name identifier scheme. If nameIdentifier is used, nameIdentifierScheme is\\n\",\n",
    "    \"mandatory. Examples: ORCID, ISNI, ROR, GRID\\n\",\n",
    "    \" </li>\\n\",\n",
    "    \"    <li><b>[8] Date (0-n)</b>. Different dates relevant to the\\n\",\n",
    "    \"work\\n\",\n",
    "    \"YYYY, YYYY-MM-DD, YYYYMM-DDThh:mm:ssTZD or any\\n\",\n",
    "    \"other format or level of\\n\",\n",
    "    \"granularity described in\\n\",\n",
    "    \"W3CDTF. Use RKMSISO8601 standard for\\n\",\n",
    "    \"depicting date ranges.</li>\\n\",\n",
    "    \"    <li><b>[8.a] dateType (1)</b>. The type of date If Date is used, dateType is\\n\",\n",
    "    \"mandatory.\\n\",\n",
    "    \"        Controlled List Values: <ol>\\n\",\n",
    "    \"        <li><b>Accepted</b>: The date that the publisher accepted the\\n\",\n",
    "    \"resource into their system\\n\",\n",
    "    \"To indicate the start of an embargo\\n\",\n",
    "    \"period, use Submitted or\\n\",\n",
    "    \"Accepted, as appropriate</li>\\n\",\n",
    "    \"        <li><b>Available</b>: The date the resource is made publicly\\n\",\n",
    "    \"available. May be a range.\\n\",\n",
    "    \"To indicate the end of an embargo\\n\",\n",
    "    \"period, use Available.</li>\\n\",\n",
    "    \"        <li><b>Copyrighted</b>: The specific, documented date at which the resource receives a copyrighted status, if applicable</li>\\n\",\n",
    "    \"        <li><b>Collected</b>: The date or date range in which the resource content was collected\\n\",\n",
    "    \"To indicate precise or particular\\n\",\n",
    "    \"timeframes in which research was\\n\",\n",
    "    \"conducted.</li>\\n\",\n",
    "    \"        <li><b>Created</b>: The date the resource itself was put\\n\",\n",
    "    \"together; this could refer to a timeframe in\\n\",\n",
    "    \"ancient history, a date range, or a single date\\n\",\n",
    "    \"for a final component, e.g., the finalised file\\n\",\n",
    "    \"with all the data.\\n\",\n",
    "    \"Recommended for discovery.</li>\\n\",\n",
    "    \"        <li><b>Issued</b>: The date that the resource is published or\\n\",\n",
    "    \"distributed, e.g., to a data centre</li>\\n\",\n",
    "    \"        <li><b>Submitted</b>: The date the creator submits the resource to\\n\",\n",
    "    \"the publisher. This could be different from\\n\",\n",
    "    \"Accepted if the publisher then applies a\\n\",\n",
    "    \"selection process.\\n\",\n",
    "    \"Recommended for discovery.\\n\",\n",
    "    \"To indicate the start of an embargo\\n\",\n",
    "    \"period, use Submitted or\\n\",\n",
    "    \"Accepted, as appropriate.</li>\\n\",\n",
    "    \"        <li><b>Updated</b>: The date of the last update to the resource,\\n\",\n",
    "    \"when the resource is being added to. May be\\n\",\n",
    "    \"a range.</li>\\n\",\n",
    "    \"        <li><b>Valid</b>: The date or date range during which the\\n\",\n",
    "    \"dataset or resource is accurate.</li>\\n\",\n",
    "    \"        <li><b>Withdrawn</b>: The date the resource is removed It is good practice to include a\\n\",\n",
    "    \"Description that indicates the\\n\",\n",
    "    \"reason for the retraction or\\n\",\n",
    "    \"withdrawal.</li>\\n\",\n",
    "    \"        <li><b>Other</b></li>\\n\",\n",
    "    \"        </ol></li>\\n\",\n",
    "    \"    <li><b>[12] RelatedIdentifier (0-n)</b>: Identifiers of related resources.\\n\",\n",
    "    \"These must be globally unique\\n\",\n",
    "    \"identifiers.\\n\",\n",
    "    \"Free text\\n\",\n",
    "    \"***\\n\",\n",
    "    \"Note: DataCite Event Data24\\n\",\n",
    "    \"collects all references to\\n\",\n",
    "    \"related resources based on\\n\",\n",
    "    \"the relatedIdentifier property.</li>\\n\",\n",
    "    \"    <li><b>[12.a] relatedIdentifierType (1) The type of the RelatedIdentifier If relatedIdentifier is used,\\n\",\n",
    "    \"relatedIdentifierType is\\n\",\n",
    "    \"mandatory.\\n\",\n",
    "    \"Controlled List Values: (ARK\\n\",\n",
    "    \"arXiv\\n\",\n",
    "    \"bibcode\\n\",\n",
    "    \"DOI\\n\",\n",
    "    \"EAN13\\n\",\n",
    "    \"EISSN\\n\",\n",
    "    \"Handle\\n\",\n",
    "    \"IGSN\\n\",\n",
    "    \"ISBN\\n\",\n",
    "    \"ISSN\\n\",\n",
    "    \"ISTC\\n\",\n",
    "    \"LISSN\\n\",\n",
    "    \"LSID\\n\",\n",
    "    \"PMID\\n\",\n",
    "    \"PURL\\n\",\n",
    "    \"UPC\\n\",\n",
    "    \"URL\\n\",\n",
    "    \"URN\\n\",\n",
    "    \"w3id)</b></li>\\n\",\n",
    "    \"    <li><b>[12.b] relationType (1)</b>: Description of the relationship of\\n\",\n",
    "    \"the resource being registered (A)\\n\",\n",
    "    \"and the related resource (B)\\n\",\n",
    "    \"If RelatedIdentifier is used,\\n\",\n",
    "    \"relationType is mandatory.\\n\",\n",
    "    \"Controlled List Values:\\n\",\n",
    "    \"        <b>IsCitedBy</b>\\n\",\n",
    "    \"        <b>Cites</b>\\n\",\n",
    "    \"IsSupplementTo\\n\",\n",
    "    \"IsSupplementedBy\\n\",\n",
    "    \"IsContinuedBy\\n\",\n",
    "    \"Continues\\n\",\n",
    "    \"IsDescribedBy\\n\",\n",
    "    \"Describes\\n\",\n",
    "    \"HasMetadata\\n\",\n",
    "    \"IsMetadataFor\\n\",\n",
    "    \"HasVersion\\n\",\n",
    "    \"IsVersionOf\\n\",\n",
    "    \"IsNewVersionOf\\n\",\n",
    "    \"IsPreviousVersionOf\\n\",\n",
    "    \"<b>IsPartOf</b>\\n\",\n",
    "    \"HasPart\\n\",\n",
    "    \"IsPublishedIn\\n\",\n",
    "    \"<b>IsReferencedBy</b>\\n\",\n",
    "    \"<b>References</b>\\n\",\n",
    "    \"IsDocumentedBy\\n\",\n",
    "    \"Documents\\n\",\n",
    "    \"IsCompiledBy\\n\",\n",
    "    \"Compiles\\n\",\n",
    "    \"IsVariantFormOf\\n\",\n",
    "    \"IsOriginalFormOf\\n\",\n",
    "    \"IsIdenticalTo\\n\",\n",
    "    \"IsReviewedBy\\n\",\n",
    "    \"Reviews\\n\",\n",
    "    \"IsDerivedFrom\\n\",\n",
    "    \"IsSourceOf\\n\",\n",
    "    \"IsRequiredBy\\n\",\n",
    "    \"Requires\\n\",\n",
    "    \"IsObsoletedBy\\n\",\n",
    "    \"Obsoletes</li>\\n\",\n",
    "    \"    <li><b>[20!!! Per index non per meta]RelatedItem (0-n)</b>: Information about a resource\\n\",\n",
    "    \"related to the one being\\n\",\n",
    "    \"registered, e.g., a journal or\\n\",\n",
    "    \"book of which the article or\\n\",\n",
    "    \"chapter is part\\n\",\n",
    "    \"Can be used to provide series\\n\",\n",
    "    \"information or a text citation\\n\",\n",
    "    \"where the related resource\\n\",\n",
    "    \"does not have an identifier.\\n\",\n",
    "    \"However, it is also optional\\n\",\n",
    "    \"to provide an identifier here.</li>\\n\",\n",
    "    \"    <li><b>[20.b] relationType (1)</b>: Description of the relationship\\n\",\n",
    "    \"of the resource being registered\\n\",\n",
    "    \"(A) and the related resource (B)\\n\",\n",
    "    \"Use the controlled list values\\n\",\n",
    "    \"as stated in 12.b.</li>\\n\",\n",
    "    \"    <li><b>[20.1] relatedItemIdentifier (0-1)</b>: The identifier for the related item (Use the controlled list values\\n\",\n",
    "    \"as stated in 12.a.)</li>\\n\",\n",
    "    \"</ol>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OC_IDManager "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creazione metodo extra_info in classe base, integrazione nel codice di tutte le classi figlie e sviluppo completo per PMID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def extra_info(self, api_response):\n",
    "        \"\"\"  Returns a dictionary with extra info about the id, if available.\n",
    "        Not all child classes check id existence because of API policies\n",
    "        Args:\n",
    "            api_response (json or string): the api response of the api request\n",
    "        Returns:\n",
    "            dict: A dictionary with additional information about the id, if provided by the API.\n",
    "        \"\"\"\n",
    "        return {\"value\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def extra_info(self, api_response):\n",
    "        result = {}\n",
    "        result[\"valid\"] = True\n",
    "\n",
    "        try:\n",
    "            title = \"\"\n",
    "            fa_title = re.findall(\"[^BV]TI\\s*-\\s*([\\S\\s]*?)\\n[A-Z]{2,5}\\s*-\\s*\", api_response)\n",
    "            for i in fa_title:\n",
    "                t = re.sub(\"\\s+\", \" \", i)\n",
    "                norm_title = t.strip()\n",
    "                if norm_title is not None:\n",
    "                    title = norm_title\n",
    "                    break\n",
    "        except:\n",
    "            title = \"\"\n",
    "\n",
    "        result[\"title\"] = title\n",
    "\n",
    "        try:\n",
    "            authors = set()\n",
    "            fa_aut = re.findall(\"FAU\\s*-\\s*.*[^\\n]\", api_response)\n",
    "            for i in fa_aut:\n",
    "                fau = re.search(\"(?:FAU\\s*-\\s*)?(.+)(?:\\n)?\", i).group(1)\n",
    "                norm_fau = fau.strip()\n",
    "                if norm_fau is not None:\n",
    "                    authors.add(norm_fau)\n",
    "            authorsList = list(authors)\n",
    "        except:\n",
    "            authorsList = []\n",
    "\n",
    "        result[\"author\"] = authorsList\n",
    "\n",
    "        try:\n",
    "            date = re.search(\n",
    "                \"DP\\s+-\\s+(\\d{4}(\\s?(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec))?(\\s?((3[0-1])|([1-2][0-9])|([0]?[1-9])))?)\",\n",
    "                api_response,\n",
    "                re.IGNORECASE,\n",
    "            ).group(1)\n",
    "            re_search = re.search(\n",
    "                \"(\\d{4})\\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s+((3[0-1])|([1-2][0-9])|([0]?[1-9]))\",\n",
    "                date,\n",
    "                re.IGNORECASE,\n",
    "            )\n",
    "            if re_search is not None:\n",
    "                src = re_search.group(0)\n",
    "                datetime_object = datetime.strptime(src, \"%Y %b %d\")\n",
    "                pmid_date = datetime.strftime(datetime_object, \"%Y-%m-%d\")\n",
    "            else:\n",
    "                re_search = re.search(\n",
    "                    \"(\\d{4})\\s+(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\",\n",
    "                    date,\n",
    "                    re.IGNORECASE,\n",
    "                )\n",
    "                if re_search is not None:\n",
    "                    src = re_search.group(0)\n",
    "                    datetime_object = datetime.strptime(src, \"%Y %b\")\n",
    "                    pmid_date = datetime.strftime(datetime_object, \"%Y-%m\")\n",
    "                else:\n",
    "                    re_search = re.search(\"(\\d{4})\", date)\n",
    "                    if re_search is not None:\n",
    "                        src = re.search(\"(\\d{4})\", date).group(0)\n",
    "                        datetime_object = datetime.strptime(src, \"%Y\")\n",
    "                        pmid_date = datetime.strftime(datetime_object, \"%Y\")\n",
    "                    else:\n",
    "                        pmid_date = \"\"\n",
    "        except:\n",
    "            pmid_date = \"\"\n",
    "        result[\"date\"] = pmid_date\n",
    "\n",
    "        try:\n",
    "            issnset = set()\n",
    "            fa_issn = re.findall(\"IS\\s+-\\s+[0-9]{4}-[0-9]{3}[0-9X]\", api_response)\n",
    "            for i in fa_issn:\n",
    "                issn = re.search(\"[0-9]{4}-[0-9]{3}[0-9X]\", i).group(0)\n",
    "                norm_issn = self._im.normalise(issn, include_prefix=True)\n",
    "                if norm_issn is not None:\n",
    "                    issnset.add(norm_issn)\n",
    "            issnlist = list(issnset)\n",
    "        except:\n",
    "            issnlist = []\n",
    "\n",
    "        try:\n",
    "            jur_title = \"\"\n",
    "            fa_jur = re.findall(\"JT\\s*-\\s*.*[^\\n]\", api_response)\n",
    "            for i in fa_jur:\n",
    "                jt = re.search(\"(?:JT\\s*-\\s*)?(.+)(?:\\n)?\", i).group(1)\n",
    "                norm_jour = jt.strip()\n",
    "                if norm_jour is not None:\n",
    "                    jur_title = norm_jour\n",
    "                    break\n",
    "        except:\n",
    "            jur_title = \"\"\n",
    "\n",
    "        result[\"venue\"] = (f'{jur_title} {[x for x in issnlist]}' if jur_title else str(issnlist).replace(\",\", \"\")).replace(\"'\",\"\")\n",
    "\n",
    "        try:\n",
    "            volume = \"\"\n",
    "            fa_volume = re.findall(\"VI\\s*-\\s*.*[^\\n]\", api_response)\n",
    "            for i in fa_volume:\n",
    "                vi = re.search(\"(?:VI\\s*-\\s*)?(.+)(?:\\n)?\", i).group(1)\n",
    "                norm_volume = vi.strip()\n",
    "                if norm_volume is not None:\n",
    "                    volume = norm_volume\n",
    "                    break\n",
    "        except:\n",
    "            volume = \"\"\n",
    "\n",
    "        result[\"volume\"] = volume\n",
    "\n",
    "        try:\n",
    "            issue = \"\"\n",
    "            fa_issue = re.findall(\"IP\\s*-\\s*.*[^\\n]\", api_response)\n",
    "            for i in fa_issue:\n",
    "                vi = re.search(\"(?:IP\\s*-\\s*)?(.+)(?:\\n)?\", i).group(1)\n",
    "                norm_issue = vi.strip()\n",
    "                if norm_issue is not None:\n",
    "                    issue = norm_issue\n",
    "                    break\n",
    "        except:\n",
    "            issue = \"\"\n",
    "\n",
    "        result[\"issue\"] = issue\n",
    "\n",
    "        try:\n",
    "            pag = \"\"\n",
    "            fa_pag = re.findall(\"PG\\s*-\\s*.*[^\\n]\", api_response)\n",
    "            for i in fa_pag:\n",
    "                pg = re.search(\"(?:PG\\s*-\\s*)?(.+)(?:\\n)?\", i).group(1)\n",
    "                norm_pag = pg.strip()\n",
    "                if norm_pag is not None:\n",
    "                    pag = norm_pag\n",
    "                    break\n",
    "        except:\n",
    "            pag = \"\"\n",
    "\n",
    "        result[\"page\"] = pag\n",
    "\n",
    "        try:\n",
    "            pub_types = set()\n",
    "            types = re.findall(\"PT\\s*-\\s*.*[^\\n]\", api_response)\n",
    "            for i in types:\n",
    "                ty = re.search(\"(?:PT\\s*-\\s*)?(.+)(?:\\n)?\", i).group(1)\n",
    "                norm_type = ty.strip().lower()\n",
    "                if norm_type is not None:\n",
    "                    pub_types.add(norm_type)\n",
    "            typeslist = list(pub_types)\n",
    "        except:\n",
    "            typeslist = []\n",
    "\n",
    "        result[\"types\"] = typeslist\n",
    "\n",
    "        try:\n",
    "            publisher = set()\n",
    "            publishers = re.findall(\"PB\\s*-\\s*.*[^\\n]\", api_response)\n",
    "            for i in publishers:\n",
    "                pbs = re.search(\"(?:PB\\s*-\\s*)?(.+)(?:\\n)?\", i).group(1)\n",
    "                norm_pbs = pbs.strip()\n",
    "                if norm_pbs is not None:\n",
    "                    publisher.add(norm_pbs)\n",
    "            publisherlist = list(publisher)\n",
    "        except:\n",
    "            publisherlist = []\n",
    "\n",
    "        result[\"publisher\"] = publisherlist\n",
    "\n",
    "        try:\n",
    "            editor = set()\n",
    "            editors = re.findall(\"F*ED\\s*-\\s*.*[^\\n]\", api_response)\n",
    "            for i in editors:\n",
    "                ed = re.search(\"(?:F*ED\\s*-\\s*)?(.+)(?:\\n)?\", i).group(1)\n",
    "                norm_ed = ed.strip()\n",
    "                if norm_ed is not None:\n",
    "                    editor.add(norm_ed)\n",
    "            editorlist = list(editor)\n",
    "        except:\n",
    "            editorlist = []\n",
    "\n",
    "        result[\"editor\"] = editorlist\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrazione per salvataggio dati processati in dizionario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integrato in tutte le classi, esempio: PMID\n",
    "    def is_valid(self, pmid, get_extra_info=False):\n",
    "        pmid = self.normalise(pmid, include_prefix=True)\n",
    "\n",
    "        if pmid is None:\n",
    "            return False\n",
    "        else:\n",
    "            if pmid not in self._data or self._data[pmid] is None:\n",
    "                if get_extra_info:\n",
    "                    info = self.exists(pmid, get_extra_info=True)\n",
    "                    self._data[pmid] = info[1]\n",
    "                    return (info[0] and self.syntax_ok(pmid)), info[1]\n",
    "                self._data[pmid] = dict()\n",
    "                self._data[pmid][\"valid\"] = True if (self.exists(pmid) and self.syntax_ok(pmid)) else False\n",
    "                return self._data[pmid].get(\"valid\")\n",
    "\n",
    "            if get_extra_info:\n",
    "                return self._data[pmid].get(\"valid\"), self._data[pmid]\n",
    "            return self._data[pmid].get(\"valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Documentazione OC_IDManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentazione in <a href=\"https://github.com/opencitations/identifier_manager/blob/main/README.md\">README.md</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controllo versioni update.py e <a href=\"https://github.com/opencitations/index/blob/master/index/python/src/oci/update.py\">upload in index</a>. Non sono sicura che la posizione vada bene. Dove è opportuno che sia?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- creare repo documents per delle guide che vanno customizzate a seconda del caso in modo che oc abbia una coerenza interna\n",
    "- deve esserci anche poetry, i test, la coverage, struttura in classi etc\n",
    "- modifica exist mettendo come default True anziché False anche nell'esecuzione. e aggiungi la spiegazione in documentazione. \n",
    "- mettere check digit come metodo privato o comunque toglierlo dalla classe generale\n",
    "- fare un parsing datacite per vedere empiricamente cosa mettono dentro a a type (non general)\n",
    "- mappiamo i quattro vocabolari \n",
    "- resource type ultima risorsa ma bisogna vedere empiricamente \n",
    "- estendi index datacite\n",
    "- sposta update in scripts\n",
    "- iniziare a guardare dati OpenAire e cominciare a guardare i dati giappone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 28/09 - 06/10 (OC_Meta Tables Update) <a class=\"anchor\" id=\"entry_24\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ho processato tutti i dati di Datacite per estrarre i data types utilizzati e ho salvato i risultati in un [file json](report_file.json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dati rilevanti:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"ris\": [\"JOUR\", \"CHAP\", \"BOOK\", \"DATA\", \"GEN\", \"RPRT\", \"COMP\", \"MPCT\", \"THES\", \"RRPT\", \"FIGURE\", \"SOUND\", \"CPAPER\", \"CONF\", \"STAND\", \"\", \"Systematic review\", \"Briefing paper\", \"Report\", \"Conference paper\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"bibtex\": [\"article\", \"inbook\", \"book\", \"misc\", \"techreport\", \"phdthesis\", \"proceedings\", \"error\", \"\", \"inproceedings\", \"TechReport\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"citeproc\": [\"article-journal\", \"chapter\", \"book\", \"dataset\", \"article\", \"report\", \"thesis\", \"graphic\", \"song\", \"\", \"misc\", \"post-weblog\", \"paper-conference\", \"Dataset\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"schemaOrg\": [\"ScholarlyArticle\", \"Chapter\", \"Book\", \"PublicationIssue\", \"Dataset\", \"CreativeWork\", \"Report\", \"Service\", \"Collection\", \"SoftwareSourceCode\", \"MediaObject\", \"Thesis\", \"ImageObject\", \"AudioObject\", \"Article\", \"Review\", \"https://health-lifesci.schema.org/study\", \"Periodical\", \"\", \"Event\", \"PublicationVolume\", \"BlogPosting\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"resourceType\" contiene invece stringhe di ogni genere, descrizioni molto lunghe e dettagliate della risorsa, codici o - in pochissimi casi - termini di vocabolari controllati. In ogni caso, la lista è lunghissima e purtroppo questo campo non potrà essere utilizzato (peccato, perché era uno dei due obbligatori)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"resourceTypeGeneral\": [\"Text\", \"Dataset\", \"InteractiveResource\", \"Other\", \"Service\", \"Collection\", \"Software\", \"Audiovisual\", \"Dissertation\", \"Preprint\", \"Report\", \"Image\", \"DataPaper\", \"PhysicalObject\", \"Film\" <b>(X)</b>, \"Sound\", \"Model\", \"JournalArticle\", \"ConferencePaper\", \"Workflow\", \"Journal\", \"Book\", \"Event\", \"BookChapter\", \"ConferenceProceeding\", \"PeerReview\", \"ComputationalNotebook\", \"Standard\", \"OutputManagementPlan\", \"List of nomenclatural and taxonomic changes for the New Zealand flora.\" <b>(X)</b>]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>Tutti i datatypes specificati in documentazione sono stati utilizzati almeno una volta (Audiovisual √\n",
    "Book √\n",
    "BookChapter √\n",
    "Collection √\n",
    "ComputationalNotebook √\n",
    "ConferencePaper √\n",
    "ConferenceProceeding √\n",
    "DataPaper √\n",
    "Dataset √\n",
    "Dissertation √\n",
    "Event √\n",
    "Image √\n",
    "InteractiveResource √\n",
    "Journal √\n",
    "JournalArticle √\n",
    "Model √\n",
    "OutputManagementPlan √\n",
    "PeerReview √\n",
    "PhysicalObject √\n",
    "Preprint √\n",
    "Report √\n",
    "Service √\n",
    "Software √\n",
    "Sound √\n",
    "Standard √\n",
    "Text √\n",
    "Workflow √\n",
    "Other √). Tuttavia, la presenza di \"Film\" e \"List of nomenclatural and taxonomic changes for the New Zealand flora.\" dimostra che non esiste un controllo sulla conformità al vocabolario controllato. </li>\n",
    "    <li>Anche per quanto riguarda gli altri vocabolari, è evidente che non ci sia un controllo, visto che vengono introdotti elementi estranei a quelli previsti</li>\n",
    "    <li>è possibile specificare campi vuoti e non c'è un controllo sulla case-sensitiveness</li>\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonti (dei tipi di pubblicazione che stiamo introducendo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li><a href=\"https://pubmed.ncbi.nlm.nih.gov/help/#publication-types\">PubMed publication types</a>: sono un sottoset controllato dei <a href=\"https://www.nlm.nih.gov/mesh/pubtypes.html\">MeSH</a>, contenente i seguenti termini: Adaptive Clinical Trial / Address / Autobiography / Bibliography / Biography / Case Reports / Classical Article / Clinical Conference / Clinical Study / Clinical Trial / Clinical Trial, Phase I / Clinical Trial, Phase II / Clinical Trial, Phase III / Clinical Trial, Phase IV / Clinical Trial Protocol / Clinical Trial, Veterinary / Collected Work / Comment / Comparative Study / Congress / Consensus Development Conference / Consensus Development Conference, NIH / Controlled Clinical Trial / Corrected and Republished Article / Dataset / Dictionary / Directory / Duplicate Publication / Editorial / Electronic Supplementary Materials / English Abstract / Equivalence Trial / Evaluation Study / Expression of Concern / Festschrift / Government Publication / Guideline / Historical Article / Interactive Tutorial/ Interview / Introductory Journal Article / Journal Article (Default value when no more descriptive PT is provided or assigned) / Lecture / Legal Case / Legislation / Letter / Meta-Analysis / Multicenter Study / News / Newspaper Article / Observational Study / Observational Study, Veterinary / Overall / Patient Education Handout / Periodical Index / Personal Narrative / Portrait / Practice Guideline / Preprint / Pragmatic Clinical Trial / Published Erratum / Randomized Controlled Trial / Randomized Controlled Trial, Veterinary / Research Support, American Recovery and Reinvestment Act / Research Support, N.I.H., Extramural / Research Support, N.I.H., Intramural / Research Support, Non-U.S. Gov't / Research Support, U.S. Gov't, Non-P.H.S. / Research Support, U.S. Gov't, P.H.S. / Retracted Publication / Retraction of Publication / Review / Scientific Integrity Review / Systematic Review / Technical Report / Twin Study / Validation Study / Video-Audio Media / Webcast</li>\n",
    "    <li><a href=\"https://refdb.sourceforge.net/manual-0.9.6/sect1-ris-format.html\">RefDB RIS Tags</a>:      \n",
    "<b>\"RRPT\", \"FIGURE\",  \"CPAPER\", \"STAND\", \"\", \"Systematic review\", \"Briefing paper\", \"Report\", \"Conference paper\"</b> sono presenti in DataCite ma non fanno parte del vocabolario (versione di riferimento: 2007(ultima revisione)). <b>Lista dei termini (segnalati con \"√\" se compaiono in DataCite):</b>\n",
    "ABST (abstract reference)\n",
    "ADVS (audiovisual material)\n",
    "ART (art work)\n",
    "BILL (bill/resolution)\n",
    "BOOK √ (whole book reference)\n",
    "CASE (case)\n",
    "CHAP √ (book chapter reference)\n",
    "COMP √ (computer program)\n",
    "CONF √ (conference proceeding)\n",
    "CTLG (catalog)\n",
    "DATA √ (data file)\n",
    "ELEC (electronic citation)\n",
    "GEN √ (generic)\n",
    "HEAR (hearing)\n",
    "ICOMM (internet communication)\n",
    "INPR (in press reference)\n",
    "JFULL (journal/periodical - full)\n",
    "JOUR √ (journal/periodical reference)\n",
    "MAP (map)\n",
    "MGZN (magazine article)\n",
    "MPCT √ (motion picture)\n",
    "MUSIC (music score)\n",
    "NEWS (newspaper)\n",
    "PAMP (pamphlet)\n",
    "PAT (patent)\n",
    "PCOMM (personal communication)\n",
    "RPRT √ (report)\n",
    "SER (serial - book, monograph)\n",
    "SLIDE (slide)\n",
    "SOUND √ (sound recording)\n",
    "STAT (statute)\n",
    "THES √ (thesis/dissertation)\n",
    "UNBILL (unenacted bill/resolution)\n",
    "UNPB (unpublished work reference)\n",
    "VIDEO (video recording)</li>\n",
    "    <li><a href=\"https://bib-it.sourceforge.net/help/fieldsAndEntryTypes.php\">BibTex entry types</a>: I seguenti elementi sono presenti in DataCite ma non fanno parte delle entità riconosciute bibtex: <b>\"error\", \"\", \"TechReport</b>. I seguenti termini fanno parte del <b>vocabolario BibTex (segnalato con √ se compaiono in DataCite)</b>:article √\n",
    "book √\n",
    "booklet\n",
    "inbook √\n",
    "incollection\n",
    "inproceedings √\n",
    "manual\n",
    "mastersthesis\n",
    "misc √\n",
    "phdthesis √\n",
    "proceedings √\n",
    "techreport √\n",
    "unpublished</li>\n",
    "    <li><a href=\"\">Schema.Org Resource Types</a> con posizionamento gerarchico in Types di Schema.Org<a href=\"https://health-lifesci.schema.org/ScholarlyArticle\">\"ScholarlyArticle\"</a> (Thing > CreativeWork > Article > ScholarlyArticle), <a href=\"https://health-lifesci.schema.org/Chapter\">\"Chapter\"</a> (Thing > CreativeWork > Chapter), <a href=\"https://health-lifesci.schema.org/Book\">\"Book\"</a> (Thing > CreativeWork > Book), <a href=\"https://health-lifesci.schema.org/PublicationIssue\">\"PublicationIssue\"</a> (Thing > CreativeWork > PublicationIssue), <a href=\"https://health-lifesci.schema.org/Dataset\">\"Dataset\"</a> (Thing > CreativeWork > Dataset), <a href=\"https://health-lifesci.schema.org/CreativeWork\">\"CreativeWork\"</a> (Thing > CreativeWork), <a href=\"https://health-lifesci.schema.org/Report\">\"Report\"</a> (Thing > CreativeWork > Article > Report), <a href=\"https://health-lifesci.schema.org/Service\">\"Service\"</a>, <a href=\"https://health-lifesci.schema.org/Collection\">\"Collection\"</a> (Thing > CreativeWork > Collection), <a href=\"https://health-lifesci.schema.org/SoftwareSourceCode\">\"SoftwareSourceCode\"</a> (Thing > CreativeWork > SoftwareSourceCode\n",
    "), <a href=\"https://health-lifesci.schema.org/MediaObject\">\"MediaObject\"</a> (Thing > CreativeWork > MediaObject\n",
    "), <a href=\"https://health-lifesci.schema.org/Thesis\">\"Thesis\"</a> (Thing > CreativeWork > Thesis), <a href=\"https://health-lifesci.schema.org/ImageObject\">\"ImageObject\"</a> (Thing > CreativeWork > MediaObject > ImageObject), <a href=\"https://health-lifesci.schema.org/AudioObject\">\"AudioObject\"</a> (Thing > CreativeWork > MediaObject > AudioObject), <a href=\"https://health-lifesci.schema.org/Article\">\"Article\"</a> (Thing > CreativeWork > Article\n",
    "), <a href=\"https://health-lifesci.schema.org/Review\">\"Review\"</a> (Thing > CreativeWork > Review\n",
    "), <a href=\"\"https://health-lifesci.schema.org/study\"\">study\n",
    "</a> (Thing > Property :: study), <a href=\"https://health-lifesci.schema.org/Periodical\">\"Periodical\"</a> (Thing > CreativeWork > CreativeWorkSeries > Periodical //\n",
    "Thing > Intangible > Series > CreativeWorkSeries > Periodical), \"\", <a href=\"https://health-lifesci.schema.org/Event\">\"Event\"</a> (Thing > Event), <a href=\"https://health-lifesci.schema.org/PublicationVolume\">\"PublicationVolume\"</a> (Thing > CreativeWork > PublicationVolume), <a href=\"https://health-lifesci.schema.org/BlogPosting\">\"BlogPosting\"</a> (Thing > CreativeWork > Article > SocialMediaPosting > BlogPosting)</li>\n",
    "    <li><a href=\"https://docs.citationstyles.org/en/stable/specification.html#appendix-iii-types\">CLS citeproc</a>: \"article-journal\", \"chapter\", \"book\", \"dataset\", \"article\", \"report\", \"thesis\", \"graphic\", \"song\",<b> \"\", \"misc\", \"Dataset\"</b>, \"post-weblog\", \"paper-conference\" </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[tabella mapping](mapping_vocabolari.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[pdf tabella vocabolari](mapping_vocabolari.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
